{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depreciated, use source/utils/save_split_model.py instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natet\\anaconda3\\envs\\cap_nb\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from source.core.engine import MoP\n",
    "import source.core.run_partition as run_p\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "from source.utils import testers\n",
    "from source.core import engine\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100-resnet101-kernel-np4-pr0.5-lcm0.0001.pt\n",
      "cifar100-resnet101-kernel-np4-pr0.75-lcm0.0001.pt\n",
      "cifar100-resnet101-kernel-np4-pr0.85-lcm0.0001.pt\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('.','assets', 'models')\n",
    "model_names = os.listdir(model_path)\n",
    "\n",
    "for model_name in model_names:\n",
    "    if 'resnet101' in model_name and '0001' in model_name:\n",
    "        print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  \n",
      "model :  resnet18\n",
      "data_code :  cifar10\n",
      "num_classes :  10\n",
      "model_file :  test.pt\n",
      "epochs :  0\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  1\n",
      "admm :  True\n",
      "admm_epochs :  300\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.005\n",
      "retrain_ep :  50\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.001\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  1\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  False\n",
      "comm_outsize :  False\n",
      "lambda_comm :  0\n",
      "lambda_comp :  0\n",
      "distill_model :  \n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "not found:  out.weight\n",
      "not found:  out.bias\n",
      "Inference time per data is 30.026197ms.\n",
      "conv1.weight 1024\n",
      "layer1.0.conv1.weight 1024\n",
      "layer1.0.conv2.weight 1024\n",
      "layer1.1.conv1.weight 1024\n",
      "layer1.1.conv2.weight 1024\n",
      "layer2.0.conv1.weight 256\n",
      "layer2.0.conv2.weight 256\n",
      "layer2.0.shortcut.0.weight 256\n",
      "layer2.1.conv1.weight 256\n",
      "layer2.1.conv2.weight 256\n",
      "layer3.0.conv1.weight 64\n",
      "layer3.0.conv2.weight 64\n",
      "layer3.0.shortcut.0.weight 64\n",
      "layer3.1.conv1.weight 64\n",
      "layer3.1.conv2.weight 64\n",
      "layer4.0.conv1.weight 16\n",
      "layer4.0.conv2.weight 16\n",
      "layer4.0.shortcut.0.weight 16\n",
      "layer4.1.conv1.weight 16\n",
      "layer4.1.conv2.weight 16\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Grab saved model and partition information\n",
    "'''\n",
    "\n",
    "# setup config\n",
    "dataset='cifar10'\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "\n",
    "configs = run_p.main()\n",
    "\n",
    "configs[\"device\"] = \"cpu\"\n",
    "configs['load_model'] = \"cifar10-resnet18-kernel-np4-pr0.85-lcm1e-05.pt\"\n",
    "configs[\"num_partition\"] = '4' #'resnet18-v2.yaml'\n",
    "\n",
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)\n",
    "\n",
    "# load model params into dictionary\n",
    "state_dict = torch.load(io.get_model_path(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "\n",
    "# load weights into full model\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n",
    "\n",
    "# gets random test input (with correct size)\n",
    "input_var = engine.get_input_from_code(configs)\n",
    "#print(input_var)\n",
    "\n",
    "# Config partitions and prune_ratio\n",
    "configs['num_partition'] = '4'#'./config/resnet18-v2.yaml'\n",
    "configs = engine.partition_generator(configs, model)\n",
    "            \n",
    "# Compute output size of each layer\n",
    "configs['partition'] = engine.featuremap_summary(model, configs['partition'], input_var)\n",
    "        \n",
    "# Setup communication costs\n",
    "configs['comm_costs'] = engine.set_communication_cost(model, configs['partition'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of machines = 4\n",
      "save path = c:\\Users\\natet\\Desktop\\graduate school\\thesis\\CaP\\assets\\models\\vsplit-cifar10-resnet18-kernel-np4-pr0.85-lcm1e-05-20240930-235425\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Setup saving for split model \n",
    "'''\n",
    "\n",
    "num_machines = int(configs[\"num_partition\"])\n",
    "\n",
    "print(f'Number of machines = {num_machines}')\n",
    "\n",
    "# make dir name \n",
    "time_stamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "if len(configs['load_model']) == 0:\n",
    "    folder_name='vsplit-{}-{}-{}-np{}-pr{}-lcm{}-{}'.format( \n",
    "                configs['data-code'], \n",
    "                configs['model'], \n",
    "                configs['sparsity-type'], \n",
    "                configs['num_partition'], \n",
    "                configs['prune-ratio'], \n",
    "                configs['lambda-comm'],\n",
    "                time_stamp)\n",
    "else:\n",
    "    folder_name = 'vsplit-{}-{}'.format(configs['load_model'][:-3],time_stamp)\n",
    "\n",
    "# make folder \n",
    "folder_path = os.path.join(os.getcwd(), 'assets', 'models',folder_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "for i in range(num_machines):\n",
    "    machine_path = os.path.join(folder_path,f'machine-{i}')\n",
    "    if not os.path.exists(machine_path):\n",
    "        os.makedirs(machine_path)\n",
    "\n",
    "print(f'save path = {folder_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total modules 62\n",
      "0 - \n",
      "1 - conv1\n",
      "2 - bn1\n",
      "3 - layer1\n",
      "4 - layer1.0\n",
      "5 - layer1.0.conv1\n",
      "6 - layer1.0.conv2\n",
      "7 - layer1.0.bn1\n",
      "8 - layer1.0.bn2\n",
      "9 - layer1.0.shortcut\n",
      "10 - layer1.1\n",
      "11 - layer1.1.conv1\n",
      "12 - layer1.1.conv2\n",
      "13 - layer1.1.bn1\n",
      "14 - layer1.1.bn2\n",
      "15 - layer1.1.shortcut\n",
      "16 - layer2\n",
      "17 - layer2.0\n",
      "18 - layer2.0.conv1\n",
      "19 - layer2.0.conv2\n",
      "20 - layer2.0.bn1\n",
      "21 - layer2.0.bn2\n",
      "22 - layer2.0.shortcut\n",
      "23 - layer2.0.shortcut.0\n",
      "24 - layer2.0.shortcut.1\n",
      "25 - layer2.1\n",
      "26 - layer2.1.conv1\n",
      "27 - layer2.1.conv2\n",
      "28 - layer2.1.bn1\n",
      "29 - layer2.1.bn2\n",
      "30 - layer2.1.shortcut\n",
      "31 - layer3\n",
      "32 - layer3.0\n",
      "33 - layer3.0.conv1\n",
      "34 - layer3.0.conv2\n",
      "35 - layer3.0.bn1\n",
      "36 - layer3.0.bn2\n",
      "37 - layer3.0.shortcut\n",
      "38 - layer3.0.shortcut.0\n",
      "39 - layer3.0.shortcut.1\n",
      "40 - layer3.1\n",
      "41 - layer3.1.conv1\n",
      "42 - layer3.1.conv2\n",
      "43 - layer3.1.bn1\n",
      "44 - layer3.1.bn2\n",
      "45 - layer3.1.shortcut\n",
      "46 - layer4\n",
      "47 - layer4.0\n",
      "48 - layer4.0.conv1\n",
      "49 - layer4.0.conv2\n",
      "50 - layer4.0.bn1\n",
      "51 - layer4.0.bn2\n",
      "52 - layer4.0.shortcut\n",
      "53 - layer4.0.shortcut.0\n",
      "54 - layer4.0.shortcut.1\n",
      "55 - layer4.1\n",
      "56 - layer4.1.conv1\n",
      "57 - layer4.1.conv2\n",
      "58 - layer4.1.bn1\n",
      "59 - layer4.1.bn2\n",
      "60 - layer4.1.shortcut\n",
      "61 - linear\n",
      "Number of split modules 21\n",
      "0 - bn_partition\n",
      "1 - conv1.weight\n",
      "2 - layer1.0.conv1.weight\n",
      "3 - layer1.0.conv2.weight\n",
      "4 - layer1.1.conv1.weight\n",
      "5 - layer1.1.conv2.weight\n",
      "6 - layer2.0.conv1.weight\n",
      "7 - layer2.0.conv2.weight\n",
      "8 - layer2.0.shortcut.0.weight\n",
      "9 - layer2.1.conv1.weight\n",
      "10 - layer2.1.conv2.weight\n",
      "11 - layer3.0.conv1.weight\n",
      "12 - layer3.0.conv2.weight\n",
      "13 - layer3.0.shortcut.0.weight\n",
      "14 - layer3.1.conv1.weight\n",
      "15 - layer3.1.conv2.weight\n",
      "16 - layer4.0.conv1.weight\n",
      "17 - layer4.0.conv2.weight\n",
      "18 - layer4.0.shortcut.0.weight\n",
      "19 - layer4.1.conv1.weight\n",
      "20 - layer4.1.conv2.weight\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Look at modules that will be split \n",
    "'''\n",
    "\n",
    "module_names =  [module[0] for i, module in enumerate(model.named_modules())]\n",
    "num_total_modules = len(module_names)\n",
    "\n",
    "print(f'Total modules {num_total_modules}')\n",
    "\n",
    "index = 0\n",
    "for mname in module_names:\n",
    "    print(f'{index} - {mname}')\n",
    "    index += 1\n",
    "\n",
    "split_module_names = list(configs['partition'].keys())\n",
    "print(f'Number of split modules {len(split_module_names)}')\n",
    "\n",
    "index = 0\n",
    "for sname in split_module_names:\n",
    "    print(f'{index} - {sname}')\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving module 0: \n",
      "\tMachine 0\n",
      "\t\t-Skipping module ResNet\n",
      "\tMachine 1\n",
      "\t\t-Skipping module ResNet\n",
      "\tMachine 2\n",
      "\t\t-Skipping module ResNet\n",
      "\tMachine 3\n",
      "\t\t-Skipping module ResNet\n",
      "Finished saving module 0\n",
      "\n",
      "Saving module 1: conv1\n",
      "\tMachine 0\n",
      "\t\t-No input assigned to this machine. Skipping...\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 1\n",
      "\n",
      "Saving module 2: bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 2\n",
      "\n",
      "Saving module 3: layer1\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 3\n",
      "\n",
      "Saving module 4: layer1.0\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 4\n",
      "\n",
      "Saving module 5: layer1.0.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 5\n",
      "\n",
      "Saving module 6: layer1.0.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 6\n",
      "\n",
      "Saving module 7: layer1.0.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 7\n",
      "\n",
      "Saving module 8: layer1.0.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 8\n",
      "\n",
      "Saving module 9: layer1.0.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 9\n",
      "\n",
      "Saving module 10: layer1.1\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 10\n",
      "\n",
      "Saving module 11: layer1.1.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 11\n",
      "\n",
      "Saving module 12: layer1.1.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 12\n",
      "\n",
      "Saving module 13: layer1.1.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 13\n",
      "\n",
      "Saving module 14: layer1.1.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 14\n",
      "\n",
      "Saving module 15: layer1.1.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 15\n",
      "\n",
      "Saving module 16: layer2\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 16\n",
      "\n",
      "Saving module 17: layer2.0\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 17\n",
      "\n",
      "Saving module 18: layer2.0.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 18\n",
      "\n",
      "Saving module 19: layer2.0.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 19\n",
      "\n",
      "Saving module 20: layer2.0.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 20\n",
      "\n",
      "Saving module 21: layer2.0.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 21\n",
      "\n",
      "Saving module 22: layer2.0.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 22\n",
      "\n",
      "Saving module 23: layer2.0.shortcut.0\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 23\n",
      "\n",
      "Saving module 24: layer2.0.shortcut.1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 24\n",
      "\n",
      "Saving module 25: layer2.1\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 25\n",
      "\n",
      "Saving module 26: layer2.1.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 26\n",
      "\n",
      "Saving module 27: layer2.1.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 27\n",
      "\n",
      "Saving module 28: layer2.1.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 28\n",
      "\n",
      "Saving module 29: layer2.1.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 29\n",
      "\n",
      "Saving module 30: layer2.1.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 30\n",
      "\n",
      "Saving module 31: layer3\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 31\n",
      "\n",
      "Saving module 32: layer3.0\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 32\n",
      "\n",
      "Saving module 33: layer3.0.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 33\n",
      "\n",
      "Saving module 34: layer3.0.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 34\n",
      "\n",
      "Saving module 35: layer3.0.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 35\n",
      "\n",
      "Saving module 36: layer3.0.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 36\n",
      "\n",
      "Saving module 37: layer3.0.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 37\n",
      "\n",
      "Saving module 38: layer3.0.shortcut.0\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 38\n",
      "\n",
      "Saving module 39: layer3.0.shortcut.1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 39\n",
      "\n",
      "Saving module 40: layer3.1\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 40\n",
      "\n",
      "Saving module 41: layer3.1.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 41\n",
      "\n",
      "Saving module 42: layer3.1.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 42\n",
      "\n",
      "Saving module 43: layer3.1.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 43\n",
      "\n",
      "Saving module 44: layer3.1.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 44\n",
      "\n",
      "Saving module 45: layer3.1.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 45\n",
      "\n",
      "Saving module 46: layer4\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 46\n",
      "\n",
      "Saving module 47: layer4.0\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 47\n",
      "\n",
      "Saving module 48: layer4.0.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 48\n",
      "\n",
      "Saving module 49: layer4.0.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 49\n",
      "\n",
      "Saving module 50: layer4.0.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 50\n",
      "\n",
      "Saving module 51: layer4.0.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 51\n",
      "\n",
      "Saving module 52: layer4.0.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 52\n",
      "\n",
      "Saving module 53: layer4.0.shortcut.0\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 53\n",
      "\n",
      "Saving module 54: layer4.0.shortcut.1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 54\n",
      "\n",
      "Saving module 55: layer4.1\n",
      "\tMachine 0\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 1\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 2\n",
      "\t\t-Skipping module BasicBlock\n",
      "\tMachine 3\n",
      "\t\t-Skipping module BasicBlock\n",
      "Finished saving module 55\n",
      "\n",
      "Saving module 56: layer4.1.conv1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 56\n",
      "\n",
      "Saving module 57: layer4.1.conv2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 57\n",
      "\n",
      "Saving module 58: layer4.1.bn1\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 58\n",
      "\n",
      "Saving module 59: layer4.1.bn2\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 59\n",
      "\n",
      "Saving module 60: layer4.1.shortcut\n",
      "\tMachine 0\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 1\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 2\n",
      "\t\t-Skipping module Sequential\n",
      "\tMachine 3\n",
      "\t\t-Skipping module Sequential\n",
      "Finished saving module 60\n",
      "\n",
      "Saving module 61: linear\n",
      "\tMachine 0\n",
      "\tMachine 1\n",
      "\tMachine 2\n",
      "\tMachine 3\n",
      "Finished saving module 61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Save split layers to diff machines\n",
    "'''\n",
    "\n",
    "# iterate through layers 1 module at a time \n",
    "for imodule in range(num_total_modules):\n",
    "\n",
    "        print(f'Saving module {imodule}: {module_names[imodule]}')\n",
    "\n",
    "        # iterate through each machine (done in parallel later)\n",
    "        for imach in range(num_machines):\n",
    "                print(f'\\tMachine {imach}')\n",
    "\n",
    "                # get the current module\n",
    "                # TODO: this is very bad for latency. Only load module if you have to \n",
    "                curr_name, curr_module = next((x for i,x in enumerate(model.named_modules()) if i==imodule)) \n",
    "\n",
    "                # update I/O if encounter split layer\n",
    "                # TODO: revist this implementation\n",
    "                split_param_name = curr_name + '.weight'\n",
    "                if split_param_name in split_module_names:\n",
    "\n",
    "                        # skip if machine doesnt expect input\n",
    "                        if len(configs['partition'][split_param_name]['channel_id'][imach]) == 0:\n",
    "                                print(f'\\t\\t-No input assigned to this machine. Skipping...')\n",
    "                                continue\n",
    "                        \n",
    "                        # TODO: reconsider implementation \n",
    "                        # What input channels does this machine compute?\n",
    "                        input_channels = torch.tensor(configs['partition'][split_param_name]['channel_id'][imach],\n",
    "                                device=torch.device(configs['device']))\n",
    "                        N_in = len(input_channels) # TODO: is this used?\n",
    "\n",
    "                        # Where to send output (map of output channels to different machines)\n",
    "                        output_channel_map = configs['partition'][split_param_name]['filter_id']\n",
    "\n",
    "                # reduce computation-- make vertically split layer\n",
    "                # supports Linear, BN, and Conv layers\n",
    "                # TODO: generalize this to more than conv layers \n",
    "                if type(curr_module) == nn.Conv2d:\n",
    "                        split_layer = nn.Conv2d(N_in,\n",
    "                                        curr_module.weight.shape[0], # TODO does this need to be an int? (currently tensor)\n",
    "                                        kernel_size= curr_module.kernel_size,\n",
    "                                        stride=curr_module.stride,\n",
    "                                        padding=curr_module.padding, \n",
    "                                        bias=curr_module.bias)\n",
    "\n",
    "                        # write parameters to split layer \n",
    "                        split_layer.weight = torch.nn.Parameter(curr_module.weight.index_select(1, input_channels))\n",
    "\n",
    "\n",
    "                elif type(curr_module) == nn.BatchNorm2d:\n",
    "                        split_layer = nn.BatchNorm2d(N_in, \n",
    "                                        curr_module.eps,\n",
    "                                        momentum=curr_module.momentum, \n",
    "                                        affine=curr_module.affine, \n",
    "                                        track_running_stats=curr_module.track_running_stats)\n",
    "\n",
    "                        # write parameters to split layer \n",
    "                        split_layer.weight = torch.nn.Parameter(curr_module.weight.index_select(0, input_channels))\n",
    "                        split_layer.running_mean = torch.nn.Parameter(curr_module.running_mean.index_select(0, input_channels))\n",
    "                        split_layer.running_var = torch.nn.Parameter(curr_module.running_var.index_select(0, input_channels))\n",
    "\n",
    "                        if not curr_module.bias == None:\n",
    "                                split_layer.bias = torch.nn.Parameter(curr_module.bias.index_select(0, input_channels))\n",
    "                        \n",
    "\n",
    "                elif type(curr_module) == nn.Linear:\n",
    "                        # TODO: assumes there is a bias \n",
    "                        split_layer = nn.Linear(N_in, \n",
    "                                        curr_module.weight.shape[0])\n",
    "\n",
    "                        # write parameters to split layer \n",
    "                        split_layer.weight = torch.nn.Parameter(curr_module.weight.index_select(1, input_channels))\n",
    "\n",
    "                        # TODO: double check bias is applied correctly\n",
    "                        if not curr_module.bias == None:\n",
    "                                split_layer.bias = curr_module.bias\n",
    "                else:\n",
    "                        print(f'\\t\\t-Skipping module {type(curr_module).__name__}')\n",
    "                        continue\n",
    "\n",
    "                # save split layer\n",
    "                curr_module_name = module_names[imodule].replace('.', '-')\n",
    "                curr_machine_path = os.path.join(folder_path,f'machine-{imach}')\n",
    "                fpath = os.path.join(curr_machine_path, f'{curr_module_name}.pth')\n",
    "                torch.save(split_layer.state_dict(), fpath)\n",
    "\n",
    "\n",
    "        print(f'Finished saving module {imodule}')\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
