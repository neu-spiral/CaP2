{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Load RESNET model and split it\\n        1. layer by layer\\n        2. [TODO] vertically \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Load RESNET model and split it\n",
    "        1. layer by layer\n",
    "        2. [TODO] vertically \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.core.engine import MoP\n",
    "import source.core.run_partition as run_p\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "from split_network import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "from source.core.split_manager import SplitManager\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "from source.utils import testers\n",
    "from source.core import engine\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from torchsummary import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  \n",
      "model :  resnet18\n",
      "data_code :  cifar10\n",
      "num_classes :  10\n",
      "model_file :  test.pt\n",
      "epochs :  0\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  1\n",
      "admm :  True\n",
      "admm_epochs :  300\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.005\n",
      "retrain_ep :  50\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.001\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  1\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  False\n",
      "comm_outsize :  False\n",
      "lambda_comm :  0\n",
      "lambda_comp :  0\n",
      "distill_model :  \n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n"
     ]
    }
   ],
   "source": [
    "# setup config\n",
    "dataset='cifar10'\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "\n",
    "configs = run_p.main()\n",
    "\n",
    "configs[\"device\"] = \"cpu\"\n",
    "configs['load_model'] = \"cifar10-resnet18-kernel-npv0-pr0.75-lcm0.001.pt\"\n",
    "#configs['load_model'] = \"cifar10-resnet18-kernel-npv2-pr0.75-lcm0.001.pt\"\n",
    "configs[\"num_partition\"] = '4' #'resnet18-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into full model\n",
    "state_dict = torch.load(io.get_model_path(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time per data is 18.342257ms.\n",
      "conv1.weight 1024\n",
      "layer1.0.conv1.weight 1024\n",
      "layer1.0.conv2.weight 1024\n",
      "layer1.1.conv1.weight 1024\n",
      "layer1.1.conv2.weight 1024\n",
      "layer2.0.conv1.weight 256\n",
      "layer2.0.conv2.weight 256\n",
      "layer2.0.shortcut.0.weight 256\n",
      "layer2.1.conv1.weight 256\n",
      "layer2.1.conv2.weight 256\n",
      "layer3.0.conv1.weight 64\n",
      "layer3.0.conv2.weight 64\n",
      "layer3.0.shortcut.0.weight 64\n",
      "layer3.1.conv1.weight 64\n",
      "layer3.1.conv2.weight 64\n",
      "layer4.0.conv1.weight 16\n",
      "layer4.0.conv2.weight 16\n",
      "layer4.0.shortcut.0.weight 16\n",
      "layer4.1.conv1.weight 16\n",
      "layer4.1.conv2.weight 16\n",
      "['x', 'conv1', 'bn1', 'relu', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avg_pool2d', 'size', 'view', 'linear']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    add partitions and communications to configs\n",
    "'''\n",
    "\n",
    "# gets random test input (with correct size)\n",
    "input_var = engine.get_input_from_code(configs)\n",
    "#print(input_var)\n",
    "\n",
    "# Config partitions and prune_ratio\n",
    "configs['num_partition'] = '4'#'./config/resnet18-v2.yaml'\n",
    "configs = engine.partition_generator(configs, model)\n",
    "            \n",
    "# Compute output size of each layer\n",
    "configs['partition'] = engine.featuremap_summary(model, configs['partition'], input_var)\n",
    "        \n",
    "# Setup communication costs\n",
    "configs['comm_costs'] = engine.set_communication_cost(model, configs['partition'],)\n",
    "\n",
    "\n",
    "# split model general parameters\n",
    "\n",
    "# make copies of model per machine\n",
    "num_machines = max(configs['partition']['bn_partition']) # TODO: double check this makes sense\n",
    "model_machines = [model]*num_machines\n",
    "\n",
    "layer_names_fx =  get_graph_node_names(model)[1]\n",
    "total_layers_fx = len(layer_names_fx)\n",
    "\n",
    "split_module_names = list(configs['partition'].keys())\n",
    "\n",
    "print(layer_names_fx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing module 0: x\n",
      "\tExecuting on machine 0\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 1\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 2\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 3\n",
      "\t\t-model input layer.. skipping\n",
      "Finished execution of layer 0\n",
      "Input layer. Skipping comparison\n",
      "\n",
      "Executing module 1: conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-WARNING: No input assigned to this machine (but it was sent input?). Skipping...\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 1\n",
      "Max diff:\n",
      "tensor([0.], dtype=torch.float64)\n",
      "\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor([], dtype=torch.int64)\n",
      "\n",
      "failing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 48)\n",
      "\n",
      "Executing module 2: bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-No input received but bn still needs to produce output.\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 2\n",
      "Max diff:\n",
      "tensor([0.], dtype=torch.float64)\n",
      "\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor([], dtype=torch.int64)\n",
      "\n",
      "failing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "passing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "\n",
      "Executing module 3: relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 3\n",
      "Max diff:\n",
      "tensor([0.], dtype=torch.float64)\n",
      "\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor([], dtype=torch.int64)\n",
      "\n",
      "failing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "passing Cout = tensor([15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 35, 36,\n",
      "        37, 38, 39, 42, 43, 44, 46, 47, 48, 49, 50, 51, 55, 56, 57, 59, 60, 61,\n",
      "        62, 63])  (len = 38)\n",
      "\n",
      "Executing module 4: layer1.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 15]) to machine 0\n",
      "\t\t sending C_out tensor([40]) to machine 2\n",
      "\t\t sending C_out tensor([63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 1,  3, 10, 12]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([40]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([0, 3, 6]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([53]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 3,  4, 15]) to machine 0\n",
      "\t\t sending C_out tensor([32, 34, 45, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 4\n",
      "Max diff:\n",
      "tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.4409e-16, 2.2204e-16, 0.0000e+00, 6.9389e-18, 1.0842e-18, 0.0000e+00,\n",
      "         4.1633e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.1633e-17, 0.0000e+00, 0.0000e+00, 1.9516e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  3,  4,  6, 12, 15, 32, 34, 40, 45, 47, 53, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  3,  4,  6, 12, 15, 32, 34, 40, 45, 47, 53, 63])  (len = 14)\n",
      "passing Cout = tensor([ 2,  5,  7,  8,  9, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
      "        26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 48,\n",
      "        49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62])  (len = 49)\n",
      "\n",
      "Executing module 5: layer1.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 5\n",
      "Max diff:\n",
      "tensor([1.3323e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.2204e-16, 1.1102e-16, 0.0000e+00, 3.4694e-18, 3.4694e-18, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2736e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  3,  4,  6, 12, 15, 32, 34, 40, 45, 47, 53, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  3,  4,  6, 12, 15, 32, 34, 40, 45, 47, 53, 63])  (len = 14)\n",
      "passing Cout = tensor([ 2,  5,  7,  8,  9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
      "        25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46,\n",
      "        48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62])  (len = 50)\n",
      "\n",
      "Executing module 6: layer1.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 6\n",
      "Max diff:\n",
      "tensor([1.3323e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.2204e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1919e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([ 0,  1, 32, 40, 45, 53])\n",
      "\n",
      "failing Cout = tensor([ 0,  1, 32, 40, 45, 53])  (len = 6)\n",
      "passing Cout = tensor([16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 48, 51, 52,\n",
      "        54, 55, 59, 61, 63])  (len = 23)\n",
      "\n",
      "Executing module 7: layer1.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([27]) to machine 1\n",
      "\t\t sending C_out tensor([57, 59]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([6]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([42, 45]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([4, 9]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([54, 56]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([4, 5]) to machine 0\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 7\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.6021e-18, 1.3878e-17, 1.2143e-17, 2.7756e-17, 1.4211e-14, 4.1633e-17,\n",
      "         3.9031e-18, 2.7756e-17, 1.3878e-17, 1.1102e-16, 1.1102e-16, 1.3878e-17,\n",
      "         5.2042e-18, 2.7756e-17, 2.0817e-17, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.2768e-15, 8.8818e-16, 6.6613e-16, 1.7764e-15,\n",
      "         1.3323e-15, 1.7764e-15, 2.6645e-15, 1.2490e-16, 4.4409e-16, 8.8818e-16,\n",
      "         1.3323e-15, 1.1657e-15, 6.6613e-16, 1.3323e-15, 1.7764e-15, 1.3323e-15,\n",
      "         2.2204e-16, 1.1102e-16, 1.6653e-16, 1.1102e-16, 5.5511e-17, 9.7145e-17,\n",
      "         2.6645e-15, 1.3878e-16, 1.7764e-15, 8.8818e-16, 0.0000e+00, 1.3878e-16,\n",
      "         1.1102e-16, 1.1102e-16, 8.3267e-17, 5.5511e-17]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 27, 32,\n",
      "        33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "        51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 27, 32,\n",
      "        33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "        51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63])  (len = 48)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 58])  (len = 16)\n",
      "\n",
      "Executing module 8: layer1.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 8\n",
      "Max diff:\n",
      "tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.7756e-17, 6.9389e-18, 1.3878e-17, 1.3878e-17, 1.2434e-14, 1.3878e-17,\n",
      "         3.4694e-18, 8.6736e-18, 1.3878e-17, 5.5511e-17, 2.7756e-17, 6.9389e-18,\n",
      "         1.3878e-17, 1.3878e-17, 1.3878e-17, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7756e-16, 3.3307e-16, 6.9389e-17, 4.4409e-16,\n",
      "         3.3307e-16, 4.4409e-16, 8.8818e-16, 0.0000e+00, 5.5511e-17, 1.1102e-16,\n",
      "         3.3307e-16, 2.7756e-16, 5.5511e-17, 4.4409e-16, 3.3307e-16, 4.4409e-16,\n",
      "         1.1102e-16, 1.1102e-16, 1.1102e-16, 5.5511e-17, 4.1633e-17, 5.5511e-17,\n",
      "         5.5511e-16, 6.9389e-17, 5.5511e-16, 3.3307e-16, 0.0000e+00, 4.1633e-17,\n",
      "         5.5511e-17, 5.5511e-17, 2.7756e-17, 2.7756e-17]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 27, 32,\n",
      "        33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 27, 32,\n",
      "        33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63])  (len = 47)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 39, 58])  (len = 17)\n",
      "\n",
      "Executing module 9: layer1.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 9\n",
      "Max diff:\n",
      "tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.7756e-17, 6.9389e-18, 1.3878e-17, 1.3878e-17, 1.2434e-14, 1.3878e-17,\n",
      "         3.4694e-18, 8.6736e-18, 1.3878e-17, 5.5511e-17, 2.7756e-17, 6.9389e-18,\n",
      "         1.3878e-17, 1.3878e-17, 1.3878e-17, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7756e-16, 3.3307e-16, 6.9389e-17, 4.4409e-16,\n",
      "         3.3307e-16, 4.4409e-16, 8.8818e-16, 0.0000e+00, 5.5511e-17, 1.1102e-16,\n",
      "         3.3307e-16, 2.7756e-16, 2.2204e-16, 4.4409e-16, 3.3307e-16, 4.4409e-16,\n",
      "         1.1102e-16, 1.1102e-16, 1.1102e-16, 5.5511e-17, 4.1633e-17, 5.5511e-17,\n",
      "         5.5511e-16, 5.5511e-17, 5.5511e-16, 4.4409e-16, 0.0000e+00, 1.1102e-16,\n",
      "         1.1102e-16, 5.5511e-17, 5.5511e-17, 2.7756e-17]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 27, 32,\n",
      "        33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 27, 32,\n",
      "        33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63])  (len = 47)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 39, 58])  (len = 17)\n",
      "\n",
      "Executing module 10: layer1.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 10\n",
      "Max diff:\n",
      "tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2434e-14, 0.0000e+00,\n",
      "         0.0000e+00, 8.6736e-18, 0.0000e+00, 5.5511e-17, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7756e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-16, 2.7756e-16, 2.2204e-16, 2.0817e-17, 3.3307e-16, 3.3307e-16,\n",
      "         1.1102e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00, 2.0817e-17, 0.0000e+00,\n",
      "         5.5511e-16, 5.5511e-17, 5.5511e-16, 4.4409e-16, 0.0000e+00, 1.1102e-16,\n",
      "         1.1102e-16, 0.0000e+00, 5.5511e-17, 2.4286e-17]], dtype=torch.float64)\n",
      "tensor([ 4,  7,  9, 11, 27, 32, 36, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55,\n",
      "        56, 57, 59, 60, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 4,  7,  9, 11, 27, 32, 36, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55,\n",
      "        56, 57, 59, 60, 62, 63])  (len = 24)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 38, 39, 50])  (len = 18)\n",
      "\n",
      "Executing module 11: layer1.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 2,  6,  8, 12, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([38, 47]) to machine 2\n",
      "\t\t sending C_out tensor([49]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 1, 10]) to machine 0\n",
      "\t\t sending C_out tensor([30]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([62]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 1,  5, 12, 13]) to machine 0\n",
      "\t\t sending C_out tensor([36, 44]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 11\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.1102e-16, 3.5527e-15, 1.7764e-15, 5.5511e-16, 2.6645e-15, 1.1102e-15,\n",
      "         1.7764e-15, 1.1102e-15, 1.3323e-15, 1.3323e-15, 6.6613e-16, 1.7764e-15,\n",
      "         4.4409e-15, 1.1102e-15, 1.1102e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15,\n",
      "         1.7764e-15, 1.7764e-15, 1.7764e-15, 8.8818e-16, 3.5527e-15, 1.7764e-15,\n",
      "         1.7764e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15,\n",
      "         1.7764e-15, 3.5527e-15, 4.4409e-16, 2.7756e-16, 1.3323e-15, 1.1102e-16,\n",
      "         1.6653e-16, 1.1102e-16, 1.3323e-15, 4.4409e-16, 8.8818e-16, 6.2450e-17,\n",
      "         3.3307e-16, 8.8818e-16, 1.1102e-16, 3.4868e-16, 1.1102e-16, 5.3291e-15,\n",
      "         5.5511e-17, 1.6653e-16, 6.6613e-16, 6.6613e-16, 8.3267e-17, 5.5511e-16,\n",
      "         2.2204e-16, 1.6653e-16, 8.8818e-16, 3.3307e-16, 5.5511e-17, 6.6613e-16,\n",
      "         2.2204e-16, 6.6613e-16, 4.4409e-16, 1.1102e-16]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 12: layer1.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 12\n",
      "Max diff:\n",
      "tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.7756e-17, 6.6613e-16, 5.5511e-16, 1.1102e-16, 6.6613e-16, 1.6653e-16,\n",
      "         4.4409e-16, 2.2204e-16, 2.7756e-16, 2.2204e-16, 1.6653e-16, 3.3307e-16,\n",
      "         8.8818e-16, 2.2204e-16, 3.3307e-16, 6.6613e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 1.7764e-15, 4.4409e-16,\n",
      "         1.7764e-15, 8.8818e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 3.5527e-15, 1.1102e-16, 5.5511e-17, 4.4409e-16, 1.3878e-17,\n",
      "         3.4694e-17, 2.7756e-17, 3.3307e-16, 1.1102e-16, 4.4409e-16, 1.3878e-17,\n",
      "         5.5511e-17, 3.3307e-16, 4.1633e-17, 8.3267e-17, 2.7756e-17, 2.2204e-15,\n",
      "         1.3878e-17, 3.4694e-17, 2.7756e-16, 1.6653e-16, 1.3878e-17, 1.3878e-16,\n",
      "         4.1633e-17, 2.7756e-17, 4.4409e-16, 8.3267e-17, 1.3878e-17, 2.2204e-16,\n",
      "         5.5511e-17, 2.2204e-16, 2.2204e-16, 2.7756e-17]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 13: layer1.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 13\n",
      "Max diff:\n",
      "tensor([8.8818e-16], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16, 4.4409e-16,\n",
      "         1.1102e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16,\n",
      "         2.2204e-16, 1.6653e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 2.2204e-16,\n",
      "         4.4409e-16, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-17, 0.0000e+00, 8.3267e-17, 0.0000e+00, 1.4919e-16,\n",
      "         0.0000e+00, 0.0000e+00, 1.7521e-16, 2.2551e-17, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 9.0206e-17, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 1.1102e-16, 5.5511e-17, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40,\n",
      "        43, 45, 47, 50, 51, 53, 56, 59, 61, 62])\n",
      "\n",
      "failing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40,\n",
      "        43, 45, 47, 50, 51, 53, 56, 59, 61, 62])  (len = 28)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 14: layer1.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 4,  7,  9, 14]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([45]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([52]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([2]) to machine 0\n",
      "\t\t sending C_out tensor([40, 43, 46]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 14\n",
      "Max diff:\n",
      "tensor([1.7764e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 8.8818e-16, 4.4409e-16,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 1.7764e-15, 4.4409e-16,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 1.7764e-15, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 1.7764e-15, 2.2204e-16, 1.6653e-16, 1.6653e-16, 1.6653e-16,\n",
      "         2.0730e-16, 1.1102e-16, 2.4980e-16, 5.5511e-17, 3.3307e-16, 5.5511e-17,\n",
      "         2.2204e-16, 4.4409e-16, 8.3267e-17, 3.3307e-16, 1.1102e-16, 1.1102e-16,\n",
      "         8.8818e-16, 1.1102e-16, 1.1102e-16, 7.7195e-17, 2.4980e-16, 1.1102e-16,\n",
      "         2.7756e-17, 2.2204e-16, 3.3307e-16, 8.3267e-17, 1.6653e-16, 1.1102e-16,\n",
      "         5.6379e-17, 1.6653e-16, 1.5266e-16, 5.5511e-17]], dtype=torch.float64)\n",
      "tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 53)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 15: layer1.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 15\n",
      "Max diff:\n",
      "tensor([1.7764e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 1.7764e-15, 2.2204e-16,\n",
      "         2.2204e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16, 1.7764e-15, 2.2204e-16,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 1.7764e-15, 4.4409e-16, 8.8818e-16,\n",
      "         6.6613e-16, 1.7764e-15, 1.1102e-16, 8.3267e-17, 2.7756e-17, 4.1633e-17,\n",
      "         8.2833e-17, 2.7756e-17, 9.7145e-17, 1.1102e-16, 2.2204e-16, 6.9389e-18,\n",
      "         1.3878e-16, 2.2204e-16, 2.7756e-17, 2.7756e-17, 2.7756e-17, 2.7756e-17,\n",
      "         5.5511e-16, 5.5511e-17, 5.5511e-17, 5.5511e-17, 1.1102e-16, 2.7756e-17,\n",
      "         0.0000e+00, 1.1102e-16, 5.5511e-17, 1.3878e-17, 5.5511e-17, 6.9389e-18,\n",
      "         1.3878e-17, 5.5511e-17, 2.7756e-17, 1.3878e-17]], dtype=torch.float64)\n",
      "tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 52)\n",
      "passing Cout = tensor([ 0,  1,  3,  5,  6,  8, 10, 11, 12, 13, 15, 54])  (len = 12)\n",
      "\n",
      "Executing module 16: layer1.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 16\n",
      "Max diff:\n",
      "tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 1.2434e-14, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 0.0000e+00, 1.1102e-16, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 1.7764e-15, 4.4409e-16,\n",
      "         4.4409e-16, 1.7764e-15, 8.8818e-16, 8.8818e-16, 1.7764e-15, 2.2204e-16,\n",
      "         8.8818e-16, 8.8818e-16, 1.7764e-15, 1.7764e-15, 4.4409e-16, 8.8818e-16,\n",
      "         6.6613e-16, 1.7764e-15, 2.7756e-16, 8.3267e-17, 2.7756e-17, 4.1633e-17,\n",
      "         8.2833e-17, 2.7756e-17, 9.7145e-17, 2.2204e-16, 2.2204e-16, 6.9389e-18,\n",
      "         2.4980e-16, 4.4409e-16, 2.2204e-16, 2.7756e-17, 3.3307e-16, 3.3307e-16,\n",
      "         5.5511e-16, 1.1102e-16, 5.5511e-17, 5.5511e-17, 2.2204e-16, 2.7756e-17,\n",
      "         6.6613e-16, 1.3878e-16, 4.9960e-16, 4.4409e-16, 5.5511e-17, 1.1102e-16,\n",
      "         1.1102e-16, 5.5511e-17, 1.1102e-16, 2.7756e-17]], dtype=torch.float64)\n",
      "tensor([ 2,  4,  7,  9, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
      "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 2,  4,  7,  9, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
      "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 54)\n",
      "passing Cout = tensor([ 0,  1,  3,  5,  6,  8, 10, 12, 13, 15])  (len = 10)\n",
      "\n",
      "Executing module 17: layer1.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 17\n",
      "Max diff:\n",
      "tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2434e-14, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 0.0000e+00, 1.1102e-16, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 4.4409e-16,\n",
      "         4.4409e-16, 1.7764e-15, 8.8818e-16, 8.8818e-16, 2.2204e-16, 2.2204e-16,\n",
      "         8.8818e-16, 8.8818e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16,\n",
      "         6.6613e-16, 1.6653e-16, 1.6653e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.4980e-16, 4.4409e-16, 2.2204e-16, 0.0000e+00, 1.1102e-16, 2.2204e-16,\n",
      "         1.1102e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         6.6613e-16, 1.1102e-16, 4.9960e-16, 4.4409e-16, 0.0000e+00, 1.1102e-16,\n",
      "         1.1102e-16, 0.0000e+00, 1.1102e-16, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([ 4,  7,  9, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 36, 42, 43, 44, 46, 47, 48, 49, 52, 54, 55, 56, 57, 59, 60,\n",
      "        62])\n",
      "\n",
      "failing Cout = tensor([ 4,  7,  9, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 36, 42, 43, 44, 46, 47, 48, 49, 52, 54, 55, 56, 57, 59, 60,\n",
      "        62])  (len = 37)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 18: layer2.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 18\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.7764e-15, 2.6645e-15, 5.5511e-16, 3.5527e-15, 4.4409e-16, 3.5527e-15,\n",
      "         6.6613e-16, 2.4980e-16, 2.6645e-15, 8.8818e-16, 3.3307e-16, 8.8818e-16,\n",
      "         2.7756e-16, 2.2204e-16, 1.7347e-16, 8.3267e-17, 3.5527e-15, 5.2736e-16,\n",
      "         3.3307e-16, 8.8818e-16, 6.6613e-16, 6.6613e-16, 1.7764e-15, 3.6082e-16,\n",
      "         5.3291e-15, 2.8449e-16, 1.6653e-16, 6.6613e-16, 6.6613e-16, 3.8858e-16,\n",
      "         1.9429e-16, 3.3307e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 3.5527e-15,\n",
      "         1.7764e-15, 1.7764e-15, 8.8818e-16, 3.5527e-15, 8.8818e-16, 2.6645e-15,\n",
      "         1.7764e-15, 1.7764e-15, 3.5527e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15,\n",
      "         2.6645e-15, 3.5527e-15, 1.3323e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15,\n",
      "         1.7764e-15, 1.7764e-15, 1.3323e-15, 3.5527e-15, 1.7764e-15, 8.8818e-16,\n",
      "         1.7764e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15, 5.5511e-17, 1.1102e-16,\n",
      "         5.5511e-17, 8.8818e-16, 2.2204e-16, 1.1102e-16, 5.5511e-17, 5.5511e-17,\n",
      "         1.1102e-16, 1.3878e-17, 8.8818e-16, 1.1102e-16, 1.1102e-16, 2.7756e-17,\n",
      "         2.3592e-16, 2.2204e-16, 4.4409e-16, 5.5511e-17, 4.4409e-16, 2.2204e-16,\n",
      "         3.3307e-16, 4.4409e-16, 4.5103e-17, 1.3878e-17, 2.0817e-17, 8.8818e-16,\n",
      "         1.3878e-17, 3.3307e-16, 1.1102e-16, 1.6653e-16, 1.6653e-16, 8.8818e-16,\n",
      "         5.5511e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.1633e-17, 4.4409e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 6.6613e-16,\n",
      "         5.5511e-16, 8.8818e-16, 5.5511e-16, 8.8818e-16, 2.7756e-17, 8.8818e-16,\n",
      "         2.2204e-16, 1.1102e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 6.6613e-16, 6.6613e-16,\n",
      "         4.4409e-16, 8.8818e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 19: layer2.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 19\n",
      "Max diff:\n",
      "tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.4409e-16, 8.8818e-16, 1.3878e-16, 8.8818e-16, 1.1102e-16, 8.8818e-16,\n",
      "         1.6653e-16, 5.5511e-17, 6.6613e-16, 2.2204e-16, 5.5511e-17, 2.2204e-16,\n",
      "         5.5511e-17, 5.5511e-17, 4.8572e-17, 2.0817e-17, 6.6613e-16, 1.3878e-16,\n",
      "         8.3267e-17, 2.2204e-16, 1.6653e-16, 1.6653e-16, 6.6613e-16, 6.9389e-17,\n",
      "         1.3323e-15, 6.9389e-17, 4.1633e-17, 2.2204e-16, 1.6653e-16, 8.3267e-17,\n",
      "         4.1633e-17, 5.5511e-17, 5.5511e-16, 2.2204e-16, 6.6613e-16, 1.7764e-15,\n",
      "         1.7764e-15, 8.8818e-16, 4.4409e-16, 1.7764e-15, 4.4409e-16, 1.7764e-15,\n",
      "         6.6613e-16, 8.8818e-16, 3.5527e-15, 8.8818e-16, 8.8818e-16, 1.7764e-15,\n",
      "         1.7764e-15, 3.5527e-15, 7.7716e-16, 1.3323e-15, 8.8818e-16, 8.8818e-16,\n",
      "         1.3323e-15, 1.3323e-15, 6.6613e-16, 1.7764e-15, 1.7764e-15, 4.4409e-16,\n",
      "         6.6613e-16, 8.8818e-16, 6.6613e-16, 8.8818e-16, 1.3878e-17, 5.5511e-17,\n",
      "         1.3878e-17, 4.4409e-16, 5.5511e-17, 2.7756e-17, 2.7756e-17, 2.7756e-17,\n",
      "         5.5511e-17, 6.9389e-18, 4.4409e-16, 2.7756e-17, 2.7756e-17, 2.7756e-17,\n",
      "         9.0206e-17, 8.3267e-17, 2.2204e-16, 2.7756e-17, 4.4409e-16, 5.5511e-17,\n",
      "         8.3267e-17, 2.2204e-16, 1.3878e-17, 1.3878e-17, 1.3878e-17, 4.4409e-16,\n",
      "         1.3878e-17, 1.1102e-16, 2.7756e-17, 4.1633e-17, 2.7756e-17, 4.4409e-16,\n",
      "         1.8041e-16, 1.6653e-16, 2.2204e-16, 3.3307e-16, 1.1102e-16, 2.2204e-16,\n",
      "         1.3878e-17, 2.2204e-16, 1.6653e-16, 1.1102e-16, 5.5511e-17, 1.9429e-16,\n",
      "         1.9429e-16, 8.8818e-16, 2.4980e-16, 4.4409e-16, 1.3878e-17, 3.3307e-16,\n",
      "         3.4694e-17, 2.7756e-17, 2.2204e-16, 3.3307e-16, 4.4409e-16, 2.2204e-16,\n",
      "         2.2204e-16, 6.6613e-16, 2.2204e-16, 2.7756e-16, 2.2204e-16, 2.2204e-16,\n",
      "         1.6653e-16, 3.3307e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 20: layer2.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 20\n",
      "Max diff:\n",
      "tensor([1.7764e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.4409e-16, 8.8818e-16, 2.2551e-17, 8.8818e-16, 0.0000e+00, 8.8818e-16,\n",
      "         0.0000e+00, 0.0000e+00, 6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 5.5511e-17,\n",
      "         1.2143e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 0.0000e+00,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6429e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00, 6.6613e-16, 1.7764e-15,\n",
      "         1.7764e-15, 8.8818e-16, 2.2204e-16, 6.6613e-16, 4.4409e-16, 1.2212e-15,\n",
      "         4.4409e-16, 2.7756e-16, 2.8449e-16, 8.8818e-16, 5.5511e-16, 0.0000e+00,\n",
      "         8.8818e-16, 0.0000e+00, 4.9960e-16, 1.3323e-15, 8.8818e-16, 4.4409e-16,\n",
      "         6.6613e-16, 9.9920e-16, 5.5511e-16, 1.7764e-15, 1.7764e-15, 4.4409e-16,\n",
      "         4.4409e-16, 4.1633e-17, 4.4409e-16, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.0206e-17, 8.3267e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 1.1102e-16, 0.0000e+00, 4.1633e-17, 0.0000e+00, 0.0000e+00,\n",
      "         1.8041e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 1.6653e-16, 3.4694e-17, 0.0000e+00, 3.4694e-17,\n",
      "         1.0235e-16, 8.8818e-16, 2.4980e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-17, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1102e-16, 6.6613e-16, 1.1102e-16, 2.2898e-16, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-17, 4.1633e-17]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   5,   8,  16,  17,  18,  22,  24,  28,  32,  34,\n",
      "         35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  48,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  78,\n",
      "         79,  89,  91,  93,  96,  97, 101, 104, 105, 107, 108, 109, 110, 114,\n",
      "        116, 120, 121, 122, 123, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   5,   8,  16,  17,  18,  22,  24,  28,  32,  34,\n",
      "         35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  48,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  78,\n",
      "         79,  89,  91,  93,  96,  97, 101, 104, 105, 107, 108, 109, 110, 114,\n",
      "        116, 120, 121, 122, 123, 126, 127])  (len = 63)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 21: layer2.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([10]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 21\n",
      "Max diff:\n",
      "tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.2204e-16, 1.6653e-16, 3.3307e-16, 6.6613e-16, 8.3267e-17, 8.8818e-16,\n",
      "         9.7145e-17, 1.9429e-16, 1.6653e-16, 2.3592e-16, 3.3307e-16, 4.4409e-16,\n",
      "         1.3878e-16, 1.6653e-16, 2.2204e-16, 1.5266e-16, 3.3307e-16, 2.2204e-16,\n",
      "         3.3307e-16, 1.3878e-16, 1.7764e-15, 8.3267e-17, 4.1633e-17, 8.8818e-16,\n",
      "         2.2204e-16, 1.1102e-16, 4.4409e-16, 2.2204e-16, 1.2490e-16, 3.3307e-16,\n",
      "         3.3307e-16, 8.8818e-16, 1.7764e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 2.3315e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15,\n",
      "         2.3870e-15, 3.1086e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15, 3.5527e-15,\n",
      "         3.5527e-15, 1.8874e-15, 1.7764e-15, 3.5527e-15, 3.5527e-15, 2.8866e-15,\n",
      "         2.6645e-15, 1.7764e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15,\n",
      "         7.1054e-15, 3.5527e-15, 1.7764e-15, 3.5527e-15, 5.5511e-17, 2.0817e-17,\n",
      "         4.4409e-16, 3.3307e-16, 4.1633e-17, 4.4409e-16, 1.1102e-16, 1.6653e-16,\n",
      "         5.5511e-17, 2.7756e-17, 5.5511e-17, 1.1102e-16, 4.1633e-17, 3.3307e-16,\n",
      "         2.7756e-17, 2.2204e-16, 2.7756e-17, 1.1102e-16, 5.5511e-17, 2.2204e-16,\n",
      "         2.2204e-16, 4.4409e-16, 1.1102e-16, 5.5511e-17, 4.4409e-16, 3.3307e-16,\n",
      "         4.4409e-16, 3.3307e-16, 4.1633e-17, 8.6736e-18, 2.2204e-16, 5.5511e-17,\n",
      "         2.2204e-16, 1.7764e-15, 6.6613e-16, 8.8818e-16, 1.7764e-15, 1.1102e-16,\n",
      "         1.1102e-16, 8.8818e-16, 7.7716e-16, 1.1102e-16, 1.1102e-16, 8.8818e-16,\n",
      "         4.4409e-16, 1.3323e-15, 8.8818e-16, 2.2204e-16, 2.2204e-16, 8.8818e-16,\n",
      "         1.7764e-15, 1.3323e-15, 1.7764e-15, 6.6613e-16, 1.1102e-16, 2.6645e-15,\n",
      "         8.8818e-16, 1.1102e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 2.2204e-16,\n",
      "         2.6645e-15, 6.6613e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 22: layer2.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 22\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[8.3267e-17, 5.5511e-17, 1.1102e-16, 2.2204e-16, 2.0817e-17, 3.3307e-16,\n",
      "         2.4286e-17, 6.9389e-17, 5.5511e-17, 8.3267e-17, 1.1102e-16, 1.6653e-16,\n",
      "         4.8572e-17, 5.5511e-17, 8.3267e-17, 5.3776e-17, 1.1102e-16, 5.5511e-17,\n",
      "         9.7145e-17, 4.6838e-17, 8.8818e-16, 2.9490e-17, 1.0408e-17, 3.3307e-16,\n",
      "         8.3267e-17, 4.1633e-17, 1.6653e-16, 8.3267e-17, 4.8572e-17, 1.1102e-16,\n",
      "         1.1102e-16, 3.3307e-16, 1.7764e-15, 3.5527e-15, 2.2204e-15, 1.7764e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.2482e-15, 1.8874e-15, 1.7764e-15, 2.6645e-15,\n",
      "         1.7764e-15, 2.6645e-15, 3.5527e-15, 1.7764e-15, 1.3323e-15, 3.5527e-15,\n",
      "         1.7764e-15, 1.7764e-15, 1.3323e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15,\n",
      "         2.6645e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 1.3878e-17, 1.3878e-17,\n",
      "         1.6653e-16, 1.6653e-16, 1.3878e-17, 4.4409e-16, 5.5511e-17, 5.5511e-17,\n",
      "         2.0817e-17, 1.3878e-17, 2.7756e-17, 2.7756e-17, 1.3878e-17, 1.6653e-16,\n",
      "         1.3878e-17, 5.5511e-17, 1.3878e-17, 5.5511e-17, 2.7756e-17, 5.5511e-17,\n",
      "         1.1102e-16, 4.4409e-16, 5.5511e-17, 1.3878e-17, 4.4409e-16, 3.3307e-16,\n",
      "         2.2204e-16, 1.1102e-16, 1.3878e-17, 3.4694e-18, 1.1102e-16, 1.7347e-17,\n",
      "         1.1102e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.3323e-15, 5.5511e-17,\n",
      "         2.7756e-17, 9.4369e-16, 4.4409e-16, 2.7756e-17, 5.5511e-17, 2.2204e-16,\n",
      "         4.4409e-16, 6.6613e-16, 4.4409e-16, 8.3267e-17, 5.5511e-17, 4.4409e-16,\n",
      "         1.7764e-15, 3.3307e-16, 6.6613e-16, 2.2204e-16, 5.5511e-17, 3.5527e-15,\n",
      "         4.4409e-16, 5.5511e-17, 4.4409e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17,\n",
      "         1.1102e-15, 2.2204e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 23: layer2.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([38]) to machine 1\n",
      "\t\t sending C_out tensor([121]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  2,  3,  5,  7, 10, 19, 24]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([65, 66, 68, 70, 73, 78, 80, 92, 93]) to machine 2\n",
      "\t\t sending C_out tensor([104, 115, 121]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([14, 28]) to machine 0\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([101, 102, 121, 122]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 4,  5, 10, 21, 23, 30]) to machine 0\n",
      "\t\t sending C_out tensor([33, 60]) to machine 1\n",
      "\t\t sending C_out tensor([65, 68, 86]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 23\n",
      "Max diff:\n",
      "tensor([6.2172e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.4409e-16, 3.8858e-16, 4.4409e-16, 3.3307e-16, 5.5511e-17, 2.7756e-16,\n",
      "         1.3010e-18, 4.2501e-17, 8.3267e-17, 4.8572e-17, 3.3307e-16, 1.3878e-16,\n",
      "         6.6613e-16, 2.7756e-16, 3.3307e-16, 5.5511e-16, 3.8858e-16, 3.3307e-16,\n",
      "         4.4409e-16, 1.9429e-16, 1.7764e-15, 1.6653e-16, 4.3368e-18, 3.3307e-16,\n",
      "         5.5511e-17, 3.3307e-16, 2.7756e-16, 3.8858e-16, 1.6653e-16, 3.3307e-16,\n",
      "         5.5511e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 2.2204e-16,\n",
      "         2.2204e-16, 8.8818e-16, 6.2172e-15, 2.2204e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 2.2204e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 3.3307e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.3878e-17, 1.3878e-17,\n",
      "         1.1102e-16, 1.6653e-16, 5.5511e-17, 1.1102e-16, 5.5511e-17, 2.7756e-17,\n",
      "         8.6736e-18, 2.7756e-17, 6.9389e-18, 6.9389e-18, 1.0408e-17, 1.6653e-16,\n",
      "         7.8063e-18, 5.5511e-17, 1.0408e-17, 2.7756e-17, 1.3878e-17, 5.5511e-17,\n",
      "         5.5511e-17, 1.1102e-16, 2.7756e-17, 2.7756e-17, 1.6653e-16, 1.1102e-16,\n",
      "         1.6653e-16, 1.6653e-16, 2.7756e-17, 6.0715e-18, 8.3267e-17, 1.3878e-17,\n",
      "         1.3878e-17, 7.6328e-17, 1.1796e-16, 1.1102e-16, 1.6653e-16, 2.0817e-17,\n",
      "         2.7756e-17, 1.6653e-16, 2.2204e-16, 1.3878e-17, 1.3878e-17, 8.3267e-17,\n",
      "         1.1102e-16, 8.3267e-17, 1.1102e-16, 2.7756e-17, 2.7756e-17, 2.2204e-16,\n",
      "         1.6653e-16, 1.3323e-15, 1.1102e-16, 1.3878e-16, 2.7756e-17, 1.3878e-16,\n",
      "         2.2204e-16, 2.0817e-17, 2.2204e-16, 1.6653e-16, 1.6653e-16, 4.1633e-17,\n",
      "         2.2204e-16, 1.1102e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 24: layer2.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 24\n",
      "Max diff:\n",
      "tensor([4.4409e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.3878e-16, 8.3267e-17, 1.3878e-16, 8.3267e-17, 1.2143e-17, 5.5511e-17,\n",
      "         0.0000e+00, 9.5410e-18, 2.0817e-17, 1.3878e-17, 9.7145e-17, 3.9899e-17,\n",
      "         1.6653e-16, 6.2450e-17, 8.3267e-17, 1.3878e-16, 9.7145e-17, 6.9389e-17,\n",
      "         1.3878e-16, 4.8572e-17, 5.5511e-16, 4.8572e-17, 8.6736e-19, 1.1102e-16,\n",
      "         1.3878e-17, 8.3267e-17, 6.9389e-17, 8.3267e-17, 5.5511e-17, 8.3267e-17,\n",
      "         1.6653e-16, 1.3878e-16, 2.2204e-16, 4.4409e-16, 4.4409e-16, 1.1102e-16,\n",
      "         2.7756e-17, 8.8818e-16, 4.4409e-15, 1.1102e-16, 5.5511e-17, 2.2204e-16,\n",
      "         2.2204e-16, 1.1102e-16, 1.6653e-16, 2.2204e-16, 4.4409e-16, 4.4409e-16,\n",
      "         1.6653e-16, 2.2204e-16, 2.2204e-16, 1.1102e-16, 1.1102e-16, 4.4409e-16,\n",
      "         2.2204e-16, 1.6653e-16, 1.1102e-16, 4.4409e-16, 2.2204e-16, 2.2204e-16,\n",
      "         4.4409e-16, 6.6613e-16, 2.2898e-16, 2.2204e-16, 3.1442e-18, 6.9389e-18,\n",
      "         2.7756e-17, 6.9389e-17, 2.7756e-17, 1.1102e-16, 1.3878e-17, 1.3878e-17,\n",
      "         6.9389e-18, 6.0715e-18, 1.3878e-17, 6.9389e-18, 1.3878e-17, 1.1102e-16,\n",
      "         3.4694e-18, 1.3878e-17, 3.4694e-18, 6.9389e-18, 3.4694e-18, 2.7756e-17,\n",
      "         1.3878e-17, 6.2450e-17, 1.3878e-17, 6.9389e-18, 5.5511e-17, 5.5511e-17,\n",
      "         2.7756e-17, 8.3267e-17, 1.3878e-17, 6.9389e-18, 2.7756e-17, 1.3878e-17,\n",
      "         1.3878e-17, 5.5511e-17, 5.5511e-17, 9.7145e-17, 1.1102e-16, 6.9389e-18,\n",
      "         6.9389e-18, 8.3267e-17, 2.2204e-16, 6.9389e-18, 3.4694e-18, 2.9490e-17,\n",
      "         5.5511e-17, 5.5511e-17, 2.7756e-17, 6.9389e-18, 1.3878e-17, 2.2204e-16,\n",
      "         8.3267e-17, 1.7764e-15, 5.5511e-17, 8.3267e-17, 1.3878e-17, 5.5511e-17,\n",
      "         1.0408e-16, 6.9389e-18, 5.5511e-17, 8.3267e-17, 8.3267e-17, 6.9389e-18,\n",
      "         1.1102e-16, 2.7756e-17]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127])  (len = 127)\n",
      "passing Cout = tensor([6])  (len = 1)\n",
      "\n",
      "Executing module 25: layer2.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 25\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.6653e-16, 8.3267e-17, 1.6653e-16, 3.3307e-16, 2.7756e-17, 3.3307e-16,\n",
      "         2.4286e-17, 6.9389e-17, 8.3267e-17, 8.3267e-17, 1.3878e-16, 1.3878e-16,\n",
      "         1.8041e-16, 9.7145e-17, 1.1102e-16, 1.6653e-16, 1.6653e-16, 1.1102e-16,\n",
      "         1.7347e-16, 5.5511e-17, 8.8818e-16, 6.9389e-17, 1.3878e-17, 3.3307e-16,\n",
      "         8.3267e-17, 8.3267e-17, 2.2204e-16, 1.1102e-16, 8.3267e-17, 1.3878e-16,\n",
      "         1.6653e-16, 4.4409e-16, 1.7764e-15, 3.5527e-15, 2.2204e-15, 1.7764e-15,\n",
      "         1.7764e-15, 3.5527e-15, 5.3291e-15, 1.9984e-15, 1.7764e-15, 3.5527e-15,\n",
      "         1.7764e-15, 2.6645e-15, 3.5527e-15, 1.7764e-15, 1.3323e-15, 3.5527e-15,\n",
      "         1.7764e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15,\n",
      "         2.2204e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 2.7756e-17, 2.7756e-17,\n",
      "         2.2204e-16, 1.9429e-16, 5.5511e-17, 4.4409e-16, 5.5511e-17, 5.5511e-17,\n",
      "         2.7756e-17, 2.7756e-17, 2.7756e-17, 2.7756e-17, 2.7756e-17, 4.4409e-16,\n",
      "         1.3878e-17, 1.1102e-16, 1.3878e-17, 5.5511e-17, 2.7756e-17, 1.1102e-16,\n",
      "         1.1102e-16, 4.4409e-16, 5.5511e-17, 2.7756e-17, 4.4409e-16, 3.3307e-16,\n",
      "         2.2204e-16, 2.2204e-16, 2.7756e-17, 1.3878e-17, 1.1102e-16, 2.7756e-17,\n",
      "         1.1102e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.3323e-15, 5.5511e-17,\n",
      "         5.5511e-17, 9.4369e-16, 4.4409e-16, 5.5511e-17, 8.3267e-17, 2.2204e-16,\n",
      "         4.4409e-16, 6.6613e-16, 2.2204e-16, 8.3267e-17, 1.1102e-16, 4.4409e-16,\n",
      "         1.7764e-15, 1.7764e-15, 6.6613e-16, 2.2204e-16, 5.5511e-17, 3.5527e-15,\n",
      "         4.4409e-16, 5.5511e-17, 4.4409e-16, 8.8818e-16, 6.6613e-16, 5.5511e-17,\n",
      "         8.8818e-16, 2.2204e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 26: layer2.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 26\n",
      "Max diff:\n",
      "tensor([3.9968e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-17, 8.3267e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.8041e-16, 0.0000e+00, 0.0000e+00, 1.6653e-16, 0.0000e+00, 0.0000e+00,\n",
      "         9.0206e-17, 0.0000e+00, 0.0000e+00, 6.9389e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7764e-15, 8.8818e-16, 1.3323e-15, 1.3323e-15,\n",
      "         5.5511e-16, 3.5527e-15, 3.9968e-15, 1.7764e-15, 4.4409e-16, 0.0000e+00,\n",
      "         1.7764e-15, 2.6645e-15, 4.9960e-16, 8.8818e-16, 8.8818e-16, 3.5527e-15,\n",
      "         1.7764e-15, 8.8818e-16, 8.8818e-16, 8.8818e-16, 2.6645e-15, 1.7764e-15,\n",
      "         2.2204e-15, 8.8818e-16, 1.7764e-15, 8.8818e-16, 8.8818e-16, 3.5527e-15,\n",
      "         0.0000e+00, 3.5527e-15, 8.8818e-16, 1.3323e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9429e-16, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16, 8.3267e-17,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.7184e-16, 4.1633e-16, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.4369e-16, 3.3307e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16,\n",
      "         4.4409e-16, 6.6613e-16, 2.2204e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         1.7764e-15, 1.7764e-15, 6.9389e-17, 2.2204e-16, 0.0000e+00, 3.5527e-15,\n",
      "         4.4409e-16, 0.0000e+00, 0.0000e+00, 8.8818e-16, 1.3878e-16, 0.0000e+00,\n",
      "         2.2204e-16, 2.2204e-16]], dtype=torch.float64)\n",
      "tensor([  7,   8,  12,  15,  18,  21,  32,  33,  34,  35,  36,  37,  38,  39,\n",
      "         40,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
      "         55,  56,  57,  58,  59,  61,  62,  63,  67,  69,  85,  88,  89,  91,\n",
      "         97,  98,  99, 103, 104, 107, 108, 109, 110, 113, 114, 115, 116, 117,\n",
      "        119, 120, 123, 124, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  7,   8,  12,  15,  18,  21,  32,  33,  34,  35,  36,  37,  38,  39,\n",
      "         40,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
      "         55,  56,  57,  58,  59,  61,  62,  63,  67,  69,  85,  88,  89,  91,\n",
      "         97,  98,  99, 103, 104, 107, 108, 109, 110, 113, 114, 115, 116, 117,\n",
      "        119, 120, 123, 124, 126, 127])  (len = 62)\n",
      "passing Cout = tensor([6])  (len = 1)\n",
      "\n",
      "Executing module 27: layer2.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([80]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 2, 14]) to machine 0\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 27\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.4286e-17, 8.6736e-18, 2.7756e-17, 1.0408e-17, 7.8063e-18, 1.3010e-17,\n",
      "         2.0817e-17, 1.0408e-17, 5.2042e-18, 4.3368e-18, 1.0408e-17, 1.0408e-17,\n",
      "         1.0408e-17, 6.9389e-18, 2.2204e-16, 1.4637e-17, 1.3878e-17, 6.9389e-18,\n",
      "         2.0817e-17, 1.7347e-17, 3.1225e-17, 1.3878e-17, 1.3878e-17, 2.4286e-17,\n",
      "         8.6736e-18, 1.0408e-17, 1.0408e-17, 9.7036e-18, 1.3878e-17, 2.0817e-17,\n",
      "         9.6494e-18, 1.5613e-17, 7.1054e-15, 7.1054e-15, 8.8818e-15, 1.4211e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.0658e-14, 1.4211e-14, 7.1054e-15, 7.1054e-15,\n",
      "         1.4211e-14, 7.1054e-15, 7.1054e-15, 7.1054e-15, 1.4211e-14, 7.1054e-15,\n",
      "         1.0658e-14, 7.1054e-15, 8.8818e-15, 7.1054e-15, 1.4211e-14, 7.1054e-15,\n",
      "         1.0658e-14, 7.1054e-15, 7.1054e-15, 7.1054e-15, 1.4211e-14, 1.4211e-14,\n",
      "         7.1054e-15, 7.1054e-15, 7.1054e-15, 1.4211e-14, 1.1102e-16, 2.2204e-16,\n",
      "         4.4409e-16, 2.2204e-16, 8.3267e-17, 3.3307e-16, 1.1102e-16, 2.2204e-16,\n",
      "         2.2204e-16, 1.6653e-16, 1.7764e-15, 3.3307e-16, 8.8818e-16, 2.7756e-17,\n",
      "         4.4409e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16,\n",
      "         2.2204e-16, 1.1102e-16, 1.1102e-16, 6.6613e-16, 2.2204e-16, 1.1102e-16,\n",
      "         2.2204e-16, 4.4409e-16, 1.1102e-16, 6.6613e-16, 2.2204e-16, 2.2204e-16,\n",
      "         7.1054e-15, 8.8818e-16, 3.5527e-15, 7.1054e-15, 1.7764e-15, 3.5527e-15,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 2.2204e-15, 2.2204e-16, 1.3323e-15,\n",
      "         1.3323e-15, 8.8818e-16, 1.7764e-15, 5.3291e-15, 2.4425e-15, 3.5527e-15,\n",
      "         4.4409e-16, 8.8818e-16, 5.3291e-15, 7.1054e-15, 3.5527e-15, 2.6645e-15,\n",
      "         8.8818e-16, 5.3291e-15, 3.5527e-15, 5.3291e-15, 2.6645e-15, 5.3291e-15,\n",
      "         3.5527e-15, 4.4409e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 28: layer2.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 28\n",
      "Max diff:\n",
      "tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.3878e-17, 2.6021e-18, 6.9389e-18, 2.6021e-18, 3.4694e-18, 6.9389e-18,\n",
      "         5.2042e-18, 6.9389e-18, 1.1926e-18, 8.6736e-19, 3.4694e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 5.5511e-17, 3.2526e-18, 6.9389e-18, 3.4694e-18,\n",
      "         6.9389e-18, 6.9389e-18, 1.3878e-17, 3.4694e-18, 3.4694e-18, 5.2042e-18,\n",
      "         1.7347e-18, 2.6021e-18, 2.6021e-18, 2.6021e-18, 3.4694e-18, 5.2042e-18,\n",
      "         6.9389e-18, 4.3368e-18, 5.3291e-15, 2.6645e-15, 4.4409e-15, 1.0658e-14,\n",
      "         5.3291e-15, 5.3291e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15,\n",
      "         7.1054e-15, 2.6645e-15, 1.7764e-15, 4.4409e-15, 5.3291e-15, 4.4409e-15,\n",
      "         5.3291e-15, 3.5527e-15, 3.5527e-15, 2.6645e-15, 5.3291e-15, 3.5527e-15,\n",
      "         3.5527e-15, 5.3291e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15, 5.3291e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 7.1054e-15, 2.7756e-17, 5.5511e-17,\n",
      "         1.1102e-16, 5.5511e-17, 2.0817e-17, 8.3267e-17, 2.7756e-17, 5.5511e-17,\n",
      "         5.5511e-17, 2.7756e-17, 4.4409e-16, 8.3267e-17, 1.6653e-16, 6.9389e-18,\n",
      "         1.1102e-16, 2.7756e-17, 5.5511e-17, 5.5511e-17, 2.7756e-17, 2.7756e-17,\n",
      "         4.1633e-17, 2.7756e-17, 2.7756e-17, 1.6653e-16, 5.5511e-17, 2.7756e-17,\n",
      "         2.7756e-17, 1.1102e-16, 2.7756e-17, 1.6653e-16, 5.5511e-17, 5.5511e-17,\n",
      "         2.6645e-15, 2.2204e-16, 6.6613e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16,\n",
      "         2.2204e-16, 2.2204e-16, 8.3267e-17, 6.6613e-16, 5.5511e-17, 2.2204e-16,\n",
      "         3.3307e-16, 2.2204e-16, 3.3307e-16, 1.3323e-15, 2.7756e-16, 6.6613e-16,\n",
      "         8.3267e-17, 2.2204e-16, 8.8818e-16, 1.3323e-15, 6.6613e-16, 6.6613e-16,\n",
      "         2.2204e-16, 4.4409e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 1.7764e-15,\n",
      "         6.6613e-16, 2.2204e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 29: layer2.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 29\n",
      "Max diff:\n",
      "tensor([2.9976e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.3878e-17, 2.6021e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18, 6.9389e-18,\n",
      "         5.2042e-18, 6.9389e-18, 1.1926e-18, 8.6736e-19, 3.4694e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 5.5511e-17, 3.2526e-18, 6.9389e-18, 3.4694e-18,\n",
      "         6.9389e-18, 6.9389e-18, 1.3878e-17, 3.4694e-18, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 2.6021e-18, 0.0000e+00, 2.6021e-18, 3.4694e-18, 0.0000e+00,\n",
      "         6.9389e-18, 4.3368e-18, 1.3323e-15, 8.8818e-16, 2.2204e-15, 1.7764e-15,\n",
      "         1.7764e-15, 2.9976e-15, 1.7764e-15, 3.3654e-16, 1.9984e-15, 1.7764e-15,\n",
      "         8.8818e-16, 6.6613e-16, 1.7764e-15, 1.1102e-15, 0.0000e+00, 1.7764e-15,\n",
      "         0.0000e+00, 0.0000e+00, 8.8818e-16, 1.8319e-15, 1.7764e-15, 0.0000e+00,\n",
      "         1.3323e-15, 2.6645e-15, 1.9984e-15, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.5543e-15, 1.7764e-15, 8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-16, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1062e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6328e-17, 2.7756e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.2212e-15, 0.0000e+00, 1.2837e-16, 5.5511e-16,\n",
      "         0.0000e+00, 7.2164e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  25,  27,  28,  30,  31,  32,  33,\n",
      "         34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  47,  50,\n",
      "         51,  52,  54,  55,  56,  57,  60,  61,  62,  96,  98, 105, 111, 112,\n",
      "        122, 124, 125, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  25,  27,  28,  30,  31,  32,  33,\n",
      "         34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  47,  50,\n",
      "         51,  52,  54,  55,  56,  57,  60,  61,  62,  96,  98, 105, 111, 112,\n",
      "        122, 124, 125, 127])  (len = 60)\n",
      "passing Cout = tensor([26])  (len = 1)\n",
      "\n",
      "Executing module 30: layer2.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([4]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 30\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[3.9031e-18, 3.4694e-18, 1.3878e-17, 1.3878e-17, 2.7756e-17, 6.9389e-18,\n",
      "         1.7347e-18, 5.2042e-18, 1.3878e-17, 1.3878e-17, 4.3368e-18, 1.3878e-17,\n",
      "         1.3878e-17, 1.6128e-18, 1.3878e-17, 1.0408e-17, 6.9389e-18, 2.6021e-18,\n",
      "         6.9389e-18, 2.0817e-17, 1.1102e-16, 1.3878e-17, 3.4694e-18, 1.3878e-17,\n",
      "         1.3878e-17, 1.7347e-18, 6.9389e-18, 3.4694e-18, 5.2042e-18, 2.7756e-17,\n",
      "         1.3878e-17, 2.7756e-17, 1.7764e-15, 2.2204e-15, 1.7764e-15, 2.6645e-15,\n",
      "         2.4425e-15, 2.6645e-15, 1.9984e-15, 3.5527e-15, 2.6645e-15, 1.8319e-15,\n",
      "         3.5527e-15, 2.6645e-15, 1.7764e-15, 1.3323e-15, 1.7764e-15, 3.5527e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15,\n",
      "         1.7764e-15, 1.4433e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15, 1.9984e-15,\n",
      "         2.6645e-15, 5.3291e-15, 3.5527e-15, 2.6645e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16,\n",
      "         4.4409e-16, 6.1062e-16, 4.4409e-16, 4.4409e-16, 5.5511e-17, 8.8818e-16,\n",
      "         3.6082e-16, 3.3307e-16, 5.5511e-16, 1.1102e-16, 8.8818e-16, 8.8818e-16,\n",
      "         4.4409e-16, 4.4409e-16, 2.7756e-16, 4.4409e-16, 2.2204e-16, 6.6613e-16,\n",
      "         4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 5.2736e-16, 4.4409e-16,\n",
      "         4.9960e-16, 8.8818e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])  (len = 96)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 31: layer2.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-No input received but bn still needs to produce output.\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 31\n",
      "Max diff:\n",
      "tensor([2.6645e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[3.4694e-18, 6.9389e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18,\n",
      "         8.6736e-19, 3.4694e-18, 6.9389e-18, 6.9389e-18, 1.7347e-18, 6.9389e-18,\n",
      "         5.2042e-18, 6.9389e-18, 3.4694e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18,\n",
      "         1.3878e-17, 6.9389e-18, 2.7756e-17, 6.9389e-18, 1.7347e-18, 6.9389e-18,\n",
      "         3.4694e-18, 1.7347e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18, 1.0408e-17,\n",
      "         6.9389e-18, 1.3878e-17, 4.4409e-16, 8.8818e-16, 8.8818e-16, 5.5511e-16,\n",
      "         2.5951e-15, 1.7764e-15, 1.7764e-15, 2.6645e-15, 8.8818e-16, 8.8818e-16,\n",
      "         1.3323e-15, 1.3323e-15, 8.8818e-16, 4.4409e-16, 1.3323e-15, 2.2204e-15,\n",
      "         8.8818e-16, 1.7764e-15, 6.6613e-16, 6.6613e-16, 1.3323e-15, 1.7764e-15,\n",
      "         1.3323e-15, 4.4409e-16, 3.3307e-16, 6.6613e-16, 1.7764e-15, 1.3323e-15,\n",
      "         1.3323e-15, 2.6645e-15, 1.7764e-15, 1.1102e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-16, 3.3307e-16, 2.2204e-16, 1.7347e-18, 5.5511e-17, 4.4409e-16,\n",
      "         1.1102e-16, 3.3307e-16, 5.5511e-17, 2.2204e-16, 1.3878e-17, 4.4409e-16,\n",
      "         4.6838e-17, 5.5511e-17, 2.2204e-16, 2.7756e-17, 2.2204e-16, 2.7756e-16,\n",
      "         2.2204e-16, 1.3878e-17, 5.5511e-17, 1.1102e-16, 5.5511e-17, 4.4409e-16,\n",
      "         4.1633e-17, 4.4409e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16, 1.1102e-16,\n",
      "         1.1102e-16, 2.2204e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])  (len = 96)\n",
      "passing Cout = tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])  (len = 32)\n",
      "\n",
      "Executing module 32: layer2.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 32\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[3.4694e-18, 6.9389e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18,\n",
      "         8.6736e-19, 6.9389e-17, 8.3267e-17, 6.9389e-18, 1.7347e-18, 6.9389e-18,\n",
      "         1.8041e-16, 6.9389e-18, 3.4694e-18, 1.6653e-16, 6.9389e-18, 6.9389e-18,\n",
      "         8.3267e-17, 6.9389e-18, 2.7756e-17, 6.9389e-17, 1.7347e-18, 6.9389e-18,\n",
      "         3.4694e-18, 1.7347e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18, 1.0408e-17,\n",
      "         6.9389e-18, 1.3878e-17, 1.7764e-15, 1.3323e-15, 1.3323e-15, 1.3323e-15,\n",
      "         2.5951e-15, 5.3291e-15, 4.6629e-15, 2.6645e-15, 8.8818e-16, 8.8818e-16,\n",
      "         1.7764e-15, 3.1086e-15, 8.8818e-16, 8.3267e-16, 1.5543e-15, 3.5527e-15,\n",
      "         1.7764e-15, 2.2204e-15, 8.8818e-16, 8.8818e-16, 3.1086e-15, 1.7764e-15,\n",
      "         2.8866e-15, 8.8818e-16, 1.7764e-15, 1.1102e-15, 1.7764e-15, 3.5527e-15,\n",
      "         1.3323e-15, 3.5527e-15, 1.7764e-15, 2.1094e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9429e-16, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16, 8.3267e-17,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-16, 6.6613e-16, 4.1633e-16, 4.4409e-16, 5.5511e-17, 4.4409e-16,\n",
      "         1.1102e-16, 1.0547e-15, 3.3307e-16, 2.2204e-16, 1.3878e-17, 4.4409e-16,\n",
      "         4.4409e-16, 6.6613e-16, 4.4409e-16, 2.7756e-17, 2.2204e-16, 2.7756e-16,\n",
      "         1.7764e-15, 1.7764e-15, 5.8981e-17, 4.4409e-16, 5.5511e-17, 3.5527e-15,\n",
      "         4.4409e-16, 4.4409e-16, 1.1102e-16, 1.3323e-15, 2.2204e-16, 1.1102e-16,\n",
      "         2.2204e-16, 2.7756e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  67,  69,  85,  88,  89,  91,\n",
      "         96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  67,  69,  85,  88,  89,  91,\n",
      "         96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])  (len = 102)\n",
      "passing Cout = tensor([64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,\n",
      "        84, 86, 87, 90, 92, 93, 94, 95])  (len = 26)\n",
      "\n",
      "Executing module 33: layer2.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 33\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-17, 8.3267e-17, 0.0000e+00, 1.7347e-18, 6.9389e-18,\n",
      "         1.8041e-16, 0.0000e+00, 0.0000e+00, 1.6653e-16, 0.0000e+00, 0.0000e+00,\n",
      "         8.3267e-17, 0.0000e+00, 0.0000e+00, 6.9389e-17, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7764e-15, 1.3323e-15, 1.3323e-15, 1.3323e-15,\n",
      "         1.9984e-15, 5.3291e-15, 4.6629e-15, 1.7764e-15, 8.8818e-16, 4.4409e-16,\n",
      "         1.7764e-15, 3.1086e-15, 5.8287e-16, 8.3267e-16, 1.5543e-15, 3.5527e-15,\n",
      "         1.7764e-15, 1.7764e-15, 8.8818e-16, 8.8818e-16, 3.1086e-15, 1.3323e-15,\n",
      "         2.8866e-15, 8.8818e-16, 1.7764e-15, 1.1102e-15, 1.7764e-15, 3.5527e-15,\n",
      "         9.9920e-16, 3.5527e-15, 6.1062e-16, 2.1094e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9429e-16, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16, 8.3267e-17,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.9093e-16, 6.6613e-16, 4.1633e-16, 4.4409e-16, 0.0000e+00, 3.0531e-16,\n",
      "         0.0000e+00, 4.9960e-16, 3.3307e-16, 1.5005e-16, 0.0000e+00, 4.4409e-16,\n",
      "         4.4409e-16, 6.6613e-16, 2.7756e-16, 0.0000e+00, 2.2204e-16, 2.2204e-16,\n",
      "         1.7764e-15, 1.7764e-15, 5.7246e-17, 4.4409e-16, 0.0000e+00, 3.5527e-15,\n",
      "         4.4409e-16, 2.7756e-16, 2.7756e-17, 1.3323e-15, 1.3878e-16, 3.7513e-17,\n",
      "         2.2204e-16, 2.7756e-16]], dtype=torch.float64)\n",
      "tensor([  7,   8,  10,  11,  12,  15,  18,  21,  23,  26,  32,  33,  34,  35,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,\n",
      "         50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,\n",
      "         67,  69,  85,  88,  89,  91,  96,  97,  98,  99, 101, 103, 104, 105,\n",
      "        107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  7,   8,  10,  11,  12,  15,  18,  21,  23,  26,  32,  33,  34,  35,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,\n",
      "         50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,\n",
      "         67,  69,  85,  88,  89,  91,  96,  97,  98,  99, 101, 103, 104, 105,\n",
      "        107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127])  (len = 75)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 34: layer3.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 34\n",
      "Max diff:\n",
      "tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.7756e-17, 2.0817e-17, 1.0408e-17, 1.0408e-17, 1.3878e-17, 2.7756e-17,\n",
      "         1.3878e-17, 1.0408e-17, 1.3878e-17, 5.2042e-18, 1.0408e-17, 1.3878e-17,\n",
      "         1.3878e-17, 1.3878e-17, 1.0408e-17, 8.6736e-18, 1.3878e-17, 1.0408e-17,\n",
      "         1.3878e-17, 6.0715e-18, 2.7756e-17, 1.0408e-17, 1.3878e-17, 1.0408e-17,\n",
      "         8.6736e-18, 3.4694e-18, 1.2143e-17, 1.7347e-17, 9.5410e-18, 1.0408e-17,\n",
      "         2.0817e-17, 8.6736e-18, 6.9389e-18, 1.3878e-17, 1.3878e-17, 1.0408e-17,\n",
      "         1.0408e-17, 5.2042e-18, 2.0817e-17, 1.0408e-17, 1.7347e-17, 1.7347e-17,\n",
      "         1.3878e-17, 1.7347e-17, 1.3878e-17, 2.0817e-17, 6.0715e-18, 2.0817e-17,\n",
      "         5.2042e-18, 8.6736e-18, 2.7756e-17, 6.9389e-18, 1.3878e-17, 2.7756e-17,\n",
      "         1.3878e-17, 1.0408e-17, 1.3878e-17, 9.1073e-18, 1.0408e-17, 1.0408e-17,\n",
      "         2.0817e-17, 3.0358e-18, 6.9389e-18, 2.0817e-17, 1.0658e-14, 1.7764e-15,\n",
      "         4.4409e-15, 7.1054e-15, 3.5527e-15, 6.2172e-15, 7.1054e-15, 8.2157e-15,\n",
      "         5.3291e-15, 1.2434e-14, 3.7262e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15,\n",
      "         5.3291e-15, 7.1054e-15, 8.8818e-15, 8.8818e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.0658e-14, 7.1054e-15, 5.3291e-15, 7.1054e-15, 6.6613e-15, 7.1054e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.3323e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15,\n",
      "         3.5527e-15, 5.3291e-15, 7.1054e-15, 1.0658e-14, 3.5527e-15, 7.1054e-15,\n",
      "         3.5527e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15, 3.5527e-15,\n",
      "         7.1054e-15, 8.8818e-15, 7.1054e-15, 7.1054e-15, 3.5527e-15, 8.8818e-15,\n",
      "         3.9968e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15,\n",
      "         5.3291e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15,\n",
      "         6.2172e-15, 7.1054e-15, 2.7756e-17, 8.8818e-16, 2.7756e-17, 1.1102e-16,\n",
      "         5.5511e-17, 1.1102e-16, 4.4409e-16, 6.6613e-16, 2.2204e-16, 2.2204e-16,\n",
      "         5.5511e-17, 2.2204e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 1.7764e-15,\n",
      "         8.8818e-16, 4.4409e-16, 5.5511e-17, 1.1102e-16, 4.4409e-16, 2.2204e-16,\n",
      "         8.8818e-16, 1.7764e-15, 5.5511e-17, 2.2204e-16, 1.1102e-16, 1.1102e-16,\n",
      "         5.5511e-17, 8.3267e-17, 1.1102e-16, 1.1102e-16, 4.1633e-17, 1.1102e-16,\n",
      "         5.5511e-17, 1.1102e-16, 1.7764e-15, 5.5511e-17, 4.4409e-16, 5.5511e-17,\n",
      "         8.8818e-16, 5.5511e-17, 4.4409e-16, 4.4409e-16, 2.7756e-17, 5.5511e-17,\n",
      "         4.1633e-17, 1.7764e-15, 6.6613e-16, 5.5511e-17, 5.5511e-17, 2.2204e-16,\n",
      "         8.3267e-17, 8.8818e-16, 1.1102e-16, 5.5511e-17, 1.1102e-16, 6.6613e-16,\n",
      "         8.8818e-16, 8.8818e-16, 1.7764e-15, 5.5511e-17, 1.1102e-16, 1.1102e-16,\n",
      "         7.1054e-15, 3.5527e-15, 2.6645e-15, 8.8818e-16, 3.3307e-16, 7.1054e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15, 5.3291e-15, 7.1054e-15,\n",
      "         2.6645e-15, 2.2204e-16, 2.2204e-16, 7.1054e-15, 3.5527e-15, 3.5527e-15,\n",
      "         1.7764e-15, 8.8818e-16, 7.1054e-15, 3.5527e-15, 7.1054e-15, 1.7764e-15,\n",
      "         1.7764e-15, 7.1054e-15, 4.4409e-16, 7.1054e-15, 4.4409e-15, 3.5527e-15,\n",
      "         2.6645e-15, 3.5527e-15, 6.6613e-16, 8.8818e-16, 3.5527e-15, 7.1054e-15,\n",
      "         3.5527e-15, 4.4409e-16, 4.4409e-16, 2.6645e-15, 2.6645e-15, 1.7764e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 1.7764e-15, 7.1054e-15,\n",
      "         2.2204e-16, 3.5527e-15, 8.8818e-16, 3.5527e-15, 5.3291e-15, 8.8818e-16,\n",
      "         1.7764e-15, 4.4409e-16, 7.1054e-15, 2.8866e-15, 1.7764e-15, 5.3291e-15,\n",
      "         1.3323e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 35: layer3.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 35\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[6.9389e-18, 6.9389e-18, 2.6021e-18, 3.4694e-18, 3.4694e-18, 6.9389e-18,\n",
      "         3.4694e-18, 1.7347e-18, 3.4694e-18, 1.7347e-18, 6.9389e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18,\n",
      "         1.7347e-18, 8.6736e-19, 3.4694e-18, 4.1200e-18, 1.7347e-18, 1.7347e-18,\n",
      "         5.2042e-18, 1.9516e-18, 1.7347e-18, 3.4694e-18, 6.9389e-18, 2.6021e-18,\n",
      "         3.4694e-18, 1.3010e-18, 4.6621e-18, 6.9389e-18, 3.4694e-18, 6.9389e-18,\n",
      "         3.4694e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18,\n",
      "         1.7347e-18, 1.7347e-18, 6.9389e-18, 1.7347e-18, 3.4694e-18, 6.9389e-18,\n",
      "         1.7347e-18, 3.4694e-18, 3.4694e-18, 2.1684e-18, 2.6021e-18, 3.4694e-18,\n",
      "         6.9389e-18, 6.9389e-18, 1.7347e-18, 5.2042e-18, 3.5527e-15, 4.4409e-16,\n",
      "         2.2204e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 2.2204e-15, 2.8866e-15,\n",
      "         2.2204e-15, 3.9968e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15, 3.5527e-15,\n",
      "         1.7764e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 2.3315e-15, 3.5527e-15,\n",
      "         2.6645e-15, 1.7764e-15, 3.3307e-16, 2.2204e-15, 3.5527e-15, 2.6645e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.2204e-15, 5.3291e-15, 1.7764e-15, 3.5527e-15,\n",
      "         1.7764e-15, 3.5527e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15,\n",
      "         2.2204e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15, 1.3323e-15, 3.5527e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.2204e-15, 1.7764e-15, 3.5527e-15, 1.7764e-15,\n",
      "         2.6645e-15, 2.6645e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15,\n",
      "         2.6645e-15, 1.7764e-15, 6.9389e-18, 4.4409e-16, 6.9389e-18, 2.7756e-17,\n",
      "         1.3878e-17, 2.7756e-17, 1.1102e-16, 4.4409e-16, 5.5511e-17, 5.5511e-17,\n",
      "         1.3878e-17, 5.5511e-17, 1.1102e-16, 2.2204e-16, 5.5511e-17, 2.2204e-16,\n",
      "         1.3878e-16, 1.1102e-16, 1.3878e-17, 2.7756e-17, 5.5511e-17, 5.5511e-17,\n",
      "         2.2204e-16, 8.8818e-16, 1.3878e-17, 2.7756e-17, 2.7756e-17, 2.7756e-17,\n",
      "         1.3878e-17, 2.0817e-17, 1.3878e-17, 2.7756e-17, 1.3878e-17, 2.7756e-17,\n",
      "         1.3878e-17, 2.7756e-17, 4.4409e-16, 1.3878e-17, 1.1102e-16, 1.3878e-17,\n",
      "         8.8818e-16, 1.3878e-17, 2.2204e-16, 1.1102e-16, 6.9389e-18, 1.3878e-17,\n",
      "         1.0408e-17, 4.4409e-16, 1.1102e-16, 1.3878e-17, 1.3878e-17, 5.5511e-17,\n",
      "         1.3878e-17, 2.2204e-16, 2.7756e-17, 1.3878e-17, 2.7756e-17, 1.1102e-16,\n",
      "         2.2204e-16, 8.8818e-16, 2.2204e-16, 1.3878e-17, 2.7756e-17, 2.7756e-17,\n",
      "         1.7764e-15, 1.7764e-15, 6.6613e-16, 2.2204e-16, 1.1102e-16, 2.6645e-15,\n",
      "         2.2204e-16, 6.6613e-16, 8.8818e-16, 1.7764e-15, 1.3323e-15, 3.5527e-15,\n",
      "         1.3323e-15, 5.5511e-17, 5.5511e-17, 1.7764e-15, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 2.2204e-16, 8.8818e-16, 8.8818e-16, 2.6645e-15, 4.4409e-16,\n",
      "         2.2204e-16, 2.6645e-15, 1.1102e-16, 5.3291e-15, 1.3323e-15, 8.8818e-16,\n",
      "         8.8818e-16, 8.8818e-16, 1.6653e-16, 2.2204e-16, 1.3323e-15, 1.7764e-15,\n",
      "         8.8818e-16, 1.1102e-16, 1.1102e-16, 8.8818e-16, 5.9674e-16, 4.4409e-16,\n",
      "         1.7764e-15, 1.1102e-15, 1.3323e-15, 4.4409e-16, 8.8818e-16, 1.3323e-15,\n",
      "         5.5511e-17, 1.7764e-15, 2.2204e-16, 8.8818e-16, 1.3323e-15, 2.2204e-16,\n",
      "         3.3307e-16, 1.1102e-16, 2.6645e-15, 7.7716e-16, 4.4409e-16, 1.3323e-15,\n",
      "         6.6613e-16, 1.3323e-15, 8.8818e-16, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 36: layer3.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 36\n",
      "Max diff:\n",
      "tensor([3.9968e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 6.9389e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 3.4694e-18,\n",
      "         3.4694e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 6.9389e-18, 3.4694e-18,\n",
      "         1.7347e-18, 2.6021e-18, 3.4694e-18, 3.4694e-18, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 8.6736e-19, 0.0000e+00, 3.4694e-18, 3.4694e-18,\n",
      "         1.7347e-18, 8.6736e-19, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.2042e-18, 0.0000e+00, 1.7347e-18, 3.4694e-18, 6.9389e-18, 1.2197e-18,\n",
      "         3.4694e-18, 0.0000e+00, 4.6621e-18, 6.9389e-18, 3.4694e-18, 6.9389e-18,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 1.7347e-18, 6.9389e-18, 0.0000e+00, 3.4694e-18, 6.9389e-18,\n",
      "         1.7347e-18, 0.0000e+00, 3.4694e-18, 2.1684e-18, 0.0000e+00, 3.4694e-18,\n",
      "         6.9389e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         1.2212e-15, 0.0000e+00, 1.3323e-15, 1.3184e-15, 2.2204e-15, 1.5543e-15,\n",
      "         1.1102e-15, 3.9968e-15, 1.4277e-15, 2.6645e-15, 3.3307e-16, 4.4409e-16,\n",
      "         8.8818e-16, 4.4409e-16, 0.0000e+00, 7.7716e-16, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.7716e-16, 2.6645e-15, 2.3315e-15, 4.4409e-16,\n",
      "         2.6645e-15, 1.7764e-15, 0.0000e+00, 1.3323e-15, 0.0000e+00, 2.6645e-15,\n",
      "         4.4409e-16, 6.6613e-16, 2.2204e-15, 1.5543e-15, 0.0000e+00, 1.4433e-15,\n",
      "         1.3323e-15, 8.8818e-16, 1.7764e-15, 0.0000e+00, 2.6645e-15, 1.7764e-15,\n",
      "         9.5063e-16, 1.1102e-15, 5.2736e-16, 8.8818e-16, 8.8818e-16, 0.0000e+00,\n",
      "         8.8818e-16, 7.7716e-16, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.6645e-15, 0.0000e+00, 2.2898e-16, 2.2204e-16, 1.1866e-15,\n",
      "         2.6645e-15, 1.7764e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.2450e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1062e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7456e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0531e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 5.9674e-16, 0.0000e+00,\n",
      "         0.0000e+00, 1.6653e-16, 3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7764e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00, 0.0000e+00,\n",
      "         3.3307e-16, 0.0000e+00, 8.8818e-16, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  1,   3,   5,   6,   8,  10,  11,  12,  13,  14,  15,  16,  19,  20,\n",
      "         22,  23,  24,  25,  26,  30,  32,  33,  34,  35,  36,  38,  39,  40,\n",
      "         41,  42,  45,  47,  49,  50,  52,  53,  54,  56,  57,  59,  60,  61,\n",
      "         64,  66,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         81,  82,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,  98,  99,\n",
      "        101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116,\n",
      "        121, 123, 124, 125, 126, 127, 141, 144, 150, 168, 193, 208, 213, 220,\n",
      "        226, 231, 232, 235, 236, 241, 249, 252, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   3,   5,   6,   8,  10,  11,  12,  13,  14,  15,  16,  19,  20,\n",
      "         22,  23,  24,  25,  26,  30,  32,  33,  34,  35,  36,  38,  39,  40,\n",
      "         41,  42,  45,  47,  49,  50,  52,  53,  54,  56,  57,  59,  60,  61,\n",
      "         64,  66,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         81,  82,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,  98,  99,\n",
      "        101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116,\n",
      "        121, 123, 124, 125, 126, 127, 141, 144, 150, 168, 193, 208, 213, 220,\n",
      "        226, 231, 232, 235, 236, 241, 249, 252, 254, 255])  (len = 108)\n",
      "passing Cout = tensor([ 18, 105, 120])  (len = 3)\n",
      "\n",
      "Executing module 37: layer3.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 37\n",
      "Max diff:\n",
      "tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.3878e-17, 3.4694e-18, 3.4694e-18, 6.9389e-18, 1.3878e-17, 1.3878e-17,\n",
      "         6.9389e-18, 4.3368e-18, 2.6021e-18, 2.6021e-18, 3.4694e-18, 1.7347e-18,\n",
      "         3.4694e-18, 2.6021e-18, 3.4694e-18, 8.6736e-19, 1.7347e-18, 3.4694e-18,\n",
      "         1.3010e-18, 1.3010e-18, 3.4694e-18, 3.4694e-18, 1.3878e-17, 3.4694e-18,\n",
      "         1.7347e-18, 1.3878e-17, 2.7756e-17, 2.6021e-18, 1.7347e-18, 2.6021e-18,\n",
      "         6.9389e-18, 3.4694e-18, 6.9389e-18, 1.7347e-18, 4.3368e-18, 1.3878e-17,\n",
      "         6.9389e-18, 6.9389e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18, 1.3878e-17,\n",
      "         3.4694e-18, 1.3878e-17, 6.9389e-18, 6.9389e-18, 5.2042e-18, 6.9389e-18,\n",
      "         1.7347e-18, 2.6021e-18, 2.2768e-18, 1.7347e-18, 6.9389e-18, 3.4694e-18,\n",
      "         1.3010e-18, 1.3878e-17, 6.9389e-18, 2.1684e-18, 1.3878e-17, 1.3878e-17,\n",
      "         1.3878e-17, 4.3368e-18, 6.9389e-18, 8.6736e-19, 7.9936e-15, 3.5527e-15,\n",
      "         5.3291e-15, 7.1054e-15, 8.8818e-15, 3.5527e-15, 1.0658e-14, 7.1054e-15,\n",
      "         5.3291e-15, 5.3291e-15, 7.9936e-15, 4.4409e-15, 7.1054e-15, 8.8818e-15,\n",
      "         3.5527e-15, 1.0658e-14, 5.3291e-15, 7.1054e-15, 5.3291e-15, 1.0658e-14,\n",
      "         3.5527e-15, 4.4409e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 5.3291e-15,\n",
      "         1.0658e-14, 8.8818e-15, 6.2172e-15, 7.1054e-15, 6.2172e-15, 7.1054e-15,\n",
      "         3.5527e-15, 8.8818e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15,\n",
      "         5.3291e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15, 5.3291e-15, 8.8818e-15,\n",
      "         5.3291e-15, 5.3291e-15, 5.3291e-15, 4.4409e-15, 3.5527e-15, 5.3291e-15,\n",
      "         5.3291e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 1.0658e-14, 1.0658e-14,\n",
      "         5.3291e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 3.5527e-15,\n",
      "         5.3291e-15, 5.3291e-15, 8.8818e-16, 2.7756e-16, 8.8818e-16, 2.7756e-17,\n",
      "         2.2204e-16, 4.4409e-16, 3.3307e-16, 8.8818e-16, 2.7756e-17, 2.2204e-16,\n",
      "         2.2204e-16, 1.1102e-16, 2.7756e-17, 2.2204e-16, 2.7756e-17, 2.2204e-16,\n",
      "         2.2204e-16, 2.7756e-16, 4.4409e-16, 3.8858e-16, 1.3878e-17, 2.7756e-16,\n",
      "         3.8858e-16, 4.4409e-16, 3.3307e-16, 3.0531e-16, 4.4409e-16, 1.1102e-16,\n",
      "         4.4409e-16, 5.5511e-17, 6.6613e-16, 6.9389e-18, 4.4409e-16, 8.8818e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 2.7756e-17, 3.3307e-16, 4.4409e-16,\n",
      "         2.2204e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 5.5511e-17,\n",
      "         4.4409e-16, 5.5511e-17, 2.2204e-16, 1.3323e-15, 8.8818e-16, 5.5511e-17,\n",
      "         4.4409e-16, 2.7756e-17, 2.7756e-17, 4.4409e-16, 1.9429e-16, 4.4409e-16,\n",
      "         5.5511e-17, 3.3307e-16, 5.5511e-17, 4.4409e-16, 1.1102e-16, 5.5511e-16,\n",
      "         1.6653e-16, 4.4409e-16, 1.7764e-15, 2.2204e-15, 3.5527e-15, 2.6645e-15,\n",
      "         1.7764e-15, 1.3323e-15, 2.6645e-15, 2.6645e-15, 2.2204e-15, 1.3323e-15,\n",
      "         2.2204e-16, 1.7764e-15, 1.4433e-15, 1.7764e-15, 3.3307e-16, 1.3323e-15,\n",
      "         2.2204e-15, 1.7764e-15, 1.3323e-15, 1.7764e-15, 4.4409e-16, 1.7764e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.7764e-15, 1.1102e-15, 3.5527e-15, 1.7764e-15,\n",
      "         1.7764e-15, 3.5527e-15, 1.3323e-15, 2.2204e-16, 1.7764e-15, 1.7764e-15,\n",
      "         2.2204e-16, 8.8818e-16, 1.7764e-15, 1.7764e-15, 1.3323e-15, 1.7764e-15,\n",
      "         1.3323e-15, 3.3307e-16, 2.6645e-15, 1.3323e-15, 3.5527e-15, 1.1102e-16,\n",
      "         2.2204e-15, 1.7764e-15, 1.5543e-15, 4.4409e-16, 1.7764e-15, 2.6645e-15,\n",
      "         1.7764e-15, 1.7764e-15, 2.2204e-15, 1.7764e-15, 2.2204e-16, 2.2204e-16,\n",
      "         3.3307e-16, 1.7764e-15, 1.1102e-15, 1.3323e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 38: layer3.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 38\n",
      "Max diff:\n",
      "tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[3.4694e-18, 8.6736e-19, 1.0842e-18, 2.6021e-18, 3.9031e-18, 5.2042e-18,\n",
      "         1.9516e-18, 1.7347e-18, 8.6736e-19, 3.4694e-18, 1.7347e-18, 3.4694e-18,\n",
      "         3.4694e-18, 1.7347e-18, 1.0842e-18, 1.7347e-18, 3.4694e-18, 1.7347e-18,\n",
      "         4.3368e-19, 3.4694e-18, 1.7347e-18, 6.9389e-18, 5.2042e-18, 3.4694e-18,\n",
      "         1.7347e-18, 6.9389e-18, 6.9389e-18, 1.7347e-18, 1.7347e-18, 8.6736e-19,\n",
      "         1.7347e-18, 3.4694e-18, 6.9389e-18, 8.6736e-19, 1.7347e-18, 6.9389e-18,\n",
      "         2.6021e-18, 1.8431e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18, 3.4694e-18,\n",
      "         3.4694e-18, 6.9389e-18, 2.6021e-18, 6.9389e-18, 1.5179e-18, 3.4694e-18,\n",
      "         4.3368e-19, 3.4694e-18, 1.7347e-18, 8.6736e-19, 1.7347e-18, 1.7347e-18,\n",
      "         3.7947e-19, 6.9389e-18, 6.9389e-18, 8.6736e-19, 3.4694e-18, 6.9389e-18,\n",
      "         3.4694e-18, 8.6736e-19, 1.7347e-18, 1.7347e-18, 4.8850e-15, 2.6645e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.9968e-15, 3.5527e-15, 5.3291e-15, 3.5527e-15,\n",
      "         3.1086e-15, 3.5527e-15, 4.4409e-15, 3.5527e-15, 4.4409e-15, 3.5527e-15,\n",
      "         2.2204e-15, 5.3291e-15, 3.3307e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         2.6645e-15, 2.2204e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15,\n",
      "         2.6645e-15, 6.2172e-15, 2.6645e-15, 2.6645e-15, 3.5527e-15, 3.5527e-15,\n",
      "         2.2204e-15, 4.8850e-15, 3.5527e-15, 2.6645e-15, 2.2204e-15, 3.1086e-15,\n",
      "         3.5527e-15, 3.5527e-15, 7.1054e-15, 4.4409e-15, 2.2204e-15, 4.4409e-15,\n",
      "         3.5527e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15, 1.9984e-15,\n",
      "         1.7764e-15, 2.6645e-15, 4.4409e-15, 3.9968e-15, 5.3291e-15, 7.1054e-15,\n",
      "         2.6645e-15, 2.8311e-15, 5.3291e-15, 3.5527e-15, 3.1086e-15, 1.7764e-15,\n",
      "         2.4425e-15, 4.4409e-15, 1.6653e-16, 5.5511e-17, 3.3307e-16, 1.3878e-17,\n",
      "         5.5511e-17, 1.6653e-16, 1.1102e-16, 2.2204e-16, 1.3878e-17, 5.5511e-17,\n",
      "         5.5511e-17, 2.7756e-17, 1.3878e-17, 5.5511e-17, 1.3878e-17, 4.5103e-17,\n",
      "         1.1102e-16, 1.1102e-16, 1.1102e-16, 1.3184e-16, 6.9389e-18, 1.1102e-16,\n",
      "         1.1102e-16, 1.1102e-16, 5.5511e-17, 1.3878e-16, 2.2204e-16, 5.5511e-17,\n",
      "         1.1102e-16, 1.3878e-17, 3.8858e-16, 1.7347e-18, 2.2204e-16, 4.4409e-16,\n",
      "         1.9429e-16, 1.3878e-16, 1.6653e-16, 6.9389e-18, 1.3878e-16, 1.6653e-16,\n",
      "         5.5511e-17, 2.2204e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16, 1.3878e-17,\n",
      "         2.2204e-16, 1.3878e-17, 5.5511e-17, 3.3307e-16, 2.2204e-16, 1.3878e-17,\n",
      "         1.1102e-16, 1.3878e-17, 1.3878e-17, 4.4409e-16, 4.1633e-17, 1.6653e-16,\n",
      "         1.3878e-17, 2.2204e-16, 1.3878e-17, 1.1102e-16, 2.7756e-17, 6.2450e-17,\n",
      "         4.1633e-17, 1.1102e-16, 6.6613e-16, 1.3323e-15, 8.8818e-16, 1.3323e-15,\n",
      "         2.2204e-16, 5.5511e-16, 6.6613e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16,\n",
      "         1.1102e-16, 8.8818e-16, 5.5511e-16, 1.7764e-15, 8.3267e-17, 4.4409e-16,\n",
      "         8.8818e-16, 5.5511e-16, 4.4409e-16, 8.8818e-16, 1.1102e-16, 8.8818e-16,\n",
      "         1.1102e-16, 8.8818e-16, 5.5511e-16, 5.5511e-16, 2.6645e-15, 6.6613e-16,\n",
      "         4.4409e-16, 1.7764e-15, 4.4409e-16, 5.5511e-17, 3.3307e-16, 6.6613e-16,\n",
      "         5.5511e-17, 2.2204e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 1.3323e-15,\n",
      "         4.4409e-16, 8.3267e-17, 6.6613e-16, 8.8818e-16, 1.3323e-15, 5.5511e-17,\n",
      "         1.3323e-15, 6.6613e-16, 3.6082e-16, 1.1102e-16, 4.4409e-16, 8.8818e-16,\n",
      "         2.2204e-16, 4.4409e-16, 2.2204e-16, 8.8818e-16, 5.5511e-17, 5.5511e-17,\n",
      "         8.3267e-17, 6.6613e-16, 5.5511e-16, 5.1348e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 39: layer3.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([182]) to machine 2\n",
      "\t\t sending C_out tensor([208, 234, 243, 247, 252]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 4,  7,  8, 10, 12, 13, 18, 22, 24, 28, 32, 40, 44, 52, 57, 61]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([199, 243, 251]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([35, 37]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  3, 14, 15, 20, 22, 28, 29, 30, 34, 38, 54, 58, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 77,  86, 111]) to machine 1\n",
      "\t\t sending C_out tensor([155, 186]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 39\n",
      "Max diff:\n",
      "tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[5.4210e-18, 2.6021e-18, 6.9389e-18, 3.4694e-18, 5.2042e-18, 3.4694e-18,\n",
      "         4.3368e-18, 3.0358e-18, 1.7347e-18, 2.3852e-18, 1.1926e-18, 1.3010e-18,\n",
      "         5.2042e-18, 3.4694e-18, 2.6021e-18, 1.7347e-18, 3.9031e-18, 3.4694e-18,\n",
      "         2.1684e-18, 3.0358e-18, 3.4694e-18, 1.9516e-18, 4.3368e-18, 3.4694e-18,\n",
      "         2.2768e-18, 5.6379e-18, 1.7347e-18, 1.3010e-18, 3.4694e-18, 4.3368e-18,\n",
      "         3.4694e-18, 2.1684e-18, 6.9389e-18, 1.7347e-18, 4.5536e-18, 6.9389e-18,\n",
      "         5.2042e-18, 3.4694e-18, 4.5536e-18, 5.2042e-18, 4.3368e-18, 3.2526e-18,\n",
      "         3.4694e-18, 3.4694e-18, 4.3368e-18, 2.6021e-18, 5.2042e-18, 8.6736e-19,\n",
      "         1.7347e-18, 3.0358e-18, 1.7347e-18, 3.9031e-18, 5.2042e-18, 1.7347e-18,\n",
      "         2.6021e-18, 3.4694e-18, 6.9389e-18, 2.6021e-18, 3.0900e-18, 2.6021e-18,\n",
      "         2.1684e-18, 8.2399e-18, 1.0408e-17, 1.3010e-18, 1.7764e-15, 1.3323e-15,\n",
      "         2.6645e-15, 6.6613e-16, 2.2204e-15, 8.8818e-16, 1.7764e-15, 1.7764e-15,\n",
      "         1.1102e-15, 1.7764e-15, 1.7764e-15, 8.8818e-16, 1.3323e-15, 1.9984e-15,\n",
      "         1.7764e-15, 2.2204e-15, 1.1102e-15, 2.0262e-15, 1.3323e-15, 9.4369e-16,\n",
      "         1.3323e-15, 1.3323e-15, 1.1102e-15, 1.3323e-15, 8.8818e-16, 1.5266e-15,\n",
      "         2.4425e-15, 7.1054e-15, 1.3323e-15, 5.3291e-15, 1.7764e-15, 2.2204e-15,\n",
      "         1.7764e-15, 8.8818e-16, 3.5527e-15, 1.3323e-15, 1.3323e-15, 1.3323e-15,\n",
      "         1.7764e-15, 1.3323e-15, 1.1102e-15, 7.4246e-16, 1.3323e-15, 1.7764e-15,\n",
      "         1.3323e-15, 6.6613e-16, 1.1657e-15, 8.8818e-16, 2.3592e-15, 1.3323e-15,\n",
      "         3.5527e-15, 2.6645e-15, 1.3323e-15, 1.3323e-15, 1.1102e-15, 1.3323e-15,\n",
      "         1.7764e-15, 6.6613e-16, 1.7764e-15, 8.8818e-16, 1.7764e-15, 9.4369e-16,\n",
      "         1.7764e-15, 8.8818e-16, 1.1102e-16, 3.3307e-16, 2.7756e-17, 1.3878e-17,\n",
      "         2.2204e-16, 5.5511e-17, 2.7756e-17, 2.2204e-16, 1.9949e-17, 5.5511e-17,\n",
      "         1.7347e-17, 2.7756e-17, 1.3878e-17, 1.1102e-16, 1.3878e-17, 2.2204e-16,\n",
      "         2.2204e-16, 5.5511e-17, 1.1102e-16, 4.4409e-16, 1.3878e-17, 5.5511e-17,\n",
      "         1.1102e-16, 1.1102e-16, 1.1102e-16, 1.3878e-17, 1.1102e-16, 2.7756e-17,\n",
      "         1.1102e-16, 5.5511e-17, 1.0408e-17, 6.9389e-18, 1.1102e-16, 2.2204e-16,\n",
      "         4.4409e-16, 2.7756e-17, 2.2204e-16, 1.0408e-17, 1.1102e-16, 2.2204e-16,\n",
      "         1.1102e-16, 2.2204e-16, 4.4409e-16, 2.2204e-16, 1.1102e-16, 2.7756e-17,\n",
      "         1.1102e-16, 1.3878e-17, 1.1102e-16, 2.2204e-16, 2.2204e-16, 1.3878e-17,\n",
      "         3.1225e-17, 5.2042e-18, 1.3878e-17, 2.2204e-16, 2.2204e-16, 2.2204e-16,\n",
      "         1.3878e-17, 1.3878e-17, 2.0817e-17, 2.2204e-16, 2.7756e-17, 5.5511e-17,\n",
      "         1.1102e-16, 2.2204e-16, 8.8818e-16, 1.0825e-15, 8.8818e-16, 2.2204e-16,\n",
      "         8.8818e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.1102e-16,\n",
      "         1.6653e-16, 2.2204e-16, 3.0531e-16, 1.7764e-15, 1.1102e-16, 8.8818e-16,\n",
      "         6.6613e-16, 6.6613e-16, 6.6613e-16, 2.2204e-16, 3.3307e-16, 2.2204e-16,\n",
      "         1.3323e-15, 3.3307e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16,\n",
      "         2.2204e-16, 1.1102e-15, 8.8818e-16, 2.7756e-17, 1.3323e-15, 5.5511e-16,\n",
      "         5.5511e-17, 3.3307e-16, 8.8818e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16,\n",
      "         1.3878e-16, 1.1102e-16, 4.4409e-16, 8.8818e-16, 1.1102e-16, 4.1633e-17,\n",
      "         4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 6.6613e-16, 2.2204e-16,\n",
      "         1.7764e-15, 2.2204e-16, 8.8818e-16, 8.8818e-16, 2.2204e-16, 1.1102e-16,\n",
      "         8.3267e-17, 1.7347e-16, 6.7307e-16, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 40: layer3.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 40\n",
      "Max diff:\n",
      "tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.3010e-18, 5.9631e-19, 6.9389e-18, 1.7347e-18, 1.7347e-18, 8.6736e-19,\n",
      "         8.6736e-19, 1.7347e-18, 1.7347e-18, 1.7347e-18, 6.9389e-18, 1.3878e-17,\n",
      "         8.6736e-19, 6.9389e-18, 1.7347e-18, 8.6736e-19, 1.7347e-18, 8.6736e-19,\n",
      "         1.7347e-18, 1.7347e-18, 3.4694e-18, 3.4694e-18, 1.0842e-18, 8.6736e-19,\n",
      "         4.3368e-19, 1.7347e-18, 6.9389e-18, 4.3368e-19, 8.6736e-19, 6.9389e-18,\n",
      "         1.7347e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18, 1.0300e-18, 3.4694e-18,\n",
      "         6.9389e-18, 8.6736e-19, 6.9389e-18, 6.9389e-18, 8.6736e-19, 3.4694e-18,\n",
      "         1.7347e-18, 8.6736e-19, 3.4694e-18, 6.9389e-18, 6.9389e-18, 0.0000e+00,\n",
      "         4.3368e-19, 0.0000e+00, 1.7347e-18, 3.4694e-18, 1.7347e-18, 1.7347e-18,\n",
      "         3.4694e-18, 6.9389e-18, 1.7347e-18, 1.7347e-18, 6.5052e-19, 1.7347e-18,\n",
      "         1.7347e-18, 3.4694e-18, 2.6021e-18, 8.6736e-19, 1.7764e-15, 8.8818e-16,\n",
      "         1.3323e-15, 3.3307e-16, 1.1102e-15, 4.4409e-16, 6.6613e-16, 6.6613e-16,\n",
      "         4.4409e-16, 8.8818e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16, 1.1102e-15,\n",
      "         8.8818e-16, 8.8818e-16, 3.3307e-16, 1.0564e-15, 4.4409e-16, 4.4409e-16,\n",
      "         3.3307e-16, 6.6613e-16, 5.5511e-16, 2.7756e-16, 2.2204e-16, 9.4369e-16,\n",
      "         1.5543e-15, 7.1054e-15, 7.7716e-16, 2.6645e-15, 8.8818e-16, 1.3323e-15,\n",
      "         6.6613e-16, 4.4409e-16, 2.6645e-15, 6.6613e-16, 4.4409e-16, 6.6613e-16,\n",
      "         8.8818e-16, 8.8818e-16, 1.1102e-16, 1.6653e-16, 8.8818e-16, 1.3323e-15,\n",
      "         4.4409e-16, 2.2204e-16, 8.8818e-16, 6.6613e-16, 8.3614e-16, 1.1102e-15,\n",
      "         1.7764e-15, 1.3323e-15, 3.3307e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16,\n",
      "         8.8818e-16, 2.2204e-16, 1.7764e-15, 4.4409e-16, 1.7764e-15, 3.3307e-16,\n",
      "         6.6613e-16, 3.3307e-16, 2.7756e-17, 5.5511e-17, 6.9389e-18, 3.4694e-18,\n",
      "         1.1102e-16, 1.3878e-17, 0.0000e+00, 1.1102e-16, 1.3878e-17, 1.3878e-17,\n",
      "         0.0000e+00, 1.3878e-17, 6.9389e-18, 5.5511e-17, 6.9389e-18, 1.1102e-16,\n",
      "         1.1102e-16, 1.0408e-17, 4.1633e-17, 2.2204e-16, 6.9389e-18, 0.0000e+00,\n",
      "         2.7756e-17, 3.1225e-17, 5.5511e-17, 0.0000e+00, 1.3878e-17, 6.9389e-18,\n",
      "         2.7756e-17, 1.3878e-17, 0.0000e+00, 1.7347e-18, 5.5511e-17, 1.1102e-16,\n",
      "         4.4409e-16, 6.9389e-18, 1.1102e-16, 3.4694e-18, 2.7756e-17, 1.1102e-16,\n",
      "         4.1633e-17, 1.1102e-16, 1.6653e-16, 5.5511e-17, 5.5511e-17, 6.9389e-18,\n",
      "         2.7756e-17, 3.4694e-18, 2.7756e-17, 2.7756e-17, 5.5511e-17, 3.4694e-18,\n",
      "         1.3878e-17, 6.9389e-18, 3.4694e-18, 1.1102e-16, 8.3267e-17, 2.2204e-16,\n",
      "         3.4694e-18, 0.0000e+00, 6.9389e-18, 1.1102e-16, 1.3878e-17, 5.5511e-17,\n",
      "         2.7756e-17, 5.5511e-17, 4.4409e-16, 3.5388e-16, 1.6653e-16, 6.9389e-18,\n",
      "         1.6653e-16, 6.6613e-16, 1.6653e-16, 1.1102e-16, 2.2204e-16, 0.0000e+00,\n",
      "         4.1633e-17, 6.9389e-18, 0.0000e+00, 1.3323e-15, 2.7756e-17, 4.4409e-16,\n",
      "         2.2204e-16, 1.5266e-16, 2.7756e-16, 0.0000e+00, 8.3267e-17, 2.7756e-17,\n",
      "         1.3323e-15, 2.7756e-17, 2.2204e-16, 8.8818e-16, 2.2204e-16, 2.7756e-17,\n",
      "         2.7756e-17, 5.5511e-16, 4.4409e-16, 6.9389e-18, 6.6613e-16, 6.5052e-17,\n",
      "         1.3878e-17, 1.1102e-16, 4.4409e-16, 5.5511e-17, 1.1102e-16, 7.6328e-17,\n",
      "         2.7756e-17, 2.7756e-17, 2.7756e-17, 2.2204e-16, 1.3878e-17, 1.3878e-17,\n",
      "         9.7145e-17, 4.4409e-16, 3.3307e-16, 1.6653e-16, 8.3267e-17, 2.7756e-17,\n",
      "         1.7764e-15, 5.5511e-17, 2.2204e-16, 4.4409e-16, 5.5511e-17, 2.7756e-17,\n",
      "         2.0817e-17, 0.0000e+00, 1.9429e-16, 8.8818e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  48,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 150, 151, 152, 154, 155, 156, 157, 159, 160,\n",
      "        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "        175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189,\n",
      "        190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204,\n",
      "        205, 207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  48,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 150, 151, 152, 154, 155, 156, 157, 159, 160,\n",
      "        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "        175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189,\n",
      "        190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204,\n",
      "        205, 207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 254, 255])  (len = 244)\n",
      "passing Cout = tensor([ 47,  49, 134, 138, 149, 153, 158, 187, 203, 206, 213, 253])  (len = 12)\n",
      "\n",
      "Executing module 41: layer3.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 41\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[5.2042e-18, 1.3010e-18, 6.9389e-18, 3.4694e-18, 5.2042e-18, 6.9389e-18,\n",
      "         3.4694e-18, 1.7347e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18, 2.7756e-17,\n",
      "         3.4694e-18, 1.3878e-17, 3.4694e-18, 1.7347e-18, 6.9389e-18, 2.6021e-18,\n",
      "         1.7347e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18, 5.2042e-18, 6.9389e-18,\n",
      "         1.7347e-18, 6.9389e-18, 1.3878e-17, 1.7347e-18, 3.4694e-18, 6.9389e-18,\n",
      "         2.6021e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18, 3.4694e-18, 6.9389e-18,\n",
      "         6.9389e-18, 3.4694e-18, 6.9389e-18, 1.3878e-17, 3.4694e-18, 6.9389e-18,\n",
      "         5.2042e-18, 8.6736e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18, 3.4694e-18,\n",
      "         8.6736e-19, 3.4694e-18, 1.7347e-18, 3.4694e-18, 2.6021e-18, 3.4694e-18,\n",
      "         3.4694e-18, 1.3878e-17, 1.0408e-17, 3.4694e-18, 3.4694e-18, 6.9389e-18,\n",
      "         3.4694e-18, 3.4694e-18, 3.4694e-18, 1.7347e-18, 6.2172e-15, 2.6645e-15,\n",
      "         4.4409e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 4.4409e-15, 3.5527e-15, 4.4409e-15, 3.5527e-15,\n",
      "         2.2204e-15, 5.3291e-15, 3.3307e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         2.6645e-15, 2.2204e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.4211e-14, 2.6645e-15, 3.5527e-15, 3.9968e-15, 3.5527e-15,\n",
      "         1.7764e-15, 4.4409e-15, 7.1054e-15, 3.5527e-15, 2.2204e-15, 2.8866e-15,\n",
      "         3.5527e-15, 3.5527e-15, 7.1054e-15, 4.4409e-15, 2.6645e-15, 4.4409e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 1.9984e-15, 1.7764e-15, 2.6645e-15,\n",
      "         3.5527e-15, 3.1086e-15, 4.4409e-15, 3.9968e-15, 5.3291e-15, 5.3291e-15,\n",
      "         2.6645e-15, 2.7756e-15, 5.3291e-15, 3.1086e-15, 3.5527e-15, 1.7764e-15,\n",
      "         3.1086e-15, 4.4409e-15, 2.2204e-16, 8.3267e-17, 3.3307e-16, 1.3878e-17,\n",
      "         1.3878e-16, 2.2204e-16, 1.1102e-16, 4.4409e-16, 2.7756e-17, 5.5511e-17,\n",
      "         1.1102e-16, 5.5511e-17, 1.3878e-17, 5.5511e-17, 2.7756e-17, 1.6653e-16,\n",
      "         2.2204e-16, 1.1102e-16, 2.2204e-16, 4.4409e-16, 1.3878e-17, 2.2204e-16,\n",
      "         1.1102e-16, 1.1102e-16, 8.3267e-17, 2.2204e-16, 2.2204e-16, 5.5511e-17,\n",
      "         1.1102e-16, 2.7756e-17, 3.8858e-16, 6.9389e-18, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 1.3878e-16, 2.2204e-16, 1.3878e-17, 1.3878e-16, 4.4409e-16,\n",
      "         1.1102e-16, 4.4409e-16, 2.2204e-16, 3.3307e-16, 2.2204e-16, 1.3878e-17,\n",
      "         2.2204e-16, 1.3878e-17, 1.1102e-16, 3.3307e-16, 2.2204e-16, 1.3878e-17,\n",
      "         1.1102e-16, 2.7756e-17, 1.3878e-17, 4.4409e-16, 8.3267e-17, 3.3307e-16,\n",
      "         1.3878e-17, 4.4409e-16, 1.3878e-17, 2.2204e-16, 5.5511e-17, 1.1102e-16,\n",
      "         5.5511e-17, 1.1102e-16, 7.7716e-16, 1.5543e-15, 8.8818e-16, 1.3323e-15,\n",
      "         2.2204e-16, 8.8818e-16, 4.4409e-16, 1.1102e-15, 8.8818e-16, 8.8818e-16,\n",
      "         1.1102e-16, 8.8818e-16, 5.5511e-16, 2.2204e-15, 1.1102e-16, 6.6613e-16,\n",
      "         8.8818e-16, 6.1062e-16, 5.5511e-16, 8.8818e-16, 2.2204e-16, 8.8818e-16,\n",
      "         1.3323e-15, 8.8818e-16, 6.6613e-16, 1.3323e-15, 2.6645e-15, 6.6613e-16,\n",
      "         4.4409e-16, 1.7764e-15, 8.8818e-16, 5.5511e-17, 8.8818e-16, 6.6613e-16,\n",
      "         5.5511e-17, 3.3307e-16, 1.1102e-15, 8.8818e-16, 8.8818e-16, 1.3323e-15,\n",
      "         4.4409e-16, 1.1102e-16, 6.6613e-16, 8.8818e-16, 1.3323e-15, 5.5511e-17,\n",
      "         1.3323e-15, 8.8818e-16, 5.5511e-16, 2.2204e-16, 4.4409e-16, 8.8818e-16,\n",
      "         1.7764e-15, 4.4409e-16, 3.8858e-16, 1.7764e-15, 1.1102e-16, 5.5511e-17,\n",
      "         1.1102e-16, 8.8818e-16, 5.5511e-16, 1.3323e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 42: layer3.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 42\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 6.9389e-18, 2.1684e-19, 6.9389e-18,\n",
      "         0.0000e+00, 1.7347e-18, 1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 3.4694e-18, 0.0000e+00, 1.3878e-17, 0.0000e+00, 6.9389e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 1.0408e-17, 0.0000e+00, 6.5052e-19, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 2.6645e-15, 0.0000e+00,\n",
      "         1.7764e-15, 3.8858e-16, 1.3323e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         2.2204e-15, 2.6645e-15, 4.4409e-15, 2.4425e-15, 1.5543e-15, 2.2204e-16,\n",
      "         1.7764e-15, 0.0000e+00, 3.3307e-15, 4.4409e-15, 6.6613e-16, 0.0000e+00,\n",
      "         1.9984e-15, 1.7764e-15, 0.0000e+00, 1.4294e-15, 1.7764e-15, 1.3323e-15,\n",
      "         8.8818e-16, 0.0000e+00, 1.7764e-15, 2.2204e-16, 3.9968e-15, 3.5527e-15,\n",
      "         1.6653e-15, 2.8866e-15, 0.0000e+00, 2.1094e-15, 2.2204e-15, 2.6645e-15,\n",
      "         8.8818e-16, 3.5527e-15, 1.7764e-15, 2.9421e-15, 2.6645e-15, 4.4409e-15,\n",
      "         1.7764e-15, 1.1102e-15, 9.4369e-16, 9.9920e-16, 1.3323e-15, 8.8818e-16,\n",
      "         3.5527e-15, 1.7764e-15, 6.6613e-16, 3.9968e-15, 1.2212e-15, 8.4655e-16,\n",
      "         2.6645e-15, 2.7756e-15, 0.0000e+00, 1.7764e-15, 9.9920e-16, 1.3323e-15,\n",
      "         3.1086e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         1.3878e-16, 2.7756e-17, 5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 1.6653e-16,\n",
      "         1.6653e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         2.7756e-17, 0.0000e+00, 5.5511e-17, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.8858e-16, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-16, 1.1102e-16, 0.0000e+00, 1.3878e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 4.4409e-16, 8.3267e-17, 3.3307e-16,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.7716e-16, 1.5543e-15, 0.0000e+00, 4.9960e-16,\n",
      "         0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00, 5.5511e-16, 4.4409e-16,\n",
      "         0.0000e+00, 8.8818e-16, 5.5511e-16, 1.3323e-15, 0.0000e+00, 2.2204e-16,\n",
      "         8.8818e-16, 5.5511e-16, 5.5511e-16, 8.8818e-16, 0.0000e+00, 4.4409e-16,\n",
      "         1.1102e-15, 4.4409e-16, 6.6613e-16, 0.0000e+00, 2.2204e-16, 5.5511e-16,\n",
      "         4.4409e-16, 0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 1.9429e-16, 8.8818e-16, 7.7716e-16, 0.0000e+00, 1.3323e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0206e-17, 4.4409e-16,\n",
      "         1.7764e-15, 0.0000e+00, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 4.4409e-16, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([  5,  20,  21,  22,  23,  25,  26,  36,  37,  39,  41,  42,  52,  55,\n",
      "         56,  58,  59,  62,  64,  66,  67,  68,  70,  72,  73,  74,  75,  76,\n",
      "         77,  78,  80,  81,  82,  84,  85,  87,  88,  89,  90,  92,  93,  94,\n",
      "         95,  96,  97,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124,\n",
      "        125, 126, 130, 132, 133, 134, 141, 143, 144, 145, 149, 150, 152, 153,\n",
      "        158, 160, 163, 164, 166, 171, 177, 180, 183, 184, 185, 187, 189, 194,\n",
      "        195, 197, 199, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 215,\n",
      "        216, 217, 218, 220, 221, 222, 224, 227, 229, 230, 231, 233, 237, 240,\n",
      "        244, 245, 246, 248, 253, 254])\n",
      "\n",
      "failing Cout = tensor([  5,  20,  21,  22,  23,  25,  26,  36,  37,  39,  41,  42,  52,  55,\n",
      "         56,  58,  59,  62,  64,  66,  67,  68,  70,  72,  73,  74,  75,  76,\n",
      "         77,  78,  80,  81,  82,  84,  85,  87,  88,  89,  90,  92,  93,  94,\n",
      "         95,  96,  97,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124,\n",
      "        125, 126, 130, 132, 133, 134, 141, 143, 144, 145, 149, 150, 152, 153,\n",
      "        158, 160, 163, 164, 166, 171, 177, 180, 183, 184, 185, 187, 189, 194,\n",
      "        195, 197, 199, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 215,\n",
      "        216, 217, 218, 220, 221, 222, 224, 227, 229, 230, 231, 233, 237, 240,\n",
      "        244, 245, 246, 248, 253, 254])  (len = 132)\n",
      "passing Cout = tensor([35, 48])  (len = 2)\n",
      "\n",
      "Executing module 43: layer3.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 43\n",
      "Max diff:\n",
      "tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[6.9389e-18, 6.9389e-18, 6.9389e-18, 3.4694e-18, 3.4694e-18, 2.1684e-18,\n",
      "         3.4694e-18, 1.3010e-18, 3.4694e-18, 1.0842e-18, 6.9389e-18, 1.7347e-18,\n",
      "         6.9389e-18, 1.7347e-18, 1.7347e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 1.7347e-18, 8.6736e-19, 3.4694e-18, 4.3368e-19,\n",
      "         6.9389e-18, 3.4694e-18, 1.7347e-18, 3.4694e-18, 1.7347e-18, 6.9389e-18,\n",
      "         1.7347e-18, 1.7347e-18, 6.9389e-18, 8.6736e-19, 6.9389e-18, 1.0842e-18,\n",
      "         6.9389e-18, 7.5894e-19, 3.4694e-18, 6.9389e-18, 6.9389e-18, 3.4694e-18,\n",
      "         6.9389e-18, 6.9389e-18, 8.6736e-19, 6.9389e-18, 3.4694e-18, 3.4694e-18,\n",
      "         8.6736e-19, 4.3368e-19, 6.9389e-18, 6.9389e-18, 3.4694e-18, 3.4694e-18,\n",
      "         6.9389e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18, 3.4694e-18,\n",
      "         6.9389e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18, 1.0658e-14, 1.0658e-14,\n",
      "         1.0658e-14, 8.8818e-15, 1.4211e-14, 2.1316e-14, 1.2434e-14, 1.4211e-14,\n",
      "         7.1054e-15, 1.4211e-14, 8.8818e-15, 1.0658e-14, 1.7764e-14, 8.8818e-15,\n",
      "         2.8422e-14, 1.7764e-14, 2.1316e-14, 2.1316e-14, 2.1316e-14, 1.0658e-14,\n",
      "         1.4211e-14, 1.4211e-14, 1.4211e-14, 9.7700e-15, 1.4211e-14, 1.4211e-14,\n",
      "         1.0658e-14, 1.0658e-14, 2.8422e-14, 1.2434e-14, 1.4211e-14, 1.0658e-14,\n",
      "         1.2434e-14, 1.0658e-14, 8.8818e-15, 1.4211e-14, 1.0658e-14, 1.0658e-14,\n",
      "         1.4211e-14, 1.0658e-14, 1.7764e-14, 7.9936e-15, 2.1316e-14, 1.0880e-14,\n",
      "         9.7700e-15, 1.4211e-14, 2.1316e-14, 1.4211e-14, 5.3291e-15, 1.4211e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.4211e-14, 1.7764e-14, 1.7764e-14, 1.0658e-14,\n",
      "         2.1316e-14, 1.4211e-14, 2.1316e-14, 1.4211e-14, 7.1054e-15, 8.8818e-15,\n",
      "         1.4211e-14, 2.1316e-14, 1.1102e-16, 2.2204e-16, 4.4409e-16, 8.8818e-16,\n",
      "         2.2204e-16, 1.1102e-16, 4.4409e-16, 1.1102e-16, 8.8818e-16, 4.4409e-16,\n",
      "         6.6613e-16, 2.2204e-16, 1.1102e-16, 1.1102e-16, 1.7764e-15, 7.7716e-16,\n",
      "         8.8818e-16, 8.8818e-16, 1.3323e-15, 2.2204e-16, 8.8818e-16, 5.5511e-17,\n",
      "         4.4409e-16, 3.3307e-16, 3.3307e-16, 5.5511e-17, 8.8818e-16, 1.1102e-16,\n",
      "         8.3267e-17, 5.5511e-17, 8.8818e-16, 8.8818e-16, 8.3267e-17, 6.6613e-16,\n",
      "         5.5511e-17, 8.8818e-16, 1.1102e-16, 8.8818e-16, 1.7764e-15, 6.6613e-16,\n",
      "         1.1102e-16, 1.1102e-16, 2.2204e-16, 1.1102e-16, 5.5511e-17, 4.4409e-16,\n",
      "         5.5511e-17, 8.8818e-16, 5.5511e-17, 1.1102e-16, 1.1102e-16, 2.7756e-17,\n",
      "         8.8818e-16, 8.8818e-16, 5.5511e-17, 4.4409e-16, 8.8818e-16, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 1.1102e-16, 2.2204e-16, 1.1102e-16, 5.5511e-17,\n",
      "         4.4409e-16, 3.5527e-15, 8.8818e-16, 8.8818e-16, 4.4409e-16, 2.2204e-15,\n",
      "         5.3291e-15, 2.2204e-16, 2.2204e-16, 4.4409e-16, 7.1054e-15, 7.1054e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.6645e-15, 3.3307e-16, 4.4409e-16, 2.2204e-16,\n",
      "         1.1102e-16, 5.3291e-15, 8.8818e-16, 2.4425e-15, 3.5527e-15, 3.5527e-15,\n",
      "         1.3323e-15, 2.2204e-16, 3.5527e-15, 4.4409e-16, 3.5527e-15, 3.3307e-16,\n",
      "         3.5527e-15, 2.6645e-15, 3.1086e-15, 1.7764e-15, 8.8818e-16, 1.7764e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.2204e-16, 5.3291e-15, 3.3307e-16, 3.1086e-15,\n",
      "         3.5527e-15, 2.6645e-15, 7.1054e-15, 8.8818e-16, 2.2204e-16, 3.5527e-15,\n",
      "         3.5527e-15, 8.8818e-16, 4.4409e-16, 4.4409e-16, 4.4409e-15, 8.8818e-16,\n",
      "         2.6645e-15, 8.8818e-16, 8.8818e-16, 8.8818e-16, 1.7764e-15, 3.5527e-15,\n",
      "         2.6645e-15, 3.5527e-15, 2.2204e-16, 8.8818e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 44: layer3.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 44\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.6021e-18, 1.7347e-18, 1.7347e-18, 1.7347e-18, 8.6736e-19, 1.7347e-18,\n",
      "         8.6736e-19, 4.3368e-19, 3.4694e-18, 4.3368e-19, 1.7347e-18, 3.4694e-18,\n",
      "         1.7347e-18, 8.6736e-19, 4.3368e-19, 8.6736e-19, 1.6568e-18, 1.7347e-18,\n",
      "         8.6736e-19, 8.6736e-19, 1.7347e-18, 0.0000e+00, 8.6736e-19, 1.7347e-18,\n",
      "         1.7347e-18, 8.6736e-19, 1.7347e-18, 1.7347e-18, 8.6736e-19, 1.7347e-18,\n",
      "         3.4694e-18, 8.6736e-19, 1.7347e-18, 0.0000e+00, 3.4694e-18, 3.4694e-18,\n",
      "         1.9516e-18, 8.6736e-19, 8.6736e-19, 3.4694e-18, 2.1684e-18, 6.9389e-18,\n",
      "         1.7347e-18, 1.7347e-18, 4.3368e-19, 1.7347e-18, 8.6736e-19, 8.6736e-19,\n",
      "         1.7347e-18, 8.6736e-19, 1.7347e-18, 2.6021e-18, 9.7578e-19, 3.4694e-18,\n",
      "         1.7347e-18, 1.7347e-18, 1.9516e-18, 1.7347e-18, 1.7347e-18, 1.7347e-18,\n",
      "         1.7347e-18, 1.3010e-18, 1.7347e-18, 1.7347e-18, 4.4409e-15, 5.3291e-15,\n",
      "         5.3291e-15, 3.5527e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15,\n",
      "         3.5527e-15, 5.3291e-15, 4.4409e-15, 5.3291e-15, 1.0658e-14, 4.4409e-15,\n",
      "         1.0658e-14, 7.1054e-15, 1.4211e-14, 1.0658e-14, 1.4211e-14, 3.5527e-15,\n",
      "         7.1054e-15, 5.3291e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15, 8.8818e-15,\n",
      "         4.4409e-15, 1.3323e-15, 1.4211e-14, 6.2172e-15, 8.8818e-15, 4.4409e-15,\n",
      "         5.3291e-15, 3.9968e-15, 4.8850e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15,\n",
      "         8.8818e-15, 3.5527e-15, 7.1054e-15, 2.9976e-15, 1.0658e-14, 4.6629e-15,\n",
      "         3.9968e-15, 7.1054e-15, 1.4211e-14, 5.1070e-15, 1.3323e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.5527e-15, 3.5527e-15, 7.1054e-15, 4.8850e-15, 3.5527e-15,\n",
      "         8.8818e-15, 5.3291e-15, 1.0658e-14, 7.1054e-15, 3.5527e-15, 4.4409e-15,\n",
      "         7.1054e-15, 8.8818e-15, 2.7756e-17, 5.5511e-17, 1.1102e-16, 2.4980e-16,\n",
      "         5.5511e-17, 2.7756e-17, 1.1102e-16, 2.7756e-17, 2.2204e-16, 1.1102e-16,\n",
      "         1.1102e-16, 5.5511e-17, 2.7756e-17, 2.7756e-17, 4.4409e-16, 2.2204e-16,\n",
      "         3.3307e-16, 2.2204e-16, 4.4409e-16, 5.5511e-17, 1.1102e-16, 1.3878e-17,\n",
      "         1.1102e-16, 5.5511e-17, 5.5511e-17, 6.9389e-18, 4.4409e-16, 2.7756e-17,\n",
      "         1.3878e-17, 1.3878e-17, 2.2204e-16, 1.6653e-16, 2.0817e-17, 1.1102e-16,\n",
      "         2.7756e-17, 1.6653e-16, 2.7756e-17, 1.8041e-16, 6.6613e-16, 1.3878e-16,\n",
      "         2.7756e-17, 2.7756e-17, 5.5511e-17, 2.7756e-17, 1.3878e-17, 1.1102e-16,\n",
      "         1.3878e-17, 1.6653e-16, 1.3878e-17, 2.7756e-17, 2.7756e-17, 6.9389e-18,\n",
      "         2.2204e-16, 2.2204e-16, 1.3878e-17, 1.1102e-16, 1.1102e-16, 5.5511e-17,\n",
      "         1.1102e-16, 1.1102e-16, 2.7756e-17, 2.7756e-17, 2.7756e-17, 1.3878e-17,\n",
      "         1.1102e-16, 8.8818e-16, 2.2204e-16, 2.2204e-16, 1.1102e-16, 3.3307e-16,\n",
      "         1.3323e-15, 5.5511e-17, 5.5511e-17, 1.1102e-16, 3.5527e-15, 3.5527e-15,\n",
      "         4.4409e-16, 8.8818e-16, 1.3323e-15, 8.3267e-17, 1.1102e-16, 1.1102e-16,\n",
      "         2.7756e-17, 2.6645e-15, 2.2204e-16, 7.2164e-16, 1.7764e-15, 8.8818e-16,\n",
      "         3.3307e-16, 5.5511e-17, 8.8818e-16, 1.1102e-16, 1.7764e-15, 8.3267e-17,\n",
      "         6.6613e-16, 9.9920e-16, 1.3323e-15, 4.4409e-16, 2.2204e-16, 3.3307e-16,\n",
      "         8.8818e-16, 8.8818e-16, 5.5511e-17, 1.3323e-15, 1.1102e-16, 8.8818e-16,\n",
      "         1.3323e-15, 8.8818e-16, 1.7764e-15, 2.2204e-16, 5.5511e-17, 8.8818e-16,\n",
      "         1.3323e-15, 2.2204e-16, 1.1102e-16, 1.1102e-16, 1.7764e-15, 4.4409e-16,\n",
      "         6.6613e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16, 8.8818e-16,\n",
      "         4.4409e-16, 1.3323e-15, 5.5511e-17, 2.2204e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])  (len = 254)\n",
      "passing Cout = tensor([21, 33])  (len = 2)\n",
      "\n",
      "Executing module 45: layer3.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 45\n",
      "Max diff:\n",
      "tensor([6.2172e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 8.6736e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         4.2013e-19, 0.0000e+00, 3.4694e-18, 0.0000e+00, 1.7347e-18, 3.4694e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6568e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 8.6736e-19, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         3.4694e-18, 0.0000e+00, 8.6736e-19, 0.0000e+00, 3.4694e-18, 3.4694e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18, 8.6736e-19, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 2.6021e-18, 4.3368e-19, 3.4694e-18,\n",
      "         1.7347e-18, 8.6736e-19, 8.6736e-19, 8.9955e-19, 0.0000e+00, 1.7347e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18, 1.3323e-15, 3.9968e-15,\n",
      "         8.8818e-16, 1.7764e-15, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.5527e-15, 8.8818e-16, 6.6613e-16, 1.9706e-15, 9.9920e-16, 1.9984e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2490e-15, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 9.9920e-16, 1.7208e-15, 3.8303e-15, 0.0000e+00,\n",
      "         1.6740e-15, 0.0000e+00, 0.0000e+00, 6.2172e-15, 0.0000e+00, 1.5543e-15,\n",
      "         2.8866e-15, 7.7716e-16, 4.1078e-15, 1.7764e-15, 0.0000e+00, 1.1102e-15,\n",
      "         4.4409e-16, 1.3323e-15, 0.0000e+00, 2.3037e-15, 0.0000e+00, 4.6629e-15,\n",
      "         2.8866e-15, 6.1062e-16, 2.2204e-15, 2.6645e-15, 0.0000e+00, 0.0000e+00,\n",
      "         4.2188e-15, 1.3323e-15, 1.7764e-15, 2.6645e-15, 8.8818e-16, 1.3323e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9429e-16, 8.8818e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4980e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0470e-16, 1.9429e-16,\n",
      "         1.1102e-16, 9.7145e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.6653e-16, 1.5266e-16, 0.0000e+00, 4.8572e-17,\n",
      "         0.0000e+00, 1.6653e-16, 0.0000e+00, 1.8041e-16, 8.3267e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.6653e-16, 3.4694e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-16, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4572e-16, 8.3267e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-16, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([  1,   5,   6,   8,  10,  11,  12,  16,  20,  22,  26,  29,  30,  32,\n",
      "         34,  35,  36,  39,  40,  41,  45,  48,  51,  52,  53,  54,  55,  56,\n",
      "         57,  59,  60,  63,  64,  65,  66,  67,  68,  72,  73,  74,  75,  76,\n",
      "         77,  81,  83,  86,  87,  88,  90,  93,  95,  96,  97,  98,  99, 101,\n",
      "        102, 103, 105, 107, 108, 109, 110, 111, 114, 115, 116, 117, 118, 119,\n",
      "        124, 125, 131, 142, 143, 144, 145, 154, 158, 159, 161, 163, 165, 166,\n",
      "        180, 181, 198, 203, 206, 213, 223, 224, 228, 229, 233, 234, 244, 253])\n",
      "\n",
      "failing Cout = tensor([  1,   5,   6,   8,  10,  11,  12,  16,  20,  22,  26,  29,  30,  32,\n",
      "         34,  35,  36,  39,  40,  41,  45,  48,  51,  52,  53,  54,  55,  56,\n",
      "         57,  59,  60,  63,  64,  65,  66,  67,  68,  72,  73,  74,  75,  76,\n",
      "         77,  81,  83,  86,  87,  88,  90,  93,  95,  96,  97,  98,  99, 101,\n",
      "        102, 103, 105, 107, 108, 109, 110, 111, 114, 115, 116, 117, 118, 119,\n",
      "        124, 125, 131, 142, 143, 144, 145, 154, 158, 159, 161, 163, 165, 166,\n",
      "        180, 181, 198, 203, 206, 213, 223, 224, 228, 229, 233, 234, 244, 253])  (len = 98)\n",
      "passing Cout = tensor([ 0,  2,  4, 14, 15, 21, 24, 25, 33, 42, 43, 58, 61])  (len = 13)\n",
      "\n",
      "Executing module 46: layer3.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 46\n",
      "Max diff:\n",
      "tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.8789e-19, 3.4694e-18, 1.7347e-18, 0.0000e+00, 3.4694e-18, 3.4694e-18,\n",
      "         1.7347e-18, 1.7347e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18,\n",
      "         6.9389e-18, 6.9389e-18, 8.6736e-19, 1.7347e-18, 6.9389e-18, 0.0000e+00,\n",
      "         6.9389e-18, 3.4694e-18, 4.3368e-19, 1.7347e-18, 3.4694e-18, 1.7347e-18,\n",
      "         3.4694e-18, 0.0000e+00, 1.7347e-18, 3.4694e-18, 8.6736e-19, 3.4694e-18,\n",
      "         1.7347e-18, 0.0000e+00, 4.3368e-19, 1.7347e-18, 6.9389e-18, 6.9389e-18,\n",
      "         8.6736e-19, 8.6736e-19, 1.7347e-18, 3.4694e-18, 1.7347e-18, 1.7347e-18,\n",
      "         8.6736e-19, 3.4694e-18, 3.4694e-18, 6.9389e-18, 1.7347e-18, 3.4694e-18,\n",
      "         8.6736e-19, 1.7347e-18, 8.6736e-19, 6.9389e-18, 1.7347e-18, 3.4694e-18,\n",
      "         3.4694e-18, 0.0000e+00, 1.7347e-18, 6.9389e-18, 3.4694e-18, 1.7347e-18,\n",
      "         3.4694e-18, 3.4694e-18, 1.7347e-18, 1.7347e-18, 7.1054e-15, 5.3291e-15,\n",
      "         5.3291e-15, 3.5527e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15,\n",
      "         5.3291e-15, 5.3291e-15, 5.3291e-15, 4.4409e-15, 4.4409e-15, 4.6629e-15,\n",
      "         8.8818e-15, 5.3291e-15, 4.4409e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15,\n",
      "         8.8818e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15, 1.0658e-14, 3.5527e-15,\n",
      "         5.3291e-15, 5.3291e-15, 7.1054e-15, 5.3291e-15, 3.5527e-15, 3.9968e-15,\n",
      "         3.5527e-15, 7.1054e-15, 5.3291e-15, 3.5527e-15, 4.4409e-15, 5.3291e-15,\n",
      "         2.3315e-15, 4.8850e-15, 8.8818e-15, 7.1054e-15, 3.5527e-15, 7.1054e-15,\n",
      "         5.3291e-15, 5.7732e-15, 8.8818e-15, 3.5527e-15, 3.5527e-15, 7.1054e-15,\n",
      "         5.3291e-15, 5.3291e-15, 7.1054e-15, 6.2172e-15, 3.9968e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.5527e-15, 5.3291e-15, 8.8818e-15, 5.3291e-15, 5.7732e-15,\n",
      "         5.3291e-15, 6.2172e-15, 3.3307e-16, 3.3307e-16, 5.5511e-16, 5.5511e-17,\n",
      "         2.2204e-16, 2.2204e-16, 1.1102e-16, 3.3307e-16, 2.7756e-17, 1.1102e-16,\n",
      "         1.3878e-16, 4.1633e-17, 4.1633e-17, 6.6613e-16, 5.5511e-17, 8.3267e-17,\n",
      "         2.2204e-16, 2.2204e-16, 4.4409e-16, 5.5511e-16, 4.1633e-17, 3.3307e-16,\n",
      "         1.6653e-16, 2.2204e-16, 2.2204e-16, 8.8818e-16, 9.7145e-17, 4.1633e-17,\n",
      "         3.3307e-16, 5.5511e-17, 4.4409e-16, 2.7756e-17, 3.3307e-16, 1.1102e-16,\n",
      "         6.6613e-16, 2.2204e-16, 3.3307e-16, 5.5511e-17, 3.3307e-16, 6.2450e-17,\n",
      "         1.6653e-16, 1.1102e-16, 2.2204e-16, 3.3307e-16, 2.7756e-16, 1.6653e-16,\n",
      "         4.4409e-16, 2.7756e-17, 4.4409e-16, 1.1102e-16, 2.2204e-16, 2.0817e-17,\n",
      "         2.2204e-16, 8.3267e-17, 2.0817e-17, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.1633e-17, 1.1102e-16, 1.1102e-16, 5.5511e-16, 5.5511e-17, 2.2204e-16,\n",
      "         1.1102e-16, 4.4409e-16, 6.6613e-16, 1.7764e-15, 8.8818e-16, 5.5511e-16,\n",
      "         1.3323e-15, 1.1102e-15, 8.8818e-16, 8.8818e-16, 4.4409e-16, 5.5511e-16,\n",
      "         1.7764e-15, 5.5511e-16, 6.6613e-16, 4.4409e-16, 1.1102e-16, 7.7716e-16,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 1.6653e-16, 9.9920e-16,\n",
      "         6.6613e-16, 1.7764e-15, 4.4409e-16, 5.6899e-16, 8.8818e-16, 6.6613e-16,\n",
      "         8.8818e-16, 8.8818e-16, 6.6613e-16, 4.4409e-16, 3.3307e-16, 8.8818e-16,\n",
      "         4.4409e-16, 8.8818e-16, 8.8818e-16, 5.5511e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 1.1102e-16, 8.8818e-16, 7.7716e-16, 1.3323e-15, 5.5511e-16,\n",
      "         1.1102e-15, 6.6613e-16, 5.5511e-16, 8.8818e-16, 1.3323e-15, 7.7716e-16,\n",
      "         9.9920e-16, 6.6613e-16, 4.4409e-16, 5.5511e-16, 1.6653e-16, 5.5511e-17,\n",
      "         1.3323e-15, 5.1348e-16, 6.6613e-16, 6.6613e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  18,  19,  20,  21,  22,  23,  24,  26,  27,  28,  29,  30,\n",
      "         32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "         46,  47,  48,  49,  50,  51,  52,  53,  54,  56,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "         89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "        103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
      "        145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
      "        173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
      "        187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "        201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "        215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  18,  19,  20,  21,  22,  23,  24,  26,  27,  28,  29,  30,\n",
      "         32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "         46,  47,  48,  49,  50,  51,  52,  53,  54,  56,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "         89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "        103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
      "        145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "        159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
      "        173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
      "        187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "        201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "        215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 251)\n",
      "passing Cout = tensor([ 3, 17, 25, 31, 55])  (len = 5)\n",
      "\n",
      "Executing module 47: layer3.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 47\n",
      "Max diff:\n",
      "tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 4.3368e-19, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 6.9389e-18, 6.9389e-18, 1.3878e-17, 0.0000e+00,\n",
      "         4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 8.6736e-19, 0.0000e+00, 3.4694e-18, 0.0000e+00, 4.3368e-19,\n",
      "         4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 8.6736e-19,\n",
      "         4.3368e-19, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 1.7347e-18,\n",
      "         8.6736e-19, 0.0000e+00, 0.0000e+00, 3.4694e-18, 1.7347e-18, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 4.3368e-19, 2.6645e-15, 1.7764e-15,\n",
      "         2.2204e-15, 1.1102e-15, 2.2204e-15, 1.7764e-15, 2.4425e-15, 2.6645e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.5527e-15, 2.2204e-15, 2.2204e-15, 1.8874e-15,\n",
      "         4.4409e-15, 2.6645e-15, 2.2204e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15,\n",
      "         3.5527e-15, 2.6645e-15, 2.6645e-15, 2.6645e-15, 7.1054e-15, 8.8818e-16,\n",
      "         2.2204e-15, 2.2204e-15, 3.5527e-15, 1.7764e-15, 8.8818e-16, 1.4433e-15,\n",
      "         1.3323e-15, 4.4409e-15, 8.8818e-16, 1.3323e-15, 9.9920e-16, 2.2204e-15,\n",
      "         4.4409e-16, 1.7764e-15, 3.1086e-15, 3.5527e-15, 1.3323e-15, 1.2212e-15,\n",
      "         2.2204e-15, 2.2204e-15, 3.5527e-15, 6.6613e-16, 1.3323e-15, 4.4409e-15,\n",
      "         1.7764e-15, 3.5527e-15, 3.5527e-15, 2.6645e-15, 1.3323e-15, 2.6645e-15,\n",
      "         1.5543e-15, 8.8818e-16, 1.7764e-15, 5.3291e-15, 1.7764e-15, 1.1657e-15,\n",
      "         2.4425e-15, 3.5527e-15, 1.1102e-16, 4.1633e-17, 1.6653e-16, 1.3878e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3267e-17, 6.9389e-18, 2.7756e-17,\n",
      "         2.7756e-17, 1.3878e-17, 6.9389e-18, 1.1102e-16, 1.3878e-17, 1.3878e-17,\n",
      "         1.3878e-17, 5.5511e-17, 1.6653e-16, 8.3267e-17, 1.0408e-17, 8.3267e-17,\n",
      "         5.5511e-17, 8.3267e-17, 4.1633e-17, 3.3307e-16, 0.0000e+00, 1.3878e-17,\n",
      "         1.3878e-16, 1.3878e-17, 2.7756e-17, 6.9389e-18, 4.1633e-17, 1.3878e-17,\n",
      "         1.1102e-16, 5.5511e-17, 5.5511e-17, 6.9389e-18, 1.1796e-16, 0.0000e+00,\n",
      "         3.4694e-17, 3.4694e-18, 6.9389e-18, 3.8164e-17, 2.7756e-17, 2.7756e-17,\n",
      "         1.1102e-16, 6.9389e-18, 1.1102e-16, 6.9389e-18, 2.7756e-17, 6.9389e-18,\n",
      "         7.2858e-17, 1.3878e-17, 6.9389e-18, 5.5511e-17, 5.5511e-17, 8.3267e-17,\n",
      "         6.9389e-18, 1.3878e-17, 2.7756e-17, 1.3878e-16, 1.3878e-17, 5.5511e-17,\n",
      "         2.7756e-17, 1.1102e-16, 1.1102e-16, 5.5511e-16, 3.3307e-16, 2.7756e-17,\n",
      "         6.6613e-16, 2.0817e-16, 2.2204e-16, 1.1102e-16, 2.7756e-17, 8.3267e-17,\n",
      "         8.8818e-16, 2.2204e-16, 5.5511e-17, 2.2204e-16, 2.7756e-17, 2.2204e-16,\n",
      "         2.2204e-16, 3.4694e-18, 5.5511e-17, 3.3307e-16, 2.7756e-17, 5.4123e-16,\n",
      "         8.3267e-17, 6.6613e-16, 5.5511e-17, 3.0878e-16, 2.2204e-16, 8.3267e-17,\n",
      "         2.7756e-17, 2.2204e-16, 1.3878e-17, 8.3267e-17, 5.5511e-17, 5.5511e-17,\n",
      "         5.5511e-17, 4.4409e-16, 2.7756e-16, 1.8735e-16, 2.2204e-16, 3.3307e-16,\n",
      "         4.4409e-16, 2.7756e-17, 2.7756e-16, 2.2204e-16, 4.4409e-16, 1.0235e-16,\n",
      "         2.2204e-16, 8.3267e-17, 5.5511e-17, 2.2204e-16, 4.4409e-16, 1.3878e-16,\n",
      "         4.1633e-16, 5.5511e-17, 4.1633e-17, 0.0000e+00, 5.5511e-17, 6.9389e-18,\n",
      "         8.8818e-16, 1.3878e-17, 1.8041e-16, 5.5511e-17]], dtype=torch.float64)\n",
      "tensor([  5,   6,  11,  12,  15,  18,  22,  24,  26,  27,  28,  30,  35,  37,\n",
      "         39,  41,  42,  46,  47,  48,  51,  53,  54,  57,  58,  60,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 135, 136, 137,\n",
      "        138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "        152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  5,   6,  11,  12,  15,  18,  22,  24,  26,  27,  28,  30,  35,  37,\n",
      "         39,  41,  42,  46,  47,  48,  51,  53,  54,  57,  58,  60,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 135, 136, 137,\n",
      "        138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "        152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 213)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   7,   8,   9,  10,  13,  14,  16,  17,  19,\n",
      "         20,  21,  23,  25,  29,  31,  32,  33,  34,  36,  38,  40,  43,  44,\n",
      "         45,  49,  50,  52,  55,  56,  59,  61,  62, 132, 133, 134, 154, 167,\n",
      "        249])  (len = 43)\n",
      "\n",
      "Executing module 48: layer3.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 48\n",
      "Max diff:\n",
      "tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 4.3368e-19, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 1.3878e-17, 1.3878e-17, 3.4694e-18, 1.3878e-17,\n",
      "         1.7347e-18, 6.9389e-18, 1.3878e-17, 6.9389e-18, 1.3878e-17, 0.0000e+00,\n",
      "         4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         1.3878e-17, 3.4694e-18, 0.0000e+00, 1.3878e-17, 0.0000e+00, 6.9389e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 8.6736e-19,\n",
      "         4.3368e-19, 0.0000e+00, 0.0000e+00, 6.9389e-18, 3.4694e-18, 1.7347e-18,\n",
      "         8.6736e-19, 2.7756e-17, 1.3878e-17, 3.4694e-18, 1.7347e-18, 2.7756e-17,\n",
      "         1.7347e-18, 0.0000e+00, 2.7756e-17, 4.3368e-19, 2.6645e-15, 1.7764e-15,\n",
      "         2.2204e-15, 1.1102e-15, 2.2204e-15, 1.7764e-15, 5.3291e-15, 2.6645e-15,\n",
      "         2.6645e-15, 3.5527e-15, 5.3291e-15, 2.6645e-15, 2.6645e-15, 1.8874e-15,\n",
      "         3.9968e-15, 2.6645e-15, 4.4409e-15, 4.8850e-15, 1.7764e-15, 3.5527e-15,\n",
      "         3.5527e-15, 2.6645e-15, 2.6645e-15, 3.1086e-15, 7.1054e-15, 1.9984e-15,\n",
      "         2.2204e-15, 2.2204e-15, 3.5527e-15, 1.7764e-15, 4.4409e-15, 3.5527e-15,\n",
      "         1.7764e-15, 5.3291e-15, 8.8818e-16, 2.4425e-15, 2.6645e-15, 2.6645e-15,\n",
      "         1.1102e-15, 3.5527e-15, 3.1086e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15,\n",
      "         3.1086e-15, 2.2204e-15, 3.5527e-15, 1.3323e-15, 2.2204e-15, 4.4409e-15,\n",
      "         3.5527e-15, 5.3291e-15, 3.5527e-15, 3.9968e-15, 1.3323e-15, 2.6645e-15,\n",
      "         2.6645e-15, 2.8866e-15, 1.7764e-15, 5.3291e-15, 1.7764e-15, 1.3323e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.1102e-16, 4.1633e-17, 2.2204e-16, 1.3878e-17,\n",
      "         1.1102e-16, 2.7756e-17, 5.5511e-17, 8.3267e-17, 6.9389e-18, 2.7756e-17,\n",
      "         2.7756e-17, 1.3878e-17, 6.9389e-18, 1.1102e-16, 1.3878e-17, 1.6653e-16,\n",
      "         1.6653e-16, 1.6653e-16, 1.6653e-16, 8.3267e-17, 1.0408e-17, 3.3307e-16,\n",
      "         5.5511e-17, 8.3267e-17, 6.2450e-17, 4.4409e-16, 0.0000e+00, 1.3878e-17,\n",
      "         1.3878e-16, 1.3878e-17, 3.8858e-16, 6.9389e-18, 5.5511e-17, 1.3878e-17,\n",
      "         1.1102e-16, 1.3184e-16, 1.2490e-16, 6.9389e-18, 1.1102e-16, 0.0000e+00,\n",
      "         3.4694e-17, 3.4694e-18, 6.9389e-18, 3.8164e-17, 2.7756e-17, 2.7756e-17,\n",
      "         1.1102e-16, 6.9389e-18, 1.1102e-16, 1.3878e-16, 2.7756e-17, 6.9389e-18,\n",
      "         7.2858e-17, 1.3878e-17, 6.9389e-18, 4.4409e-16, 8.3267e-17, 3.3307e-16,\n",
      "         6.9389e-18, 4.4409e-16, 2.7756e-17, 1.9429e-16, 1.3878e-17, 5.5511e-17,\n",
      "         2.7756e-17, 1.1102e-16, 7.7716e-16, 1.5543e-15, 3.3307e-16, 5.2736e-16,\n",
      "         6.6613e-16, 8.8818e-16, 2.2204e-16, 1.1102e-16, 5.5511e-16, 4.4409e-16,\n",
      "         8.8818e-16, 8.8818e-16, 5.5511e-16, 1.3323e-15, 2.7756e-17, 2.2204e-16,\n",
      "         8.8818e-16, 5.5511e-16, 5.5511e-16, 1.3323e-15, 2.7756e-17, 5.4123e-16,\n",
      "         1.1102e-15, 6.6613e-16, 6.6613e-16, 3.0878e-16, 3.3307e-16, 5.5511e-16,\n",
      "         4.4409e-16, 2.2204e-16, 8.8818e-16, 8.3267e-17, 5.5511e-17, 4.4409e-16,\n",
      "         5.5511e-17, 4.4409e-16, 7.7716e-16, 8.3267e-16, 2.2204e-16, 1.3323e-15,\n",
      "         4.4409e-16, 2.7756e-17, 2.7756e-16, 9.9920e-16, 4.4409e-16, 1.0235e-16,\n",
      "         1.1102e-15, 8.3267e-17, 5.5511e-17, 2.2204e-16, 4.4409e-16, 4.4409e-16,\n",
      "         3.5527e-15, 5.5511e-17, 1.1796e-16, 0.0000e+00, 5.5511e-17, 6.9389e-18,\n",
      "         8.8818e-16, 4.4409e-16, 6.6613e-16, 5.5511e-17]], dtype=torch.float64)\n",
      "tensor([  5,   6,  11,  12,  15,  18,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  30,  35,  36,  37,  39,  41,  42,  46,  47,  48,  51,  52,  53,\n",
      "         54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
      "        153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([  5,   6,  11,  12,  15,  18,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  30,  35,  36,  37,  39,  41,  42,  46,  47,  48,  51,  52,  53,\n",
      "         54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
      "        153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253,\n",
      "        254, 255])  (len = 226)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   7,   8,   9,  10,  13,  14,  16,  17,  19,\n",
      "         29,  31,  32,  33,  34,  38,  40,  43,  44,  45,  49,  50,  61, 154,\n",
      "        167, 249])  (len = 30)\n",
      "\n",
      "Executing module 49: layer3.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 49\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 1.3878e-17, 1.3878e-17, 3.4694e-18, 1.3878e-17,\n",
      "         1.7347e-18, 6.9389e-18, 1.3878e-17, 6.9389e-18, 1.3878e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         1.3878e-17, 3.4694e-18, 0.0000e+00, 1.3878e-17, 0.0000e+00, 6.9389e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 3.4694e-18, 1.7347e-18,\n",
      "         0.0000e+00, 2.7756e-17, 1.3878e-17, 3.4694e-18, 1.7347e-18, 2.7756e-17,\n",
      "         1.7347e-18, 0.0000e+00, 2.7756e-17, 0.0000e+00, 2.2204e-16, 1.3045e-15,\n",
      "         1.7764e-15, 4.4409e-16, 1.7764e-15, 1.7764e-15, 5.3291e-15, 0.0000e+00,\n",
      "         6.6613e-16, 3.5527e-15, 5.3291e-15, 1.9984e-15, 2.6645e-15, 7.9797e-16,\n",
      "         6.6613e-16, 1.2212e-15, 4.4409e-15, 4.8850e-15, 4.3021e-16, 0.0000e+00,\n",
      "         2.6645e-15, 1.5543e-15, 7.6328e-16, 8.8818e-16, 2.2204e-15, 1.7764e-15,\n",
      "         6.6613e-16, 1.1102e-15, 1.7764e-15, 4.9960e-16, 4.4409e-15, 3.5527e-15,\n",
      "         1.7764e-15, 2.6645e-15, 4.4409e-16, 8.8818e-16, 2.6645e-15, 2.6645e-15,\n",
      "         1.1102e-15, 3.5527e-15, 2.4425e-15, 1.9984e-15, 3.5527e-15, 5.3291e-15,\n",
      "         2.6645e-15, 8.8818e-16, 9.4369e-16, 1.1102e-15, 1.7764e-15, 0.0000e+00,\n",
      "         3.5527e-15, 2.4425e-15, 0.0000e+00, 3.5527e-15, 1.3323e-15, 8.8818e-16,\n",
      "         2.6645e-15, 2.8866e-15, 6.6613e-16, 0.0000e+00, 0.0000e+00, 1.3323e-15,\n",
      "         5.3291e-15, 4.1633e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 5.2042e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00, 1.6653e-16,\n",
      "         1.6653e-16, 1.1102e-16, 2.0817e-17, 2.4286e-17, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 2.7756e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-16, 0.0000e+00, 3.8858e-16, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-16, 1.2490e-16, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-16, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 0.0000e+00, 4.4409e-16, 8.3267e-17, 3.3307e-16,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 1.9429e-16, 0.0000e+00, 4.8572e-17,\n",
      "         0.0000e+00, 0.0000e+00, 7.7716e-16, 1.5543e-15, 1.7922e-16, 5.2736e-16,\n",
      "         1.7347e-16, 8.8818e-16, 6.0715e-17, 0.0000e+00, 5.5511e-16, 4.4409e-16,\n",
      "         2.4980e-16, 8.8818e-16, 5.5511e-16, 1.3323e-15, 0.0000e+00, 2.2204e-16,\n",
      "         8.8818e-16, 5.5511e-16, 5.5511e-16, 1.3323e-15, 0.0000e+00, 4.4409e-16,\n",
      "         1.1102e-15, 5.5511e-16, 6.6613e-16, 2.2204e-16, 3.3307e-16, 5.5511e-16,\n",
      "         4.4409e-16, 5.5511e-17, 8.8818e-16, 1.0842e-17, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 2.6368e-16, 5.5511e-16, 5.5511e-16, 0.0000e+00, 1.3323e-15,\n",
      "         1.6653e-16, 0.0000e+00, 1.2490e-16, 9.9920e-16, 1.2186e-16, 1.0235e-16,\n",
      "         1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3592e-16, 4.4409e-16,\n",
      "         3.5527e-15, 0.0000e+00, 1.1796e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.6082e-16, 4.4409e-16, 6.6613e-16, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([  5,   6,  11,  18,  20,  21,  22,  23,  24,  25,  26,  27,  28,  35,\n",
      "         36,  37,  39,  41,  42,  46,  51,  52,  53,  55,  56,  57,  58,  59,\n",
      "         60,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,\n",
      "         77,  78,  79,  80,  81,  82,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121,\n",
      "        122, 125, 126, 127, 130, 132, 135, 141, 143, 144, 145, 146, 147, 149,\n",
      "        152, 153, 156, 158, 160, 163, 164, 166, 171, 177, 180, 183, 184, 185,\n",
      "        187, 189, 191, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205,\n",
      "        206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 227, 229, 230, 231, 233, 234, 236, 237, 238, 239,\n",
      "        240, 244, 245, 246, 248, 252, 253, 254])\n",
      "\n",
      "failing Cout = tensor([  5,   6,  11,  18,  20,  21,  22,  23,  24,  25,  26,  27,  28,  35,\n",
      "         36,  37,  39,  41,  42,  46,  51,  52,  53,  55,  56,  57,  58,  59,\n",
      "         60,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,\n",
      "         77,  78,  79,  80,  81,  82,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121,\n",
      "        122, 125, 126, 127, 130, 132, 135, 141, 143, 144, 145, 146, 147, 149,\n",
      "        152, 153, 156, 158, 160, 163, 164, 166, 171, 177, 180, 183, 184, 185,\n",
      "        187, 189, 191, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205,\n",
      "        206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 227, 229, 230, 231, 233, 234, 236, 237, 238, 239,\n",
      "        240, 244, 245, 246, 248, 252, 253, 254])  (len = 162)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   7,   8,   9,  10,  13,  14,  16,  17,  19,\n",
      "         29,  31,  32,  33,  34,  38,  40,  43,  45,  49,  50,  54,  61, 134])  (len = 28)\n",
      "\n",
      "Executing module 50: layer4.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 50\n",
      "Max diff:\n",
      "tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 5.5511e-17, 2.7756e-17, 2.7756e-17,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-17, 5.5511e-17, 1.3878e-17, 0.0000e+00, 2.7756e-17, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 2.7756e-17,\n",
      "         0.0000e+00, 1.3878e-17, 1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 1.3878e-17, 0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 5.5511e-17, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-17, 8.8818e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.2434e-14, 7.1054e-15, 4.6629e-15, 5.3291e-15, 4.4409e-15, 4.8850e-15,\n",
      "         1.4211e-14, 1.4211e-14, 5.3291e-15, 1.0658e-14, 6.2172e-15, 8.8818e-15,\n",
      "         7.1054e-15, 7.1054e-15, 8.8818e-15, 7.9936e-15, 7.1054e-15, 5.3291e-15,\n",
      "         7.1054e-15, 7.1054e-15, 7.7716e-15, 7.1054e-15, 7.1054e-15, 2.8422e-14,\n",
      "         1.4211e-14, 7.1054e-15, 8.8818e-15, 5.3291e-15, 6.2172e-15, 7.1054e-15,\n",
      "         7.1054e-15, 3.5527e-15, 7.1054e-15, 7.1054e-15, 8.8818e-15, 1.4211e-14,\n",
      "         1.0658e-14, 5.3291e-15, 8.8818e-15, 7.1054e-15, 3.5527e-15, 1.4211e-14,\n",
      "         3.5527e-15, 7.1054e-15, 6.2172e-15, 7.1054e-15, 1.0658e-14, 1.0658e-14,\n",
      "         6.6613e-15, 8.8818e-15, 1.2434e-14, 4.4409e-15, 7.1054e-15, 4.6629e-15,\n",
      "         7.1054e-15, 1.4211e-14, 8.8818e-15, 7.1054e-15, 7.1054e-15, 6.2172e-15,\n",
      "         6.2172e-15, 7.1054e-15, 7.1054e-15, 1.0658e-14, 3.5527e-15, 7.1054e-15,\n",
      "         1.0658e-14, 3.5527e-15, 5.3291e-15, 7.1054e-15, 1.0658e-14, 4.7184e-15,\n",
      "         7.1054e-15, 3.5527e-15, 7.1054e-15, 5.3291e-15, 1.0658e-14, 1.0658e-14,\n",
      "         7.1054e-15, 8.8818e-15, 7.1054e-15, 7.1054e-15, 1.0658e-14, 8.8818e-15,\n",
      "         7.1054e-15, 1.0658e-14, 7.1054e-15, 1.4211e-14, 4.4409e-15, 1.4211e-14,\n",
      "         6.2172e-15, 7.1054e-15, 8.8818e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.0658e-14, 3.5527e-15, 4.4409e-15, 1.4211e-14, 5.3291e-15, 1.0658e-14,\n",
      "         5.7732e-15, 8.8818e-15, 1.4211e-14, 5.3291e-15, 7.1054e-15, 1.0658e-14,\n",
      "         6.2172e-15, 7.1054e-15, 7.1054e-15, 1.4211e-14, 1.0658e-14, 1.0658e-14,\n",
      "         5.3291e-15, 7.1054e-15, 4.2188e-15, 1.0658e-14, 1.0658e-14, 7.1054e-15,\n",
      "         1.0658e-14, 1.4211e-14, 5.1070e-15, 6.2172e-15, 1.1102e-16, 2.2204e-16,\n",
      "         4.4409e-16, 4.4409e-16, 8.8818e-16, 5.5511e-17, 1.1102e-16, 8.8818e-16,\n",
      "         8.8818e-16, 1.7764e-15, 6.6613e-16, 4.4409e-16, 1.7764e-15, 4.4409e-16,\n",
      "         1.1102e-16, 6.6613e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 1.1102e-16,\n",
      "         8.8818e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16, 2.2204e-16, 6.6613e-16,\n",
      "         2.2204e-16, 1.1102e-16, 2.2204e-16, 4.4409e-16, 8.8818e-16, 6.6613e-16,\n",
      "         8.8818e-16, 2.2204e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 6.6613e-16,\n",
      "         8.8818e-16, 1.1102e-16, 2.2204e-16, 8.8818e-16, 1.1102e-16, 8.8818e-16,\n",
      "         4.4409e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 3.3307e-16,\n",
      "         2.2204e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         5.5511e-17, 4.4409e-16, 6.6613e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         2.2204e-16, 4.4409e-16, 2.2204e-16, 1.1102e-15, 8.8818e-16, 8.8818e-16,\n",
      "         5.5511e-17, 5.5511e-17, 4.4409e-16, 8.8818e-16, 1.1102e-16, 2.2204e-16,\n",
      "         1.3323e-15, 1.1102e-16, 5.5511e-17, 2.2204e-16, 8.8818e-16, 8.3267e-17,\n",
      "         4.4409e-16, 6.6613e-16, 2.2204e-16, 6.6613e-16, 2.2204e-16, 4.4409e-16,\n",
      "         2.2204e-16, 1.7764e-15, 4.4409e-16, 8.8818e-16, 8.8818e-16, 1.1102e-16,\n",
      "         4.4409e-16, 5.5511e-16, 8.8818e-16, 2.2204e-16, 8.8818e-16, 4.4409e-16,\n",
      "         1.7764e-15, 1.1102e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 6.6613e-16,\n",
      "         4.4409e-16, 1.7764e-15, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 1.7764e-15,\n",
      "         3.3307e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16, 2.2204e-16,\n",
      "         5.3291e-15, 3.5527e-15, 2.2204e-16, 1.7764e-15, 1.8874e-15, 1.7764e-15,\n",
      "         8.8818e-16, 3.5527e-15, 8.8818e-16, 4.4409e-16, 2.2204e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 1.9984e-15, 4.4409e-15, 1.3323e-15, 3.1086e-15,\n",
      "         1.3323e-15, 4.4409e-16, 3.5527e-15, 3.5527e-15, 7.1054e-15, 1.7764e-15,\n",
      "         3.5527e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15, 2.6645e-15, 5.3291e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 7.1054e-15, 1.7764e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 4.4409e-16, 4.4409e-16, 2.6645e-15, 3.5527e-15,\n",
      "         1.7764e-15, 1.7764e-15, 3.5527e-15, 1.7764e-15, 1.7764e-15, 2.2204e-15,\n",
      "         1.7764e-15, 4.4409e-16, 3.5527e-15, 8.8818e-16, 2.6645e-15, 4.4409e-15,\n",
      "         2.5535e-15, 1.7764e-15, 2.6645e-15, 1.7764e-15, 3.5527e-15, 3.9968e-15,\n",
      "         3.5527e-15, 1.7764e-15, 4.4409e-16, 2.6645e-15, 1.8874e-15, 1.7764e-15,\n",
      "         3.5527e-15, 1.1102e-15, 1.7764e-15, 2.2204e-15, 1.7764e-15, 3.5527e-15,\n",
      "         1.1102e-15, 3.5527e-15, 1.4433e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15,\n",
      "         1.7764e-15, 8.8818e-16, 3.5527e-15, 1.7764e-15, 3.5527e-15, 3.5527e-15,\n",
      "         5.3291e-15, 8.8818e-16, 4.4409e-16, 1.7764e-15, 1.7764e-15, 4.4409e-16,\n",
      "         1.7764e-15, 3.5527e-15, 8.8818e-16, 5.3291e-15, 8.8818e-16, 3.5527e-15,\n",
      "         8.8818e-16, 1.7764e-15, 1.7764e-15, 4.4409e-16, 1.7764e-15, 2.6645e-15,\n",
      "         1.7764e-15, 1.7764e-15, 3.5527e-15, 1.7764e-15, 2.2204e-16, 1.7764e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15, 8.8818e-16,\n",
      "         8.8818e-16, 2.6645e-15, 2.6645e-15, 8.8818e-16, 3.5527e-15, 2.6645e-15,\n",
      "         2.6645e-15, 4.4409e-16, 1.7764e-15, 2.6645e-15, 1.7764e-15, 2.6645e-15,\n",
      "         3.5527e-15, 5.3291e-15]], dtype=torch.float64)\n",
      "tensor([  3,   7,   8,  12,  15,  26,  28,  31,  33,  34,  35,  37,  39,  42,\n",
      "         43,  44,  46,  47,  58,  59,  61,  62,  66,  73,  75,  78,  79,  82,\n",
      "         84,  87,  91,  95,  98, 103, 105, 109, 110, 112, 115, 119, 121, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
      "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
      "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
      "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
      "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "        394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
      "        408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "        422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
      "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
      "        450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "        464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
      "        478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
      "        492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
      "        506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  3,   7,   8,  12,  15,  26,  28,  31,  33,  34,  35,  37,  39,  42,\n",
      "         43,  44,  46,  47,  58,  59,  61,  62,  66,  73,  75,  78,  79,  82,\n",
      "         84,  87,  91,  95,  98, 103, 105, 109, 110, 112, 115, 119, 121, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
      "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
      "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
      "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
      "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "        394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
      "        408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "        422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
      "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
      "        450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "        464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
      "        478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
      "        492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
      "        506, 507, 508, 509, 510, 511])  (len = 426)\n",
      "passing Cout = tensor([  0,   1,   2,   4,   5,   6,   9,  10,  11,  13,  14,  16,  17,  18,\n",
      "         19,  20,  21,  22,  23,  24,  25,  27,  29,  30,  32,  36,  38,  40,\n",
      "         41,  45,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  60,  63,\n",
      "         64,  65,  67,  68,  69,  70,  71,  72,  74,  76,  77,  80,  81,  83,\n",
      "         85,  86,  88,  89,  90,  92,  93,  94,  96,  97,  99, 100, 101, 102,\n",
      "        104, 106, 107, 108, 111, 113, 114, 116, 117, 118, 120, 122, 123, 124,\n",
      "        125, 126])  (len = 86)\n",
      "\n",
      "Executing module 51: layer4.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 51\n",
      "Max diff:\n",
      "tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3726e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 1.3878e-17, 6.8305e-18, 6.9389e-18,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 1.3878e-17, 3.4694e-18, 0.0000e+00, 6.9389e-18, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 6.9389e-18,\n",
      "         0.0000e+00, 3.4694e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         3.6050e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.2042e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 1.3878e-17, 0.0000e+00, 1.3878e-17, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 3.5527e-15, 2.6645e-15, 2.6645e-15, 2.8866e-15,\n",
      "         4.8850e-15, 3.5527e-15, 1.8735e-15, 2.6645e-15, 2.2204e-15, 1.9984e-15,\n",
      "         6.2172e-15, 5.3291e-15, 2.2204e-15, 5.3291e-15, 2.6645e-15, 3.5527e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.1086e-15, 3.9968e-15, 3.5527e-15, 1.3323e-15,\n",
      "         2.6645e-15, 3.5527e-15, 2.8866e-15, 2.6645e-15, 2.6645e-15, 1.0658e-14,\n",
      "         5.3291e-15, 2.2204e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15,\n",
      "         2.6645e-15, 1.1102e-15, 3.5527e-15, 2.6645e-15, 2.6645e-15, 5.3291e-15,\n",
      "         3.5527e-15, 1.7764e-15, 2.6645e-15, 1.7764e-15, 1.3323e-15, 5.3291e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.6645e-15, 3.5527e-15, 5.3291e-15, 5.3291e-15,\n",
      "         2.4425e-15, 2.6645e-15, 5.3291e-15, 1.7764e-15, 2.6645e-15, 1.9984e-15,\n",
      "         2.6645e-15, 5.3291e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15, 2.2204e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 1.7764e-15, 3.5527e-15,\n",
      "         4.4409e-15, 1.7764e-15, 2.2204e-15, 2.6645e-15, 4.4409e-15, 1.9706e-15,\n",
      "         3.1086e-15, 1.7764e-15, 2.6645e-15, 1.7764e-15, 3.5527e-15, 5.3291e-15,\n",
      "         2.6645e-15, 2.7756e-15, 2.6645e-15, 2.6645e-15, 4.4409e-15, 3.5527e-15,\n",
      "         2.6645e-15, 4.4409e-15, 2.6645e-15, 4.8850e-15, 1.7764e-15, 5.3291e-15,\n",
      "         2.2204e-15, 3.5527e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 2.6645e-15,\n",
      "         5.3291e-15, 1.7764e-15, 2.2274e-15, 7.1054e-15, 1.7764e-15, 4.4409e-15,\n",
      "         2.2204e-15, 3.9968e-15, 5.3291e-15, 2.6645e-15, 2.6645e-15, 5.3291e-15,\n",
      "         2.2204e-15, 3.5527e-15, 4.4409e-15, 5.3291e-15, 5.3291e-15, 2.6645e-15,\n",
      "         2.6645e-15, 3.5527e-15, 1.7764e-15, 6.2172e-15, 4.4409e-15, 2.8866e-15,\n",
      "         3.5527e-15, 5.3291e-15, 1.9984e-15, 2.4425e-15, 2.7756e-17, 5.5511e-17,\n",
      "         1.1102e-16, 5.5511e-17, 2.2204e-16, 1.3878e-17, 2.7756e-17, 1.1102e-16,\n",
      "         2.2204e-16, 8.8818e-16, 1.3878e-16, 1.1102e-16, 5.5511e-16, 5.5511e-17,\n",
      "         2.7756e-17, 1.6653e-16, 1.1102e-16, 1.6653e-16, 1.1102e-16, 2.7756e-17,\n",
      "         3.3307e-16, 1.1102e-16, 4.4409e-16, 1.1102e-16, 1.3878e-16, 2.7756e-17,\n",
      "         2.2204e-16, 1.1102e-16, 1.1102e-16, 3.3307e-16, 5.5511e-17, 3.3307e-16,\n",
      "         5.5511e-17, 2.7756e-17, 1.1102e-16, 1.1102e-16, 2.2204e-16, 2.4980e-16,\n",
      "         4.4409e-16, 5.5511e-17, 3.3307e-16, 5.5511e-17, 1.1102e-16, 2.2204e-16,\n",
      "         3.3307e-16, 2.7756e-17, 5.5511e-17, 2.2204e-16, 2.7756e-17, 2.2204e-16,\n",
      "         1.1102e-16, 1.1102e-16, 1.6653e-16, 2.2204e-16, 1.1102e-16, 5.5511e-17,\n",
      "         2.7756e-17, 3.4694e-17, 3.3307e-16, 3.3307e-16, 1.1102e-16, 1.1102e-16,\n",
      "         1.3878e-17, 5.5511e-17, 2.7756e-16, 1.1102e-16, 1.1102e-16, 8.3267e-17,\n",
      "         5.5511e-17, 1.1102e-16, 2.7756e-17, 3.8858e-16, 4.4409e-16, 2.2204e-16,\n",
      "         1.3878e-17, 1.3878e-17, 1.1102e-16, 1.3878e-16, 2.7756e-17, 5.5511e-17,\n",
      "         6.6613e-16, 2.7756e-17, 1.3878e-17, 5.5511e-17, 1.1102e-16, 2.7756e-17,\n",
      "         1.6653e-16, 1.9429e-16, 2.7756e-17, 1.0408e-16, 5.5511e-17, 2.2204e-16,\n",
      "         5.5511e-17, 2.2204e-16, 1.1102e-16, 2.2204e-16, 3.3307e-16, 2.7756e-17,\n",
      "         1.1102e-16, 1.6653e-16, 2.2204e-16, 5.5511e-17, 4.4409e-16, 1.1102e-16,\n",
      "         3.3307e-16, 2.7756e-17, 8.3267e-17, 1.1102e-16, 2.2204e-16, 2.3245e-16,\n",
      "         6.9389e-17, 4.4409e-16, 1.1102e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16,\n",
      "         2.2204e-16, 2.2204e-16, 2.2204e-16, 2.7756e-17, 2.2204e-16, 3.3307e-16,\n",
      "         5.5511e-17, 5.5511e-17, 5.5511e-17, 5.5511e-17, 2.2204e-16, 1.1102e-16,\n",
      "         1.3323e-15, 2.2204e-16, 5.5511e-17, 4.4409e-16, 6.9389e-16, 8.8818e-16,\n",
      "         2.2204e-16, 8.8818e-16, 2.2204e-16, 1.1102e-16, 6.6613e-16, 8.8818e-16,\n",
      "         1.1102e-15, 1.7764e-15, 6.6613e-16, 1.7764e-15, 3.3307e-16, 1.9984e-15,\n",
      "         4.4409e-16, 1.1102e-16, 8.8818e-16, 8.8818e-16, 2.6645e-15, 2.2204e-16,\n",
      "         1.3323e-15, 4.4409e-16, 7.7716e-16, 4.4409e-16, 4.4409e-16, 1.7764e-15,\n",
      "         8.8818e-16, 8.8818e-16, 1.7764e-15, 1.7764e-15, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 4.4409e-16, 1.1102e-16, 1.1102e-16, 3.3307e-16, 8.8818e-16,\n",
      "         4.4409e-16, 1.1102e-15, 8.8818e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16,\n",
      "         6.6613e-16, 1.1102e-16, 1.7764e-15, 2.2204e-16, 8.8818e-16, 1.3323e-15,\n",
      "         8.8818e-16, 8.8818e-16, 1.4433e-15, 6.6613e-16, 8.8818e-16, 1.2212e-15,\n",
      "         1.7764e-15, 4.4409e-16, 2.2204e-16, 6.6613e-16, 1.1102e-15, 6.6613e-16,\n",
      "         8.8818e-16, 4.4409e-16, 8.8818e-16, 7.2164e-16, 4.4409e-16, 8.8818e-16,\n",
      "         3.8858e-16, 1.7764e-15, 6.6613e-16, 1.3323e-15, 6.6613e-16, 1.7764e-15,\n",
      "         8.8818e-16, 2.2204e-16, 1.3323e-15, 3.3307e-16, 8.8818e-16, 1.3323e-15,\n",
      "         1.7764e-15, 2.2204e-16, 1.1102e-16, 8.8818e-16, 4.4409e-16, 1.1102e-16,\n",
      "         8.8818e-16, 8.8818e-16, 2.2204e-16, 2.6645e-15, 2.2204e-16, 1.7764e-15,\n",
      "         2.2204e-16, 4.4409e-16, 1.7764e-15, 1.1102e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16, 5.5511e-17, 4.4409e-16,\n",
      "         6.6613e-16, 1.1102e-15, 4.4409e-16, 7.7716e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 7.7716e-16, 1.3323e-15, 2.2204e-16, 9.9920e-16, 1.1102e-15,\n",
      "         8.8818e-16, 1.1102e-16, 8.8818e-16, 9.9920e-16, 5.5511e-16, 1.3323e-15,\n",
      "         8.8818e-16, 1.3323e-15]], dtype=torch.float64)\n",
      "tensor([ 15,  26,  28,  31,  33,  34,  35,  37,  39,  42,  43,  44,  46,  47,\n",
      "         58,  59,  61,  62,  66,  73,  75,  78,  79,  82,  84,  87,  91,  95,\n",
      "         98, 103, 105, 109, 110, 112, 115, 119, 121, 127, 128, 129, 130, 131,\n",
      "        132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
      "        146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
      "        160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "        174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "        188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "        202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
      "        216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "        230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
      "        244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257,\n",
      "        258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271,\n",
      "        272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
      "        300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
      "        314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327,\n",
      "        328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
      "        342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
      "        356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369,\n",
      "        370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
      "        384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\n",
      "failing Cout = tensor([ 15,  26,  28,  31,  33,  34,  35,  37,  39,  42,  43,  44,  46,  47,\n",
      "         58,  59,  61,  62,  66,  73,  75,  78,  79,  82,  84,  87,  91,  95,\n",
      "         98, 103, 105, 109, 110, 112, 115, 119, 121, 127, 128, 129, 130, 131,\n",
      "        132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
      "        146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
      "        160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "        174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "        188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "        202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
      "        216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "        230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
      "        244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257,\n",
      "        258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271,\n",
      "        272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
      "        300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
      "        314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327,\n",
      "        328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
      "        342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
      "        356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369,\n",
      "        370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
      "        384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])  (len = 422)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  27,  29,  30,\n",
      "         32,  36,  38,  40,  41,  45,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  60,  63,  64,  65,  67,  68,  69,  70,  71,  72,  74,  76,\n",
      "         77,  80,  81,  83,  85,  86,  88,  89,  90,  92,  93,  94,  96,  97,\n",
      "         99, 100, 101, 102, 104, 106, 107, 108, 111, 113, 114, 116, 117, 118,\n",
      "        120, 122, 123, 124, 125, 126])  (len = 90)\n",
      "\n",
      "Executing module 52: layer4.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 52\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3726e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00, 6.8305e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.2042e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5527e-15, 0.0000e+00, 0.0000e+00, 4.5103e-16,\n",
      "         2.2204e-15, 0.0000e+00, 1.1102e-15, 1.1102e-15, 1.1102e-15, 1.9984e-15,\n",
      "         1.8874e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 3.5527e-15, 8.8818e-16, 3.9968e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5023e-15, 1.3878e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-15, 2.9976e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0654e-16, 8.8818e-16, 0.0000e+00, 2.6645e-15, 1.5543e-15, 1.7764e-15,\n",
      "         1.7764e-15, 1.7764e-15, 0.0000e+00, 3.6082e-16, 6.6613e-16, 0.0000e+00,\n",
      "         1.5543e-15, 2.6645e-15, 0.0000e+00, 3.5527e-15, 5.3291e-15, 5.5511e-16,\n",
      "         2.4425e-15, 9.9920e-16, 3.1919e-16, 1.7764e-15, 5.5511e-16, 1.1241e-15,\n",
      "         6.6613e-16, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 2.2204e-15,\n",
      "         1.6653e-15, 0.0000e+00, 7.7716e-16, 1.1657e-15, 1.5543e-15, 3.5527e-15,\n",
      "         8.8818e-16, 1.1102e-15, 1.7764e-15, 0.0000e+00, 0.0000e+00, 1.9706e-15,\n",
      "         1.7764e-15, 0.0000e+00, 1.2212e-15, 0.0000e+00, 0.0000e+00, 5.3291e-15,\n",
      "         3.3307e-16, 2.7756e-15, 1.3878e-15, 0.0000e+00, 4.4409e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5543e-15, 4.8850e-15, 8.8818e-16, 0.0000e+00,\n",
      "         2.2204e-15, 3.5527e-15, 3.5527e-15, 1.3323e-15, 8.8818e-16, 8.8818e-16,\n",
      "         1.5543e-15, 0.0000e+00, 1.7764e-15, 0.0000e+00, 1.7764e-15, 1.9984e-15,\n",
      "         1.9984e-15, 3.9968e-15, 5.3291e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9984e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.5527e-15, 1.7764e-15, 0.0000e+00, 2.4425e-15, 2.8866e-15,\n",
      "         3.5527e-15, 0.0000e+00, 1.9984e-15, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.2042e-17, 0.0000e+00, 0.0000e+00, 8.3267e-17,\n",
      "         5.2042e-17, 0.0000e+00, 1.3878e-16, 0.0000e+00, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 3.5562e-17, 4.1633e-17, 3.6429e-17, 0.0000e+00, 0.0000e+00,\n",
      "         9.7145e-17, 3.8164e-17, 0.0000e+00, 0.0000e+00, 1.3878e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-17, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         4.8572e-17, 0.0000e+00, 2.7756e-16, 2.7756e-17, 0.0000e+00, 5.5511e-17,\n",
      "         8.3267e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.3267e-17, 3.4694e-17, 1.1102e-16, 0.0000e+00, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 2.9490e-17, 0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00, 9.0206e-17, 4.1633e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1225e-17, 0.0000e+00, 0.0000e+00,\n",
      "         1.6653e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1102e-16, 1.2490e-16, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0715e-17, 2.8569e-17, 0.0000e+00,\n",
      "         2.7756e-17, 1.1102e-16, 2.7756e-17, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.1633e-17, 0.0000e+00, 1.2490e-16, 1.6653e-16,\n",
      "         0.0000e+00, 2.7756e-17, 0.0000e+00, 2.7756e-17, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 8.3267e-17, 0.0000e+00, 1.6653e-16, 1.2212e-15,\n",
      "         3.8858e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00,\n",
      "         3.6082e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16, 1.3878e-16,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 9.6451e-16, 6.6613e-16,\n",
      "         1.1102e-16, 4.4409e-16, 0.0000e+00, 7.2164e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1225e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7145e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0123e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6653e-16, 3.3307e-16, 2.7756e-17,\n",
      "         0.0000e+00, 2.4980e-16, 2.2204e-16, 0.0000e+00, 9.9920e-16, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([ 15,  28,  31,  34,  44,  61,  62,  73,  79,  82,  91, 103, 105, 128,\n",
      "        131, 132, 134, 135, 136, 137, 138, 142, 145, 146, 147, 152, 153, 157,\n",
      "        158, 162, 163, 165, 166, 167, 168, 169, 171, 172, 174, 175, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 188, 191, 192, 194, 195, 196,\n",
      "        197, 198, 199, 200, 203, 204, 206, 209, 210, 211, 212, 214, 218, 219,\n",
      "        220, 222, 223, 224, 225, 226, 227, 228, 230, 232, 233, 234, 235, 236,\n",
      "        242, 247, 248, 250, 251, 252, 254, 255, 260, 263, 264, 266, 268, 271,\n",
      "        272, 273, 276, 277, 280, 287, 290, 293, 294, 296, 297, 299, 300, 306,\n",
      "        307, 308, 311, 313, 316, 320, 322, 323, 327, 333, 336, 342, 343, 345,\n",
      "        351, 352, 354, 355, 356, 358, 362, 364, 365, 367, 369, 370, 374, 382,\n",
      "        383, 388, 394, 396, 398, 400, 401, 402, 410, 424, 426, 427, 430, 431,\n",
      "        432, 436, 438, 447, 448, 449, 450, 451, 453, 458, 465, 472, 477, 482,\n",
      "        486, 488, 495, 496, 497, 499, 500, 502, 503, 507, 508])\n",
      "\n",
      "failing Cout = tensor([ 15,  28,  31,  34,  44,  61,  62,  73,  79,  82,  91, 103, 105, 128,\n",
      "        131, 132, 134, 135, 136, 137, 138, 142, 145, 146, 147, 152, 153, 157,\n",
      "        158, 162, 163, 165, 166, 167, 168, 169, 171, 172, 174, 175, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 188, 191, 192, 194, 195, 196,\n",
      "        197, 198, 199, 200, 203, 204, 206, 209, 210, 211, 212, 214, 218, 219,\n",
      "        220, 222, 223, 224, 225, 226, 227, 228, 230, 232, 233, 234, 235, 236,\n",
      "        242, 247, 248, 250, 251, 252, 254, 255, 260, 263, 264, 266, 268, 271,\n",
      "        272, 273, 276, 277, 280, 287, 290, 293, 294, 296, 297, 299, 300, 306,\n",
      "        307, 308, 311, 313, 316, 320, 322, 323, 327, 333, 336, 342, 343, 345,\n",
      "        351, 352, 354, 355, 356, 358, 362, 364, 365, 367, 369, 370, 374, 382,\n",
      "        383, 388, 394, 396, 398, 400, 401, 402, 410, 424, 426, 427, 430, 431,\n",
      "        432, 436, 438, 447, 448, 449, 450, 451, 453, 458, 465, 472, 477, 482,\n",
      "        486, 488, 495, 496, 497, 499, 500, 502, 503, 507, 508])  (len = 179)\n",
      "passing Cout = tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         16,  17,  18,  19,  20,  23,  25,  29,  33,  37,  38,  39,  41,  43,\n",
      "         47,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  63,\n",
      "         64,  65,  68,  69,  70,  72,  77,  78,  80,  81,  83,  87,  88,  90,\n",
      "         92,  99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 115, 116, 117,\n",
      "        119, 120, 121, 124, 125, 126, 265, 292, 305])  (len = 79)\n",
      "\n",
      "Executing module 53: layer4.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 53\n",
      "Max diff:\n",
      "tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[6.9389e-18, 3.4694e-18, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         2.1684e-19, 0.0000e+00, 8.6736e-19, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 1.3878e-17, 2.1684e-19, 0.0000e+00, 6.9389e-18, 6.9389e-18,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 6.9389e-18,\n",
      "         0.0000e+00, 3.4694e-18, 0.0000e+00, 6.9389e-18, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 2.7105e-19, 8.6736e-19, 6.9389e-18, 1.7347e-18, 3.4694e-18,\n",
      "         0.0000e+00, 4.3368e-19, 3.4694e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 4.3368e-19, 6.9389e-18,\n",
      "         0.0000e+00, 1.3010e-18, 0.0000e+00, 4.3368e-19, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3368e-19, 3.4694e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 8.6736e-19, 1.7347e-18, 6.9389e-18,\n",
      "         8.6736e-19, 3.4694e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         6.9389e-18, 0.0000e+00, 8.6736e-19, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 4.3368e-19, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 6.9389e-18, 0.0000e+00, 4.3368e-19,\n",
      "         0.0000e+00, 6.9389e-18, 6.9389e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 6.9389e-18, 6.9389e-18, 1.7347e-18, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 8.6736e-19, 0.0000e+00,\n",
      "         0.0000e+00, 4.3368e-19, 1.0658e-14, 1.3323e-14, 2.1316e-14, 6.2172e-15,\n",
      "         1.4211e-14, 5.3291e-15, 1.0658e-14, 1.0658e-14, 7.9936e-15, 7.7716e-15,\n",
      "         1.0658e-14, 1.2434e-14, 1.0658e-14, 7.1054e-15, 1.4211e-14, 2.4869e-14,\n",
      "         1.4211e-14, 1.4211e-14, 1.4211e-14, 1.4211e-14, 2.1316e-14, 7.9936e-15,\n",
      "         7.1054e-15, 1.7764e-14, 7.1054e-15, 7.1054e-15, 1.0658e-14, 1.4211e-14,\n",
      "         1.4211e-14, 1.4211e-14, 2.4869e-14, 8.8818e-15, 1.0658e-14, 7.1054e-15,\n",
      "         1.4211e-14, 1.0658e-14, 9.7700e-15, 2.8422e-14, 7.1054e-15, 1.0658e-14,\n",
      "         8.8818e-15, 8.4377e-15, 1.4211e-14, 1.4211e-14, 2.4869e-14, 8.0491e-15,\n",
      "         1.4211e-14, 8.8818e-15, 7.9936e-15, 1.0103e-14, 1.0658e-14, 1.0658e-14,\n",
      "         7.1054e-15, 1.4211e-14, 1.4211e-14, 1.7764e-14, 7.1054e-15, 7.1054e-15,\n",
      "         7.1054e-15, 2.1316e-14, 7.5495e-15, 1.4211e-14, 1.2434e-14, 1.0658e-14,\n",
      "         8.8818e-15, 2.1316e-14, 7.1054e-15, 1.0658e-14, 1.0658e-14, 1.0658e-14,\n",
      "         7.1054e-15, 8.8818e-15, 2.1316e-14, 7.1054e-15, 2.1316e-14, 7.1054e-15,\n",
      "         2.1316e-14, 1.4211e-14, 1.0658e-14, 1.4211e-14, 1.7764e-14, 1.0658e-14,\n",
      "         2.4869e-14, 3.5527e-15, 8.8818e-15, 1.4211e-14, 1.2434e-14, 1.0658e-14,\n",
      "         2.6645e-15, 1.7764e-14, 1.4211e-14, 8.8818e-15, 1.4211e-14, 1.0658e-14,\n",
      "         1.4211e-14, 8.8818e-15, 1.4211e-14, 7.1054e-15, 7.9936e-15, 1.0658e-14,\n",
      "         1.4211e-14, 1.7764e-14, 2.8422e-14, 1.0658e-14, 1.4211e-14, 1.0658e-14,\n",
      "         1.0658e-14, 1.2434e-14, 7.1054e-15, 8.8818e-15, 8.8818e-15, 1.0658e-14,\n",
      "         2.8422e-14, 7.9936e-15, 7.1054e-15, 1.0658e-14, 1.0658e-14, 2.1316e-14,\n",
      "         7.1054e-15, 7.1054e-15, 6.2172e-15, 1.0658e-14, 1.7764e-14, 7.1054e-15,\n",
      "         1.4211e-14, 5.3291e-15, 1.0658e-14, 6.6613e-15, 5.5511e-17, 1.7764e-15,\n",
      "         8.8818e-16, 2.7756e-17, 5.5511e-17, 1.3323e-15, 1.3323e-15, 2.2204e-16,\n",
      "         3.3307e-16, 4.4409e-16, 4.4409e-16, 2.7756e-17, 1.3323e-15, 6.6613e-16,\n",
      "         4.4409e-16, 4.4409e-16, 3.3307e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 8.8818e-16, 2.2204e-16, 1.7764e-15, 4.4409e-16,\n",
      "         1.3323e-15, 4.4409e-16, 4.4409e-16, 2.6645e-15, 4.4409e-16, 5.5511e-17,\n",
      "         1.1102e-16, 6.6613e-16, 2.9837e-16, 8.8818e-16, 2.2204e-16, 4.4409e-16,\n",
      "         8.8818e-16, 8.8818e-16, 2.2204e-16, 2.6645e-15, 2.2204e-16, 8.8818e-16,\n",
      "         5.5511e-16, 1.1102e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 5.5511e-17,\n",
      "         8.8818e-16, 2.2204e-16, 4.4409e-16, 1.1102e-16, 2.2204e-15, 1.7764e-15,\n",
      "         8.8818e-16, 6.6613e-16, 5.5511e-17, 4.4409e-16, 6.6613e-16, 1.1102e-16,\n",
      "         6.6613e-16, 1.1102e-16, 4.4409e-16, 1.1102e-15, 8.8818e-16, 2.2204e-16,\n",
      "         3.3307e-16, 5.5511e-17, 2.7756e-17, 4.4409e-16, 8.8818e-16, 2.7756e-16,\n",
      "         1.1102e-16, 8.8818e-16, 8.8818e-16, 1.1102e-16, 2.2204e-16, 4.4409e-16,\n",
      "         1.1102e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 1.1102e-15,\n",
      "         8.8818e-16, 8.8818e-16, 2.7756e-17, 5.5511e-16, 4.1633e-17, 5.5511e-17,\n",
      "         1.1102e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17, 6.6613e-16,\n",
      "         8.8818e-16, 1.6653e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17, 1.3323e-15,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.3267e-17, 5.5511e-17,\n",
      "         8.8818e-16, 5.5511e-17, 1.3323e-15, 1.3878e-16, 4.4409e-16, 5.5511e-17,\n",
      "         1.1102e-15, 1.7764e-15, 4.4409e-16, 4.4409e-16, 1.1102e-16, 1.1102e-16,\n",
      "         4.4409e-16, 8.8818e-16, 1.6653e-16, 4.4409e-16, 4.4409e-16, 1.1102e-16,\n",
      "         1.1102e-15, 8.8818e-16, 6.6613e-16, 1.5543e-15, 7.7716e-16, 5.3291e-15,\n",
      "         2.6645e-15, 1.7764e-15, 2.2204e-16, 1.7764e-15, 1.7764e-15, 2.6645e-15,\n",
      "         8.8818e-16, 1.3323e-15, 1.7764e-15, 1.7764e-15, 1.3323e-15, 8.8818e-16,\n",
      "         1.3323e-15, 1.1102e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15,\n",
      "         1.3323e-15, 1.7764e-15, 1.7764e-15, 8.8818e-16, 1.3323e-15, 6.6613e-16,\n",
      "         1.7764e-15, 8.8818e-16, 1.3323e-15, 8.8818e-16, 3.5527e-15, 1.3323e-15,\n",
      "         8.8818e-16, 1.7764e-15, 1.3323e-15, 8.8818e-16, 6.6613e-16, 8.8818e-16,\n",
      "         1.7764e-15, 1.3323e-15, 1.7764e-15, 2.2204e-15, 6.6613e-16, 8.8818e-16,\n",
      "         1.3323e-15, 1.3323e-15, 1.7764e-15, 2.6645e-15, 1.3323e-15, 9.9920e-16,\n",
      "         1.7764e-15, 8.8818e-16, 8.8818e-16, 3.5527e-15, 2.6645e-15, 4.9960e-16,\n",
      "         1.3323e-15, 2.6645e-15, 8.8818e-16, 1.7764e-15, 1.3323e-15, 1.3323e-15,\n",
      "         6.6613e-16, 1.3323e-15, 9.9920e-16, 6.6613e-16, 1.7764e-15, 1.1102e-15,\n",
      "         8.8818e-16, 1.3323e-15, 1.3323e-15, 1.7764e-15, 1.7764e-15, 8.8818e-16,\n",
      "         1.1102e-15, 8.8818e-16, 1.7764e-15, 1.3323e-15, 1.7764e-15, 6.6613e-16,\n",
      "         2.2204e-15, 1.7764e-15, 1.1102e-15, 1.4988e-15, 1.5543e-15, 1.3323e-15,\n",
      "         1.3323e-15, 2.6645e-15, 1.7764e-15, 1.1102e-16, 1.3323e-15, 1.7764e-15,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 9.4369e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 8.8818e-16, 2.6645e-15, 8.8818e-16, 1.0547e-15, 1.3323e-15,\n",
      "         1.7764e-15, 8.8818e-16, 1.3323e-15, 2.2204e-15, 1.7764e-15, 8.8818e-16,\n",
      "         1.3323e-15, 1.3323e-15, 9.4369e-16, 1.7764e-15, 8.8818e-16, 1.3323e-15,\n",
      "         6.6613e-16, 1.7764e-15, 1.9984e-15, 2.2204e-15, 8.8818e-16, 1.1102e-15,\n",
      "         1.7764e-15, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   3,   6,   8,  11,  13,  14,  16,  17,  18,  21,  24,  28,\n",
      "         29,  31,  33,  34,  37,  38,  39,  40,  41,  43,  44,  45,  50,  56,\n",
      "         58,  59,  61,  63,  65,  71,  76,  77,  78,  81,  82,  83,  84,  85,\n",
      "         86,  89,  90,  92,  93,  98, 100, 104, 105, 107, 109, 110, 111, 114,\n",
      "        116, 117, 118, 119, 123, 124, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "        163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "        177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
      "        191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
      "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
      "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
      "        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "        289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
      "        303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
      "        317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "        331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
      "        345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
      "        359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
      "        373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386,\n",
      "        387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
      "        401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n",
      "        415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
      "        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
      "        457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "        485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   3,   6,   8,  11,  13,  14,  16,  17,  18,  21,  24,  28,\n",
      "         29,  31,  33,  34,  37,  38,  39,  40,  41,  43,  44,  45,  50,  56,\n",
      "         58,  59,  61,  63,  65,  71,  76,  77,  78,  81,  82,  83,  84,  85,\n",
      "         86,  89,  90,  92,  93,  98, 100, 104, 105, 107, 109, 110, 111, 114,\n",
      "        116, 117, 118, 119, 123, 124, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "        163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "        177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
      "        191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
      "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
      "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
      "        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "        289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
      "        303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
      "        317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "        331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
      "        345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
      "        359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
      "        373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386,\n",
      "        387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
      "        401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n",
      "        415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
      "        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
      "        457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "        485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])  (len = 447)\n",
      "passing Cout = tensor([  2,   4,   5,   7,   9,  10,  12,  15,  19,  20,  22,  23,  25,  26,\n",
      "         27,  30,  32,  35,  36,  42,  46,  47,  48,  49,  51,  52,  53,  54,\n",
      "         55,  57,  60,  62,  64,  66,  67,  68,  69,  70,  72,  73,  74,  75,\n",
      "         79,  80,  87,  88,  91,  94,  95,  96,  97,  99, 101, 102, 103, 106,\n",
      "        108, 112, 113, 115, 120, 121, 122, 125, 126])  (len = 65)\n",
      "\n",
      "Executing module 54: layer4.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 54\n",
      "Max diff:\n",
      "tensor([1.5987e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.6021e-18, 8.6736e-19, 0.0000e+00, 2.6021e-18, 0.0000e+00, 0.0000e+00,\n",
      "         8.6736e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 8.6736e-19, 0.0000e+00, 1.9516e-18, 1.7347e-18,\n",
      "         8.6736e-19, 0.0000e+00, 0.0000e+00, 1.8431e-18, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18, 1.7347e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 2.1684e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6736e-19,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6736e-19,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4395e-19, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 8.6736e-19, 1.7347e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         2.1684e-18, 0.0000e+00, 2.1684e-19, 8.6736e-19, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 2.1684e-19, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.3368e-19, 2.1684e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7347e-18, 1.7618e-18, 8.6736e-19, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 1.7347e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6021e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5527e-15, 3.7748e-15, 5.3291e-15, 3.9968e-15,\n",
      "         7.1054e-15, 2.2204e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 4.2188e-15,\n",
      "         2.6645e-15, 5.3291e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15, 1.5987e-14,\n",
      "         4.4409e-15, 8.8818e-15, 7.1054e-15, 6.2172e-15, 1.4211e-14, 2.6645e-15,\n",
      "         3.5527e-15, 1.0658e-14, 2.6645e-15, 1.5543e-15, 4.4409e-15, 5.3291e-15,\n",
      "         5.3291e-15, 5.3291e-15, 1.0658e-14, 4.4409e-15, 1.7764e-15, 2.6645e-15,\n",
      "         6.2172e-15, 2.6645e-15, 3.4417e-15, 1.0658e-14, 3.5527e-15, 3.7748e-15,\n",
      "         5.3291e-15, 2.7756e-15, 5.3291e-15, 5.3291e-15, 7.1054e-15, 3.2196e-15,\n",
      "         5.3291e-15, 5.3291e-15, 2.7756e-15, 3.6360e-15, 3.5527e-15, 7.1054e-15,\n",
      "         3.5527e-15, 7.1054e-15, 7.1054e-15, 8.8818e-15, 2.6645e-15, 3.5527e-15,\n",
      "         2.6645e-15, 8.8818e-15, 3.9968e-15, 3.5527e-15, 8.8818e-15, 4.4409e-15,\n",
      "         3.5527e-15, 1.0658e-14, 2.6645e-15, 5.3291e-15, 5.3291e-15, 3.5527e-15,\n",
      "         2.6645e-15, 2.6645e-15, 8.8818e-15, 2.6645e-15, 1.0658e-14, 2.4425e-15,\n",
      "         7.1054e-15, 7.1054e-15, 4.4409e-15, 4.4409e-15, 7.1054e-15, 6.2172e-15,\n",
      "         1.4211e-14, 2.2204e-15, 2.6645e-15, 1.0658e-14, 3.9968e-15, 5.3291e-15,\n",
      "         8.8818e-16, 1.0658e-14, 5.3291e-15, 2.6645e-15, 7.1054e-15, 5.3291e-15,\n",
      "         5.3291e-15, 3.5527e-15, 7.1054e-15, 3.5527e-15, 3.9968e-15, 4.4409e-15,\n",
      "         7.1054e-15, 4.4409e-15, 1.4211e-14, 2.6645e-15, 6.2172e-15, 7.1054e-15,\n",
      "         4.4409e-15, 5.3291e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15,\n",
      "         1.0658e-14, 3.6637e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 1.0658e-14,\n",
      "         3.5527e-15, 3.1086e-15, 2.6645e-15, 5.3291e-15, 8.8818e-15, 5.3291e-15,\n",
      "         1.0658e-14, 1.3323e-15, 4.4409e-15, 2.4425e-15, 2.0817e-17, 6.6613e-16,\n",
      "         4.4409e-16, 6.9389e-18, 1.3878e-17, 3.3307e-16, 5.5511e-16, 5.5511e-17,\n",
      "         8.3267e-17, 1.1102e-16, 1.1102e-16, 1.3878e-17, 5.5511e-16, 1.6653e-16,\n",
      "         2.2204e-16, 2.2204e-16, 5.5511e-17, 2.2204e-16, 3.3307e-16, 1.1102e-16,\n",
      "         1.6653e-16, 1.1102e-16, 1.1102e-16, 5.5511e-17, 8.8818e-16, 6.5919e-17,\n",
      "         4.4409e-16, 1.1102e-16, 1.1102e-16, 1.3323e-15, 5.5511e-17, 1.3878e-17,\n",
      "         2.7756e-17, 3.3307e-16, 5.5511e-17, 3.3307e-16, 2.7756e-17, 2.2204e-16,\n",
      "         2.2204e-16, 4.4409e-16, 5.5511e-17, 1.1102e-15, 5.5511e-17, 6.6613e-16,\n",
      "         8.3267e-17, 2.7756e-17, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.3878e-17,\n",
      "         2.2204e-16, 5.5511e-17, 1.6653e-16, 2.7756e-17, 1.3323e-15, 8.8818e-16,\n",
      "         3.3307e-16, 1.6653e-16, 1.3878e-17, 5.5511e-17, 1.1102e-16, 2.7756e-17,\n",
      "         3.3307e-16, 2.7756e-17, 1.1102e-16, 4.4409e-16, 4.4409e-16, 2.7756e-17,\n",
      "         1.1102e-16, 2.7756e-17, 6.9389e-18, 1.1102e-16, 4.4409e-16, 1.1102e-16,\n",
      "         2.0817e-17, 2.2204e-16, 4.4409e-16, 2.7756e-17, 5.5511e-17, 1.1102e-16,\n",
      "         2.7756e-17, 2.2204e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16,\n",
      "         4.4409e-16, 2.2204e-16, 6.9389e-18, 1.6653e-16, 6.9389e-18, 1.3878e-17,\n",
      "         2.7756e-17, 2.2204e-16, 4.4409e-16, 1.1102e-16, 2.7756e-17, 2.2204e-16,\n",
      "         4.4409e-16, 2.7756e-17, 4.4409e-16, 2.2204e-16, 1.3878e-17, 4.4409e-16,\n",
      "         2.2204e-16, 2.2204e-16, 2.2204e-16, 3.0531e-16, 2.7756e-17, 1.3878e-17,\n",
      "         2.2204e-16, 1.3878e-17, 6.6613e-16, 0.0000e+00, 2.2204e-16, 2.0817e-17,\n",
      "         5.5511e-16, 8.8818e-16, 8.3267e-17, 2.2204e-16, 2.7756e-17, 2.7756e-17,\n",
      "         2.2204e-16, 4.4409e-16, 4.1633e-17, 2.2204e-16, 1.6653e-16, 5.5511e-17,\n",
      "         4.9960e-16, 2.2204e-16, 1.3878e-16, 6.6613e-16, 4.4409e-16, 1.3323e-15,\n",
      "         6.6613e-16, 4.4409e-16, 5.5511e-17, 5.5511e-16, 4.4409e-16, 1.1102e-15,\n",
      "         4.4409e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16, 1.1102e-16,\n",
      "         6.6613e-16, 4.4409e-16, 1.3323e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16,\n",
      "         5.5511e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 3.3307e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 2.7756e-16, 1.3323e-15, 6.6613e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 3.3307e-16, 2.7756e-16, 4.4409e-16,\n",
      "         4.4409e-16, 6.6613e-16, 8.8818e-16, 9.9920e-16, 8.3267e-17, 4.4409e-16,\n",
      "         4.4409e-16, 5.5511e-16, 6.6613e-16, 1.1102e-15, 5.5511e-16, 3.8858e-16,\n",
      "         4.4409e-16, 4.9960e-16, 6.6613e-16, 1.3323e-15, 1.3323e-15, 2.4980e-16,\n",
      "         6.6613e-16, 8.8818e-16, 4.4409e-16, 5.5511e-16, 4.4409e-16, 6.6613e-16,\n",
      "         2.2204e-16, 6.6613e-16, 3.3307e-16, 2.2204e-16, 6.6613e-16, 4.4409e-16,\n",
      "         3.3307e-16, 6.6613e-16, 6.6613e-16, 4.4409e-16, 6.6613e-16, 3.3307e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 6.6613e-16, 1.3878e-16, 1.9429e-16,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16,\n",
      "         6.6613e-16, 1.3323e-15, 6.6613e-16, 2.0817e-17, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 3.3307e-16, 2.2204e-16, 2.4980e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 3.1225e-16, 1.3323e-15, 4.4409e-16, 4.1633e-16, 6.6613e-16,\n",
      "         8.8818e-16, 1.1102e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16, 3.3307e-16,\n",
      "         5.5511e-16, 4.4409e-16, 3.8858e-16, 8.8818e-16, 4.4409e-16, 6.6613e-16,\n",
      "         2.2204e-16, 6.6613e-16, 1.1102e-15, 8.8818e-16, 3.3307e-16, 4.4409e-16,\n",
      "         3.3307e-16, 5.5511e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   3,   6,  13,  14,  16,  17,  18,  21,  24,  28,  29,  33,\n",
      "         34,  39,  56,  59,  61,  65,  71,  77,  81,  83,  85,  86,  89,  90,\n",
      "         92,  93,  98, 100, 104, 105, 109, 110, 111, 114, 116, 117, 123, 128,\n",
      "        129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "        227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
      "        269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
      "        283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
      "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310,\n",
      "        311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "        339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
      "        353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366,\n",
      "        367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "        396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
      "        410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
      "        424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "        438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
      "        452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
      "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
      "        508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   3,   6,  13,  14,  16,  17,  18,  21,  24,  28,  29,  33,\n",
      "         34,  39,  56,  59,  61,  65,  71,  77,  81,  83,  85,  86,  89,  90,\n",
      "         92,  93,  98, 100, 104, 105, 109, 110, 111, 114, 116, 117, 123, 128,\n",
      "        129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "        227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
      "        269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
      "        283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
      "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310,\n",
      "        311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "        339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
      "        353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366,\n",
      "        367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "        396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
      "        410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
      "        424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "        438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
      "        452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
      "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
      "        508, 509, 510, 511])  (len = 424)\n",
      "passing Cout = tensor([  2,   4,   5,   7,   8,   9,  10,  11,  12,  15,  19,  20,  22,  23,\n",
      "         25,  26,  27,  30,  31,  32,  35,  36,  37,  38,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  57,  58,\n",
      "         60,  62,  63,  64,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,\n",
      "         78,  79,  80,  82,  84,  87,  88,  91,  94,  95,  96,  97,  99, 101,\n",
      "        102, 103, 106, 107, 108, 112, 113, 115, 118, 119, 120, 121, 122, 124,\n",
      "        125, 126, 127, 369])  (len = 88)\n",
      "\n",
      "Executing module 55: layer4.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([344, 355]) to machine 2\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([ 60,  61,  76,  89,  96, 117, 125, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([262, 300, 313, 342, 353, 369]) to machine 2\n",
      "\t\t sending C_out tensor([399, 403, 417, 419, 450, 459, 484, 510]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([ 58,  67,  87, 100, 127]) to machine 0\n",
      "\t\t sending C_out tensor([141, 149, 150, 152, 165, 238, 239, 240]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  4,  39,  53,  61,  70,  81,  86,  96, 118, 123, 124]) to machine 0\n",
      "\t\t sending C_out tensor([129, 130, 134, 137, 138, 140, 141, 147, 153, 154, 160, 171, 174, 177,\n",
      "        178, 181, 188, 189, 204, 206, 207, 211, 212, 213, 214, 215, 216, 221,\n",
      "        224, 229, 232, 236, 240, 244, 246, 251, 252, 254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([262, 269, 275, 280, 310, 313, 314, 322, 354, 369, 378]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 55\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 1.7347e-18, 1.7347e-18, 0.0000e+00, 6.9389e-18, 1.3878e-17,\n",
      "         8.6736e-19, 3.4694e-18, 1.7347e-18, 0.0000e+00, 4.3368e-19, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 1.3878e-17, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 8.6736e-19, 6.9389e-18, 0.0000e+00, 3.4694e-18, 6.9389e-18,\n",
      "         6.9389e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 4.3368e-19, 8.6736e-19, 6.9389e-18, 8.6736e-19, 0.0000e+00,\n",
      "         6.9389e-18, 1.7347e-18, 0.0000e+00, 6.9389e-18, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 3.4694e-18, 8.6736e-19,\n",
      "         0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00,\n",
      "         6.9389e-18, 1.7347e-18, 0.0000e+00, 8.6736e-19, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 0.0000e+00, 3.4694e-18, 1.7347e-18, 0.0000e+00,\n",
      "         6.9389e-18, 6.9389e-18, 3.4694e-18, 8.6736e-19, 1.3010e-18, 0.0000e+00,\n",
      "         0.0000e+00, 1.7347e-18, 3.4694e-18, 3.4694e-18, 1.7347e-18, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 3.4694e-18, 1.7347e-18,\n",
      "         6.9389e-18, 3.4694e-18, 8.6736e-19, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         1.0842e-18, 0.0000e+00, 8.6736e-19, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         1.7347e-18, 3.4694e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 8.6736e-19,\n",
      "         0.0000e+00, 3.4694e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-18, 0.0000e+00, 6.9389e-18, 1.3878e-17, 3.4694e-18, 1.7347e-18,\n",
      "         0.0000e+00, 1.7347e-18, 6.9389e-18, 2.0817e-17, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 8.6736e-19, 1.7764e-15, 2.4425e-15, 1.5543e-15, 2.2135e-15,\n",
      "         1.7764e-15, 2.2204e-15, 3.5527e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15,\n",
      "         1.7764e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15,\n",
      "         1.3323e-15, 1.7764e-15, 2.6645e-15, 2.2204e-15, 1.7764e-15, 1.3323e-15,\n",
      "         2.6645e-15, 5.3291e-15, 1.7764e-15, 1.7764e-15, 2.6645e-15, 1.3323e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15, 1.2212e-15, 2.4425e-15,\n",
      "         2.2204e-15, 3.1086e-15, 1.7764e-15, 1.1102e-15, 1.7764e-15, 2.6645e-15,\n",
      "         2.2204e-15, 1.3323e-15, 2.2204e-15, 2.2204e-15, 2.2204e-15, 2.6645e-15,\n",
      "         8.8818e-16, 2.6645e-15, 1.1102e-15, 1.6653e-15, 2.2204e-15, 2.6645e-15,\n",
      "         2.1094e-15, 1.7764e-15, 3.5527e-15, 2.4425e-15, 1.3323e-15, 2.6645e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.2204e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15,\n",
      "         1.7764e-15, 8.8818e-16, 1.3323e-15, 1.9984e-15, 3.1086e-15, 2.4425e-15,\n",
      "         1.3323e-15, 1.7764e-15, 2.2204e-15, 3.9968e-15, 1.6098e-15, 2.3315e-15,\n",
      "         3.5527e-15, 3.5527e-15, 2.6645e-15, 2.2204e-15, 1.3323e-15, 1.7764e-15,\n",
      "         3.5527e-15, 1.7764e-15, 8.8818e-16, 1.1102e-15, 2.6645e-15, 1.1102e-15,\n",
      "         4.4409e-16, 1.9984e-15, 1.7764e-15, 1.9984e-15, 1.3323e-15, 1.7764e-15,\n",
      "         1.7764e-15, 2.2204e-15, 8.8818e-16, 1.3323e-15, 3.5527e-15, 1.7764e-15,\n",
      "         2.6645e-15, 1.9984e-15, 1.7764e-15, 2.6645e-15, 1.7764e-15, 1.5543e-15,\n",
      "         3.5527e-15, 2.1649e-15, 2.2204e-15, 4.4409e-15, 1.6653e-15, 1.4433e-15,\n",
      "         2.6645e-15, 1.7764e-15, 1.3323e-15, 2.6645e-15, 1.3323e-15, 4.4409e-15,\n",
      "         1.9984e-15, 1.7764e-15, 1.7764e-15, 1.3323e-15, 2.2204e-15, 2.6645e-15,\n",
      "         1.9984e-15, 2.6645e-15, 2.6645e-15, 3.5527e-15, 1.3878e-17, 2.2204e-16,\n",
      "         2.7756e-17, 1.3878e-17, 1.3878e-17, 1.6653e-16, 3.3307e-16, 1.0408e-16,\n",
      "         1.0408e-17, 1.1102e-16, 2.7756e-16, 2.7756e-17, 1.9429e-16, 4.4409e-16,\n",
      "         6.9389e-17, 7.9797e-17, 2.2204e-16, 1.2490e-16, 4.1633e-17, 5.5511e-17,\n",
      "         5.5511e-17, 5.2042e-17, 1.1102e-16, 2.7756e-17, 1.1102e-16, 2.2204e-16,\n",
      "         1.3878e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 3.4694e-17, 1.7347e-17,\n",
      "         2.7756e-17, 1.6653e-16, 1.9429e-16, 4.1633e-17, 5.5511e-17, 1.1102e-16,\n",
      "         3.3307e-16, 1.6653e-16, 5.5511e-17, 1.5959e-16, 5.5511e-17, 5.5511e-17,\n",
      "         1.3323e-15, 2.7756e-17, 1.6653e-16, 2.2204e-16, 9.7145e-17, 6.9389e-18,\n",
      "         2.2204e-16, 4.1633e-17, 1.6653e-16, 1.7347e-17, 2.2204e-16, 2.2204e-16,\n",
      "         1.6653e-16, 8.8818e-16, 1.3010e-17, 1.1102e-16, 5.5511e-17, 2.7756e-17,\n",
      "         8.3267e-17, 1.3878e-17, 2.2204e-16, 1.1102e-16, 6.6613e-16, 1.1796e-16,\n",
      "         1.6653e-16, 2.7756e-17, 2.0817e-17, 1.1102e-16, 2.2204e-16, 9.7145e-17,\n",
      "         6.9389e-18, 8.3267e-17, 1.1102e-16, 2.7756e-17, 1.4311e-17, 1.1102e-16,\n",
      "         1.3878e-17, 1.1102e-16, 9.7145e-17, 1.1102e-16, 1.1102e-16, 4.4409e-16,\n",
      "         1.6653e-16, 1.0929e-16, 2.0817e-17, 2.2204e-16, 1.0408e-17, 6.9389e-18,\n",
      "         2.7756e-17, 1.1102e-16, 6.9389e-17, 5.5511e-17, 2.7756e-17, 2.7756e-16,\n",
      "         2.2204e-16, 4.1633e-17, 2.7756e-17, 2.2204e-16, 1.3878e-17, 4.1633e-17,\n",
      "         8.3267e-17, 2.2204e-16, 2.0817e-17, 6.5919e-17, 1.3878e-17, 1.0408e-17,\n",
      "         2.2204e-16, 1.3227e-17, 2.2204e-16, 2.2204e-16, 1.1102e-16, 1.3878e-17,\n",
      "         1.0061e-16, 1.6653e-16, 1.0408e-16, 2.2204e-16, 1.3878e-17, 1.3878e-17,\n",
      "         8.3267e-17, 1.1102e-16, 1.3878e-17, 8.3267e-17, 1.6653e-16, 2.7756e-17,\n",
      "         5.5511e-16, 3.8858e-16, 2.7756e-16, 4.9960e-16, 1.6653e-16, 8.8818e-16,\n",
      "         4.4409e-16, 5.5511e-16, 8.3267e-17, 4.4409e-16, 4.4409e-16, 6.6613e-16,\n",
      "         6.6613e-16, 2.7756e-16, 1.6653e-16, 4.4409e-16, 3.3307e-16, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 6.6613e-16, 2.2204e-16, 8.8818e-16, 2.9837e-16,\n",
      "         4.4409e-16, 4.4409e-16, 6.6613e-16, 3.3307e-16, 1.6653e-16, 2.7756e-16,\n",
      "         6.6613e-16, 4.4409e-16, 6.6613e-16, 2.7756e-16, 2.2204e-16, 2.2204e-16,\n",
      "         4.4409e-16, 2.2204e-16, 5.5511e-16, 6.6613e-16, 6.6613e-16, 1.7764e-15,\n",
      "         4.4409e-16, 2.2204e-16, 8.8818e-16, 4.4409e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 8.8818e-16, 2.9143e-16, 2.2204e-16, 8.8818e-16,\n",
      "         1.9429e-16, 4.3368e-16, 2.2204e-16, 4.4409e-16, 3.3307e-16, 2.2204e-16,\n",
      "         1.3323e-15, 4.4409e-16, 1.1102e-15, 2.2204e-16, 2.2204e-16, 6.6613e-16,\n",
      "         8.8818e-16, 3.1919e-16, 1.2490e-16, 6.6613e-16, 4.4409e-16, 2.2204e-16,\n",
      "         8.8818e-16, 6.6613e-16, 1.3878e-16, 4.4409e-16, 3.3307e-16, 8.8818e-16,\n",
      "         2.2204e-16, 2.2204e-16, 8.8818e-16, 1.3878e-16, 4.4409e-16, 1.1102e-16,\n",
      "         2.2204e-16, 3.3307e-16, 1.1102e-16, 4.4409e-16, 2.7756e-16, 8.8818e-16,\n",
      "         4.4409e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17, 1.1102e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16,\n",
      "         4.4409e-16, 4.4409e-16, 3.3307e-16, 3.3307e-16, 1.3323e-15, 3.8858e-16,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 1.3184e-16, 3.3307e-16,\n",
      "         4.4409e-16, 6.6613e-16, 2.7756e-16, 2.2204e-16, 4.4409e-16, 3.3307e-16,\n",
      "         4.4409e-16, 2.4980e-16, 2.2204e-16, 2.2204e-16, 2.7756e-16, 3.3307e-16,\n",
      "         8.8818e-16, 2.2204e-16]], dtype=torch.float64)\n",
      "tensor([  1,   2,   4,   5,   6,   7,   8,  10,  11,  14,  17,  20,  21,  22,\n",
      "         25,  26,  28,  29,  30,  31,  35,  37,  38,  39,  40,  42,  43,  45,\n",
      "         47,  50,  52,  53,  55,  58,  60,  61,  63,  64,  67,  69,  70,  72,\n",
      "         73,  74,  75,  76,  79,  80,  81,  82,  83,  86,  88,  89,  90,  91,\n",
      "         92,  94,  96,  98, 101, 102, 103, 105, 107, 109, 110, 114, 116, 117,\n",
      "        118, 119, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "        163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "        177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
      "        191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
      "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
      "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
      "        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "        289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
      "        303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
      "        317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "        331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
      "        345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
      "        359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
      "        373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386,\n",
      "        387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
      "        401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n",
      "        415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
      "        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
      "        457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "        485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   4,   5,   6,   7,   8,  10,  11,  14,  17,  20,  21,  22,\n",
      "         25,  26,  28,  29,  30,  31,  35,  37,  38,  39,  40,  42,  43,  45,\n",
      "         47,  50,  52,  53,  55,  58,  60,  61,  63,  64,  67,  69,  70,  72,\n",
      "         73,  74,  75,  76,  79,  80,  81,  82,  83,  86,  88,  89,  90,  91,\n",
      "         92,  94,  96,  98, 101, 102, 103, 105, 107, 109, 110, 114, 116, 117,\n",
      "        118, 119, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "        163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "        177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
      "        191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
      "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
      "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
      "        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "        289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
      "        303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
      "        317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "        331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
      "        345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
      "        359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
      "        373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386,\n",
      "        387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
      "        401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n",
      "        415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
      "        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
      "        457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "        485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])  (len = 461)\n",
      "passing Cout = tensor([  0,   3,   9,  12,  13,  15,  16,  18,  19,  23,  24,  27,  32,  33,\n",
      "         34,  36,  41,  44,  46,  48,  49,  51,  54,  56,  57,  59,  62,  65,\n",
      "         66,  68,  71,  77,  78,  84,  85,  87,  93,  95,  97,  99, 100, 104,\n",
      "        106, 108, 111, 112, 113, 115, 120, 124, 126])  (len = 51)\n",
      "\n",
      "Executing module 56: layer4.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 56\n",
      "Max diff:\n",
      "tensor([1.9984e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 4.3368e-19, 4.3368e-19, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.1684e-19, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 2.1684e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00,\n",
      "         1.3010e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 8.6736e-19, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-18, 8.6736e-19, 4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.6736e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 3.4694e-18, 1.7347e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-16, 6.3838e-16, 8.8818e-16, 1.1935e-15,\n",
      "         8.8818e-16, 5.5511e-16, 9.9920e-16, 5.5511e-16, 6.6613e-16, 8.8818e-16,\n",
      "         7.7716e-16, 6.6613e-16, 5.5511e-16, 8.8818e-16, 7.7716e-16, 1.3323e-15,\n",
      "         4.9960e-16, 4.4409e-16, 8.8818e-16, 6.6613e-16, 8.8818e-16, 3.3307e-16,\n",
      "         6.6613e-16, 1.7764e-15, 6.6613e-16, 8.8818e-16, 1.3323e-15, 4.4409e-16,\n",
      "         4.4409e-16, 6.6613e-16, 2.2204e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16,\n",
      "         7.7716e-16, 6.6613e-16, 6.6613e-16, 4.4409e-16, 3.8858e-16, 5.5511e-16,\n",
      "         5.5511e-16, 3.8858e-16, 6.6613e-16, 6.6613e-16, 6.1062e-16, 6.6613e-16,\n",
      "         2.2204e-16, 8.8818e-16, 2.4980e-16, 5.5511e-16, 8.8818e-16, 1.3323e-15,\n",
      "         8.3267e-16, 6.6613e-16, 1.3323e-15, 8.3267e-16, 4.4409e-16, 1.1102e-15,\n",
      "         5.5511e-16, 1.3323e-15, 8.8818e-16, 6.6613e-16, 1.1102e-15, 1.1102e-15,\n",
      "         4.4409e-16, 4.4409e-16, 3.3307e-16, 6.6613e-16, 8.8818e-16, 1.0547e-15,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 1.9984e-15, 7.1471e-16, 6.6613e-16,\n",
      "         1.1102e-15, 1.1102e-15, 1.3323e-15, 6.6613e-16, 3.3307e-16, 8.8818e-16,\n",
      "         1.7764e-15, 6.6613e-16, 4.4409e-16, 4.4409e-16, 6.6613e-16, 4.9960e-16,\n",
      "         1.1102e-16, 8.3267e-16, 3.3307e-16, 4.1633e-16, 3.3307e-16, 4.9960e-16,\n",
      "         6.6613e-16, 8.8818e-16, 2.2204e-16, 3.0531e-16, 1.5543e-15, 4.4409e-16,\n",
      "         9.9920e-16, 7.7716e-16, 3.8858e-16, 9.9920e-16, 6.6613e-16, 3.3307e-16,\n",
      "         1.3323e-15, 3.3307e-16, 8.8818e-16, 1.1102e-15, 6.9389e-16, 4.9960e-16,\n",
      "         1.1102e-15, 4.4409e-16, 2.7756e-16, 8.3267e-16, 4.4409e-16, 8.8818e-16,\n",
      "         5.5511e-16, 4.7184e-16, 6.6613e-16, 4.4409e-16, 6.3838e-16, 1.3323e-15,\n",
      "         8.8818e-16, 7.7716e-16, 8.8818e-16, 1.5543e-15, 3.4694e-18, 5.5511e-17,\n",
      "         3.4694e-18, 3.4694e-18, 3.4694e-18, 5.5511e-17, 8.3267e-17, 2.7756e-17,\n",
      "         3.4694e-18, 2.7756e-17, 9.7145e-17, 0.0000e+00, 5.5511e-17, 2.2204e-16,\n",
      "         1.3878e-17, 8.6736e-18, 6.9389e-17, 3.4694e-17, 0.0000e+00, 3.1225e-17,\n",
      "         2.7756e-17, 2.7756e-17, 0.0000e+00, 6.9389e-18, 2.7756e-17, 8.3267e-17,\n",
      "         3.9031e-17, 1.3878e-17, 5.5511e-17, 1.0408e-17, 2.7756e-17, 6.9389e-18,\n",
      "         6.9389e-18, 6.9389e-18, 5.5511e-17, 6.9389e-18, 2.7756e-17, 5.5511e-17,\n",
      "         0.0000e+00, 4.1633e-17, 2.7756e-17, 2.7756e-17, 1.3878e-17, 6.9389e-18,\n",
      "         6.6613e-16, 1.3878e-17, 1.3878e-17, 5.5511e-17, 1.7347e-18, 3.4694e-18,\n",
      "         8.3267e-17, 6.9389e-18, 4.1633e-17, 3.0358e-18, 3.4694e-17, 2.7756e-17,\n",
      "         3.4694e-17, 4.1633e-16, 0.0000e+00, 3.4694e-17, 2.7756e-17, 6.9389e-18,\n",
      "         0.0000e+00, 3.4694e-18, 1.1102e-16, 2.7756e-17, 2.2204e-16, 1.3878e-17,\n",
      "         5.5511e-17, 0.0000e+00, 6.9389e-18, 0.0000e+00, 2.7756e-17, 1.3878e-17,\n",
      "         6.9389e-18, 2.0817e-17, 2.7756e-17, 6.9389e-18, 3.4694e-18, 2.7756e-17,\n",
      "         3.4694e-18, 1.3878e-17, 2.7756e-17, 4.1633e-17, 0.0000e+00, 1.1102e-16,\n",
      "         2.7756e-17, 1.3878e-17, 3.4694e-18, 2.7756e-17, 1.7347e-18, 1.7347e-18,\n",
      "         3.4694e-18, 2.7756e-17, 6.9389e-18, 2.7756e-17, 6.9389e-18, 5.5511e-17,\n",
      "         5.5511e-17, 1.3878e-17, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 1.1102e-16, 0.0000e+00, 2.7756e-17, 1.7347e-18, 3.4694e-18,\n",
      "         5.5511e-17, 3.4694e-18, 6.9389e-17, 5.5511e-17, 1.3878e-17, 3.4694e-18,\n",
      "         1.3878e-17, 3.4694e-17, 2.0817e-17, 8.3267e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-17, 3.4694e-18, 0.0000e+00, 4.1633e-17, 6.9389e-18,\n",
      "         1.3878e-16, 0.0000e+00, 5.5511e-17, 5.5511e-17, 0.0000e+00, 2.2204e-16,\n",
      "         2.2204e-16, 2.2204e-16, 2.0817e-17, 5.5511e-17, 1.1102e-16, 1.6653e-16,\n",
      "         2.2204e-16, 2.7756e-17, 1.3878e-17, 2.7756e-17, 5.5511e-17, 9.7145e-17,\n",
      "         1.1102e-16, 3.3307e-16, 5.5511e-17, 5.5511e-17, 2.2204e-16, 2.2551e-17,\n",
      "         1.1102e-16, 4.5103e-17, 2.2204e-16, 6.9389e-17, 2.7756e-17, 8.3267e-17,\n",
      "         2.2204e-16, 5.5511e-17, 2.2204e-16, 1.1102e-16, 5.5511e-17, 4.6838e-17,\n",
      "         1.1102e-16, 1.1102e-16, 1.1102e-16, 1.3878e-16, 2.2204e-16, 6.6613e-16,\n",
      "         6.2450e-17, 2.7756e-17, 2.2204e-16, 1.1102e-16, 1.1102e-16, 1.1102e-16,\n",
      "         8.3267e-17, 4.1633e-17, 2.2204e-16, 1.6653e-16, 4.1633e-17, 2.2204e-16,\n",
      "         2.7756e-17, 9.7145e-17, 6.2450e-17, 1.1102e-16, 2.7756e-17, 1.3878e-17,\n",
      "         2.2204e-16, 1.1102e-16, 1.6653e-16, 0.0000e+00, 5.5511e-17, 2.2204e-16,\n",
      "         4.4409e-16, 1.3878e-17, 0.0000e+00, 1.1102e-16, 1.1102e-16, 1.3878e-17,\n",
      "         4.4409e-16, 1.6653e-16, 1.7347e-18, 1.1102e-16, 1.3878e-17, 1.3878e-16,\n",
      "         0.0000e+00, 1.0408e-17, 1.6653e-16, 6.9389e-18, 2.7756e-17, 0.0000e+00,\n",
      "         2.7756e-17, 1.6653e-16, 0.0000e+00, 1.3878e-16, 6.7654e-17, 2.2204e-16,\n",
      "         8.3267e-17, 1.6653e-16, 2.2204e-16, 1.3878e-17, 0.0000e+00, 8.3267e-17,\n",
      "         2.2204e-16, 5.5511e-17, 2.2204e-16, 3.3307e-16, 1.1102e-16, 2.2204e-16,\n",
      "         2.7756e-17, 1.1102e-16, 8.3267e-17, 6.9389e-18, 3.3307e-16, 2.7756e-17,\n",
      "         4.1633e-17, 1.1102e-16, 5.5511e-17, 5.5511e-17, 0.0000e+00, 2.7756e-17,\n",
      "         2.7756e-17, 8.3267e-17, 2.7756e-17, 0.0000e+00, 1.1102e-16, 2.7756e-17,\n",
      "         1.3878e-16, 3.8164e-17, 1.3878e-17, 1.3878e-17, 5.5511e-17, 5.5511e-17,\n",
      "         2.7756e-16, 5.5511e-17]], dtype=torch.float64)\n",
      "tensor([  1,   2,   5,   8,  14,  17,  20,  26,  29,  30,  31,  35,  38,  45,\n",
      "         47,  52,  61,  64,  67,  69,  72,  73,  80,  81,  83,  90,  91,  92,\n",
      "         96, 101, 109, 116, 117, 118, 122, 125, 128, 129, 130, 131, 132, 133,\n",
      "        134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
      "        148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "        162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "        176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
      "        190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,\n",
      "        204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
      "        218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
      "        232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245,\n",
      "        246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "        260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 272, 273, 275,\n",
      "        276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
      "        291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "        306, 307, 308, 309, 310, 311, 312, 313, 315, 316, 317, 319, 320, 321,\n",
      "        322, 323, 324, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
      "        353, 354, 355, 357, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "        371, 372, 373, 374, 375, 379, 380, 382, 383, 384, 386, 387, 389, 390,\n",
      "        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
      "        405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
      "        419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "        433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
      "        448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463,\n",
      "        464, 465, 466, 468, 469, 471, 472, 473, 474, 475, 476, 477, 479, 480,\n",
      "        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
      "        495, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
      "        511])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   5,   8,  14,  17,  20,  26,  29,  30,  31,  35,  38,  45,\n",
      "         47,  52,  61,  64,  67,  69,  72,  73,  80,  81,  83,  90,  91,  92,\n",
      "         96, 101, 109, 116, 117, 118, 122, 125, 128, 129, 130, 131, 132, 133,\n",
      "        134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
      "        148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "        162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "        176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
      "        190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,\n",
      "        204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
      "        218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
      "        232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245,\n",
      "        246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "        260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 272, 273, 275,\n",
      "        276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
      "        291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "        306, 307, 308, 309, 310, 311, 312, 313, 315, 316, 317, 319, 320, 321,\n",
      "        322, 323, 324, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
      "        353, 354, 355, 357, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "        371, 372, 373, 374, 375, 379, 380, 382, 383, 384, 386, 387, 389, 390,\n",
      "        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
      "        405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
      "        419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "        433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
      "        448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463,\n",
      "        464, 465, 466, 468, 469, 471, 472, 473, 474, 475, 476, 477, 479, 480,\n",
      "        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
      "        495, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
      "        511])  (len = 393)\n",
      "passing Cout = tensor([  0,   3,   4,   6,   7,   9,  10,  11,  12,  13,  15,  16,  18,  19,\n",
      "         21,  22,  23,  24,  25,  27,  28,  32,  33,  34,  36,  37,  39,  40,\n",
      "         41,  42,  43,  44,  46,  48,  49,  50,  51,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  62,  63,  65,  66,  68,  70,  71,  74,  75,  76,  77,\n",
      "         78,  79,  82,  84,  85,  86,  87,  88,  89,  93,  94,  95,  97,  98,\n",
      "         99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114,\n",
      "        115, 119, 120, 121, 123, 124, 126, 127, 267, 274, 278, 294, 314, 318,\n",
      "        325, 327, 340, 356, 358, 359, 362, 376, 377, 378, 381, 385, 388, 447,\n",
      "        452, 462, 467, 470, 478, 496, 501])  (len = 119)\n",
      "\n",
      "Executing module 57: layer4.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 57\n",
      "Max diff:\n",
      "tensor([1.7764e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[3.4694e-18, 8.6736e-19, 8.6736e-19, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         8.6736e-19, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 8.6736e-19, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         8.6736e-19, 0.0000e+00, 3.4694e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 3.4694e-18, 6.9389e-18,\n",
      "         3.4694e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 0.0000e+00, 1.7347e-18, 0.0000e+00, 3.4694e-18,\n",
      "         1.3010e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 8.6736e-19, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         3.4694e-18, 1.7347e-18, 4.3368e-19, 1.7347e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7347e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7347e-18, 1.7347e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 6.9389e-18, 1.7347e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5527e-15, 3.7748e-15, 5.3291e-15, 4.4409e-15,\n",
      "         1.0658e-14, 2.4425e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 4.6629e-15,\n",
      "         2.6645e-15, 5.3291e-15, 2.2204e-15, 2.6645e-15, 3.5527e-15, 1.7764e-14,\n",
      "         3.5527e-15, 7.1054e-15, 7.1054e-15, 6.2172e-15, 1.7764e-14, 2.6645e-15,\n",
      "         3.5527e-15, 1.0658e-14, 2.6645e-15, 1.3323e-15, 5.3291e-15, 5.3291e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.0658e-14, 5.3291e-15, 1.7764e-15, 3.1086e-15,\n",
      "         5.3291e-15, 2.6645e-15, 3.7748e-15, 1.0658e-14, 3.5527e-15, 3.9968e-15,\n",
      "         5.3291e-15, 2.4425e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15, 3.5527e-15,\n",
      "         5.3291e-15, 5.3291e-15, 2.7200e-15, 3.9899e-15, 3.5527e-15, 7.1054e-15,\n",
      "         3.5527e-15, 8.8818e-15, 7.1054e-15, 8.8818e-15, 2.2204e-15, 3.9968e-15,\n",
      "         2.6645e-15, 8.8818e-15, 4.4409e-15, 3.5527e-15, 8.8818e-15, 4.4409e-15,\n",
      "         3.5527e-15, 1.0658e-14, 2.6645e-15, 5.3291e-15, 5.3291e-15, 3.5527e-15,\n",
      "         3.5527e-15, 2.6645e-15, 8.8818e-15, 3.5527e-15, 1.0658e-14, 3.1086e-15,\n",
      "         7.1054e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.7764e-14, 1.7764e-15, 2.6645e-15, 1.0658e-14, 3.5527e-15, 5.3291e-15,\n",
      "         8.8818e-16, 1.0658e-14, 5.3291e-15, 2.6645e-15, 7.1054e-15, 5.3291e-15,\n",
      "         5.3291e-15, 3.5527e-15, 7.1054e-15, 3.5527e-15, 3.9968e-15, 5.3291e-15,\n",
      "         7.1054e-15, 5.3291e-15, 1.4211e-14, 3.5527e-15, 7.1054e-15, 7.1054e-15,\n",
      "         5.3291e-15, 5.3291e-15, 2.2204e-15, 5.3291e-15, 2.6645e-15, 3.5527e-15,\n",
      "         1.0658e-14, 3.6637e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 1.0658e-14,\n",
      "         3.5527e-15, 3.5527e-15, 2.2204e-15, 5.3291e-15, 8.8818e-15, 5.3291e-15,\n",
      "         1.0658e-14, 1.3323e-15, 4.4409e-15, 3.9968e-15, 2.7756e-17, 8.8818e-16,\n",
      "         4.4409e-16, 6.9389e-18, 2.7756e-17, 3.3307e-16, 5.5511e-16, 5.5511e-17,\n",
      "         8.3267e-17, 1.1102e-16, 1.6653e-16, 2.7756e-17, 4.4409e-16, 3.3307e-16,\n",
      "         2.2204e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16, 1.6653e-16,\n",
      "         1.6653e-16, 2.2204e-16, 2.2204e-16, 5.5511e-17, 8.8818e-16, 1.6653e-16,\n",
      "         4.4409e-16, 1.1102e-16, 2.2204e-16, 1.3323e-15, 1.1102e-16, 2.7756e-17,\n",
      "         2.7756e-17, 3.3307e-16, 1.1102e-16, 3.3307e-16, 5.5511e-17, 2.2204e-16,\n",
      "         2.2204e-16, 4.4409e-16, 1.1102e-16, 1.1102e-15, 5.5511e-17, 6.6613e-16,\n",
      "         6.6613e-16, 5.5511e-17, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.3878e-17,\n",
      "         2.2204e-16, 5.5511e-17, 1.6653e-16, 2.7756e-17, 1.3323e-15, 8.8818e-16,\n",
      "         3.3307e-16, 5.5511e-16, 1.3878e-17, 1.1102e-16, 1.1102e-16, 2.7756e-17,\n",
      "         3.3307e-16, 2.7756e-17, 2.2204e-16, 4.4409e-16, 4.4409e-16, 5.5511e-17,\n",
      "         1.1102e-16, 5.5511e-17, 1.3878e-17, 2.2204e-16, 4.4409e-16, 1.1102e-16,\n",
      "         2.7756e-17, 2.2204e-16, 4.4409e-16, 5.5511e-17, 5.5511e-17, 2.2204e-16,\n",
      "         5.5511e-17, 2.2204e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 1.3878e-17, 2.2204e-16, 1.3878e-17, 1.3878e-17,\n",
      "         2.7756e-17, 2.2204e-16, 4.4409e-16, 1.1102e-16, 2.7756e-17, 2.2204e-16,\n",
      "         4.4409e-16, 2.7756e-17, 4.4409e-16, 2.2204e-16, 1.3878e-17, 4.4409e-16,\n",
      "         2.2204e-16, 2.2204e-16, 2.2204e-16, 3.0531e-16, 2.7756e-17, 2.0817e-17,\n",
      "         4.4409e-16, 2.7756e-17, 6.6613e-16, 5.5511e-17, 2.2204e-16, 1.3878e-17,\n",
      "         5.5511e-16, 4.4409e-16, 8.3267e-17, 3.3307e-16, 2.7756e-17, 2.7756e-17,\n",
      "         4.4409e-16, 5.5511e-16, 4.1633e-17, 2.2204e-16, 1.6653e-16, 5.5511e-17,\n",
      "         4.4409e-16, 2.2204e-16, 1.1102e-16, 7.2164e-16, 4.4409e-16, 1.3323e-15,\n",
      "         4.4409e-16, 4.4409e-16, 5.5511e-17, 5.5511e-16, 4.4409e-16, 1.1102e-15,\n",
      "         4.4409e-16, 8.8818e-16, 6.6613e-16, 6.6613e-16, 8.8818e-16, 2.2204e-16,\n",
      "         6.6613e-16, 5.5511e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16,\n",
      "         4.4409e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 3.3307e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 2.7756e-16, 1.3323e-15, 6.6613e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16,\n",
      "         4.4409e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 1.1102e-16, 4.4409e-16,\n",
      "         4.4409e-16, 5.5511e-16, 6.6613e-16, 1.1102e-15, 5.5511e-16, 6.6613e-16,\n",
      "         4.4409e-16, 5.5511e-16, 8.8818e-16, 1.3323e-15, 1.3323e-15, 2.2204e-16,\n",
      "         6.6613e-16, 8.8818e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16, 8.8818e-16,\n",
      "         5.5511e-16, 6.6613e-16, 3.3307e-16, 3.3307e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16, 8.8818e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 6.6613e-16, 1.6653e-16, 1.6653e-16,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16,\n",
      "         6.6613e-16, 1.5543e-15, 4.4409e-16, 2.7756e-17, 4.4409e-16, 4.4409e-16,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 6.6613e-16,\n",
      "         4.4409e-16, 2.7756e-16, 1.3323e-15, 4.4409e-16, 4.4409e-16, 6.6613e-16,\n",
      "         8.8818e-16, 1.1102e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16, 3.3307e-16,\n",
      "         4.4409e-16, 4.4409e-16, 3.8858e-16, 8.8818e-16, 3.3307e-16, 6.6613e-16,\n",
      "         2.7756e-16, 6.6613e-16, 1.1102e-15, 8.8818e-16, 3.3307e-16, 4.4409e-16,\n",
      "         4.4409e-16, 5.5511e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   6,   8,  13,  14,  17,  18,  20,  21,  24,  26,\n",
      "         28,  29,  30,  31,  34,  47,  52,  56,  59,  64,  67,  69,  71,  72,\n",
      "         73,  77,  80,  81,  83,  89,  90,  91,  92,  93,  98, 101, 105, 109,\n",
      "        110, 116, 117, 118, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "        138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "        152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
      "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
      "        264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
      "        278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "        292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "        306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319,\n",
      "        320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "        334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347,\n",
      "        348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
      "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
      "        376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
      "        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
      "        418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
      "        432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "        446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
      "        460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "        474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487,\n",
      "        488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
      "        502, 503, 504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   6,   8,  13,  14,  17,  18,  20,  21,  24,  26,\n",
      "         28,  29,  30,  31,  34,  47,  52,  56,  59,  64,  67,  69,  71,  72,\n",
      "         73,  77,  80,  81,  83,  89,  90,  91,  92,  93,  98, 101, 105, 109,\n",
      "        110, 116, 117, 118, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "        138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "        152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
      "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
      "        264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
      "        278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "        292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "        306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319,\n",
      "        320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "        334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347,\n",
      "        348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
      "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
      "        376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
      "        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
      "        418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
      "        432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "        446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
      "        460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "        474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487,\n",
      "        488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
      "        502, 503, 504, 505, 506, 507, 508, 509, 510, 511])  (len = 430)\n",
      "passing Cout = tensor([  4,   5,   7,   9,  10,  11,  12,  15,  16,  19,  22,  23,  25,  27,\n",
      "         32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
      "         48,  49,  50,  51,  53,  54,  55,  57,  58,  60,  61,  62,  63,  65,\n",
      "         66,  68,  70,  74,  75,  76,  78,  79,  82,  84,  85,  86,  87,  88,\n",
      "         94,  95,  96,  97,  99, 100, 102, 103, 104, 106, 107, 108, 111, 112,\n",
      "        113, 114, 115, 119, 120, 121, 122, 123, 124, 125, 126, 127])  (len = 82)\n",
      "\n",
      "Executing module 58: layer4.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 58\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.6736e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3010e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7748e-15, 0.0000e+00, 2.4425e-15,\n",
      "         0.0000e+00, 1.7764e-15, 8.8818e-16, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-15, 2.6645e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.5543e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 2.2204e-15, 8.8818e-16, 1.3323e-15, 0.0000e+00, 1.7764e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00, 3.1086e-15,\n",
      "         0.0000e+00, 1.3323e-15, 2.2204e-15, 0.0000e+00, 0.0000e+00, 3.9968e-15,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 2.6645e-15, 3.5527e-15,\n",
      "         1.6653e-16, 0.0000e+00, 9.9920e-16, 1.7764e-15, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.2188e-15, 4.4409e-16, 0.0000e+00, 2.2204e-15,\n",
      "         0.0000e+00, 0.0000e+00, 2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7764e-15, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3323e-15, 7.7716e-16, 0.0000e+00, 1.7764e-15,\n",
      "         2.2204e-15, 2.2204e-15, 0.0000e+00, 2.6090e-15, 3.9968e-15, 1.5543e-15,\n",
      "         3.1086e-15, 6.6613e-16, 0.0000e+00, 3.3307e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.5535e-15, 2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5527e-15, 1.7764e-15, 8.8818e-16, 0.0000e+00,\n",
      "         2.2204e-15, 2.2204e-15, 1.1657e-15, 2.4980e-16, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 8.8818e-16, 1.3323e-15, 3.9968e-15, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 1.6653e-16, 0.0000e+00, 8.3267e-17, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 4.8572e-17, 0.0000e+00, 1.6653e-16, 6.9389e-17,\n",
      "         4.8572e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9429e-16, 1.6653e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-16, 9.7145e-17, 0.0000e+00, 1.2490e-16,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         6.6613e-16, 0.0000e+00, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 4.1633e-17,\n",
      "         4.1633e-17, 5.5511e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00, 5.5511e-17,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 3.4694e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         2.2204e-16, 1.9429e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00, 1.1102e-16,\n",
      "         2.7756e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 4.5103e-17, 8.3267e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 4.1633e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         1.9429e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 4.1633e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 3.3307e-16, 3.3307e-16, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0531e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-16, 2.2204e-16, 2.2204e-16,\n",
      "         2.7756e-16, 0.0000e+00, 4.4409e-16, 2.7756e-16, 0.0000e+00, 3.3307e-16,\n",
      "         3.8858e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-16, 4.4409e-16, 0.0000e+00, 4.4409e-16, 3.3307e-16, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 6.6613e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         2.2204e-16, 0.0000e+00, 4.3021e-16, 3.3307e-16, 0.0000e+00, 8.8818e-16,\n",
      "         0.0000e+00, 3.3307e-16, 3.3307e-16, 3.3307e-16, 3.3307e-16, 4.4409e-16,\n",
      "         0.0000e+00, 2.4980e-16, 1.6653e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.6653e-16, 0.0000e+00, 0.0000e+00, 2.7756e-17, 3.4694e-17, 1.6653e-16,\n",
      "         2.2204e-16, 2.2204e-16, 3.3307e-16, 8.8818e-16, 3.3307e-16, 2.2204e-16,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 3.0531e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0531e-16, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 2.4980e-16, 3.3307e-16, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 8.3267e-17, 0.0000e+00, 1.6653e-16, 3.3307e-16,\n",
      "         0.0000e+00, 4.4409e-16, 3.8858e-16, 2.2204e-16, 3.3307e-16, 3.3307e-16,\n",
      "         2.7756e-16, 0.0000e+00, 1.1102e-16, 0.0000e+00, 0.0000e+00, 1.9429e-16,\n",
      "         0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([  1,  18,  72, 129, 131, 133, 134, 136, 140, 141, 144, 149, 151, 152,\n",
      "        153, 155, 159, 161, 163, 164, 167, 169, 172, 173, 174, 176, 177, 178,\n",
      "        183, 188, 189, 191, 194, 199, 203, 211, 212, 218, 219, 221, 222, 223,\n",
      "        225, 226, 227, 228, 229, 231, 235, 236, 242, 243, 244, 246, 247, 248,\n",
      "        249, 251, 253, 254, 255, 258, 261, 263, 266, 268, 270, 272, 274, 275,\n",
      "        276, 280, 281, 290, 291, 293, 295, 297, 300, 302, 308, 311, 312, 313,\n",
      "        318, 321, 323, 324, 329, 331, 338, 340, 342, 343, 350, 353, 354, 360,\n",
      "        362, 363, 374, 375, 382, 384, 385, 386, 387, 388, 391, 395, 397, 398,\n",
      "        399, 403, 407, 411, 412, 413, 414, 416, 417, 419, 420, 424, 429, 432,\n",
      "        433, 435, 436, 439, 440, 443, 444, 446, 447, 449, 451, 452, 453, 454,\n",
      "        455, 457, 458, 462, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
      "        478, 479, 483, 485, 487, 489, 490, 491, 494, 496, 497, 499, 500, 501,\n",
      "        502, 503, 504, 506, 509])\n",
      "\n",
      "failing Cout = tensor([  1,  18,  72, 129, 131, 133, 134, 136, 140, 141, 144, 149, 151, 152,\n",
      "        153, 155, 159, 161, 163, 164, 167, 169, 172, 173, 174, 176, 177, 178,\n",
      "        183, 188, 189, 191, 194, 199, 203, 211, 212, 218, 219, 221, 222, 223,\n",
      "        225, 226, 227, 228, 229, 231, 235, 236, 242, 243, 244, 246, 247, 248,\n",
      "        249, 251, 253, 254, 255, 258, 261, 263, 266, 268, 270, 272, 274, 275,\n",
      "        276, 280, 281, 290, 291, 293, 295, 297, 300, 302, 308, 311, 312, 313,\n",
      "        318, 321, 323, 324, 329, 331, 338, 340, 342, 343, 350, 353, 354, 360,\n",
      "        362, 363, 374, 375, 382, 384, 385, 386, 387, 388, 391, 395, 397, 398,\n",
      "        399, 403, 407, 411, 412, 413, 414, 416, 417, 419, 420, 424, 429, 432,\n",
      "        433, 435, 436, 439, 440, 443, 444, 446, 447, 449, 451, 452, 453, 454,\n",
      "        455, 457, 458, 462, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
      "        478, 479, 483, 485, 487, 489, 490, 491, 494, 496, 497, 499, 500, 501,\n",
      "        502, 503, 504, 506, 509])  (len = 173)\n",
      "passing Cout = tensor([ 17,  42,  47,  69,  87, 104, 108, 119, 310, 345])  (len = 10)\n",
      "\n",
      "Executing module 59: layer4.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 59\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.3368e-19, 2.7105e-20, 0.0000e+00, 0.0000e+00, 2.1684e-19, 0.0000e+00,\n",
      "         5.4210e-20, 1.0842e-19, 0.0000e+00, 1.3553e-20, 2.7105e-20, 0.0000e+00,\n",
      "         1.3553e-20, 1.3553e-20, 0.0000e+00, 0.0000e+00, 2.7105e-20, 0.0000e+00,\n",
      "         0.0000e+00, 6.7763e-21, 1.0842e-19, 0.0000e+00, 5.4210e-20, 5.4210e-20,\n",
      "         2.1684e-19, 4.3368e-19, 4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7105e-20, 0.0000e+00, 2.7105e-20, 0.0000e+00, 0.0000e+00, 2.1684e-19,\n",
      "         0.0000e+00, 4.3368e-19, 0.0000e+00, 2.7105e-20, 2.7105e-20, 2.1684e-19,\n",
      "         4.3368e-19, 1.0842e-19, 1.0842e-19, 1.3553e-20, 2.7105e-20, 2.1684e-19,\n",
      "         4.3368e-19, 1.3553e-20, 0.0000e+00, 4.3368e-19, 1.3553e-20, 0.0000e+00,\n",
      "         6.7763e-21, 1.3553e-20, 5.4210e-20, 2.7105e-20, 2.1684e-19, 1.3553e-20,\n",
      "         4.3368e-19, 2.7105e-20, 0.0000e+00, 1.3553e-20, 0.0000e+00, 0.0000e+00,\n",
      "         2.7105e-20, 2.1684e-19, 1.0842e-19, 1.3553e-20, 2.7105e-20, 2.1684e-19,\n",
      "         2.7105e-20, 2.1684e-19, 2.1684e-19, 1.3553e-20, 0.0000e+00, 2.1684e-19,\n",
      "         0.0000e+00, 0.0000e+00, 1.3553e-20, 0.0000e+00, 4.3368e-19, 5.4210e-20,\n",
      "         0.0000e+00, 1.0842e-19, 5.4210e-20, 0.0000e+00, 5.4210e-20, 5.4210e-20,\n",
      "         2.7105e-20, 5.4210e-20, 2.7105e-20, 0.0000e+00, 1.3553e-20, 2.1684e-19,\n",
      "         0.0000e+00, 1.0842e-19, 1.3553e-20, 4.3368e-19, 6.7763e-21, 0.0000e+00,\n",
      "         6.7763e-21, 8.6736e-19, 4.3368e-19, 0.0000e+00, 1.3553e-20, 1.0842e-19,\n",
      "         0.0000e+00, 1.3553e-20, 0.0000e+00, 0.0000e+00, 1.0842e-19, 5.4210e-20,\n",
      "         1.0842e-19, 0.0000e+00, 0.0000e+00, 2.7105e-20, 2.1684e-19, 1.0842e-19,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7105e-20, 2.1684e-19, 2.7105e-20,\n",
      "         2.1684e-19, 0.0000e+00, 6.2172e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15,\n",
      "         7.1054e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15, 6.6613e-15, 7.9936e-15,\n",
      "         1.4211e-14, 6.2172e-15, 5.3291e-15, 1.3323e-15, 8.8818e-15, 4.4409e-15,\n",
      "         8.8818e-15, 4.8850e-15, 3.5527e-15, 6.2172e-15, 7.1054e-15, 7.1054e-15,\n",
      "         4.4409e-15, 6.2172e-15, 5.3291e-15, 5.9952e-15, 6.6613e-16, 4.8850e-15,\n",
      "         7.1054e-15, 8.8818e-15, 7.1054e-15, 2.6645e-15, 7.1054e-15, 4.4409e-15,\n",
      "         3.9968e-15, 6.6613e-16, 8.8818e-15, 7.1054e-15, 9.7700e-15, 1.4211e-14,\n",
      "         5.3291e-15, 5.3291e-15, 6.2172e-15, 8.8818e-15, 5.4401e-15, 4.4409e-15,\n",
      "         8.8818e-15, 6.6613e-15, 1.4211e-14, 6.6336e-15, 4.4409e-15, 3.5527e-15,\n",
      "         4.0246e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15, 3.5527e-15, 1.0658e-14,\n",
      "         4.4409e-15, 7.6050e-15, 5.7732e-15, 6.2172e-15, 5.3291e-15, 5.6621e-15,\n",
      "         3.6637e-15, 4.2188e-15, 8.8818e-15, 6.2172e-15, 3.5527e-15, 5.3291e-15,\n",
      "         5.3291e-15, 4.4409e-15, 1.0658e-14, 5.3291e-15, 3.5527e-15, 6.2172e-15,\n",
      "         7.9936e-15, 7.1054e-15, 8.8818e-15, 6.6613e-16, 8.8818e-16, 3.5527e-15,\n",
      "         5.1070e-15, 1.0658e-14, 8.8818e-16, 5.3291e-15, 7.1054e-15, 6.2172e-15,\n",
      "         7.1054e-15, 7.1054e-15, 5.3291e-15, 5.6066e-15, 7.1054e-15, 7.1054e-15,\n",
      "         3.5527e-15, 9.7700e-15, 3.5527e-15, 3.5527e-15, 5.7732e-15, 6.2172e-15,\n",
      "         3.5527e-15, 8.8818e-15, 6.2172e-15, 4.6074e-15, 8.8818e-15, 4.4409e-15,\n",
      "         6.6891e-15, 1.1546e-14, 4.4409e-16, 7.9936e-15, 8.8818e-15, 4.4409e-15,\n",
      "         3.5527e-15, 7.1054e-15, 3.9968e-15, 3.5527e-15, 5.3291e-15, 7.1054e-15,\n",
      "         5.3291e-15, 8.8818e-15, 4.4409e-15, 3.5527e-15, 8.8818e-15, 7.1054e-15,\n",
      "         3.7748e-15, 1.0658e-14, 6.2172e-15, 7.1054e-15, 4.4409e-16, 1.1102e-15,\n",
      "         6.6613e-16, 5.5511e-17, 5.5511e-17, 8.8818e-16, 5.5511e-17, 4.4409e-16,\n",
      "         1.3323e-15, 4.2327e-16, 1.1102e-16, 5.5511e-17, 2.2204e-16, 5.5511e-17,\n",
      "         1.3323e-15, 8.8818e-16, 1.1102e-16, 2.2204e-16, 5.5511e-17, 5.5511e-17,\n",
      "         1.1102e-16, 5.5511e-17, 4.4409e-16, 8.8818e-16, 1.3323e-15, 5.5511e-17,\n",
      "         1.1102e-16, 1.6653e-16, 1.1102e-16, 1.7764e-15, 5.5511e-17, 8.8818e-16,\n",
      "         8.8818e-16, 2.2204e-16, 8.3267e-17, 4.4409e-16, 5.5511e-17, 8.8818e-16,\n",
      "         1.1102e-16, 2.2204e-16, 1.1102e-16, 1.1102e-16, 2.2204e-16, 3.8858e-16,\n",
      "         5.5511e-17, 5.5511e-17, 1.1102e-16, 8.8818e-16, 4.4409e-16, 1.1102e-16,\n",
      "         3.3307e-16, 5.5511e-17, 6.6613e-16, 5.5511e-17, 8.8818e-16, 6.6613e-16,\n",
      "         8.8818e-16, 8.8818e-16, 2.7756e-17, 2.2204e-16, 6.9389e-17, 8.8818e-16,\n",
      "         1.1102e-16, 2.7756e-17, 5.5511e-16, 5.5511e-17, 2.7756e-17, 6.6613e-16,\n",
      "         1.1102e-16, 8.8818e-16, 4.4409e-16, 8.3267e-17, 5.5511e-17, 8.8818e-16,\n",
      "         5.5511e-17, 3.3307e-16, 8.8818e-16, 5.5511e-17, 8.8818e-16, 1.1102e-16,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.3323e-15, 2.0817e-17,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 1.7764e-15, 8.8818e-16, 8.8818e-16,\n",
      "         4.4409e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17, 1.1102e-16, 4.4409e-16,\n",
      "         5.5511e-17, 8.3267e-17, 2.7756e-17, 1.1102e-16, 2.7756e-17, 5.5511e-17,\n",
      "         2.2204e-16, 4.4409e-16, 8.8818e-16, 1.1102e-16, 3.3307e-16, 8.8818e-16,\n",
      "         4.4409e-16, 2.2204e-16, 2.7756e-17, 5.5511e-17, 5.5511e-17, 8.8818e-16,\n",
      "         1.3323e-15, 2.2204e-16, 8.8818e-16, 2.2204e-16, 6.6613e-16, 4.4409e-16,\n",
      "         5.5511e-17, 5.5511e-17, 4.4409e-16, 8.3267e-17, 4.4409e-16, 4.4409e-16,\n",
      "         6.6613e-16, 2.6645e-15, 5.3291e-15, 3.5527e-15, 8.8818e-16, 1.7764e-15,\n",
      "         4.4409e-16, 1.1102e-16, 2.2204e-16, 6.6613e-16, 2.6645e-15, 3.3307e-16,\n",
      "         3.3307e-16, 3.5527e-15, 1.7764e-15, 6.6613e-16, 2.6645e-15, 1.7764e-15,\n",
      "         1.3323e-15, 2.2204e-16, 2.6645e-15, 2.6645e-15, 6.6613e-16, 2.6645e-15,\n",
      "         3.5527e-15, 2.2204e-15, 1.3323e-15, 3.5527e-15, 1.1102e-16, 3.5527e-15,\n",
      "         2.6645e-15, 1.7764e-15, 3.5527e-15, 3.5527e-15, 3.3307e-16, 8.8818e-16,\n",
      "         2.6645e-15, 4.4409e-16, 2.2204e-16, 5.3291e-15, 3.3307e-16, 2.6645e-15,\n",
      "         3.3307e-16, 1.1102e-16, 1.7764e-15, 5.3291e-15, 2.2204e-16, 1.1102e-16,\n",
      "         8.8818e-16, 1.7764e-15, 1.1102e-16, 2.6645e-15, 2.2204e-15, 2.6645e-15,\n",
      "         8.8818e-16, 8.8818e-16, 3.5527e-15, 3.5527e-15, 2.2204e-15, 1.1102e-16,\n",
      "         1.7764e-15, 4.4409e-16, 3.5527e-15, 1.7764e-15, 1.1102e-16, 2.6645e-15,\n",
      "         1.5543e-15, 1.6653e-16, 1.7764e-15, 1.7764e-15, 2.6645e-15, 1.3323e-15,\n",
      "         2.2204e-16, 2.2204e-15, 3.3307e-16, 1.7764e-15, 1.1102e-16, 1.3323e-15,\n",
      "         1.2212e-15, 1.7764e-15, 2.2204e-16, 2.2204e-16, 2.2204e-16, 2.6645e-15,\n",
      "         2.6645e-15, 1.7764e-15, 3.3307e-16, 2.2204e-15, 1.3323e-15, 8.8818e-16,\n",
      "         2.6645e-15, 2.2204e-16, 1.7764e-15, 8.8818e-16, 3.3307e-16, 1.8874e-15,\n",
      "         1.5543e-15, 1.7764e-15, 3.3307e-16, 2.6645e-15, 3.5527e-15, 4.4409e-16,\n",
      "         2.2204e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16, 2.6645e-15,\n",
      "         2.6645e-15, 2.6645e-15, 1.7764e-15, 4.4409e-16, 1.6653e-16, 1.9984e-15,\n",
      "         3.3307e-16, 2.2204e-16, 4.4409e-16, 6.6613e-16, 2.2204e-16, 1.3323e-15,\n",
      "         2.2204e-16, 2.2204e-15, 2.6645e-15, 1.6653e-16, 4.4409e-15, 1.7764e-15,\n",
      "         1.7764e-15, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   4,   6,   7,   9,  10,  12,  13,  16,  19,  20,  22,  23,\n",
      "         24,  25,  26,  30,  32,  35,  37,  39,  40,  41,  42,  43,  44,  45,\n",
      "         46,  47,  48,  49,  51,  52,  54,  55,  56,  57,  58,  59,  60,  61,\n",
      "         63,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,  80,  82,\n",
      "         83,  85,  86,  88,  89,  90,  91,  92,  94,  95,  97,  98,  99, 100,\n",
      "        102, 103, 104, 106, 107, 109, 112, 113, 114, 117, 118, 119, 123, 124,\n",
      "        125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   4,   6,   7,   9,  10,  12,  13,  16,  19,  20,  22,  23,\n",
      "         24,  25,  26,  30,  32,  35,  37,  39,  40,  41,  42,  43,  44,  45,\n",
      "         46,  47,  48,  49,  51,  52,  54,  55,  56,  57,  58,  59,  60,  61,\n",
      "         63,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,  80,  82,\n",
      "         83,  85,  86,  88,  89,  90,  91,  92,  94,  95,  97,  98,  99, 100,\n",
      "        102, 103, 104, 106, 107, 109, 112, 113, 114, 117, 118, 119, 123, 124,\n",
      "        125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 470)\n",
      "passing Cout = tensor([  2,   3,   5,   8,  11,  14,  15,  17,  18,  21,  27,  28,  29,  31,\n",
      "         33,  34,  36,  38,  50,  53,  62,  64,  65,  76,  78,  79,  81,  84,\n",
      "         87,  93,  96, 101, 105, 108, 110, 111, 115, 116, 120, 121, 122, 127])  (len = 42)\n",
      "\n",
      "Executing module 60: layer4.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 60\n",
      "Max diff:\n",
      "tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1684e-19, 0.0000e+00, 0.0000e+00,\n",
      "         1.0842e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0842e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4210e-20, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.4210e-20, 0.0000e+00, 7.1054e-15, 3.5527e-15, 3.5527e-15, 2.2204e-15,\n",
      "         4.4409e-15, 2.2204e-15, 2.6645e-15, 1.3323e-15, 3.6637e-15, 2.6645e-15,\n",
      "         1.0658e-14, 3.1086e-15, 4.4409e-15, 2.7756e-16, 2.6645e-15, 3.5527e-15,\n",
      "         4.4409e-15, 1.9984e-15, 5.3291e-15, 6.2172e-15, 2.6645e-15, 4.4409e-15,\n",
      "         1.7764e-15, 5.3291e-15, 3.5527e-15, 2.0123e-15, 1.6653e-16, 3.3307e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 6.6613e-16, 3.9968e-15, 2.2204e-15,\n",
      "         1.3323e-15, 1.6653e-16, 4.4409e-15, 4.4409e-15, 3.7748e-15, 6.2172e-15,\n",
      "         4.4409e-15, 2.6645e-15, 2.2204e-15, 4.4409e-15, 1.0825e-15, 3.9968e-15,\n",
      "         4.4409e-15, 2.4425e-15, 6.2172e-15, 3.9066e-15, 2.6645e-15, 9.9920e-16,\n",
      "         1.9949e-15, 1.7764e-15, 5.3291e-15, 2.6645e-15, 2.6645e-15, 8.8818e-15,\n",
      "         3.9968e-15, 3.0670e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 2.4425e-15,\n",
      "         9.1593e-16, 2.3315e-15, 6.2172e-15, 1.5543e-15, 1.7764e-15, 2.6645e-15,\n",
      "         2.6645e-15, 2.2204e-15, 7.1054e-15, 1.7764e-15, 2.6645e-15, 1.7764e-15,\n",
      "         6.2172e-15, 1.5543e-15, 5.3291e-15, 1.6653e-16, 2.2204e-16, 5.5511e-16,\n",
      "         1.9984e-15, 3.5527e-15, 2.2204e-16, 1.7764e-15, 1.9984e-15, 2.6645e-15,\n",
      "         2.6645e-15, 6.2172e-15, 3.5527e-15, 2.5535e-15, 3.5527e-15, 2.2204e-15,\n",
      "         1.7764e-15, 8.8818e-15, 2.0539e-15, 1.7764e-15, 1.4433e-15, 2.6645e-15,\n",
      "         1.3323e-15, 4.4409e-15, 2.2204e-15, 1.5543e-15, 4.4409e-15, 1.7764e-15,\n",
      "         2.1372e-15, 7.1054e-15, 1.1102e-16, 3.1086e-15, 3.1086e-15, 3.5527e-15,\n",
      "         1.3323e-15, 3.1086e-15, 1.3323e-15, 1.7764e-15, 4.4409e-15, 3.5527e-15,\n",
      "         2.6645e-15, 2.6645e-15, 4.4409e-15, 1.3323e-15, 3.5527e-15, 1.7764e-15,\n",
      "         2.3315e-15, 2.6645e-15, 1.9984e-15, 3.5527e-15, 1.6653e-16, 4.4409e-16,\n",
      "         1.9429e-16, 1.3878e-17, 1.3878e-17, 3.3307e-16, 1.3878e-17, 1.1102e-16,\n",
      "         6.6613e-16, 3.3307e-16, 2.7756e-17, 1.3878e-17, 5.5511e-17, 1.3878e-17,\n",
      "         3.3307e-16, 4.4409e-16, 2.7756e-17, 5.5511e-17, 1.3878e-17, 6.9389e-18,\n",
      "         2.7756e-17, 1.3878e-17, 1.1102e-16, 4.4409e-16, 6.6613e-16, 1.3878e-17,\n",
      "         2.7756e-17, 4.1633e-17, 2.7756e-17, 8.8818e-16, 1.3878e-17, 4.4409e-16,\n",
      "         3.3307e-16, 5.5511e-17, 2.7756e-17, 2.2204e-16, 1.3878e-17, 3.3307e-16,\n",
      "         2.7756e-17, 5.5511e-17, 2.7756e-17, 2.7756e-17, 5.5511e-17, 1.1102e-16,\n",
      "         1.3878e-17, 1.3878e-17, 1.3878e-17, 2.2204e-16, 2.2204e-16, 2.7756e-17,\n",
      "         8.3267e-17, 1.3878e-17, 1.1102e-16, 6.9389e-18, 2.2204e-16, 2.7756e-16,\n",
      "         4.4409e-16, 6.6613e-16, 6.9389e-18, 2.7756e-17, 1.7347e-17, 2.2204e-16,\n",
      "         2.7756e-17, 1.3878e-17, 2.2204e-16, 1.3878e-17, 6.9389e-18, 2.2204e-16,\n",
      "         1.3878e-17, 8.8818e-16, 1.1102e-16, 2.0817e-17, 1.3878e-17, 2.2204e-16,\n",
      "         1.3878e-17, 1.1102e-16, 4.4409e-16, 1.3878e-17, 2.2204e-16, 2.7756e-17,\n",
      "         4.4409e-16, 2.2204e-16, 1.1102e-16, 1.6653e-16, 6.6613e-16, 3.4694e-18,\n",
      "         4.4409e-16, 4.4409e-16, 6.6613e-16, 6.6613e-16, 4.4409e-16, 2.2204e-16,\n",
      "         1.1102e-16, 2.2204e-16, 8.3267e-17, 6.9389e-18, 2.0817e-17, 1.6653e-16,\n",
      "         1.3878e-17, 2.0817e-17, 6.9389e-18, 2.7756e-17, 6.9389e-18, 1.3878e-17,\n",
      "         5.5511e-17, 2.2204e-16, 4.4409e-16, 1.3878e-17, 5.5511e-17, 4.4409e-16,\n",
      "         1.1102e-16, 5.5511e-17, 6.9389e-18, 1.3878e-17, 1.3878e-17, 2.2204e-16,\n",
      "         4.4409e-16, 5.5511e-17, 2.2204e-16, 4.1633e-17, 1.1102e-16, 3.3307e-16,\n",
      "         1.3878e-17, 1.3878e-17, 1.1102e-16, 2.0817e-17, 1.9429e-16, 1.2490e-16,\n",
      "         1.6653e-16, 1.7764e-15, 2.2204e-15, 1.5543e-15, 2.2204e-16, 6.6613e-16,\n",
      "         1.1102e-16, 2.7756e-17, 5.5511e-17, 1.6653e-16, 8.8818e-16, 5.5511e-17,\n",
      "         5.5511e-17, 8.8818e-16, 1.3323e-15, 1.6653e-16, 1.7764e-15, 8.8818e-16,\n",
      "         4.4409e-16, 5.5511e-17, 8.8818e-16, 1.7764e-15, 1.6653e-16, 8.8818e-16,\n",
      "         1.3323e-15, 6.6613e-16, 6.6613e-16, 1.3323e-15, 2.7756e-17, 8.8818e-16,\n",
      "         5.5511e-16, 6.6613e-16, 1.3323e-15, 1.1102e-15, 8.3267e-17, 1.1102e-16,\n",
      "         6.6613e-16, 1.1102e-16, 5.5511e-17, 2.6645e-15, 8.3267e-17, 8.8818e-16,\n",
      "         8.3267e-17, 2.7756e-17, 4.4409e-16, 1.7764e-15, 5.5511e-17, 2.7756e-17,\n",
      "         2.2204e-16, 1.7764e-15, 2.7756e-17, 1.1102e-15, 8.8818e-16, 1.1102e-15,\n",
      "         5.5511e-17, 2.2204e-16, 6.6613e-16, 6.6613e-16, 1.5543e-15, 2.7756e-17,\n",
      "         8.8818e-16, 1.1102e-16, 1.7764e-15, 6.6613e-16, 2.7756e-17, 1.1102e-15,\n",
      "         6.6613e-16, 4.1633e-17, 3.3307e-16, 1.1102e-15, 6.6613e-16, 7.7716e-16,\n",
      "         5.5511e-17, 1.3323e-15, 5.5511e-17, 6.6613e-16, 2.7756e-17, 6.6613e-16,\n",
      "         5.5511e-16, 2.2204e-16, 5.5511e-17, 5.5511e-17, 5.5511e-17, 1.1102e-15,\n",
      "         1.7764e-15, 6.6613e-16, 8.3267e-17, 4.4409e-16, 5.5511e-16, 1.6653e-16,\n",
      "         1.1102e-15, 5.5511e-17, 3.3307e-16, 1.6653e-16, 8.3267e-17, 8.6042e-16,\n",
      "         1.1102e-15, 6.6613e-16, 8.3267e-17, 8.8818e-16, 1.3323e-15, 1.1102e-16,\n",
      "         5.5511e-17, 8.8818e-16, 2.2204e-16, 1.3878e-16, 1.1102e-16, 1.7764e-15,\n",
      "         1.1102e-15, 1.7764e-15, 6.6613e-16, 1.1102e-16, 2.7756e-17, 1.3323e-15,\n",
      "         8.3267e-17, 5.5511e-17, 8.3267e-17, 1.1102e-16, 5.5511e-17, 6.6613e-16,\n",
      "         5.5511e-17, 1.1102e-15, 8.8818e-16, 2.7756e-17, 2.2204e-15, 4.4409e-16,\n",
      "         4.4409e-16, 7.7716e-16]], dtype=torch.float64)\n",
      "tensor([ 39,  42, 104, 117, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
      "        263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
      "        277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
      "        291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "        305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
      "        319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
      "        333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "        347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
      "        361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "        375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388,\n",
      "        389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
      "        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430,\n",
      "        431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n",
      "        445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "        459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "        473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "        487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500,\n",
      "        501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([ 39,  42, 104, 117, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
      "        263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
      "        277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
      "        291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "        305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
      "        319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
      "        333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "        347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
      "        361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "        375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388,\n",
      "        389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
      "        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430,\n",
      "        431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n",
      "        445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "        459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "        473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "        487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500,\n",
      "        501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])  (len = 389)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  40,  41,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "        115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 127])  (len = 123)\n",
      "\n",
      "Executing module 61: layer4.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 61\n",
      "Max diff:\n",
      "tensor([4.4409e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0842e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6645e-15, 1.3323e-15,\n",
      "         3.3307e-15, 0.0000e+00, 1.1102e-16, 0.0000e+00, 3.6637e-15, 8.8818e-16,\n",
      "         0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5543e-15, 0.0000e+00, 1.4988e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 2.0123e-15, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15,\n",
      "         4.1633e-16, 0.0000e+00, 4.4409e-15, 0.0000e+00, 1.4988e-15, 1.7764e-15,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-15, 0.0000e+00, 1.0825e-15, 3.9968e-15,\n",
      "         4.4409e-15, 2.4425e-15, 0.0000e+00, 1.8874e-15, 2.6645e-15, 6.1062e-16,\n",
      "         1.7764e-15, 0.0000e+00, 1.9984e-15, 2.6645e-15, 2.5535e-15, 0.0000e+00,\n",
      "         2.6645e-15, 4.1633e-16, 0.0000e+00, 1.1102e-15, 8.8818e-16, 1.5543e-15,\n",
      "         9.1593e-16, 2.3315e-15, 8.4394e-16, 3.3307e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7764e-15, 0.0000e+00, 1.3323e-15, 1.1068e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9960e-16,\n",
      "         9.1593e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5527e-15, 7.7716e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.9976e-15, 2.0539e-15, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5543e-15, 0.0000e+00, 6.6613e-16,\n",
      "         2.1372e-15, 7.7716e-16, 0.0000e+00, 2.2204e-15, 8.6042e-16, 3.3307e-16,\n",
      "         5.8287e-16, 6.2450e-16, 0.0000e+00, 1.1657e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.7764e-15, 1.3878e-15, 0.0000e+00, 2.1511e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9984e-15, 0.0000e+00, 1.6653e-16, 3.4694e-17,\n",
      "         5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3267e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8572e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6653e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.5266e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0929e-16, 0.0000e+00, 0.0000e+00, 6.7004e-17,\n",
      "         0.0000e+00, 1.6653e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.1633e-17, 0.0000e+00, 8.3267e-17, 0.0000e+00, 0.0000e+00,\n",
      "         1.5266e-16, 1.6653e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7145e-17, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 1.1102e-15, 2.4980e-16,\n",
      "         3.5215e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.9429e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.4720e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00, 6.6613e-16,\n",
      "         0.0000e+00, 4.9960e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         2.0817e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3592e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1001e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.7716e-16]], dtype=torch.float64)\n",
      "tensor([104, 130, 131, 132, 134, 136, 137, 139, 145, 147, 150, 153, 155, 161,\n",
      "        162, 164, 166, 167, 170, 172, 173, 174, 175, 177, 178, 179, 180, 182,\n",
      "        183, 184, 186, 187, 189, 190, 191, 192, 193, 194, 195, 199, 201, 202,\n",
      "        209, 210, 218, 219, 223, 224, 227, 231, 233, 234, 235, 237, 238, 239,\n",
      "        240, 241, 243, 246, 247, 249, 254, 256, 257, 258, 265, 271, 280, 285,\n",
      "        293, 304, 312, 320, 323, 325, 337, 339, 342, 343, 346, 377, 382, 383,\n",
      "        398, 400, 401, 402, 408, 414, 442, 447, 453, 455, 457, 461, 462, 472,\n",
      "        479, 494, 497, 511])\n",
      "\n",
      "failing Cout = tensor([104, 130, 131, 132, 134, 136, 137, 139, 145, 147, 150, 153, 155, 161,\n",
      "        162, 164, 166, 167, 170, 172, 173, 174, 175, 177, 178, 179, 180, 182,\n",
      "        183, 184, 186, 187, 189, 190, 191, 192, 193, 194, 195, 199, 201, 202,\n",
      "        209, 210, 218, 219, 223, 224, 227, 231, 233, 234, 235, 237, 238, 239,\n",
      "        240, 241, 243, 246, 247, 249, 254, 256, 257, 258, 265, 271, 280, 285,\n",
      "        293, 304, 312, 320, 323, 325, 337, 339, 342, 343, 346, 377, 382, 383,\n",
      "        398, 400, 401, 402, 408, 414, 442, 447, 453, 455, 457, 461, 462, 472,\n",
      "        479, 494, 497, 511])  (len = 102)\n",
      "passing Cout = tensor([  0,   4,   5,   6,   8,   9,  11,  17,  20,  21,  23,  25,  26,  28,\n",
      "         29,  33,  34,  35,  37,  41,  43,  47,  48,  50,  58,  64,  65,  68,\n",
      "         70,  74,  77,  82,  84,  86,  87,  88,  90,  91,  93,  95,  96,  99,\n",
      "        103, 105, 107, 108, 111, 114, 115, 119, 120, 121, 311, 480])  (len = 54)\n",
      "\n",
      "Executing module 62: layer4.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 62\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-15, 1.0658e-14, 3.5527e-15, 1.0658e-14,\n",
      "         4.4409e-15, 5.3291e-15, 3.5527e-15, 7.9936e-15, 5.3291e-15, 5.3291e-15,\n",
      "         3.5527e-15, 5.3291e-15, 1.3323e-15, 7.4385e-15, 1.0658e-14, 2.6645e-15,\n",
      "         7.1054e-15, 5.7732e-15, 6.2172e-15, 1.4211e-14, 7.1054e-15, 7.1054e-15,\n",
      "         3.5527e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15, 4.4409e-15,\n",
      "         3.9968e-15, 2.6645e-15, 7.1054e-15, 2.9976e-15, 3.5527e-15, 8.8818e-15,\n",
      "         4.4409e-15, 2.4425e-15, 4.4409e-15, 3.9968e-15, 3.9968e-15, 1.0658e-14,\n",
      "         5.7732e-15, 7.9936e-15, 5.3291e-15, 1.4211e-14, 2.2204e-15, 1.0658e-14,\n",
      "         2.8866e-15, 4.4409e-15, 2.9976e-15, 2.6645e-15, 5.3291e-15, 3.5527e-15,\n",
      "         5.3291e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15, 7.1054e-15, 7.9936e-15,\n",
      "         4.4409e-15, 8.8818e-15, 2.6645e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15,\n",
      "         5.3291e-15, 2.6645e-15, 8.8818e-15, 5.3291e-15, 7.1054e-15, 5.5511e-15,\n",
      "         1.0658e-14, 7.1054e-15, 3.1086e-15, 4.4409e-15, 6.6613e-15, 7.1054e-15,\n",
      "         6.2172e-15, 3.9968e-15, 5.3291e-15, 8.8818e-15, 3.4417e-15, 8.8818e-15,\n",
      "         4.4409e-15, 8.8818e-15, 2.6645e-15, 7.1054e-15, 3.9968e-15, 5.3291e-15,\n",
      "         3.5527e-15, 4.4409e-15, 4.4409e-15, 7.1054e-15, 5.3291e-15, 4.4409e-15,\n",
      "         3.5527e-15, 3.9968e-15, 5.3291e-15, 4.8850e-15, 7.1054e-15, 3.6637e-15,\n",
      "         6.2172e-15, 8.8818e-15, 3.5527e-15, 1.0658e-14, 2.6645e-15, 7.1054e-15,\n",
      "         2.2204e-15, 8.8818e-15, 4.4409e-15, 1.1546e-14, 2.1094e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.5527e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15, 4.4409e-15,\n",
      "         9.7700e-15, 3.9968e-15, 7.1054e-15, 2.8866e-15, 4.5519e-15, 5.7732e-15,\n",
      "         8.8818e-15, 5.3291e-15, 9.3259e-15, 5.3291e-15, 3.3307e-16, 2.2204e-16,\n",
      "         2.2204e-16, 1.1102e-16, 5.5511e-17, 2.2204e-16, 8.8818e-16, 2.2204e-16,\n",
      "         2.2204e-16, 2.2204e-16, 2.2204e-16, 4.1633e-17, 2.2204e-16, 2.2204e-16,\n",
      "         3.3307e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16, 3.8858e-16, 2.2204e-16,\n",
      "         2.2204e-16, 4.4409e-16, 4.4409e-16, 2.7756e-17, 4.4409e-16, 3.3307e-16,\n",
      "         4.4409e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16, 2.2204e-16, 3.3307e-16,\n",
      "         2.7756e-16, 3.3307e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16,\n",
      "         4.4409e-16, 6.6613e-16, 1.1102e-16, 3.3307e-16, 8.8818e-16, 6.6613e-16,\n",
      "         4.4409e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 1.1102e-16,\n",
      "         4.4409e-16, 4.4409e-16, 5.5511e-17, 5.5511e-17, 4.4409e-16, 4.4409e-16,\n",
      "         2.7756e-16, 4.4409e-16, 2.7756e-17, 1.1796e-16, 2.2204e-16, 1.1102e-16,\n",
      "         4.4409e-16, 2.7756e-17, 4.4409e-16, 4.4409e-16, 6.6613e-16, 2.2204e-16,\n",
      "         2.2204e-16, 1.1102e-16, 4.4409e-16, 8.8818e-16, 2.7756e-16, 4.4409e-16,\n",
      "         2.7756e-17, 1.3323e-15, 4.4409e-16, 1.1102e-16, 1.1102e-16, 2.2204e-16,\n",
      "         8.8818e-16, 6.6613e-16, 4.4409e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         3.3307e-16, 4.4409e-16, 2.7756e-17, 8.3267e-17, 2.0817e-17, 4.4409e-16,\n",
      "         1.1102e-16, 4.4409e-16, 8.8818e-16, 3.3307e-16, 4.4409e-16, 4.4409e-16,\n",
      "         3.3307e-16, 1.1102e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16,\n",
      "         8.8818e-16, 1.1102e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 1.3878e-16, 6.6613e-16, 4.4409e-16, 5.5511e-17,\n",
      "         4.4409e-16, 6.6613e-16, 1.1102e-16, 4.4409e-16, 4.4409e-16, 5.5511e-17,\n",
      "         2.2204e-16, 4.4409e-16, 5.5511e-17, 4.4409e-16, 2.4980e-16, 1.1102e-16,\n",
      "         5.9935e-16, 4.4409e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16, 8.8818e-16,\n",
      "         6.6613e-16, 4.4409e-16, 2.7756e-17, 5.5511e-16, 8.8818e-16, 8.8818e-16,\n",
      "         4.4409e-16, 5.6899e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 7.2164e-16,\n",
      "         8.8818e-16, 8.8818e-16, 6.6613e-16, 2.2204e-16, 2.7756e-16, 6.6613e-16,\n",
      "         5.5511e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 6.1062e-16, 8.8818e-16,\n",
      "         8.8818e-16, 1.3323e-15, 2.7756e-16, 8.8818e-16, 1.3323e-15, 4.4409e-16,\n",
      "         1.1102e-15, 1.3323e-15, 4.4409e-16, 6.6613e-16, 6.6613e-16, 8.8818e-16,\n",
      "         4.4409e-16, 3.3307e-16, 8.8818e-16, 3.8858e-16, 8.8818e-16, 6.6613e-16,\n",
      "         3.4694e-16, 8.8818e-16, 3.8858e-16, 4.9960e-16, 5.5511e-16, 6.6613e-16,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 6.6613e-16, 8.8818e-16,\n",
      "         4.4409e-16, 1.7764e-15, 6.6613e-16, 4.9960e-16, 6.6613e-16, 6.6613e-16,\n",
      "         5.5511e-16, 5.5511e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 5.5511e-16, 4.7184e-16, 4.4409e-16, 6.6613e-16, 3.3307e-16,\n",
      "         8.8818e-16, 1.3323e-15, 2.7756e-16, 6.6613e-16, 5.5511e-16, 6.9389e-16,\n",
      "         4.4409e-16, 1.3323e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16,\n",
      "         8.8818e-16, 8.8818e-16, 6.3838e-16, 2.2204e-16, 1.1102e-15, 4.4409e-16,\n",
      "         6.6613e-16, 8.8818e-16, 4.4409e-16, 3.6082e-16, 1.7764e-15, 8.8818e-16,\n",
      "         8.8818e-16, 6.6613e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16, 5.5511e-16,\n",
      "         8.8818e-16, 5.5511e-16, 3.6082e-16, 7.7716e-16, 6.6613e-16, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 1.1102e-15, 4.4409e-16, 6.6613e-16, 8.8818e-16,\n",
      "         8.8818e-16, 3.3307e-16, 8.8818e-16, 6.6613e-16, 1.3323e-15, 7.7716e-16,\n",
      "         6.6613e-16, 5.8287e-16]], dtype=torch.float64)\n",
      "tensor([ 46, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
      "        393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
      "        421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
      "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
      "        463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "        477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
      "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([ 46, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
      "        393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
      "        421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
      "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
      "        463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "        477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
      "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 506, 507, 508, 509, 510, 511])  (len = 385)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127])  (len = 127)\n",
      "\n",
      "Executing module 63: layer4.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 63\n",
      "Max diff:\n",
      "tensor([9.7700e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.9552e-16, 3.1086e-15, 5.5511e-16, 3.5527e-15,\n",
      "         6.6613e-16, 1.3323e-15, 3.5527e-15, 3.3307e-15, 1.7764e-15, 2.7756e-16,\n",
      "         3.0531e-16, 1.9984e-15, 2.0817e-17, 2.6645e-15, 6.2172e-15, 4.5797e-16,\n",
      "         3.5527e-15, 2.1094e-15, 3.9968e-15, 7.1054e-15, 1.7764e-15, 1.7764e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.9968e-15, 3.5527e-15, 2.6645e-15, 1.3323e-15,\n",
      "         1.6098e-15, 7.7716e-16, 1.7764e-15, 1.1102e-15, 3.3307e-16, 5.7732e-15,\n",
      "         2.2204e-15, 1.1657e-15, 2.6645e-15, 1.4433e-15, 1.3323e-15, 1.7764e-15,\n",
      "         2.4425e-15, 3.9968e-15, 3.5527e-15, 5.3291e-15, 1.1102e-15, 2.6645e-15,\n",
      "         9.9920e-16, 2.2204e-15, 1.6376e-15, 1.7764e-15, 3.5527e-15, 8.8818e-16,\n",
      "         1.5543e-15, 2.6645e-15, 2.6645e-15, 2.6645e-15, 5.3291e-15, 9.7700e-15,\n",
      "         1.7764e-15, 3.1086e-15, 1.1102e-15, 3.5527e-15, 1.7764e-15, 1.7764e-15,\n",
      "         1.3323e-15, 2.0504e-15, 6.2172e-15, 3.5527e-15, 2.9976e-15, 2.6645e-15,\n",
      "         3.5527e-15, 4.4409e-15, 2.0817e-16, 2.2204e-15, 6.4393e-15, 2.6645e-15,\n",
      "         4.8850e-15, 1.3323e-15, 1.7764e-15, 4.4409e-15, 1.4433e-15, 2.2204e-15,\n",
      "         1.1102e-15, 3.5527e-15, 1.1102e-15, 5.3291e-15, 1.5543e-15, 5.3291e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.7764e-15, 2.2204e-15, 3.7748e-15, 1.9984e-15,\n",
      "         2.6645e-15, 3.1086e-15, 2.6645e-15, 2.2204e-15, 2.6645e-15, 3.7748e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.2204e-15, 4.4409e-15, 1.3323e-15, 1.3323e-15,\n",
      "         8.8818e-16, 3.5527e-15, 1.9984e-15, 6.6613e-15, 1.6653e-15, 1.7764e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.6645e-15, 6.6613e-16, 4.4409e-15, 3.1086e-15,\n",
      "         4.8850e-15, 2.4425e-15, 3.5527e-15, 9.9920e-16, 1.7208e-15, 3.3307e-15,\n",
      "         4.4409e-15, 2.2204e-15, 3.7192e-15, 1.7764e-15, 8.3267e-17, 1.1102e-16,\n",
      "         8.3267e-17, 2.0817e-17, 2.7756e-17, 5.5511e-17, 2.2204e-16, 8.3267e-17,\n",
      "         1.1102e-16, 5.5511e-17, 5.5511e-17, 6.9389e-18, 5.5511e-17, 1.1102e-16,\n",
      "         1.6653e-16, 1.1102e-16, 2.2204e-16, 5.5511e-17, 1.1102e-16, 5.5511e-17,\n",
      "         2.7756e-17, 1.1102e-16, 2.2204e-16, 6.9389e-18, 2.2204e-16, 5.5511e-17,\n",
      "         2.2204e-16, 5.5511e-17, 1.1102e-16, 2.2204e-16, 5.5511e-17, 1.1102e-16,\n",
      "         5.5511e-17, 1.6653e-16, 1.3878e-17, 1.3878e-17, 5.5511e-17, 4.1633e-17,\n",
      "         1.1102e-16, 3.3307e-16, 2.7756e-17, 5.5511e-17, 2.2204e-16, 3.3307e-16,\n",
      "         1.1102e-16, 2.2204e-16, 1.6653e-16, 1.1102e-16, 2.2204e-16, 2.7756e-17,\n",
      "         2.7756e-17, 1.1102e-16, 0.0000e+00, 1.3878e-17, 1.1102e-16, 2.2204e-16,\n",
      "         1.3878e-16, 2.2204e-16, 6.9389e-18, 0.0000e+00, 2.7756e-17, 2.7756e-17,\n",
      "         1.1102e-16, 6.9389e-18, 1.1102e-16, 2.2204e-16, 1.6653e-16, 5.5511e-17,\n",
      "         1.0408e-17, 2.7756e-17, 2.2204e-16, 2.2204e-16, 2.7756e-17, 1.3878e-16,\n",
      "         6.9389e-18, 4.4409e-16, 2.2204e-16, 2.7756e-17, 8.3267e-17, 1.1102e-16,\n",
      "         3.3307e-16, 1.1102e-16, 2.2204e-16, 8.3267e-17, 2.7756e-17, 2.2204e-16,\n",
      "         1.1102e-16, 2.2204e-16, 6.9389e-18, 6.9389e-18, 5.2042e-18, 2.2204e-16,\n",
      "         2.7756e-17, 1.1102e-16, 4.4409e-16, 1.6653e-16, 1.6653e-16, 1.6653e-16,\n",
      "         4.1633e-17, 2.7756e-17, 3.3307e-16, 1.1102e-16, 1.1102e-16, 2.2204e-16,\n",
      "         4.4409e-16, 0.0000e+00, 2.2204e-16, 2.2204e-16, 5.5511e-17, 5.5511e-17,\n",
      "         2.2204e-16, 5.5511e-17, 2.7756e-17, 1.1102e-16, 2.2204e-16, 1.3878e-17,\n",
      "         8.3267e-17, 3.3307e-16, 0.0000e+00, 1.1102e-16, 1.1102e-16, 1.3878e-17,\n",
      "         5.5511e-17, 2.7756e-17, 1.3878e-17, 1.1102e-16, 1.7347e-18, 2.7756e-17,\n",
      "         2.4243e-16, 1.6653e-16, 1.3878e-16, 2.7756e-16, 3.3307e-16, 2.2204e-16,\n",
      "         1.1102e-16, 6.9389e-18, 6.9389e-18, 3.3307e-16, 1.6653e-16, 2.7756e-16,\n",
      "         1.6653e-16, 1.2490e-16, 2.2204e-16, 1.6653e-16, 1.3878e-16, 2.2204e-16,\n",
      "         4.4409e-16, 3.3307e-16, 3.3307e-16, 3.9031e-18, 8.3267e-17, 4.4409e-16,\n",
      "         2.7756e-16, 2.2204e-16, 2.2204e-16, 1.6653e-16, 1.8041e-16, 2.2204e-16,\n",
      "         4.4409e-16, 4.4409e-16, 5.5511e-17, 2.2204e-16, 4.4409e-16, 1.1102e-16,\n",
      "         6.6613e-16, 4.4409e-16, 1.1102e-16, 1.1102e-16, 1.6653e-16, 2.2204e-16,\n",
      "         1.6653e-16, 1.1102e-16, 4.4409e-16, 1.6653e-16, 2.2204e-16, 4.4409e-16,\n",
      "         1.1796e-16, 3.3307e-16, 1.9429e-16, 1.3878e-16, 1.6653e-16, 2.2204e-16,\n",
      "         4.4409e-16, 2.2204e-16, 5.5511e-17, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         2.2204e-16, 8.8818e-16, 2.2204e-16, 1.3878e-16, 5.5511e-17, 2.2204e-16,\n",
      "         2.2204e-16, 2.2204e-16, 8.8818e-16, 3.3307e-16, 1.6653e-16, 2.2204e-16,\n",
      "         1.1102e-16, 2.2204e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16, 1.2490e-16,\n",
      "         3.3307e-16, 5.5511e-16, 2.2204e-16, 3.3307e-16, 1.9429e-16, 1.4051e-16,\n",
      "         5.5511e-17, 4.4409e-16, 4.4409e-16, 1.6653e-16, 4.4409e-16, 2.2204e-16,\n",
      "         1.6653e-16, 4.4409e-16, 1.6653e-16, 2.7756e-17, 4.1633e-16, 1.6653e-16,\n",
      "         1.1102e-16, 3.3307e-16, 1.1102e-16, 7.1124e-17, 1.3323e-15, 4.4409e-16,\n",
      "         3.3307e-16, 2.2204e-16, 1.1102e-16, 2.7756e-17, 2.2204e-16, 1.6653e-16,\n",
      "         4.4409e-16, 1.3878e-16, 7.2858e-17, 3.3307e-16, 2.7756e-16, 2.2204e-16,\n",
      "         1.1102e-16, 3.8858e-16, 4.4409e-16, 1.6653e-16, 1.3878e-16, 1.3878e-16,\n",
      "         4.4409e-16, 1.3878e-16, 3.3307e-16, 1.1102e-16, 4.4409e-16, 1.1102e-16,\n",
      "         1.6653e-16, 1.3878e-16]], dtype=torch.float64)\n",
      "tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
      "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310,\n",
      "        311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366, 367, 368,\n",
      "        369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
      "        384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\n",
      "failing Cout = tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
      "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310,\n",
      "        311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366, 367, 368,\n",
      "        369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
      "        384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])  (len = 380)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 308, 315, 361, 374])  (len = 132)\n",
      "\n",
      "Executing module 64: layer4.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 64\n",
      "Max diff:\n",
      "tensor([9.7700e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.9552e-16, 3.1086e-15, 5.5511e-16, 3.5527e-15,\n",
      "         6.6613e-16, 1.7764e-15, 3.5527e-15, 3.3307e-15, 3.1086e-15, 2.7756e-16,\n",
      "         3.0531e-16, 1.9984e-15, 2.2204e-15, 3.5527e-15, 6.2172e-15, 4.5797e-16,\n",
      "         3.5527e-15, 2.1094e-15, 3.9968e-15, 7.1054e-15, 1.7764e-15, 2.2204e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.9968e-15, 3.5527e-15, 2.6645e-15, 2.2204e-15,\n",
      "         1.6098e-15, 7.7716e-16, 1.7764e-15, 1.7764e-15, 3.3307e-16, 5.7732e-15,\n",
      "         2.2204e-15, 2.4425e-15, 1.7764e-15, 1.4433e-15, 1.3323e-15, 3.9968e-15,\n",
      "         2.4425e-15, 3.9968e-15, 3.5527e-15, 5.3291e-15, 3.5527e-15, 4.2188e-15,\n",
      "         9.9920e-16, 2.2204e-15, 1.6376e-15, 1.7764e-15, 7.1054e-15, 8.8818e-16,\n",
      "         1.5543e-15, 2.6645e-15, 2.6645e-15, 6.2172e-15, 5.3291e-15, 9.7700e-15,\n",
      "         1.7764e-15, 3.1086e-15, 4.8850e-15, 3.5527e-15, 1.7764e-15, 1.7764e-15,\n",
      "         1.3323e-15, 2.0504e-15, 6.2172e-15, 3.5527e-15, 2.9976e-15, 2.6645e-15,\n",
      "         3.5527e-15, 5.3291e-15, 2.0817e-16, 2.2204e-15, 6.4393e-15, 2.6645e-15,\n",
      "         4.8850e-15, 1.3323e-15, 1.7764e-15, 4.4409e-15, 1.4433e-15, 2.2204e-15,\n",
      "         1.1102e-15, 3.5527e-15, 1.1102e-15, 5.3291e-15, 1.5543e-15, 5.3291e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15, 3.7748e-15, 2.6645e-15,\n",
      "         2.6645e-15, 4.3299e-15, 2.6645e-15, 1.9984e-15, 4.4409e-15, 3.7748e-15,\n",
      "         3.9968e-15, 3.5527e-15, 2.2204e-15, 3.9968e-15, 1.3323e-15, 1.3323e-15,\n",
      "         8.8818e-16, 3.5527e-15, 1.9984e-15, 6.6613e-15, 1.6653e-15, 1.7764e-15,\n",
      "         1.7764e-15, 2.6645e-15, 5.3291e-15, 1.5543e-15, 4.4409e-15, 3.1086e-15,\n",
      "         3.5527e-15, 2.4425e-15, 4.2188e-15, 9.9920e-16, 1.7208e-15, 3.3307e-15,\n",
      "         4.4409e-15, 2.6645e-15, 3.7748e-15, 3.8858e-15, 8.3267e-17, 1.1102e-16,\n",
      "         2.2204e-16, 2.0817e-17, 2.7756e-17, 2.2204e-16, 2.2204e-16, 1.1102e-16,\n",
      "         1.1102e-16, 5.5511e-17, 1.6653e-16, 6.9389e-18, 8.3267e-17, 1.1102e-16,\n",
      "         1.6653e-16, 1.1102e-16, 2.2204e-16, 5.5511e-17, 1.9429e-16, 6.2450e-17,\n",
      "         5.5511e-17, 1.1102e-16, 2.2204e-16, 6.9389e-18, 2.7756e-16, 1.1102e-16,\n",
      "         2.2204e-16, 5.5511e-17, 1.1102e-16, 2.2204e-16, 5.5511e-17, 1.1102e-16,\n",
      "         5.5511e-17, 1.6653e-16, 9.7145e-17, 9.7145e-17, 5.5511e-17, 1.2490e-16,\n",
      "         1.1102e-16, 3.3307e-16, 2.7756e-17, 1.6653e-16, 2.2204e-16, 3.3307e-16,\n",
      "         6.6613e-16, 2.2204e-16, 2.7756e-16, 1.1102e-16, 2.2204e-16, 2.7756e-17,\n",
      "         2.7756e-17, 1.1102e-16, 5.5511e-17, 1.3878e-17, 1.1102e-16, 2.2204e-16,\n",
      "         1.8041e-16, 5.5511e-16, 6.9389e-18, 0.0000e+00, 2.7756e-17, 2.7756e-17,\n",
      "         1.1102e-16, 6.9389e-18, 1.1102e-16, 2.2204e-16, 1.6653e-16, 8.3267e-17,\n",
      "         1.1102e-16, 2.7756e-17, 2.2204e-16, 2.2204e-16, 2.7756e-17, 1.3878e-16,\n",
      "         6.9389e-18, 4.4409e-16, 2.2204e-16, 2.7756e-17, 8.3267e-17, 1.1102e-16,\n",
      "         3.3307e-16, 1.1102e-16, 2.2204e-16, 8.3267e-17, 2.2204e-16, 2.2204e-16,\n",
      "         3.3307e-16, 2.7756e-16, 6.9389e-18, 6.9389e-18, 5.2042e-18, 2.2204e-16,\n",
      "         2.7756e-17, 1.1102e-16, 4.4409e-16, 1.6653e-16, 1.6653e-16, 1.3878e-16,\n",
      "         3.3307e-16, 2.7756e-17, 3.3307e-16, 1.1102e-16, 1.1102e-16, 2.2204e-16,\n",
      "         4.4409e-16, 0.0000e+00, 2.2204e-16, 2.2204e-16, 5.5511e-17, 5.5511e-17,\n",
      "         2.2204e-16, 5.5511e-17, 2.7756e-17, 1.1102e-16, 2.2204e-16, 1.3878e-17,\n",
      "         8.3267e-17, 3.3307e-16, 5.5511e-17, 1.1102e-16, 1.1102e-16, 1.3878e-17,\n",
      "         5.5511e-17, 2.7756e-17, 1.3878e-17, 1.1102e-16, 1.1102e-16, 2.7756e-17,\n",
      "         3.8858e-16, 3.3307e-16, 2.2204e-16, 2.7756e-16, 3.3307e-16, 2.2204e-16,\n",
      "         1.1102e-16, 4.1633e-16, 6.9389e-18, 3.3307e-16, 1.6653e-16, 3.3307e-16,\n",
      "         1.6653e-16, 3.8858e-16, 2.2204e-16, 2.2204e-16, 1.3878e-16, 2.2204e-16,\n",
      "         4.4409e-16, 3.3307e-16, 3.3307e-16, 3.9031e-18, 8.3267e-17, 6.6613e-16,\n",
      "         2.7756e-16, 2.2204e-16, 2.2204e-16, 3.3307e-16, 3.3307e-16, 2.2204e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.9960e-16, 4.4409e-16, 4.4409e-16, 3.8858e-16,\n",
      "         6.6613e-16, 4.4409e-16, 1.1102e-16, 1.1102e-16, 4.4409e-16, 2.2204e-16,\n",
      "         1.6653e-16, 1.1102e-16, 4.4409e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         2.2204e-16, 3.3307e-16, 1.9429e-16, 4.4409e-16, 3.3307e-16, 2.2204e-16,\n",
      "         4.4409e-16, 4.4409e-16, 6.6613e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 4.9960e-16, 4.4409e-16, 5.5511e-17, 9.9920e-16,\n",
      "         2.2204e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 2.7756e-16, 4.9960e-16,\n",
      "         1.1102e-16, 2.2204e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16, 1.2490e-16,\n",
      "         3.8858e-16, 5.5511e-16, 2.2204e-16, 3.3307e-16, 1.9429e-16, 3.0531e-16,\n",
      "         2.2204e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 2.2204e-16,\n",
      "         2.4980e-16, 4.4409e-16, 1.6653e-16, 2.7756e-17, 4.4409e-16, 2.2204e-16,\n",
      "         1.1102e-16, 3.3307e-16, 1.1102e-16, 3.2613e-16, 1.3323e-15, 4.4409e-16,\n",
      "         3.3307e-16, 2.2204e-16, 1.1102e-16, 2.4980e-16, 4.4409e-16, 1.6653e-16,\n",
      "         4.4409e-16, 1.3878e-16, 5.5511e-17, 3.3307e-16, 2.7756e-16, 5.5511e-16,\n",
      "         1.1102e-16, 3.8858e-16, 5.5511e-16, 1.6653e-16, 3.0531e-16, 4.4409e-16,\n",
      "         2.2204e-16, 1.3878e-16, 3.3307e-16, 1.1102e-16, 4.4409e-16, 2.2204e-16,\n",
      "         1.6653e-16, 1.3878e-16]], dtype=torch.float64)\n",
      "tensor([ 18, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "        352, 353, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366,\n",
      "        367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "        381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "        395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
      "        409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422,\n",
      "        423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
      "        437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
      "        451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464,\n",
      "        465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
      "        479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
      "        493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "        507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([ 18, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "        352, 353, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366,\n",
      "        367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "        381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "        395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
      "        409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422,\n",
      "        423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
      "        437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
      "        451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464,\n",
      "        465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
      "        479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
      "        493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "        507, 508, 509, 510, 511])  (len = 383)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 315, 361])  (len = 129)\n",
      "\n",
      "Executing module 65: layer4.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 65\n",
      "Max diff:\n",
      "tensor([9.7700e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3307e-16, 2.2204e-15, 5.5511e-16, 0.0000e+00,\n",
      "         6.6613e-16, 1.7764e-15, 3.5527e-15, 0.0000e+00, 2.6645e-15, 1.3878e-16,\n",
      "         2.4286e-16, 1.3323e-15, 2.2204e-15, 3.5527e-15, 0.0000e+00, 2.2204e-16,\n",
      "         3.5527e-15, 2.1094e-15, 3.9968e-15, 0.0000e+00, 0.0000e+00, 1.3323e-15,\n",
      "         3.5527e-15, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.9920e-16, 7.7716e-16, 0.0000e+00, 1.3323e-15, 0.0000e+00, 5.7732e-15,\n",
      "         2.2204e-15, 2.4425e-15, 1.7764e-15, 1.4433e-15, 1.3323e-15, 3.9968e-15,\n",
      "         1.1362e-15, 3.9968e-15, 1.9984e-15, 3.6082e-16, 3.5527e-15, 2.2204e-16,\n",
      "         9.9920e-16, 2.2204e-15, 8.8818e-16, 1.3323e-15, 7.1054e-15, 0.0000e+00,\n",
      "         7.2164e-16, 2.6645e-15, 0.0000e+00, 6.2172e-15, 1.8319e-15, 9.7700e-15,\n",
      "         1.7764e-15, 0.0000e+00, 4.8850e-15, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         0.0000e+00, 2.0504e-15, 0.0000e+00, 1.4988e-15, 2.6645e-15, 2.6645e-15,\n",
      "         0.0000e+00, 5.3291e-15, 1.5266e-16, 2.2204e-15, 1.7764e-15, 1.3323e-15,\n",
      "         4.8850e-15, 0.0000e+00, 0.0000e+00, 1.3323e-15, 1.4433e-15, 0.0000e+00,\n",
      "         1.1102e-15, 0.0000e+00, 1.1102e-15, 0.0000e+00, 1.5543e-15, 5.3291e-15,\n",
      "         1.7764e-15, 1.4433e-15, 1.7764e-15, 0.0000e+00, 3.7748e-15, 2.6645e-15,\n",
      "         2.6645e-15, 4.3299e-15, 2.6645e-15, 1.9984e-15, 2.7756e-17, 3.7748e-15,\n",
      "         3.9968e-15, 0.0000e+00, 2.2204e-15, 3.9968e-15, 1.3323e-15, 1.9082e-16,\n",
      "         8.8818e-16, 1.9984e-15, 1.9984e-15, 0.0000e+00, 1.6653e-15, 0.0000e+00,\n",
      "         1.7764e-15, 2.6645e-15, 1.7764e-15, 1.5543e-15, 1.9984e-15, 3.1086e-15,\n",
      "         3.5527e-15, 2.4425e-15, 8.6042e-16, 2.7756e-16, 7.7716e-16, 3.3307e-15,\n",
      "         0.0000e+00, 6.6613e-16, 1.3323e-15, 3.8858e-15, 0.0000e+00, 8.3267e-17,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 1.6653e-16, 0.0000e+00, 8.3267e-17, 0.0000e+00,\n",
      "         9.3675e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9429e-16, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-16, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 9.7145e-17, 0.0000e+00, 1.2490e-16,\n",
      "         0.0000e+00, 8.3267e-17, 0.0000e+00, 1.6653e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.0206e-17, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 1.8041e-16,\n",
      "         1.8041e-16, 5.5511e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00, 8.3267e-17,\n",
      "         1.1102e-16, 0.0000e+00, 5.7788e-17, 0.0000e+00, 0.0000e+00, 1.3878e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3267e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 4.1633e-17, 2.2204e-16, 0.0000e+00,\n",
      "         3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00, 1.1102e-16,\n",
      "         3.3307e-16, 0.0000e+00, 1.5613e-17, 0.0000e+00, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7145e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         3.8858e-16, 3.3307e-16, 2.2204e-16, 2.2204e-16, 3.3307e-16, 0.0000e+00,\n",
      "         0.0000e+00, 4.1633e-16, 0.0000e+00, 1.0408e-16, 0.0000e+00, 3.3307e-16,\n",
      "         9.7145e-17, 2.2204e-16, 2.2204e-16, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 3.3307e-16, 3.3307e-16, 0.0000e+00, 0.0000e+00, 2.7756e-16,\n",
      "         2.7756e-16, 0.0000e+00, 0.0000e+00, 3.3307e-16, 3.3307e-16, 7.6328e-17,\n",
      "         0.0000e+00, 0.0000e+00, 4.9960e-16, 4.4409e-16, 0.0000e+00, 3.8858e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         3.2960e-17, 1.1102e-16, 8.3267e-17, 2.2204e-16, 1.3878e-17, 0.0000e+00,\n",
      "         2.2204e-16, 2.2204e-16, 1.9429e-16, 4.4409e-16, 3.3307e-16, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 6.6613e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         4.4409e-16, 0.0000e+00, 3.8858e-16, 4.4409e-16, 0.0000e+00, 2.2204e-16,\n",
      "         2.2204e-16, 4.4409e-16, 1.6653e-16, 3.8858e-16, 2.7756e-16, 4.4409e-16,\n",
      "         0.0000e+00, 2.2204e-16, 1.8735e-16, 0.0000e+00, 0.0000e+00, 2.4286e-17,\n",
      "         1.6653e-16, 1.1102e-16, 2.2204e-16, 1.6653e-16, 1.9429e-16, 2.2204e-16,\n",
      "         2.2204e-16, 0.0000e+00, 3.3307e-16, 8.8818e-16, 1.7521e-16, 2.2204e-16,\n",
      "         2.4980e-16, 5.0307e-17, 9.0206e-17, 0.0000e+00, 4.4409e-16, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2613e-16, 0.0000e+00, 3.8858e-16,\n",
      "         0.0000e+00, 1.9429e-16, 2.5153e-17, 1.1102e-16, 4.4409e-16, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 2.2204e-16,\n",
      "         2.7756e-17, 3.4971e-16, 1.1102e-16, 1.6653e-16, 3.0531e-16, 4.4409e-16,\n",
      "         1.6653e-16, 6.9389e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         4.1633e-17, 9.8879e-17]], dtype=torch.float64)\n",
      "tensor([128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144,\n",
      "        145, 146, 149, 150, 151, 156, 157, 159, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181,\n",
      "        183, 184, 185, 186, 188, 191, 193, 195, 196, 197, 199, 200, 201, 202,\n",
      "        203, 204, 207, 208, 210, 212, 214, 215, 216, 217, 218, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 238,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254,\n",
      "        255, 257, 258, 261, 263, 266, 268, 270, 274, 275, 280, 281, 285, 290,\n",
      "        291, 293, 295, 297, 301, 302, 308, 311, 312, 313, 318, 321, 323, 324,\n",
      "        326, 329, 334, 338, 339, 340, 342, 351, 353, 354, 356, 359, 363, 370,\n",
      "        374, 382, 384, 385, 386, 387, 388, 391, 393, 395, 396, 397, 398, 399,\n",
      "        402, 403, 404, 407, 408, 411, 412, 413, 416, 417, 419, 424, 426, 427,\n",
      "        428, 429, 430, 432, 433, 434, 435, 436, 439, 440, 443, 444, 446, 447,\n",
      "        449, 450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485,\n",
      "        487, 488, 489, 490, 491, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144,\n",
      "        145, 146, 149, 150, 151, 156, 157, 159, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181,\n",
      "        183, 184, 185, 186, 188, 191, 193, 195, 196, 197, 199, 200, 201, 202,\n",
      "        203, 204, 207, 208, 210, 212, 214, 215, 216, 217, 218, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 238,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254,\n",
      "        255, 257, 258, 261, 263, 266, 268, 270, 274, 275, 280, 281, 285, 290,\n",
      "        291, 293, 295, 297, 301, 302, 308, 311, 312, 313, 318, 321, 323, 324,\n",
      "        326, 329, 334, 338, 339, 340, 342, 351, 353, 354, 356, 359, 363, 370,\n",
      "        374, 382, 384, 385, 386, 387, 388, 391, 393, 395, 396, 397, 398, 399,\n",
      "        402, 403, 404, 407, 408, 411, 412, 413, 416, 417, 419, 424, 426, 427,\n",
      "        428, 429, 430, 432, 433, 434, 435, 436, 439, 440, 443, 444, 446, 447,\n",
      "        449, 450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485,\n",
      "        487, 488, 489, 490, 491, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 509, 510, 511])  (len = 228)\n",
      "passing Cout = tensor([189, 310, 431, 492])  (len = 4)\n",
      "\n",
      "Executing module 66: avg_pool2d\n",
      "\tExecuting on machine 0\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 1\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 2\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 3\n",
      "\t\t-average pooling\n",
      "Finished execution of layer 66\n",
      "Max diff:\n",
      "tensor([2.6645e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-16, 3.6082e-16, 8.3267e-17, 0.0000e+00,\n",
      "         1.3878e-17, 1.6653e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         0.0000e+00, 1.1102e-16, 0.0000e+00, 4.4409e-16, 0.0000e+00, 5.5511e-17,\n",
      "         8.8818e-16, 1.9429e-16, 1.3323e-15, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         1.3323e-15, 2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1796e-16, 5.5511e-17, 0.0000e+00, 1.1102e-16, 0.0000e+00, 6.6613e-16,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 1.6653e-16, 4.4409e-16, 5.5511e-17,\n",
      "         1.2230e-16, 1.1102e-16, 2.0817e-16, 2.2551e-17, 2.2204e-16, 2.7756e-17,\n",
      "         1.9429e-16, 1.6653e-16, 8.3267e-17, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 3.8858e-16, 1.3878e-16, 8.8818e-16,\n",
      "         2.7756e-16, 0.0000e+00, 3.8858e-16, 0.0000e+00, 0.0000e+00, 6.9389e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8041e-16, 2.4980e-16, 3.8858e-16,\n",
      "         0.0000e+00, 4.4409e-16, 9.9747e-18, 2.2204e-16, 1.1102e-16, 8.3267e-17,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 8.3267e-17, 5.5511e-16, 0.0000e+00,\n",
      "         1.6653e-16, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 8.3267e-17, 2.7756e-16, 0.0000e+00, 0.0000e+00, 3.0531e-16,\n",
      "         0.0000e+00, 4.4409e-16, 2.2204e-16, 1.2490e-16, 1.7347e-18, 0.0000e+00,\n",
      "         2.7756e-16, 0.0000e+00, 1.1102e-16, 6.6613e-16, 1.1102e-16, 1.1926e-17,\n",
      "         2.2204e-16, 1.1102e-16, 2.2204e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-16, 1.1102e-16, 1.5266e-16, 1.3878e-16, 4.4409e-16,\n",
      "         0.0000e+00, 2.2204e-16, 5.3776e-17, 2.7756e-17, 1.3878e-16, 1.1102e-16,\n",
      "         0.0000e+00, 5.5511e-17, 2.2204e-16, 2.7756e-16, 0.0000e+00, 1.7347e-17,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2042e-18, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-17, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2042e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 1.7347e-17,\n",
      "         0.0000e+00, 5.2042e-18, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0408e-17, 1.7347e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00, 1.3010e-17,\n",
      "         6.9389e-18, 5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.6117e-18, 0.0000e+00, 0.0000e+00, 8.3267e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 6.9389e-18, 2.7756e-17, 0.0000e+00,\n",
      "         2.0817e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00, 1.0408e-17,\n",
      "         2.0817e-17, 0.0000e+00, 9.7578e-19, 0.0000e+00, 0.0000e+00, 5.2042e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0715e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.2042e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00,\n",
      "         5.5511e-17, 1.1102e-16, 5.5511e-17, 5.5511e-17, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 5.0307e-17, 0.0000e+00, 3.4694e-18, 0.0000e+00, 1.3878e-17,\n",
      "         6.0715e-18, 2.7756e-17, 0.0000e+00, 1.7347e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 5.5511e-17, 0.0000e+00, 0.0000e+00, 1.7347e-17,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 2.0817e-17, 5.5511e-17, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0600e-18, 1.3878e-17, 5.2042e-18, 2.7756e-17, 1.7347e-18, 0.0000e+00,\n",
      "         1.3878e-17, 2.7756e-17, 2.7756e-17, 1.1102e-16, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.1633e-17, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         5.5511e-17, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         8.3267e-17, 5.5511e-17, 1.3878e-17, 2.7756e-17, 2.7756e-17, 4.1633e-17,\n",
      "         0.0000e+00, 2.7756e-17, 2.7756e-17, 0.0000e+00, 0.0000e+00, 1.3010e-18,\n",
      "         2.7756e-17, 6.9389e-18, 2.7756e-17, 2.7756e-17, 6.9389e-18, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 6.9389e-18, 8.3267e-17, 1.0408e-17, 1.3878e-17,\n",
      "         2.7756e-17, 6.9389e-18, 5.6379e-18, 0.0000e+00, 5.5511e-17, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 1.3878e-17,\n",
      "         0.0000e+00, 0.0000e+00, 1.5721e-18, 3.4694e-18, 4.1633e-17, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17, 2.7756e-17,\n",
      "         1.7347e-18, 0.0000e+00, 6.9389e-18, 2.0817e-17, 6.9389e-18, 2.7756e-17,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         0.0000e+00, 3.4694e-18]], dtype=torch.float64)\n",
      "tensor([128, 129, 130, 132, 133, 134, 137, 139, 141, 143, 144, 145, 146, 149,\n",
      "        150, 151, 156, 157, 159, 161, 162, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 178, 181, 183, 184, 185, 186, 188, 191, 195,\n",
      "        196, 197, 199, 200, 201, 202, 203, 204, 207, 208, 210, 212, 215, 217,\n",
      "        218, 221, 223, 224, 225, 226, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 254, 255,\n",
      "        257, 258, 261, 268, 270, 274, 275, 280, 285, 291, 293, 295, 297, 301,\n",
      "        302, 308, 311, 312, 313, 318, 321, 326, 329, 338, 339, 340, 342, 351,\n",
      "        353, 354, 356, 359, 363, 370, 374, 382, 384, 385, 386, 387, 388, 391,\n",
      "        393, 395, 396, 397, 399, 403, 404, 407, 408, 411, 412, 413, 419, 426,\n",
      "        427, 428, 429, 430, 432, 433, 434, 435, 436, 440, 443, 444, 446, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 488, 489,\n",
      "        490, 491, 496, 497, 498, 500, 501, 502, 503, 504, 509, 511])\n",
      "\n",
      "failing Cout = tensor([128, 129, 130, 132, 133, 134, 137, 139, 141, 143, 144, 145, 146, 149,\n",
      "        150, 151, 156, 157, 159, 161, 162, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 178, 181, 183, 184, 185, 186, 188, 191, 195,\n",
      "        196, 197, 199, 200, 201, 202, 203, 204, 207, 208, 210, 212, 215, 217,\n",
      "        218, 221, 223, 224, 225, 226, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 254, 255,\n",
      "        257, 258, 261, 268, 270, 274, 275, 280, 285, 291, 293, 295, 297, 301,\n",
      "        302, 308, 311, 312, 313, 318, 321, 326, 329, 338, 339, 340, 342, 351,\n",
      "        353, 354, 356, 359, 363, 370, 374, 382, 384, 385, 386, 387, 388, 391,\n",
      "        393, 395, 396, 397, 399, 403, 404, 407, 408, 411, 412, 413, 419, 426,\n",
      "        427, 428, 429, 430, 432, 433, 434, 435, 436, 440, 443, 444, 446, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 488, 489,\n",
      "        490, 491, 496, 497, 498, 500, 501, 502, 503, 504, 509, 511])  (len = 194)\n",
      "passing Cout = tensor([136, 138, 140, 163, 164, 177, 180, 189, 193, 214, 216, 220, 222, 227,\n",
      "        240, 246, 263, 266, 281, 290, 310, 323, 324, 334, 398, 402, 416, 417,\n",
      "        424, 431, 439, 447, 467, 487, 492, 499, 505, 510])  (len = 38)\n",
      "\n",
      "Executing module 67: size\n",
      "\tExecuting on machine 0\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 1\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 2\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 3\n",
      "\t\t-skipping\n",
      "Finished execution of layer 67\n",
      "Horizontal output is <class 'int'>. Skipping comparison\n",
      "\n",
      "Executing module 68: view\n",
      "\tExecuting on machine 0\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 1\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 2\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 3\n",
      "\t\t-reshaping (view)\n",
      "Finished execution of layer 68\n",
      "Max diff:\n",
      "tensor([2.6645e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-16, 3.6082e-16, 8.3267e-17, 0.0000e+00,\n",
      "         1.3878e-17, 1.6653e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         0.0000e+00, 1.1102e-16, 0.0000e+00, 4.4409e-16, 0.0000e+00, 5.5511e-17,\n",
      "         8.8818e-16, 1.9429e-16, 1.3323e-15, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         1.3323e-15, 2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1796e-16, 5.5511e-17, 0.0000e+00, 1.1102e-16, 0.0000e+00, 6.6613e-16,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 1.6653e-16, 4.4409e-16, 5.5511e-17,\n",
      "         1.2230e-16, 1.1102e-16, 2.0817e-16, 2.2551e-17, 2.2204e-16, 2.7756e-17,\n",
      "         1.9429e-16, 1.6653e-16, 8.3267e-17, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 3.8858e-16, 1.3878e-16, 8.8818e-16,\n",
      "         2.7756e-16, 0.0000e+00, 3.8858e-16, 0.0000e+00, 0.0000e+00, 6.9389e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8041e-16, 2.4980e-16, 3.8858e-16,\n",
      "         0.0000e+00, 4.4409e-16, 9.9747e-18, 2.2204e-16, 1.1102e-16, 8.3267e-17,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 8.3267e-17, 5.5511e-16, 0.0000e+00,\n",
      "         1.6653e-16, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 8.3267e-17, 2.7756e-16, 0.0000e+00, 0.0000e+00, 3.0531e-16,\n",
      "         0.0000e+00, 4.4409e-16, 2.2204e-16, 1.2490e-16, 1.7347e-18, 0.0000e+00,\n",
      "         2.7756e-16, 0.0000e+00, 1.1102e-16, 6.6613e-16, 1.1102e-16, 1.1926e-17,\n",
      "         2.2204e-16, 1.1102e-16, 2.2204e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-16, 1.1102e-16, 1.5266e-16, 1.3878e-16, 4.4409e-16,\n",
      "         0.0000e+00, 2.2204e-16, 5.3776e-17, 2.7756e-17, 1.3878e-16, 1.1102e-16,\n",
      "         0.0000e+00, 5.5511e-17, 2.2204e-16, 2.7756e-16, 0.0000e+00, 1.7347e-17,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2042e-18, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-17, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2042e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 1.7347e-17,\n",
      "         0.0000e+00, 5.2042e-18, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0408e-17, 1.7347e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00, 1.3010e-17,\n",
      "         6.9389e-18, 5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.6117e-18, 0.0000e+00, 0.0000e+00, 8.3267e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 6.9389e-18, 2.7756e-17, 0.0000e+00,\n",
      "         2.0817e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00, 1.0408e-17,\n",
      "         2.0817e-17, 0.0000e+00, 9.7578e-19, 0.0000e+00, 0.0000e+00, 5.2042e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0715e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.2042e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00,\n",
      "         5.5511e-17, 1.1102e-16, 5.5511e-17, 5.5511e-17, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 5.0307e-17, 0.0000e+00, 3.4694e-18, 0.0000e+00, 1.3878e-17,\n",
      "         6.0715e-18, 2.7756e-17, 0.0000e+00, 1.7347e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 5.5511e-17, 0.0000e+00, 0.0000e+00, 1.7347e-17,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 2.0817e-17, 5.5511e-17, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0600e-18, 1.3878e-17, 5.2042e-18, 2.7756e-17, 1.7347e-18, 0.0000e+00,\n",
      "         1.3878e-17, 2.7756e-17, 2.7756e-17, 1.1102e-16, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.1633e-17, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         5.5511e-17, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         8.3267e-17, 5.5511e-17, 1.3878e-17, 2.7756e-17, 2.7756e-17, 4.1633e-17,\n",
      "         0.0000e+00, 2.7756e-17, 2.7756e-17, 0.0000e+00, 0.0000e+00, 1.3010e-18,\n",
      "         2.7756e-17, 6.9389e-18, 2.7756e-17, 2.7756e-17, 6.9389e-18, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 6.9389e-18, 8.3267e-17, 1.0408e-17, 1.3878e-17,\n",
      "         2.7756e-17, 6.9389e-18, 5.6379e-18, 0.0000e+00, 5.5511e-17, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00, 1.3878e-17,\n",
      "         0.0000e+00, 0.0000e+00, 1.5721e-18, 3.4694e-18, 4.1633e-17, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17, 2.7756e-17,\n",
      "         1.7347e-18, 0.0000e+00, 6.9389e-18, 2.0817e-17, 6.9389e-18, 2.7756e-17,\n",
      "         3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17,\n",
      "         0.0000e+00, 3.4694e-18]], dtype=torch.float64)\n",
      "tensor([128, 129, 130, 132, 133, 134, 137, 139, 141, 143, 144, 145, 146, 149,\n",
      "        150, 151, 156, 157, 159, 161, 162, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 178, 181, 183, 184, 185, 186, 188, 191, 195,\n",
      "        196, 197, 199, 200, 201, 202, 203, 204, 207, 208, 210, 212, 215, 217,\n",
      "        218, 221, 223, 224, 225, 226, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 254, 255,\n",
      "        257, 258, 261, 268, 270, 274, 275, 280, 285, 291, 293, 295, 297, 301,\n",
      "        302, 308, 311, 312, 313, 318, 321, 326, 329, 338, 339, 340, 342, 351,\n",
      "        353, 354, 356, 359, 363, 370, 374, 382, 384, 385, 386, 387, 388, 391,\n",
      "        393, 395, 396, 397, 399, 403, 404, 407, 408, 411, 412, 413, 419, 426,\n",
      "        427, 428, 429, 430, 432, 433, 434, 435, 436, 440, 443, 444, 446, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 488, 489,\n",
      "        490, 491, 496, 497, 498, 500, 501, 502, 503, 504, 509, 511])\n",
      "\n",
      "failing Cout = tensor([128, 129, 130, 132, 133, 134, 137, 139, 141, 143, 144, 145, 146, 149,\n",
      "        150, 151, 156, 157, 159, 161, 162, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 178, 181, 183, 184, 185, 186, 188, 191, 195,\n",
      "        196, 197, 199, 200, 201, 202, 203, 204, 207, 208, 210, 212, 215, 217,\n",
      "        218, 221, 223, 224, 225, 226, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 254, 255,\n",
      "        257, 258, 261, 268, 270, 274, 275, 280, 285, 291, 293, 295, 297, 301,\n",
      "        302, 308, 311, 312, 313, 318, 321, 326, 329, 338, 339, 340, 342, 351,\n",
      "        353, 354, 356, 359, 363, 370, 374, 382, 384, 385, 386, 387, 388, 391,\n",
      "        393, 395, 396, 397, 399, 403, 404, 407, 408, 411, 412, 413, 419, 426,\n",
      "        427, 428, 429, 430, 432, 433, 434, 435, 436, 440, 443, 444, 446, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 488, 489,\n",
      "        490, 491, 496, 497, 498, 500, 501, 502, 503, 504, 509, 511])  (len = 194)\n",
      "passing Cout = tensor([136, 138, 140, 163, 164, 177, 180, 189, 193, 214, 216, 220, 222, 227,\n",
      "        240, 246, 263, 266, 281, 290, 310, 323, 324, 334, 398, 402, 416, 417,\n",
      "        424, 431, 439, 447, 467, 487, 492, 499, 505, 510])  (len = 38)\n",
      "\n",
      "Executing module 69: linear\n",
      "\tExecuting on machine 0\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\tExecuting on machine 1\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\t\t sending C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\tExecuting on machine 2\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\t\t sending C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\tExecuting on machine 3\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\t\t sending C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "Finished execution of layer 69\n",
      "\n",
      "\n",
      "############################# FINAL EXECUTION TIME 3.1373424530029297 [seconds] #############################\n",
      "\n",
      "\n",
      "Max diff:\n",
      "tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.4409e-16, 3.5527e-15, 1.7764e-15, 8.8818e-16, 2.9143e-15, 2.8866e-15,\n",
      "         1.7764e-15, 8.8818e-16, 1.4433e-15, 4.4409e-16]], dtype=torch.float64)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "failing Cout = tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])  (len = 10)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Prep Inout for Mock Run version 2 (fx)'''\n",
    "\n",
    "# TODO: reduce size of communicated tensors to only what is necessary \n",
    "# TODO: also check bias for nonzero\n",
    "# TODO: come up with more general scheme to handle residual layers\n",
    "\n",
    "# channel_id == INPUTS\n",
    "# filter_id  == OUTPUTS\n",
    "\n",
    "# try greater precision\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# setup input \n",
    "N_batch = 1\n",
    "torch.manual_seed(0)\n",
    "input_tensor = torch.rand(N_batch, 3, 32, 32, dtype=torch.float64, device=torch.device(configs['device'])) # 1k images, 3 channels, 32x32 image (cifar100) \n",
    "model = model.type(torch.float64)\n",
    "\n",
    "# make SplitManagers for split model execution \n",
    "configs['dtype'] = 'float64'\n",
    "split_managers = [SplitManager]*num_machines\n",
    "for i in range(num_machines):\n",
    "    split_managers[i] = SplitManager(configs, i, num_machines, input_tensor)\n",
    "\n",
    "# broadcast input_tensor to different machines\n",
    "# TODO: find a better datastructure for this\n",
    "#input = np.empty((num_machines, num_machines), dtype=torch.Tensor)\n",
    "input = [None]*num_machines\n",
    "input = [input[:] for i in range(num_machines)]\n",
    "for imach in range(num_machines):\n",
    "    input[imach][imach] = input_tensor\n",
    "\n",
    "residual_block_start, residual_connection_start, residual_block_end = get_residual_block_indexes(model)\n",
    "\n",
    "# put models into eval mode and on device\n",
    "model.eval()\n",
    "model.to(configs['device'])\n",
    "\n",
    "# set index to execute vertical splitting up to \n",
    "exec_to_layer = 69\n",
    "\n",
    "# get true output at each layer\n",
    "# WARNING: bn layers are initialized differently between model in this notebook and model in split manager. The moving mean and variance fields do not match HOWEVER the weights and biases are the same\n",
    "#horz_output, size_LUT = get_output_at_each_layer(model, input_tensor) \n",
    "horz_output, size_LUT = get_output_at_each_layer(split_managers[0].model, input_tensor)\n",
    "\n",
    "BREAK_LOOP = 0 # break loop when output differs\n",
    "\n",
    "'''\n",
    "    mock run through inference using split models \n",
    "'''\n",
    "\n",
    "# timing\n",
    "split_execution_start_time = time.time()\n",
    "layer_completion_time_stamp = {}\n",
    "layer_execution_duration = {}\n",
    "\n",
    "# make inference \n",
    "with torch.no_grad():\n",
    "    residual_input = {} # use this to keep track of inputs stored in machine memory for residule layers\n",
    "\n",
    "    # iterate through layers 1 module at a time \n",
    "    for imodule in range(exec_to_layer+1):#range(num_total_modules): # 16 <=> layer_1 block \n",
    "\n",
    "        # initialize output for ilayer\n",
    "        #output = np.empty((num_machines, num_machines), dtype=torch.Tensor) # square list indexed as: output[destination/RX machine][origin/TX machine]\n",
    "        # TODO: find a better datastructure for this \n",
    "\n",
    "        output = [None]*num_machines\n",
    "        output = [output[:] for i in range(num_machines)]\n",
    "\n",
    "        # DEBUG\n",
    "        full_input = combine_all_inputs(input, num_machines)\n",
    "\n",
    "        print(f'Executing module {imodule}: {layer_names_fx[imodule]}')\n",
    "\n",
    "        # iterate through each machine (done in parallel later)\n",
    "        for imach in range(num_machines):\n",
    "            print(f'\\tExecuting on machine {imach}')\n",
    "\n",
    "            # collect communication inputs if necessary \n",
    "            if not imodule == 0 and ('conv' in layer_names_fx[imodule-1] or 'linear' in layer_names_fx[imodule-1] or 'shortcut.1' in layer_names_fx[imodule]): # TODO: this is very hacky, needs to be generalized. The issue is ID'ing conv layers in shortcut blocks\n",
    "                curr_input = combine_inputs(input, num_machines, imach)\n",
    "            else:\n",
    "                curr_input = input[imach][imach]\n",
    "\n",
    "            out_tensor, do_comms = split_managers[imach].execute_split_layer(curr_input, imodule)\n",
    "            if not do_comms:\n",
    "                # update output to current machine and continue\n",
    "                if torch.is_tensor(out_tensor):\n",
    "                    # sometimes out_tensor is None\n",
    "                    # input is sent to all machines for 1st layer execution even though not all machines need to compute \n",
    "                    # Output from machine is None in this case TODO: fix where inputs are sent \n",
    "                    output[imach][imach] = out_tensor\n",
    "                continue\n",
    "\n",
    "            # END SplitManager execute split_layer\n",
    "\n",
    "            print(f'\\t\\t Output tensor shape : {out_tensor.shape}')\n",
    "\n",
    "            # debug\n",
    "            nonzero_out_tensor = torch.unique(torch.nonzero(out_tensor, as_tuple=True)[1])\n",
    "\n",
    "            # look at which C_out need to be computed and sent\n",
    "            #nonzero_Cout = torch.unique(torch.nonzero(split_layer.weight, as_tuple=True)[0]) # find nonzero dimensions in output channels\n",
    "            nonzero_Cout = get_nonzero_channels(out_tensor)\n",
    "\n",
    "            # prep communications by populating output\n",
    "            out_channel_array = torch.arange(out_tensor.shape[1])\n",
    "            for rx_mach in range(num_machines):\n",
    "                # only add to output if communication is necessary \n",
    "\n",
    "                # Get output channels for current rx machine? TODO: consider removing, this just maps C_out's to machine\n",
    "                #output_channels = torch.tensor(configs['partition'][][rx_mach],\n",
    "                #        device=torch.device(configs['device']))\n",
    "                output_channels = torch.tensor(split_managers[imach].output_channel_map[rx_mach],\n",
    "                        device=torch.device(configs['device']))\n",
    "\n",
    "                # TODO: is there a faster way to do this? Consider putting larger array 1st... just not sure which one that'd be\n",
    "                nonzero_out_channels = nonzero_Cout[torch.isin(nonzero_Cout, output_channels)]\n",
    "                if nonzero_out_channels.nelement() > 0:\n",
    "                        communication_mask = torch.isin(out_channel_array, nonzero_out_channels)\n",
    "\n",
    "                        # TODO: this is inefficient, redo. Probbably need to send a tensor and some info what output channels are being sent\n",
    "                        tmp_out = torch.zeros(out_tensor.shape, dtype= split_managers[imach].dtype) \n",
    "                        if imodule == total_layers_fx-1:\n",
    "                                tmp_out[:,communication_mask] = out_tensor[:,communication_mask]\n",
    "                        else:\n",
    "                                tmp_out[:,communication_mask,:,:] = out_tensor[:,communication_mask,:,:]\n",
    "                        output[rx_mach][imach] = tmp_out\n",
    "\n",
    "                        # debug\n",
    "                        print(f'\\t\\t sending C_out {nonzero_out_channels} to machine {rx_mach}')\n",
    "\n",
    "        # send to next layer  \n",
    "        input = output\n",
    "        print(f'Finished execution of layer {imodule}')\n",
    "\n",
    "        # update timing\n",
    "        layer_completion_time_stamp[layer_names_fx[imodule]] = time.time()\n",
    "        if imodule > 0:\n",
    "            layer_execution_duration[layer_names_fx[imodule]] = layer_completion_time_stamp[layer_names_fx[imodule]] - layer_completion_time_stamp[layer_names_fx[imodule-1]] \n",
    "        else:\n",
    "            layer_execution_duration[layer_names_fx[imodule]] = layer_completion_time_stamp[layer_names_fx[imodule]] - split_execution_start_time\n",
    "\n",
    "        # check output at end of each layer to see if fit matches \n",
    "        tmp_output = input \n",
    "        need_to_init  = True\n",
    "        for rx_mach in range(num_machines):\n",
    "                for tx_mach in range(num_machines):\n",
    "                        if not tmp_output[rx_mach][tx_mach] == None:\n",
    "                                if need_to_init:\n",
    "                                        vert_output = tmp_output[rx_mach][tx_mach]\n",
    "                                        need_to_init = False\n",
    "                                else:\n",
    "                                        # TODO: += causes assignment issues, switched to x = x+y which might be more more inefficent memory wise ... \n",
    "                                        vert_output = vert_output + tmp_output[rx_mach][tx_mach] \n",
    "                                        #nz_channels = get_nonzero_channels(vert_output)\n",
    "                                        #print(f'({rx_mach},{tx_mach}) {nz_channels}')\n",
    "        \n",
    "        if imodule == total_layers_fx-1:\n",
    "            # apply bias\n",
    "            # TODO: assumes Linear layer is final layer and bias can be handled as final step \n",
    "            vert_output = vert_output + get_current_module(model, imodule).bias\n",
    "            \n",
    "            # final execution time\n",
    "            tot_split_execution_time = time.time() - split_execution_start_time\n",
    "            print(f'\\n\\n############################# FINAL EXECUTION TIME {tot_split_execution_time} [seconds] #############################\\n\\n')\n",
    "\n",
    "        truth_output = horz_output[layer_names_fx[imodule]]\n",
    "        if 'x' == layer_names_fx[imodule]:\n",
    "            print(f'Input layer. Skipping comparison')\n",
    "        elif torch.is_tensor(truth_output):\n",
    "            max_diff, max_by_Cout = compare_outputs(vert_output, truth_output)\n",
    "            if max_diff > 0.1:\n",
    "                BREAK_LOOP = 1 \n",
    "        else:\n",
    "            print(f'Horizontal output is {type(truth_output)}. Skipping comparison')\n",
    "        print()\n",
    "\n",
    "        if BREAK_LOOP:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.float64, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Conv1 layer test -- should we expect some difference, or exactly 0 in the output when we split the model?\n",
    "'''\n",
    "\n",
    "# DIFFERENCE SHOULD BE 0 NOT 1E-7\n",
    "\n",
    "N_in = 1\n",
    "split_1 = nn.Conv2d(N_in,\n",
    "            model.conv1.weight.shape[0], # TODO does this need to be an int? (currently tensor)\n",
    "            kernel_size= model.conv1.kernel_size,\n",
    "            stride=model.conv1.stride,\n",
    "            padding=model.conv1.padding, \n",
    "            bias=False) # TODO: add bias during input collecting step on next layer \n",
    "split_1.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([0])))  \n",
    "out_split1 = split_1(input_tensor.index_select(1, torch.tensor([0])))\n",
    "\n",
    "split_2 = split_1\n",
    "split_2.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([1])))  \n",
    "out_split2 = split_2(input_tensor.index_select(1, torch.tensor([1])))\n",
    "\n",
    "split_3 = split_1\n",
    "split_3.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([2])))  \n",
    "out_split3 = split_3(input_tensor.index_select(1, torch.tensor([2])))\n",
    "\n",
    "split_out = torch.add(torch.add(out_split1, out_split2), out_split3)\n",
    "full_out = model.conv1(input_tensor)\n",
    "\n",
    "diff_output = torch.abs(full_out - split_out)\n",
    "max_diff = torch.max(diff_output)\n",
    "max_diff.sci_mode = True\n",
    "print(max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 4), dtype=torch.int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  \n",
    "    Inspect I/O of single layer\n",
    "'''\n",
    "\n",
    "t = torch.ones((1,2,2,2), dtype=torch.float32) # (batch, in channel, H, W)\n",
    "w = torch.ones((1,2,2,2), dtype=torch.float32) # (out channels, in channels, H, W)\n",
    "w[0,0,0,0] = 1e-10\n",
    "w[0,0,0,1] = 1e-10\n",
    "w[0,1,0,0] = 1e-10\n",
    "\n",
    "full_conv = torch.nn.Conv2d(2,1,kernel_size=(2,2), bias=False, stride=(1),dtype=torch.float32)\n",
    "full_conv.weight = torch.nn.Parameter(w)\n",
    "conv1 = torch.nn.Conv2d(1,1,kernel_size=(2,2), bias=False, stride=1, dtype=torch.float32)\n",
    "conv1.weight =torch.nn.Parameter( w[:,0:1,:,:])\n",
    "conv2 = torch.nn.Conv2d(1,1,kernel_size=(2,2), bias=False, stride=1,dtype=torch.float32)\n",
    "conv2.weight = torch.nn.Parameter(w[:,1:2,:,:])\n",
    "\n",
    "full_conv.eval()\n",
    "conv1.eval()\n",
    "conv2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    full_out = full_conv(t)\n",
    "    split_out =  conv2(t[0,1:2,:,:]) + conv1(t[:,0:1,:,:])\n",
    "\n",
    "diff = torch.abs(full_out - split_out)\n",
    "\n",
    "torch.nonzero(diff)\n",
    "#print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test bn1\n",
    "#estimate = -bn1.running_mean[1]/torch.sqrt(bn1.running_var[1] + bn1.eps)*bn1.weight[1] + bn1.bias[1]\n",
    "#estimate_split = -split_layer.running_mean[1]/torch.sqrt(split_layer.running_var[1] + split_layer.eps)*split_layer.weight[1] + split_layer.bias[1]\n",
    "\n",
    "# running estimates are different \n",
    "#bn1.running_mean[1] - split_layer.running_mean[1]\n",
    "#bn1.running_var[1] - split_layer.running_var[1] \n",
    "#bn1.weight[1] - split_layer.weight[1]\n",
    "#bn1.eps - split_layer.eps\n",
    "#bn1.bias[1] - split_layer.bias[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
