{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Load RESNET model and split it\\n        1. layer by layer\\n        2. [TODO] vertically \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Load RESNET model and split it\n",
    "        1. layer by layer\n",
    "        2. [TODO] vertically \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naugen/anaconda3/envs/cap_nb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from source.core.engine import MoP\n",
    "import source.core.run_partition as run_p\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "from split_network import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "from source.utils import testers\n",
    "from source.core import engine\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from torchsummary import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  \n",
      "model :  resnet18\n",
      "data_code :  cifar10\n",
      "num_classes :  10\n",
      "model_file :  test.pt\n",
      "epochs :  0\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  1\n",
      "admm :  True\n",
      "admm_epochs :  300\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.005\n",
      "retrain_ep :  50\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.001\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  1\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  False\n",
      "comm_outsize :  False\n",
      "lambda_comm :  0\n",
      "lambda_comp :  0\n",
      "distill_model :  \n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n"
     ]
    }
   ],
   "source": [
    "# setup config\n",
    "dataset='cifar10'\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "\n",
    "configs = run_p.main()\n",
    "\n",
    "configs[\"device\"] = \"cpu\"\n",
    "configs['load_model'] = \"cifar10-resnet18-kernel-npv2-pr0.75-lcm0.001.pt\"\n",
    "configs[\"num_partition\"] = '4' #'resnet18-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into full model\n",
    "state_dict = torch.load(io.get_model_path(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time per data is 15.526772ms.\n",
      "conv1.weight 1024\n",
      "layer1.0.conv1.weight 1024\n",
      "layer1.0.conv2.weight 1024\n",
      "layer1.1.conv1.weight 1024\n",
      "layer1.1.conv2.weight 1024\n",
      "layer2.0.conv1.weight 256\n",
      "layer2.0.conv2.weight 256\n",
      "layer2.0.shortcut.0.weight 256\n",
      "layer2.1.conv1.weight 256\n",
      "layer2.1.conv2.weight 256\n",
      "layer3.0.conv1.weight 64\n",
      "layer3.0.conv2.weight 64\n",
      "layer3.0.shortcut.0.weight 64\n",
      "layer3.1.conv1.weight 64\n",
      "layer3.1.conv2.weight 64\n",
      "layer4.0.conv1.weight 16\n",
      "layer4.0.conv2.weight 16\n",
      "layer4.0.shortcut.0.weight 16\n",
      "layer4.1.conv1.weight 16\n",
      "layer4.1.conv2.weight 16\n",
      "['x', 'conv1', 'bn1', 'relu', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avg_pool2d', 'size', 'view', 'linear']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    add partitions and communications to configs\n",
    "'''\n",
    "\n",
    "# gets random test input (with correct size)\n",
    "input_var = engine.get_input_from_code(configs)\n",
    "#print(input_var)\n",
    "\n",
    "# Config partitions and prune_ratio\n",
    "configs['num_partition'] = '4'#'./config/resnet18-v2.yaml'\n",
    "configs = engine.partition_generator(configs, model)\n",
    "            \n",
    "# Compute output size of each layer\n",
    "configs['partition'] = engine.featuremap_summary(model, configs['partition'], input_var)\n",
    "        \n",
    "# Setup communication costs\n",
    "configs['comm_costs'] = engine.set_communication_cost(model, configs['partition'],)\n",
    "\n",
    "\n",
    "# split model general parameters\n",
    "\n",
    "# make copies of model per machine\n",
    "num_machines = max(configs['partition']['bn_partition']) # TODO: double check this makes sense\n",
    "model_machines = [model]*num_machines\n",
    "\n",
    "layer_names_fx =  get_graph_node_names(model)[1]\n",
    "total_layers_fx = len(layer_names_fx)\n",
    "\n",
    "split_module_names = list(configs['partition'].keys())\n",
    "\n",
    "print(layer_names_fx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing module 0: x\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "Finished execution of layer 0\n",
      "\n",
      "Max diff:\n",
      "tensor([2.9981])\n",
      "\n",
      "tensor([[2.9968, 2.9960, 2.9981]])\n",
      "tensor([0, 1, 2])\n",
      "\n",
      "failing Cout = tensor([0, 1, 2])  (len = 3)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "Executing module 1: conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-WARNING: No input assigned to this machine (but it was sent input?). Skipping...\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31]) to machine 1\n",
      "\t\t sending C_out tensor([56, 62]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0, 12]) to machine 0\n",
      "\t\t sending C_out tensor([38, 42]) to machine 2\n",
      "\t\t sending C_out tensor([54, 57]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 4,  8, 14]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31]) to machine 1\n",
      "\t\t sending C_out tensor([36, 42, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([54, 57]) to machine 3\n",
      "Finished execution of layer 1\n",
      "\n",
      "Max diff:\n",
      "tensor([2.3842e-07])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3842e-07, 1.7881e-07,\n",
      "         2.3842e-07, 1.1921e-07, 2.3842e-07, 1.6391e-07, 1.7881e-07, 2.3842e-07,\n",
      "         1.1921e-07, 2.3842e-07, 2.3842e-07, 1.4901e-07, 1.7881e-07, 1.1921e-07,\n",
      "         0.0000e+00, 2.3842e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.4506e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0862e-07, 0.0000e+00, 0.0000e+00, 2.3842e-07, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 42, 54, 57])\n",
      "\n",
      "failing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 42, 54, 57])  (len = 18)\n",
      "passing Cout = tensor([ 0,  4,  8, 12, 14, 36, 38, 45, 46, 47, 56, 62])  (len = 12)\n"
     ]
    }
   ],
   "source": [
    "''' Prep Inout for Mock Run version 2 (fx)'''\n",
    "\n",
    "# TODO: reduce size of communicated tensors to only what is necessary \n",
    "# TODO: also check bias for nonzero\n",
    "# TODO: come up with more general scheme to handle residual layers\n",
    "\n",
    "# channel_id == INPUTS\n",
    "# filter_id  == OUTPUTS\n",
    "\n",
    "# setup input \n",
    "N_batch = 1\n",
    "input_tensor = torch.rand(N_batch, 3, 32, 32, device=torch.device(configs['device'])) # 1k images, 3 channels, 32x32 image (cifar100) \n",
    "\n",
    "# broadcast input_tensor to different machines\n",
    "# TODO: find a better datastructure for this\n",
    "#input = np.empty((num_machines, num_machines), dtype=torch.Tensor)\n",
    "input = [None]*num_machines\n",
    "input = [input[:] for i in range(num_machines)]\n",
    "for imach in range(num_machines):\n",
    "    input[imach][imach] = input_tensor\n",
    "\n",
    "residual_block_start, residual_connection_start, residual_block_end = get_residual_block_indexes(model)\n",
    "\n",
    "# put models into eval mode and on device\n",
    "model.eval()\n",
    "model.to(configs['device'])\n",
    "\n",
    "# set index to execute vertical splitting up to \n",
    "exec_to_layer = 2\n",
    "\n",
    "# get list of intermediate outputs \n",
    "get_horz_out = {}\n",
    "for aname in layer_names_fx:\n",
    "    get_horz_out[aname] = aname\n",
    "\n",
    "# make extractor model and get output\n",
    "extractor_model = create_feature_extractor(model,return_nodes = get_horz_out)\n",
    "with torch.no_grad():\n",
    "    extractor_model.eval()\n",
    "    horz_output = extractor_model(input_tensor)\n",
    "\n",
    "'''\n",
    "    mock run through inference using split models \n",
    "'''\n",
    "\n",
    "# make inference \n",
    "with torch.no_grad():\n",
    "    residual_input = {} # use this to keep track of inputs stored in machine memory for residule layers\n",
    "\n",
    "    # iterate through layers 1 module at a time \n",
    "    for imodule in range(exec_to_layer):#range(num_total_modules): # 16 <=> layer_1 block \n",
    "\n",
    "        # initialize output for ilayer\n",
    "        #output = np.empty((num_machines, num_machines), dtype=torch.Tensor) # square list indexed as: output[destination/RX machine][origin/TX machine]\n",
    "        # TODO: find a better datastructure for this \n",
    "        output = [None]*num_machines\n",
    "        output = [output[:] for i in range(num_machines)]\n",
    "\n",
    "        print(f'Executing module {imodule}: {layer_names_fx[imodule]}')\n",
    "\n",
    "        # iterate through each machine (done in parallel later)\n",
    "        for imach in range(num_machines):\n",
    "            print(f'\\tExecuting on machine {imach}')\n",
    "\n",
    "            # collect communication inputs if necessary \n",
    "            if not imodule == 0 and ('conv' in layer_names_fx[imodule-1] or 'linear' in layer_names_fx[imodule-1]):\n",
    "                curr_input = combine_inputs(input, num_machines, imach)\n",
    "            else:\n",
    "                curr_input = input[imach][imach]\n",
    "\n",
    "            # skip this machine+module if there is no input to compute \n",
    "            if not torch.is_tensor(curr_input):\n",
    "                print('\\t\\t-No input sent to this machine. Skipping module')\n",
    "                continue\n",
    "            \n",
    "            # debug\n",
    "            print(f'\\t\\t received input channels {get_nonzero_channels(curr_input)}')\n",
    "\n",
    "            # non-comms operations \n",
    "            if 'relu' in layer_names_fx[imodule]:\n",
    "                # just relu no comm necessary \n",
    "                print('\\t\\t-Applying ReLU')\n",
    "                output[imach][imach] = F.relu(curr_input)\n",
    "                continue\n",
    "\n",
    "            elif 'add' in layer_names_fx[imodule]:\n",
    "                # residual layer. No comm necessary \n",
    "                print('\\t\\t-adding residual')\n",
    "                curr_input += residual_input[str(imach)]['block_out']\n",
    "                output[imach][imach] = curr_input\n",
    "\n",
    "                # erase stored \n",
    "                residual_input[str(imach)] = {}\n",
    "                continue\n",
    "            \n",
    "            elif 'avg_pool2d' in layer_names_fx[imodule]:\n",
    "                print('\\t\\t-average pooling')\n",
    "                output[imach][imach] = F.avg_pool2d(curr_input, 4)\n",
    "                continue\n",
    "            \n",
    "            elif 'size' in layer_names_fx[imodule]:\n",
    "                print('\\t\\t-skipping')\n",
    "                output[imach][imach] = curr_input\n",
    "                continue\n",
    "            \n",
    "            elif 'view' in layer_names_fx[imodule]:\n",
    "                print('\\t\\t-reshaping (view)')\n",
    "                output[imach][imach] = curr_input.view(curr_input.size(0), -1)\n",
    "                continue\n",
    "            elif 'x' == layer_names_fx[imodule]:\n",
    "                # do nothing if model input\n",
    "                print('\\t\\t-model input layer.. skipping')\n",
    "                output[imach][imach] = curr_input\n",
    "                continue\n",
    "                        \n",
    "            # swap out io for residual connection\n",
    "            if imodule in residual_block_start:\n",
    "                # save input for later \n",
    "                residual_input[str(imach)] = {}\n",
    "                residual_input[str(imach)]['block_in'] = curr_input\n",
    "                print('\\t\\t-Saving input for later...')\n",
    "            elif imodule in residual_connection_start:\n",
    "                # swap tensors\n",
    "                residual_input[str(imach)]['block_out'] = curr_input\n",
    "                curr_input = residual_input[str(imach)]['block_in'] \n",
    "                print('\\t\\t-Saving current input. Swapping for input saved from start of block')\n",
    "\n",
    "            # get the current module\n",
    "            # TODO: is this very bad for latency? Only load module if you have to \n",
    "            curr_layer = get_current_module(model, imodule)\n",
    "\n",
    "            # update communication I/O for this layer  \n",
    "            # TODO: revist this implementation\n",
    "            split_param_name = layer_names_fx[imodule] + '.weight'\n",
    "            if split_param_name in split_module_names:\n",
    "                # skip if machine doesnt expect input\n",
    "                if len(configs['partition'][split_param_name]['channel_id'][imach]) == 0:\n",
    "                        print(f'\\t\\t-WARNING: No input assigned to this machine (but it was sent input?). Skipping...')\n",
    "                        continue\n",
    "\n",
    "                # TODO: reconsider implementation \n",
    "                # What input channels does this machine compute?\n",
    "                input_channels = torch.tensor(configs['partition'][split_param_name]['channel_id'][imach],\n",
    "                        device=torch.device(configs['device']))\n",
    "                N_in = len(input_channels) # TODO: is this used?\n",
    "\n",
    "                # Where to send output (map of output channels to different machines)\n",
    "                output_channel_map = configs['partition'][split_param_name]['filter_id']\n",
    "            elif type(curr_layer) == nn.Linear and imodule == total_layers_fx-1:\n",
    "                # if final layer output all goes to machine 0 \n",
    "                # TODO: find better way to handle this. Also will we encounter Linear layers not at the end of the model\n",
    "                N_Cin = curr_layer.in_features\n",
    "                Cin_per_machine = N_Cin/num_machines\n",
    "                if Cin_per_machine % 1 > 0:\n",
    "                        print('ERROR: UNEXPECTED NUMBER OF I/O FOR LINEAR MODULE {imodule}')\n",
    "                Cin_per_machine = int(Cin_per_machine)\n",
    "                input_channels = np.arange(Cin_per_machine) + imach*Cin_per_machine\n",
    "                N_Cout = curr_layer.out_features \n",
    "                output_channel_map = [None]*num_machines\n",
    "                for i in range(num_machines):\n",
    "                        if i == 0:\n",
    "                                output_channel_map[i] = np.arange(N_Cout) \n",
    "                        else:\n",
    "                                output_channel_map[i] = np.array([])\n",
    "                input_channels = torch.tensor(input_channels, device=torch.device(configs['device']))\n",
    "            else:\n",
    "                # for batch normal, and functional passes through the code\n",
    "                # TODO: address the following assumptions:\n",
    "                #       - assume all BN layers have C_in divisable by num_machines\n",
    "                #       - assume C_in are evenly split in sequential order WARNING THIS WILL BREAK WHEN WE START TO DO ASSIGN WEIGHTS TO DIFF MACHINES\n",
    "                N_Cin = curr_layer.num_features\n",
    "                Cin_per_machine = N_Cin/num_machines\n",
    "                if Cin_per_machine % 1 > 0:\n",
    "                        print('ERROR: UNEXPECTED NUMBER OF I/O FOR BATCH NORMAL MODULE {imodule}')\n",
    "                Cin_per_machine = int(Cin_per_machine)\n",
    "                input_channels = np.arange(Cin_per_machine) + imach*Cin_per_machine\n",
    "                output_channel_map = [None]*num_machines\n",
    "                for i in range(num_machines):\n",
    "                        if i == imach:\n",
    "                                output_channel_map[i] = input_channels\n",
    "                        else:\n",
    "                                output_channel_map[i] = np.array([])\n",
    "                input_channels = torch.tensor(input_channels, device=torch.device(configs['device']))\n",
    "\n",
    "\n",
    "            # make vertically split layer \n",
    "            if type(curr_layer) == nn.Conv2d:\n",
    "                split_layer = split_conv_layer(curr_layer, input_channels)\n",
    "            elif type(curr_layer) == nn.BatchNorm2d:\n",
    "                split_layer = split_bn_layer(curr_layer, input_channels)\n",
    "            elif type(curr_layer) == nn.Linear:\n",
    "                split_layer = split_linear_layer(curr_layer, input_channels)\n",
    "            else:\n",
    "                print(f'\\t\\t-Skipping module {type(curr_layer).__name__}')\n",
    "                continue\n",
    "                        \n",
    "            # eval split\n",
    "            split_layer.eval()\n",
    "            out_tensor = split_layer(curr_input.index_select(1, input_channels))\n",
    "            if type(curr_layer) == nn.BatchNorm2d:\n",
    "                tmp_out_tensor = torch.zeros(curr_input.shape)\n",
    "                tmp_out_tensor[:,input_channels.numpy(),:,:] = out_tensor\n",
    "                out_tensor = tmp_out_tensor\n",
    "\n",
    "            print(f'\\t\\t Output tensor shape : {out_tensor.shape}')\n",
    "\n",
    "            # debug\n",
    "            nonzero_out_tensor = torch.unique(torch.nonzero(out_tensor, as_tuple=True)[1])\n",
    "\n",
    "            # look at which C_out need to be computed and sent\n",
    "            #nonzero_Cout = torch.unique(torch.nonzero(split_layer.weight, as_tuple=True)[0]) # find nonzero dimensions in output channels\n",
    "            nonzero_Cout = get_nonzero_channels(out_tensor)\n",
    "\n",
    "            # prep communications by populating output\n",
    "            out_channel_array = torch.arange(out_tensor.shape[1])\n",
    "            for rx_mach in range(num_machines):\n",
    "                # only add to output if communication is necessary \n",
    "\n",
    "                # Get output channels for current rx machine? TODO: consider removing, this just maps C_out's to machine\n",
    "                output_channels = torch.tensor(output_channel_map[rx_mach],\n",
    "                        device=torch.device(configs['device']))\n",
    "\n",
    "                # TODO: is there a faster way to do this? Consider putting larger array 1st... just not sure which one that'd be\n",
    "                nonzero_out_channels = nonzero_Cout[torch.isin(nonzero_Cout, output_channels)]\n",
    "                if nonzero_out_channels.nelement() > 0:\n",
    "                        communication_mask = torch.isin(out_channel_array, nonzero_out_channels)\n",
    "\n",
    "                        # TODO: this is inefficient, redo. Probbably need to send a tensor and some info what output channels are being sent\n",
    "                        tmp_out = torch.zeros(out_tensor.shape) \n",
    "                        if imodule == total_layers_fx-1:\n",
    "                                tmp_out[:,communication_mask] = out_tensor[:,communication_mask]\n",
    "                        else:\n",
    "                                tmp_out[:,communication_mask,:,:] = out_tensor[:,communication_mask,:,:]\n",
    "                        output[rx_mach][imach] = tmp_out\n",
    "\n",
    "                        # debug\n",
    "                        print(f'\\t\\t sending C_out {nonzero_out_channels} to machine {rx_mach}')\n",
    "\n",
    "        # send to next layer  \n",
    "        input = output\n",
    "        print(f'Finished execution of layer {imodule}')\n",
    "        print()\n",
    "\n",
    "        # check output at end of each layer to see if fit matches \n",
    "        tmp_output = input \n",
    "        need_to_init  = True\n",
    "        for rx_mach in range(num_machines):\n",
    "                for tx_mach in range(num_machines):\n",
    "                        if not tmp_output[rx_mach][tx_mach] == None:\n",
    "                                if need_to_init:\n",
    "                                        vert_output = tmp_output[rx_mach][tx_mach]\n",
    "                                        need_to_init = False\n",
    "                                else:\n",
    "                                        # TODO: += causes assignment issues, switched to x = x+y which might be more more inefficent memory wise ... \n",
    "                                        vert_output = vert_output + tmp_output[rx_mach][tx_mach] \n",
    "                                        #nz_channels = get_nonzero_channels(vert_output)\n",
    "                                        #print(f'({rx_mach},{tx_mach}) {nz_channels}')\n",
    "        \n",
    "        compare_outputs(vert_output, horz_output[layer_names_fx[imodule]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Conv1 layer test -- should we expect some difference, or exactly 0 in the output when we split the model?\n",
    "'''\n",
    "\n",
    "# DIFFERENCE SHOULD BE 0 NOT 1E-7\n",
    "\n",
    "N_in = 1\n",
    "split_1 = nn.Conv2d(N_in,\n",
    "            model.conv1.weight.shape[0], # TODO does this need to be an int? (currently tensor)\n",
    "            kernel_size= model.conv1.kernel_size,\n",
    "            stride=model.conv1.stride,\n",
    "            padding=model.conv1.padding, \n",
    "            bias=False) # TODO: add bias during input collecting step on next layer \n",
    "split_1.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([0])))  \n",
    "out_split1 = split_1(input_tensor.index_select(1, torch.tensor([0])))\n",
    "\n",
    "split_2 = split_1\n",
    "split_2.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([1])))  \n",
    "out_split2 = split_2(input_tensor.index_select(1, torch.tensor([1])))\n",
    "\n",
    "split_3 = split_1\n",
    "split_3.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([2])))  \n",
    "out_split3 = split_3(input_tensor.index_select(1, torch.tensor([2])))\n",
    "\n",
    "split_out = torch.add(torch.add(out_split1, out_split2), out_split3)\n",
    "full_out = model.conv1(input_tensor)\n",
    "\n",
    "diff_output = torch.abs(full_out - split_out)\n",
    "max_diff = torch.max(diff_output)\n",
    "max_diff.sci_mode = True\n",
    "print(max_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
