{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Load RESNET model and split it\\n        1. layer by layer\\n        2. [TODO] vertically \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Load RESNET model and split it\n",
    "        1. layer by layer\n",
    "        2. [TODO] vertically \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naugen/anaconda3/envs/cap_nb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from source.core.engine import MoP\n",
    "import source.core.run_partition as run_p\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "from split_network import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "from source.utils import testers\n",
    "from source.core import engine\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from torchsummary import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  \n",
      "model :  resnet18\n",
      "data_code :  cifar10\n",
      "num_classes :  10\n",
      "model_file :  test.pt\n",
      "epochs :  0\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  1\n",
      "admm :  True\n",
      "admm_epochs :  300\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.005\n",
      "retrain_ep :  50\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.001\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  1\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  False\n",
      "comm_outsize :  False\n",
      "lambda_comm :  0\n",
      "lambda_comp :  0\n",
      "distill_model :  \n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n"
     ]
    }
   ],
   "source": [
    "# setup config\n",
    "dataset='cifar10'\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "\n",
    "configs = run_p.main()\n",
    "\n",
    "configs[\"device\"] = \"cpu\"\n",
    "configs['load_model'] = \"cifar10-resnet18-kernel-npv0-pr0.75-lcm0.001.pt\"\n",
    "configs[\"num_partition\"] = '4' #'resnet18-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into full model\n",
    "state_dict = torch.load(io.get_model_path(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time per data is 15.055418ms.\n",
      "conv1.weight 1024\n",
      "layer1.0.conv1.weight 1024\n",
      "layer1.0.conv2.weight 1024\n",
      "layer1.1.conv1.weight 1024\n",
      "layer1.1.conv2.weight 1024\n",
      "layer2.0.conv1.weight 256\n",
      "layer2.0.conv2.weight 256\n",
      "layer2.0.shortcut.0.weight 256\n",
      "layer2.1.conv1.weight 256\n",
      "layer2.1.conv2.weight 256\n",
      "layer3.0.conv1.weight 64\n",
      "layer3.0.conv2.weight 64\n",
      "layer3.0.shortcut.0.weight 64\n",
      "layer3.1.conv1.weight 64\n",
      "layer3.1.conv2.weight 64\n",
      "layer4.0.conv1.weight 16\n",
      "layer4.0.conv2.weight 16\n",
      "layer4.0.shortcut.0.weight 16\n",
      "layer4.1.conv1.weight 16\n",
      "layer4.1.conv2.weight 16\n",
      "['x', 'conv1', 'bn1', 'relu', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avg_pool2d', 'size', 'view', 'linear']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    add partitions and communications to configs\n",
    "'''\n",
    "\n",
    "# gets random test input (with correct size)\n",
    "input_var = engine.get_input_from_code(configs)\n",
    "#print(input_var)\n",
    "\n",
    "# Config partitions and prune_ratio\n",
    "configs['num_partition'] = '4'#'./config/resnet18-v2.yaml'\n",
    "configs = engine.partition_generator(configs, model)\n",
    "            \n",
    "# Compute output size of each layer\n",
    "configs['partition'] = engine.featuremap_summary(model, configs['partition'], input_var)\n",
    "        \n",
    "# Setup communication costs\n",
    "configs['comm_costs'] = engine.set_communication_cost(model, configs['partition'],)\n",
    "\n",
    "\n",
    "# split model general parameters\n",
    "\n",
    "# make copies of model per machine\n",
    "num_machines = max(configs['partition']['bn_partition']) # TODO: double check this makes sense\n",
    "model_machines = [model]*num_machines\n",
    "\n",
    "layer_names_fx =  get_graph_node_names(model)[1]\n",
    "total_layers_fx = len(layer_names_fx)\n",
    "\n",
    "split_module_names = list(configs['partition'].keys())\n",
    "\n",
    "print(layer_names_fx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing module 0: x\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-model input layer.. skipping\n",
      "Finished execution of layer 0\n",
      "Max diff:\n",
      "tensor([2.9995])\n",
      "\n",
      "tensor([[2.9992, 2.9958, 2.9995]])\n",
      "tensor([0, 1, 2])\n",
      "\n",
      "failing Cout = tensor([0, 1, 2])  (len = 3)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 1: conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t-WARNING: No input assigned to this machine (but it was sent input?). Skipping...\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([0, 1, 2])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 1\n",
      "Max diff:\n",
      "tensor([0.])\n",
      "\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([], dtype=torch.int64)\n",
      "\n",
      "failing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 48)\n",
      "\n",
      "Executing module 2: bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-No input sent to this machine. Skipping module\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 2\n",
      "Max diff:\n",
      "tensor([0.1934])\n",
      "\n",
      "tensor([[0.0862, 0.0171, 0.1934, 0.0010, 0.0012, 0.0679, 0.0063, 0.0023, 0.0018,\n",
      "         0.0011, 0.0864, 0.0674, 0.0034, 0.0016, 0.0006, 0.0905, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])  (len = 16)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 48)\n",
      "\n",
      "Executing module 3: relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-No input sent to this machine. Skipping module\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 3\n",
      "Max diff:\n",
      "tensor([0.0905])\n",
      "\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0006, 0.0905, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "tensor([14, 15])\n",
      "\n",
      "failing Cout = tensor([14, 15])  (len = 2)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 35, 36, 37,\n",
      "        38, 39, 42, 43, 44, 46, 47, 48, 49, 50, 51, 55, 56, 57, 59, 60, 61, 62,\n",
      "        63])  (len = 37)\n",
      "\n",
      "Executing module 4: layer1.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-No input sent to this machine. Skipping module\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 1,  3, 10, 12]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([40]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([0, 3, 6]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([53]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 55, 56, 57, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 3,  4, 15]) to machine 0\n",
      "\t\t sending C_out tensor([32, 34, 45, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 4\n",
      "Max diff:\n",
      "tensor([0.1334])\n",
      "\n",
      "tensor([[5.1387e-02, 6.1511e-02, 1.6674e-03, 3.8732e-03, 1.9895e-03, 2.1582e-03,\n",
      "         2.5826e-02, 2.2010e-03, 3.5977e-03, 2.4379e-03, 9.3132e-10, 1.6890e-03,\n",
      "         3.4768e-02, 4.0801e-03, 4.0768e-05, 8.8623e-04, 2.3842e-06, 4.7684e-06,\n",
      "         2.3842e-06, 5.7220e-06, 2.8610e-06, 2.8610e-06, 1.1921e-06, 2.3842e-06,\n",
      "         3.8147e-06, 2.8610e-06, 1.9073e-06, 2.8610e-06, 3.3379e-06, 2.8610e-06,\n",
      "         2.8610e-06, 1.0729e-06, 9.5367e-07, 2.3842e-07, 5.9605e-07, 2.3842e-07,\n",
      "         2.3842e-06, 7.1526e-07, 1.7881e-07, 2.9802e-07, 1.3338e-01, 2.3842e-07,\n",
      "         2.3842e-07, 5.9605e-07, 1.4901e-07, 9.5367e-07, 4.1723e-07, 1.1921e-07,\n",
      "         5.9605e-07, 2.9802e-07, 1.7881e-07, 1.1921e-06, 7.1526e-07, 1.9073e-06,\n",
      "         9.5367e-07, 9.5367e-07, 7.4506e-08, 1.4305e-06, 5.9605e-08, 8.3447e-07,\n",
      "         3.5763e-07, 4.7684e-07, 9.5367e-07, 3.9066e-02]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 5: layer1.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  3,  4,  6, 10, 12, 15])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 5\n",
      "Max diff:\n",
      "tensor([0.0443])\n",
      "\n",
      "tensor([[2.5406e-02, 3.1733e-02, 5.2688e-04, 1.0076e-03, 5.2280e-04, 6.6758e-04,\n",
      "         7.6223e-03, 6.4577e-04, 1.1480e-03, 8.5702e-04, 1.8626e-09, 5.6834e-04,\n",
      "         1.1884e-02, 1.3309e-03, 1.1569e-05, 2.6741e-04, 8.3447e-07, 2.3842e-06,\n",
      "         1.4305e-06, 3.3379e-06, 1.0729e-06, 8.3447e-07, 3.5763e-07, 1.1921e-06,\n",
      "         1.5497e-06, 1.3113e-06, 5.9605e-07, 1.1921e-06, 1.3113e-06, 9.5367e-07,\n",
      "         1.1921e-06, 2.6077e-07, 3.5763e-07, 5.9605e-08, 1.7881e-07, 5.9605e-08,\n",
      "         7.1526e-07, 2.0862e-07, 5.2154e-08, 8.9407e-08, 4.4336e-02, 5.9605e-08,\n",
      "         7.4506e-08, 1.7881e-07, 5.2154e-08, 4.7684e-07, 1.1921e-07, 3.7253e-08,\n",
      "         2.9802e-07, 7.4506e-08, 5.2154e-08, 4.7684e-07, 1.9372e-07, 3.0175e-07,\n",
      "         4.7684e-07, 3.5763e-07, 2.2352e-08, 2.9802e-07, 1.4901e-08, 2.3842e-07,\n",
      "         1.1921e-07, 1.7881e-07, 3.5763e-07, 1.6032e-02]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 6: layer1.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 6\n",
      "Max diff:\n",
      "tensor([0.0443])\n",
      "\n",
      "tensor([[2.5406e-02, 3.1733e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.0904e-03, 1.3309e-03, 0.0000e+00, 0.0000e+00, 7.1526e-07, 2.3842e-06,\n",
      "         8.9407e-07, 4.7684e-07, 7.3016e-07, 7.7486e-07, 0.0000e+00, 1.1921e-06,\n",
      "         5.9605e-07, 2.9616e-07, 3.2783e-07, 1.1921e-06, 9.5367e-07, 2.9802e-07,\n",
      "         5.3272e-07, 1.7881e-07, 2.3842e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.1526e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4336e-02, 1.8626e-09,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7684e-07, 0.0000e+00, 0.0000e+00,\n",
      "         6.7055e-08, 0.0000e+00, 7.4506e-09, 8.9407e-08, 9.3132e-08, 2.2352e-07,\n",
      "         1.1921e-07, 4.4703e-08, 0.0000e+00, 5.0291e-08, 0.0000e+00, 5.9605e-08,\n",
      "         0.0000e+00, 1.6391e-07, 8.3819e-08, 1.2430e-02]])\n",
      "tensor([ 0,  1, 12, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30,\n",
      "        31, 32, 36, 40, 41, 45, 48, 50, 51, 52, 53, 54, 55, 57, 59, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1, 12, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30,\n",
      "        31, 32, 36, 40, 41, 45, 48, 50, 51, 52, 53, 54, 55, 57, 59, 61, 62, 63])  (len = 36)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 7: layer1.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1, 12, 13])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([27]) to machine 1\n",
      "\t\t sending C_out tensor([57, 59]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([6]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([42, 45]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 36, 40, 41, 45])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([4, 9]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([54, 56]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 50, 51, 52, 53, 54, 55, 57, 59, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([4, 5]) to machine 0\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 7\n",
      "Max diff:\n",
      "tensor([0.1941])\n",
      "\n",
      "tensor([[4.6003e-04, 1.2465e-03, 6.8600e-04, 1.5134e-03, 1.9411e-01, 5.8432e-03,\n",
      "         1.0394e-03, 5.4540e-03, 3.0684e-03, 1.9667e-03, 5.6677e-03, 5.9148e-03,\n",
      "         8.5007e-04, 1.4681e-03, 3.5335e-03, 1.4311e-03, 2.8610e-06, 7.7486e-07,\n",
      "         1.4305e-06, 4.1723e-06, 3.8147e-06, 2.8610e-06, 2.0266e-06, 1.9073e-06,\n",
      "         2.8610e-06, 2.3842e-06, 3.3379e-06, 2.7540e-03, 9.5367e-07, 2.3842e-06,\n",
      "         2.3842e-06, 2.1458e-06, 2.7151e-03, 4.7684e-07, 4.3176e-02, 4.8054e-02,\n",
      "         2.2983e-02, 3.1573e-02, 4.1893e-02, 3.4669e-03, 1.5007e-02, 1.6216e-02,\n",
      "         3.1558e-02, 2.0953e-02, 4.1205e-03, 5.0539e-02, 1.3839e-02, 5.8842e-03,\n",
      "         7.1377e-03, 3.2327e-03, 6.1868e-03, 2.0729e-03, 1.0407e-02, 9.1136e-03,\n",
      "         8.2392e-02, 2.2673e-03, 2.4698e-03, 6.5402e-02, 9.6028e-03, 9.4356e-03,\n",
      "         8.3376e-03, 6.5435e-03, 6.0412e-03, 5.0186e-03]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 8: layer1.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 8\n",
      "Max diff:\n",
      "tensor([0.1031])\n",
      "\n",
      "tensor([[1.4319e-04, 4.2999e-04, 1.5103e-04, 5.0535e-04, 1.0310e-01, 2.2496e-03,\n",
      "         3.3673e-04, 1.7088e-03, 1.2507e-03, 8.2541e-04, 1.3182e-03, 1.3646e-03,\n",
      "         2.9426e-04, 4.7747e-04, 1.4207e-03, 4.9504e-04, 2.8610e-06, 2.4214e-08,\n",
      "         6.8545e-07, 2.8610e-06, 2.8610e-06, 2.3842e-06, 1.1921e-06, 1.1921e-06,\n",
      "         1.9073e-06, 1.6689e-06, 2.3842e-06, 1.3397e-03, 2.5332e-07, 1.6689e-06,\n",
      "         1.1921e-06, 8.9407e-07, 5.4610e-04, 1.1921e-07, 4.5552e-03, 1.2542e-02,\n",
      "         4.8718e-03, 1.1799e-02, 1.1840e-02, 5.0664e-07, 2.0693e-03, 1.5143e-03,\n",
      "         6.7887e-03, 5.2667e-03, 4.3277e-04, 1.9128e-02, 2.7430e-03, 1.7043e-03,\n",
      "         3.5112e-03, 1.7710e-03, 2.3014e-03, 7.2464e-04, 8.0622e-03, 4.8268e-03,\n",
      "         1.6217e-02, 1.1658e-03, 6.8408e-04, 2.3102e-02, 2.2279e-03, 2.6975e-03,\n",
      "         4.1897e-03, 2.4161e-03, 1.8161e-03, 2.4319e-03]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 9: layer1.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-assuming this machine did not rx any input at the beginning of this block. No residual found\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 9\n",
      "Max diff:\n",
      "tensor([0.1031])\n",
      "\n",
      "tensor([[1.4319e-04, 4.2999e-04, 1.5103e-04, 5.0535e-04, 1.0310e-01, 2.2496e-03,\n",
      "         3.3673e-04, 1.7088e-03, 1.2507e-03, 8.2541e-04, 1.3182e-03, 1.3646e-03,\n",
      "         2.9426e-04, 4.7747e-04, 1.7219e-03, 9.1007e-02, 2.8610e-06, 5.9605e-08,\n",
      "         6.8545e-07, 2.8610e-06, 2.8610e-06, 2.3842e-06, 1.1921e-06, 1.1921e-06,\n",
      "         1.9073e-06, 1.6689e-06, 2.3842e-06, 1.3397e-03, 2.5332e-07, 1.9073e-06,\n",
      "         1.1921e-06, 8.9407e-07, 5.4610e-04, 1.1921e-07, 4.5552e-03, 1.2542e-02,\n",
      "         4.8718e-03, 1.1799e-02, 1.1840e-02, 5.0664e-07, 2.0693e-03, 1.5143e-03,\n",
      "         6.7887e-03, 5.2667e-03, 4.3279e-04, 1.9128e-02, 2.7430e-03, 1.7043e-03,\n",
      "         3.5112e-03, 1.7710e-03, 2.3014e-03, 7.2464e-04, 8.0622e-03, 4.8268e-03,\n",
      "         1.6217e-02, 1.1658e-03, 6.8408e-04, 2.3102e-02, 2.2279e-03, 2.6975e-03,\n",
      "         4.1897e-03, 2.4161e-03, 1.8161e-03, 2.4319e-03]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 10: layer1.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 10\n",
      "Max diff:\n",
      "tensor([0.1031])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0310e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.7088e-03, 0.0000e+00, 8.2541e-04, 0.0000e+00, 1.3646e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9073e-06, 5.9605e-08,\n",
      "         5.9605e-07, 2.7418e-06, 1.9073e-06, 2.0862e-06, 7.7486e-07, 9.5367e-07,\n",
      "         1.9073e-06, 9.5367e-07, 2.1458e-06, 1.3396e-03, 2.5332e-07, 1.1921e-06,\n",
      "         5.3644e-07, 8.9407e-07, 5.4610e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.8717e-03, 0.0000e+00, 5.8788e-04, 5.0664e-07, 1.9178e-03, 0.0000e+00,\n",
      "         6.7887e-03, 5.2666e-03, 4.3279e-04, 1.9128e-02, 2.7429e-03, 1.7042e-03,\n",
      "         3.5112e-03, 9.7354e-04, 4.5955e-05, 0.0000e+00, 8.0622e-03, 0.0000e+00,\n",
      "         1.6217e-02, 1.1657e-03, 6.8408e-04, 2.3102e-02, 0.0000e+00, 1.9696e-03,\n",
      "         3.5324e-03, 1.1176e-08, 1.8161e-03, 4.6558e-04]])\n",
      "tensor([ 4,  7,  9, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54,\n",
      "        55, 56, 57, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 4,  7,  9, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54,\n",
      "        55, 56, 57, 59, 60, 61, 62, 63])  (len = 44)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 11: layer1.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 4,  7,  9, 11])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 2,  6,  8, 12, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([38, 47]) to machine 2\n",
      "\t\t sending C_out tensor([49]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 1, 10, 13]) to machine 0\n",
      "\t\t sending C_out tensor([30]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([59, 62]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 1,  5, 12, 13]) to machine 0\n",
      "\t\t sending C_out tensor([36, 44]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 11\n",
      "Max diff:\n",
      "tensor([0.0609])\n",
      "\n",
      "tensor([[0.0014, 0.0421, 0.0215, 0.0071, 0.0439, 0.0119, 0.0206, 0.0094, 0.0146,\n",
      "         0.0159, 0.0081, 0.0206, 0.0368, 0.0166, 0.0105, 0.0372, 0.0010, 0.0008,\n",
      "         0.0018, 0.0012, 0.0004, 0.0004, 0.0006, 0.0005, 0.0007, 0.0008, 0.0008,\n",
      "         0.0008, 0.0007, 0.0012, 0.0006, 0.0022, 0.0100, 0.0113, 0.0497, 0.0030,\n",
      "         0.0028, 0.0078, 0.0129, 0.0054, 0.0609, 0.0018, 0.0066, 0.0310, 0.0016,\n",
      "         0.0472, 0.0048, 0.0431, 0.0035, 0.0085, 0.0197, 0.0329, 0.0048, 0.0355,\n",
      "         0.0173, 0.0063, 0.0505, 0.0216, 0.0068, 0.0213, 0.0129, 0.0530, 0.0266,\n",
      "         0.0093]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 12: layer1.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 12\n",
      "Max diff:\n",
      "tensor([0.0225])\n",
      "\n",
      "tensor([[0.0003, 0.0080, 0.0062, 0.0016, 0.0090, 0.0022, 0.0059, 0.0021, 0.0034,\n",
      "         0.0034, 0.0019, 0.0047, 0.0073, 0.0038, 0.0033, 0.0078, 0.0003, 0.0002,\n",
      "         0.0007, 0.0002, 0.0001, 0.0001, 0.0001, 0.0002, 0.0004, 0.0002, 0.0002,\n",
      "         0.0002, 0.0003, 0.0003, 0.0001, 0.0006, 0.0023, 0.0017, 0.0138, 0.0007,\n",
      "         0.0006, 0.0019, 0.0032, 0.0009, 0.0225, 0.0003, 0.0010, 0.0082, 0.0005,\n",
      "         0.0089, 0.0013, 0.0193, 0.0008, 0.0020, 0.0067, 0.0069, 0.0010, 0.0083,\n",
      "         0.0029, 0.0014, 0.0182, 0.0043, 0.0013, 0.0069, 0.0028, 0.0175, 0.0087,\n",
      "         0.0026]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 13: layer1.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 13\n",
      "Max diff:\n",
      "tensor([0.0225])\n",
      "\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0002, 0.0001,\n",
      "         0.0006, 0.0002, 0.0001, 0.0001, 0.0001, 0.0002, 0.0004, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0003, 0.0001, 0.0006, 0.0000, 0.0000, 0.0138, 0.0000,\n",
      "         0.0006, 0.0003, 0.0032, 0.0000, 0.0225, 0.0000, 0.0000, 0.0082, 0.0000,\n",
      "         0.0089, 0.0000, 0.0167, 0.0000, 0.0000, 0.0067, 0.0012, 0.0000, 0.0060,\n",
      "         0.0015, 0.0000, 0.0181, 0.0019, 0.0000, 0.0069, 0.0000, 0.0114, 0.0054,\n",
      "         0.0000]])\n",
      "tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 36,\n",
      "        37, 38, 40, 43, 45, 47, 50, 51, 53, 54, 56, 57, 59, 61, 62])\n",
      "\n",
      "failing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 36,\n",
      "        37, 38, 40, 43, 45, 47, 50, 51, 53, 54, 56, 57, 59, 61, 62])  (len = 33)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 14: layer1.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([], dtype=torch.int64)\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 4,  7,  9, 14]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([45]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([34, 36, 37, 38, 40, 43, 45, 47])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([17]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([52, 54]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([50, 51, 53, 54, 56, 57, 59, 61, 62])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([2]) to machine 0\n",
      "\t\t sending C_out tensor([40, 43, 44, 46]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 14\n",
      "Max diff:\n",
      "tensor([0.0653])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.4372e-05, 0.0000e+00, 1.0072e-04, 0.0000e+00,\n",
      "         0.0000e+00, 8.5384e-06, 0.0000e+00, 4.5057e-06, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4943e-05, 0.0000e+00, 7.1228e-04, 4.0544e-04,\n",
      "         5.5072e-04, 4.9245e-04, 4.7630e-04, 5.2118e-04, 7.5793e-04, 4.3201e-04,\n",
      "         4.2057e-04, 3.7664e-04, 4.3410e-04, 7.9739e-04, 3.3677e-04, 5.4181e-04,\n",
      "         3.9420e-04, 4.5347e-04, 3.1292e-02, 8.4987e-03, 1.3201e-02, 2.4532e-02,\n",
      "         2.4603e-02, 1.9697e-02, 3.0839e-02, 2.4729e-02, 3.8013e-02, 1.5699e-02,\n",
      "         3.6726e-02, 6.5297e-02, 7.5014e-03, 1.9933e-02, 1.5229e-02, 6.8651e-03,\n",
      "         1.6230e-02, 2.1651e-02, 1.2714e-02, 1.3240e-02, 1.7470e-02, 6.4240e-03,\n",
      "         6.2682e-03, 1.2846e-02, 1.7771e-02, 2.3966e-02, 1.6283e-02, 1.1325e-02,\n",
      "         9.4113e-03, 9.2741e-03, 2.2347e-02, 5.6384e-03]])\n",
      "tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 53)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 15: layer1.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 2,  4,  7,  9, 14])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 15\n",
      "Max diff:\n",
      "tensor([0.0303])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 3.4422e-06, 0.0000e+00, 1.2044e-05, 0.0000e+00,\n",
      "         0.0000e+00, 2.6822e-06, 0.0000e+00, 1.8328e-06, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.4561e-05, 0.0000e+00, 7.9656e-04, 1.6892e-04,\n",
      "         1.9372e-04, 3.3402e-04, 2.4104e-04, 3.2371e-04, 6.6280e-04, 2.2863e-04,\n",
      "         2.8014e-04, 3.1785e-04, 2.5874e-04, 7.8333e-04, 1.3366e-04, 3.0935e-04,\n",
      "         2.4074e-04, 2.7356e-04, 1.9705e-02, 4.1682e-03, 1.7676e-03, 5.2902e-03,\n",
      "         1.0808e-02, 4.5326e-03, 1.2215e-02, 1.1098e-02, 3.0299e-02, 1.4613e-04,\n",
      "         1.9361e-02, 2.8234e-02, 1.6890e-03, 1.8491e-03, 2.2546e-03, 1.1622e-03,\n",
      "         8.9034e-03, 3.4962e-03, 3.1999e-03, 3.4577e-03, 5.4249e-03, 1.3652e-03,\n",
      "         5.2005e-06, 5.8951e-03, 3.9364e-03, 2.5982e-03, 1.5300e-03, 2.6793e-04,\n",
      "         8.5410e-04, 1.3323e-03, 4.9435e-03, 1.0238e-04]])\n",
      "tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 53)\n",
      "passing Cout = tensor([ 0,  1,  3,  5,  6,  8, 10, 11, 12, 13, 15])  (len = 11)\n",
      "\n",
      "Executing module 16: layer1.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 16\n",
      "Max diff:\n",
      "tensor([0.1031])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 3.4422e-06, 0.0000e+00, 1.0310e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.7107e-03, 0.0000e+00, 8.2523e-04, 0.0000e+00, 1.3646e-03,\n",
      "         0.0000e+00, 0.0000e+00, 1.4561e-05, 0.0000e+00, 7.9656e-04, 1.6892e-04,\n",
      "         1.9348e-04, 3.3402e-04, 2.4116e-04, 3.2371e-04, 6.6280e-04, 2.2863e-04,\n",
      "         2.8014e-04, 3.1805e-04, 2.5874e-04, 1.3140e-03, 1.3366e-04, 3.0935e-04,\n",
      "         2.4045e-04, 2.7356e-04, 1.9705e-02, 4.1682e-03, 1.7676e-03, 5.2902e-03,\n",
      "         1.0808e-02, 4.5326e-03, 1.2215e-02, 1.1098e-02, 3.0299e-02, 1.4613e-04,\n",
      "         2.6149e-02, 2.8234e-02, 2.1119e-03, 2.0977e-02, 3.2803e-03, 2.0943e-03,\n",
      "         8.9034e-03, 3.4962e-03, 3.1999e-03, 3.4577e-03, 8.3203e-03, 1.3652e-03,\n",
      "         1.6217e-02, 5.8951e-03, 3.9364e-03, 2.5568e-02, 1.5300e-03, 2.0414e-03,\n",
      "         3.1473e-03, 1.3323e-03, 4.9435e-03, 4.6452e-04]])\n",
      "tensor([ 2,  4,  7,  9, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
      "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 2,  4,  7,  9, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
      "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 54)\n",
      "passing Cout = tensor([ 0,  1,  3,  5,  6,  8, 10, 12, 13, 15])  (len = 10)\n",
      "\n",
      "Executing module 17: layer1.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 17\n",
      "Max diff:\n",
      "tensor([0.1031])\n",
      "\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1031, 0.0000, 0.0000, 0.0017, 0.0000,\n",
      "         0.0008, 0.0000, 0.0014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0006, 0.0002,\n",
      "         0.0002, 0.0003, 0.0002, 0.0003, 0.0004, 0.0002, 0.0002, 0.0003, 0.0002,\n",
      "         0.0013, 0.0001, 0.0003, 0.0002, 0.0002, 0.0010, 0.0029, 0.0001, 0.0000,\n",
      "         0.0108, 0.0000, 0.0008, 0.0000, 0.0000, 0.0000, 0.0143, 0.0103, 0.0021,\n",
      "         0.0210, 0.0029, 0.0018, 0.0048, 0.0005, 0.0000, 0.0000, 0.0083, 0.0000,\n",
      "         0.0162, 0.0059, 0.0039, 0.0256, 0.0000, 0.0020, 0.0031, 0.0000, 0.0049,\n",
      "         0.0000]])\n",
      "tensor([ 4,  7,  9, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 33, 34, 36, 38, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55,\n",
      "        56, 57, 59, 60, 62])\n",
      "\n",
      "failing Cout = tensor([ 4,  7,  9, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 33, 34, 36, 38, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55,\n",
      "        56, 57, 59, 60, 62])  (len = 41)\n",
      "passing Cout = tensor([1])  (len = 1)\n",
      "\n",
      "Executing module 18: layer2.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 1,  4,  7,  9, 11])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([32, 33, 34, 36, 38, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([48, 49, 52, 54, 55, 56, 57, 59, 60, 62])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 18\n",
      "Max diff:\n",
      "tensor([0.0856])\n",
      "\n",
      "tensor([[0.0259, 0.0461, 0.0043, 0.0635, 0.0082, 0.0630, 0.0119, 0.0017, 0.0486,\n",
      "         0.0183, 0.0058, 0.0140, 0.0029, 0.0043, 0.0007, 0.0005, 0.0635, 0.0041,\n",
      "         0.0028, 0.0142, 0.0095, 0.0083, 0.0364, 0.0010, 0.0856, 0.0008, 0.0027,\n",
      "         0.0125, 0.0057, 0.0029, 0.0016, 0.0045, 0.0008, 0.0002, 0.0010, 0.0010,\n",
      "         0.0014, 0.0008, 0.0016, 0.0008, 0.0006, 0.0007, 0.0006, 0.0006, 0.0006,\n",
      "         0.0007, 0.0008, 0.0005, 0.0008, 0.0007, 0.0009, 0.0007, 0.0004, 0.0008,\n",
      "         0.0004, 0.0005, 0.0009, 0.0013, 0.0008, 0.0007, 0.0006, 0.0005, 0.0005,\n",
      "         0.0004, 0.0036, 0.0040, 0.0011, 0.0163, 0.0033, 0.0036, 0.0024, 0.0011,\n",
      "         0.0122, 0.0003, 0.0135, 0.0027, 0.0044, 0.0010, 0.0149, 0.0096, 0.0148,\n",
      "         0.0019, 0.0086, 0.0037, 0.0054, 0.0173, 0.0023, 0.0006, 0.0008, 0.0131,\n",
      "         0.0004, 0.0108, 0.0034, 0.0053, 0.0034, 0.0141, 0.0223, 0.0297, 0.0346,\n",
      "         0.0355, 0.0179, 0.0246, 0.0027, 0.0113, 0.0117, 0.0277, 0.0106, 0.0198,\n",
      "         0.0292, 0.0406, 0.0298, 0.0209, 0.0011, 0.0299, 0.0207, 0.0047, 0.0125,\n",
      "         0.0258, 0.0268, 0.0190, 0.0235, 0.0285, 0.0146, 0.0340, 0.0358, 0.0241,\n",
      "         0.0274, 0.0173]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 19: layer2.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 19\n",
      "Max diff:\n",
      "tensor([0.0346])\n",
      "\n",
      "tensor([[6.9064e-03, 1.4713e-02, 1.2559e-03, 1.6826e-02, 2.2700e-03, 1.7522e-02,\n",
      "         3.2156e-03, 4.3760e-04, 1.2935e-02, 5.1535e-03, 1.3255e-03, 4.0419e-03,\n",
      "         6.8032e-04, 1.0446e-03, 2.0879e-04, 1.3523e-04, 1.4216e-02, 1.1342e-03,\n",
      "         6.7534e-04, 4.0952e-03, 2.0786e-03, 2.1118e-03, 1.0907e-02, 2.3600e-04,\n",
      "         2.6058e-02, 2.1465e-04, 7.5935e-04, 3.6537e-03, 1.4040e-03, 6.9987e-04,\n",
      "         4.1743e-04, 8.3907e-04, 3.5357e-04, 4.0382e-05, 3.7861e-04, 4.4823e-04,\n",
      "         6.4063e-04, 2.5308e-04, 6.0844e-04, 3.0017e-04, 1.4993e-04, 3.8800e-04,\n",
      "         1.9097e-04, 1.8495e-04, 2.9373e-04, 3.0804e-04, 3.4904e-04, 2.8086e-04,\n",
      "         4.4537e-04, 4.6492e-04, 4.4417e-04, 2.6928e-04, 1.6940e-04, 2.4486e-04,\n",
      "         2.3878e-04, 2.7111e-04, 4.3285e-04, 5.2309e-04, 4.9800e-04, 2.8521e-04,\n",
      "         1.8364e-04, 1.2791e-04, 1.5947e-04, 1.9470e-04, 8.8659e-04, 8.9794e-04,\n",
      "         2.8841e-04, 7.2857e-03, 8.9289e-04, 7.8434e-04, 4.7484e-04, 1.8729e-04,\n",
      "         3.4480e-03, 8.5473e-05, 4.8956e-03, 5.2482e-04, 1.1557e-03, 2.1837e-04,\n",
      "         6.0044e-03, 3.2500e-03, 6.3379e-03, 4.9514e-04, 5.4710e-03, 8.1795e-04,\n",
      "         1.1844e-03, 6.5525e-03, 6.4318e-04, 1.4206e-04, 2.0631e-04, 8.3944e-03,\n",
      "         1.0667e-04, 3.2486e-03, 6.6786e-04, 1.4087e-03, 9.3450e-04, 7.8014e-03,\n",
      "         6.5995e-03, 1.1832e-02, 1.4079e-02, 1.1059e-02, 3.2952e-03, 1.0410e-02,\n",
      "         7.9142e-04, 3.7671e-03, 4.0097e-03, 9.3489e-03, 2.8617e-03, 5.5015e-03,\n",
      "         9.4712e-03, 3.4592e-02, 1.2073e-02, 7.9163e-03, 2.7349e-04, 9.0908e-03,\n",
      "         2.8170e-03, 1.2331e-03, 4.2977e-03, 6.8015e-03, 1.6403e-02, 7.4156e-03,\n",
      "         9.0431e-03, 1.8034e-02, 4.5954e-03, 2.1960e-02, 9.3849e-03, 6.9779e-03,\n",
      "         8.3529e-03, 5.7020e-03]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 20: layer2.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 20\n",
      "Max diff:\n",
      "tensor([0.0277])\n",
      "\n",
      "tensor([[6.9064e-03, 1.4713e-02, 1.0926e-04, 1.6826e-02, 0.0000e+00, 1.7522e-02,\n",
      "         0.0000e+00, 0.0000e+00, 1.2935e-02, 0.0000e+00, 0.0000e+00, 1.0163e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4216e-02, 1.1315e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0907e-02, 0.0000e+00,\n",
      "         2.6058e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5357e-04, 0.0000e+00, 3.7861e-04, 4.4823e-04,\n",
      "         5.6000e-04, 2.3608e-04, 1.5241e-04, 1.1884e-04, 1.4993e-04, 2.9862e-04,\n",
      "         1.0401e-04, 1.2358e-04, 2.2436e-04, 3.0804e-04, 2.2587e-04, 7.9729e-05,\n",
      "         3.0679e-04, 1.0535e-04, 4.2415e-04, 2.6928e-04, 1.6940e-04, 2.4486e-04,\n",
      "         2.2739e-04, 2.7111e-04, 4.0704e-04, 5.2309e-04, 4.9800e-04, 2.8521e-04,\n",
      "         1.2898e-04, 9.1337e-05, 1.4090e-04, 1.4174e-04, 4.7341e-05, 0.0000e+00,\n",
      "         0.0000e+00, 1.7834e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.2155e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.0211e-03, 3.2369e-03, 3.1931e-03, 0.0000e+00, 3.7370e-03, 0.0000e+00,\n",
      "         8.1819e-04, 5.1505e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3944e-03,\n",
      "         0.0000e+00, 2.7932e-03, 0.0000e+00, 1.1116e-03, 0.0000e+00, 0.0000e+00,\n",
      "         4.4871e-03, 7.9230e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8870e-03,\n",
      "         0.0000e+00, 0.0000e+00, 4.0097e-03, 7.4366e-03, 4.8999e-04, 4.7139e-03,\n",
      "         5.9918e-03, 2.7734e-02, 8.6738e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7806e-03, 0.0000e+00, 4.2977e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.0431e-03, 1.8034e-02, 4.5954e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.9713e-03, 3.8623e-03]])\n",
      "tensor([  0,   1,   2,   3,   5,   8,  11,  16,  17,  22,  24,  32,  34,  35,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,\n",
      "         50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,\n",
      "         64,  67,  74,  78,  79,  80,  82,  84,  85,  89,  91,  93,  96,  97,\n",
      "        101, 104, 105, 106, 107, 108, 109, 110, 114, 116, 120, 121, 122, 126,\n",
      "        127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   5,   8,  11,  16,  17,  22,  24,  32,  34,  35,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,\n",
      "         50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,\n",
      "         64,  67,  74,  78,  79,  80,  82,  84,  85,  89,  91,  93,  96,  97,\n",
      "        101, 104, 105, 106, 107, 108, 109, 110, 114, 116, 120, 121, 122, 126,\n",
      "        127])  (len = 71)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 21: layer2.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  3,  5,  8, 11, 16, 17, 22, 24])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([10]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 67, 74, 78, 79, 80, 82, 84, 85, 89, 91, 93])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97, 101, 104, 105, 106, 107, 108, 109, 110, 114, 116, 120, 121,\n",
      "        122, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 21\n",
      "Max diff:\n",
      "tensor([0.0820])\n",
      "\n",
      "tensor([[0.0023, 0.0025, 0.0060, 0.0138, 0.0012, 0.0148, 0.0012, 0.0020, 0.0038,\n",
      "         0.0011, 0.0035, 0.0086, 0.0020, 0.0008, 0.0049, 0.0014, 0.0066, 0.0059,\n",
      "         0.0057, 0.0018, 0.0492, 0.0008, 0.0008, 0.0150, 0.0042, 0.0022, 0.0095,\n",
      "         0.0047, 0.0010, 0.0063, 0.0051, 0.0247, 0.0010, 0.0007, 0.0011, 0.0008,\n",
      "         0.0007, 0.0010, 0.0005, 0.0008, 0.0009, 0.0014, 0.0008, 0.0007, 0.0007,\n",
      "         0.0005, 0.0007, 0.0008, 0.0008, 0.0010, 0.0006, 0.0006, 0.0009, 0.0006,\n",
      "         0.0009, 0.0006, 0.0011, 0.0005, 0.0007, 0.0007, 0.0009, 0.0006, 0.0005,\n",
      "         0.0006, 0.0006, 0.0003, 0.0041, 0.0077, 0.0009, 0.0089, 0.0019, 0.0018,\n",
      "         0.0006, 0.0004, 0.0008, 0.0011, 0.0006, 0.0066, 0.0005, 0.0028, 0.0004,\n",
      "         0.0019, 0.0009, 0.0023, 0.0033, 0.0078, 0.0017, 0.0010, 0.0078, 0.0065,\n",
      "         0.0064, 0.0044, 0.0004, 0.0003, 0.0034, 0.0008, 0.0058, 0.0378, 0.0444,\n",
      "         0.0395, 0.0217, 0.0057, 0.0028, 0.0445, 0.0820, 0.0034, 0.0034, 0.0179,\n",
      "         0.0355, 0.0290, 0.0253, 0.0036, 0.0064, 0.0362, 0.0550, 0.0225, 0.0489,\n",
      "         0.0219, 0.0046, 0.0772, 0.0471, 0.0053, 0.0598, 0.0419, 0.0285, 0.0037,\n",
      "         0.0435, 0.0212]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 22: layer2.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 22\n",
      "Max diff:\n",
      "tensor([0.0573])\n",
      "\n",
      "tensor([[8.8429e-04, 8.0872e-04, 2.3972e-03, 4.1846e-03, 3.7110e-04, 5.4611e-03,\n",
      "         3.3945e-04, 6.8437e-04, 1.3620e-03, 4.4600e-04, 1.3672e-03, 2.6344e-03,\n",
      "         8.0716e-04, 2.9379e-04, 1.6031e-03, 5.5189e-04, 2.4932e-03, 1.4593e-03,\n",
      "         1.7806e-03, 6.9156e-04, 1.6913e-02, 3.2164e-04, 1.8743e-04, 5.0384e-03,\n",
      "         1.3496e-03, 7.3192e-04, 3.6005e-03, 1.5542e-03, 4.0395e-04, 2.0827e-03,\n",
      "         1.8905e-03, 7.7305e-03, 5.7786e-04, 4.9329e-04, 6.5756e-04, 4.3935e-04,\n",
      "         3.6430e-04, 5.6243e-04, 4.3988e-04, 4.8566e-04, 4.2057e-04, 9.0528e-04,\n",
      "         5.3912e-04, 5.2649e-04, 4.4119e-04, 3.2318e-04, 3.4481e-04, 4.3702e-04,\n",
      "         4.9806e-04, 5.3728e-04, 2.8175e-04, 4.1151e-04, 6.4230e-04, 3.4541e-04,\n",
      "         7.0131e-04, 4.3416e-04, 7.3826e-04, 4.2462e-04, 5.3406e-04, 4.3058e-04,\n",
      "         6.3992e-04, 4.3046e-04, 3.0136e-04, 3.9864e-04, 2.0801e-04, 1.0365e-04,\n",
      "         1.4926e-03, 3.9008e-03, 3.1066e-04, 5.6473e-03, 7.1384e-04, 6.2679e-04,\n",
      "         1.9091e-04, 1.1055e-04, 3.1704e-04, 3.8158e-04, 2.0535e-04, 3.0359e-03,\n",
      "         1.4317e-04, 8.0194e-04, 1.3825e-04, 6.8229e-04, 2.8831e-04, 8.4730e-04,\n",
      "         1.1165e-03, 4.6265e-03, 6.0929e-04, 2.2104e-04, 4.5282e-03, 5.3350e-03,\n",
      "         2.4008e-03, 1.6157e-03, 1.5597e-04, 9.5215e-05, 1.1496e-03, 2.6940e-04,\n",
      "         1.8858e-03, 1.3466e-02, 1.9272e-02, 1.1089e-02, 8.4517e-03, 2.2643e-03,\n",
      "         7.9205e-04, 3.0205e-02, 2.6700e-02, 1.0230e-03, 1.0613e-03, 4.0167e-03,\n",
      "         1.3526e-02, 8.7849e-03, 9.9707e-03, 1.1707e-03, 1.4626e-03, 1.1542e-02,\n",
      "         4.0440e-02, 3.9029e-03, 1.3799e-02, 5.4849e-03, 1.5240e-03, 5.7302e-02,\n",
      "         1.5981e-02, 1.6991e-03, 1.0358e-02, 2.6606e-02, 1.6148e-02, 1.0122e-03,\n",
      "         1.0022e-02, 5.6836e-03]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 23: layer2.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([38, 50]) to machine 1\n",
      "\t\t sending C_out tensor([72, 82]) to machine 2\n",
      "\t\t sending C_out tensor([121]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  2,  3,  5,  7, 10, 19, 24]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([65, 66, 68, 70, 73, 78, 80, 92, 93]) to machine 2\n",
      "\t\t sending C_out tensor([104, 115, 121]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 8, 14, 23, 27, 28]) to machine 0\n",
      "\t\t sending C_out tensor([48]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([101, 102, 121, 122, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 3,  4,  5, 10, 21, 23, 30]) to machine 0\n",
      "\t\t sending C_out tensor([33, 60]) to machine 1\n",
      "\t\t sending C_out tensor([65, 68, 83, 86]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 23\n",
      "Max diff:\n",
      "tensor([0.0613])\n",
      "\n",
      "tensor([[3.6573e-03, 3.4572e-03, 4.0726e-03, 2.9902e-03, 5.2228e-04, 3.1310e-03,\n",
      "         3.3899e-05, 3.8824e-04, 7.0432e-04, 4.3696e-04, 2.6670e-03, 1.1731e-03,\n",
      "         5.2112e-03, 2.5286e-03, 2.5298e-03, 4.8102e-03, 3.3158e-03, 3.0247e-03,\n",
      "         3.5763e-03, 1.4524e-03, 1.5717e-02, 1.5924e-03, 4.1939e-05, 2.8392e-03,\n",
      "         5.7510e-04, 2.7465e-03, 2.3220e-03, 3.2867e-03, 1.3906e-03, 2.8710e-03,\n",
      "         4.1879e-03, 3.7892e-03, 2.0111e-04, 2.4216e-03, 2.2125e-04, 2.3770e-04,\n",
      "         8.9288e-05, 5.1752e-04, 6.1348e-02, 1.9078e-04, 1.9985e-04, 3.7768e-04,\n",
      "         2.2589e-04, 1.3661e-04, 1.5328e-04, 1.8239e-04, 2.6965e-04, 2.2650e-04,\n",
      "         1.4494e-04, 5.0348e-04, 7.7289e-04, 1.1319e-04, 2.5767e-04, 1.5175e-04,\n",
      "         1.8227e-04, 1.2970e-04, 1.3217e-04, 1.8549e-04, 3.2175e-04, 3.3537e-04,\n",
      "         1.6332e-04, 2.6298e-04, 4.1936e-04, 2.2602e-04, 4.7829e-04, 2.7358e-04,\n",
      "         2.7409e-03, 5.6978e-03, 5.1434e-04, 3.4873e-03, 4.5815e-04, 7.6777e-04,\n",
      "         2.6290e-04, 7.6818e-04, 7.1566e-04, 8.6020e-04, 5.7523e-04, 8.0352e-03,\n",
      "         1.7771e-04, 1.6442e-03, 6.4557e-04, 8.6868e-04, 6.5219e-04, 1.7886e-03,\n",
      "         2.1781e-03, 1.9173e-03, 6.4287e-04, 6.4640e-04, 2.2227e-03, 4.9286e-03,\n",
      "         4.0594e-03, 2.4036e-03, 9.9372e-04, 1.9421e-04, 1.9484e-03, 1.0126e-03,\n",
      "         1.2370e-03, 2.2495e-03, 5.9146e-03, 3.6450e-03, 5.4663e-03, 8.1481e-04,\n",
      "         1.2776e-03, 6.3925e-03, 3.6774e-03, 1.2726e-03, 6.9815e-04, 5.5897e-03,\n",
      "         3.8424e-03, 3.3234e-03, 2.7881e-03, 2.0207e-03, 1.0227e-03, 7.9951e-03,\n",
      "         4.9981e-03, 4.8989e-03, 5.9084e-03, 3.3264e-03, 2.0503e-03, 3.3687e-03,\n",
      "         6.9746e-03, 6.2506e-04, 5.7952e-03, 5.2085e-03, 5.0160e-03, 1.5214e-03,\n",
      "         1.5783e-02, 4.1364e-03]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 24: layer2.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 24\n",
      "Max diff:\n",
      "tensor([4.5903])\n",
      "\n",
      "tensor([[4.2064e-03, 8.2517e-04, 1.7627e-02, 6.5692e-02, 1.7806e-04, 1.1959e-02,\n",
      "         8.4061e-06, 1.4450e-02, 2.0418e-04, 1.2861e-04, 1.4116e-02, 3.7642e-04,\n",
      "         1.6214e-03, 6.3379e-04, 8.4014e-04, 1.4266e-03, 9.5463e-04, 6.7851e-04,\n",
      "         1.2301e-03, 1.8454e-03, 5.4022e-03, 1.4665e-03, 1.0163e-05, 1.0373e-03,\n",
      "         1.2523e-02, 7.3903e-04, 6.3156e-04, 7.7183e-04, 4.4335e-04, 7.8456e-04,\n",
      "         1.2821e-03, 1.2253e-03, 1.0937e-04, 6.1111e-02, 1.1623e-04, 7.9122e-05,\n",
      "         8.5235e-06, 3.9132e-04, 4.5903e+00, 7.1201e-05, 2.1815e-05, 1.5883e-04,\n",
      "         1.0152e-04, 5.6490e-05, 1.1210e-04, 8.9467e-05, 1.7989e-04, 1.9383e-04,\n",
      "         2.4069e-03, 1.9300e-04, 3.2790e-04, 2.3425e-05, 1.1393e-04, 1.0246e-04,\n",
      "         1.0682e-04, 6.0499e-05, 4.0665e-05, 1.0312e-04, 2.1604e-04, 1.9233e-04,\n",
      "         2.0345e-02, 1.7405e-04, 2.2613e-04, 1.1781e-04, 1.1904e-04, 7.0890e-03,\n",
      "         1.2930e-02, 2.5584e-03, 4.0444e-02, 2.3123e-03, 3.3524e-02, 2.7091e-04,\n",
      "         7.0874e-05, 8.2504e-03, 2.1659e-04, 2.7963e-04, 1.7311e-04, 4.3684e-03,\n",
      "         1.6149e-03, 3.1427e-04, 4.9116e-04, 1.8708e-04, 1.4154e-04, 6.0014e-04,\n",
      "         4.0177e-04, 1.1597e-03, 5.0858e-03, 1.2522e-04, 1.0636e-03, 2.3579e-03,\n",
      "         8.1053e-04, 1.2124e-03, 4.2010e-02, 3.2785e-03, 3.5372e-04, 2.9780e-04,\n",
      "         3.7708e-04, 1.6340e-03, 2.8108e-03, 3.2380e-03, 4.5941e-03, 5.5854e-04,\n",
      "         1.3419e-02, 3.9428e-03, 6.0034e-01, 2.8672e-04, 1.8664e-04, 2.1665e-03,\n",
      "         2.2648e-03, 1.9202e-03, 9.1814e-04, 4.7251e-04, 1.7966e-04, 7.1295e-03,\n",
      "         2.5087e-03, 1.9729e+00, 3.0297e-03, 2.1412e-03, 6.1467e-04, 1.6633e-03,\n",
      "         3.4845e-03, 5.2114e-03, 8.2936e-03, 2.5779e-03, 2.4216e-03, 2.5705e-04,\n",
      "         6.2086e-03, 1.0333e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 25: layer2.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 25\n",
      "Max diff:\n",
      "tensor([4.5903])\n",
      "\n",
      "tensor([[4.1274e-03, 1.5361e-03, 2.0019e-02, 6.9558e-02, 5.2888e-04, 1.7386e-02,\n",
      "         3.3549e-04, 1.3805e-02, 1.1818e-03, 5.5027e-04, 1.5481e-02, 2.2694e-03,\n",
      "         1.6996e-03, 4.4627e-04, 2.4427e-03, 1.9717e-03, 3.4465e-03, 2.1370e-03,\n",
      "         6.6206e-04, 1.1560e-03, 1.1707e-02, 1.3707e-03, 1.7874e-04, 5.3416e-03,\n",
      "         1.3325e-02, 1.4701e-03, 4.2320e-03, 2.3260e-03, 4.7380e-04, 1.3279e-03,\n",
      "         3.1585e-03, 8.9545e-03, 6.1161e-04, 6.1094e-02, 7.0107e-04, 4.8500e-04,\n",
      "         3.6612e-04, 7.6401e-04, 4.5903e+00, 4.9162e-04, 4.3917e-04, 9.1600e-04,\n",
      "         5.6905e-04, 5.5838e-04, 4.5991e-04, 3.3927e-04, 4.2057e-04, 5.5552e-04,\n",
      "         2.3827e-03, 5.6127e-04, 4.0889e-04, 4.0913e-04, 6.8593e-04, 4.3344e-04,\n",
      "         7.0417e-04, 4.4692e-04, 7.3916e-04, 4.5967e-04, 6.4993e-04, 5.3930e-04,\n",
      "         2.0495e-02, 4.6551e-04, 4.2009e-04, 4.4942e-04, 2.5857e-04, 7.0318e-03,\n",
      "         1.3187e-02, 3.8117e-03, 4.0312e-02, 6.0676e-03, 3.3522e-02, 7.2271e-04,\n",
      "         2.0135e-04, 8.2634e-03, 2.9296e-04, 3.7217e-04, 1.9780e-04, 6.6602e-03,\n",
      "         1.7470e-03, 8.2384e-04, 4.7781e-04, 7.2367e-04, 3.0152e-04, 1.1915e-03,\n",
      "         1.1557e-03, 5.0367e-03, 5.1165e-03, 2.5650e-04, 4.7801e-03, 5.8191e-03,\n",
      "         2.3416e-03, 1.9445e-03, 4.2032e-02, 3.2763e-03, 1.1724e-03, 2.1394e-04,\n",
      "         1.7069e-03, 1.2291e-02, 2.1845e-02, 1.3181e-02, 9.6164e-03, 2.3988e-03,\n",
      "         1.3565e-02, 3.2917e-02, 6.1532e-01, 1.2700e-03, 8.9493e-04, 5.7052e-03,\n",
      "         1.3962e-02, 1.0490e-02, 1.0013e-02, 1.5138e-03, 1.5008e-03, 1.3580e-02,\n",
      "         4.0632e-02, 1.9716e+00, 1.1717e-02, 5.9702e-03, 1.9834e-03, 5.8008e-02,\n",
      "         1.7962e-02, 6.3141e-03, 1.6298e-02, 2.6775e-02, 1.6583e-02, 1.2284e-03,\n",
      "         1.4364e-02, 7.2494e-03]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 26: layer2.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 26\n",
      "Max diff:\n",
      "tensor([3.7869])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3805e-02, 1.1818e-03, 0.0000e+00, 6.4400e-04, 0.0000e+00,\n",
      "         1.6996e-03, 2.1164e-04, 0.0000e+00, 1.9717e-03, 0.0000e+00, 0.0000e+00,\n",
      "         6.1535e-04, 0.0000e+00, 0.0000e+00, 1.3707e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.4020e-04, 5.8159e-02, 6.8545e-04, 4.8500e-04,\n",
      "         2.2548e-04, 7.6401e-04, 3.7869e+00, 4.1921e-04, 3.5638e-04, 2.9850e-04,\n",
      "         5.0628e-04, 5.5838e-04, 2.9718e-04, 1.4861e-04, 4.2057e-04, 5.5552e-04,\n",
      "         1.0187e-03, 4.9686e-04, 2.5523e-04, 1.2577e-04, 6.8593e-04, 3.4809e-04,\n",
      "         7.0417e-04, 3.4968e-04, 7.3916e-04, 2.8622e-04, 5.3549e-04, 5.3930e-04,\n",
      "         4.8339e-05, 4.3422e-04, 3.3343e-04, 2.7090e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.8117e-03, 0.0000e+00, 6.0676e-03, 5.7723e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5200e-03,\n",
      "         1.5422e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.0367e-03, 0.0000e+00, 0.0000e+00, 4.7801e-03, 4.2961e-03,\n",
      "         0.0000e+00, 1.9445e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9347e-02, 1.3181e-02, 0.0000e+00, 1.6289e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2298e-03,\n",
      "         1.3962e-02, 1.0490e-02, 1.0013e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.0632e-02, 1.9716e+00, 6.1421e-03, 5.9702e-03, 0.0000e+00, 5.0060e-02,\n",
      "         1.7962e-02, 0.0000e+00, 1.2892e-02, 2.6775e-02, 0.0000e+00, 3.0961e-04,\n",
      "         1.4023e-02, 7.2494e-03]])\n",
      "tensor([  7,   8,  10,  12,  13,  15,  18,  21,  32,  33,  34,  35,  36,  37,\n",
      "         38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  67,  69,\n",
      "         70,  77,  78,  85,  88,  89,  91,  98,  99, 101, 107, 108, 109, 110,\n",
      "        114, 115, 116, 117, 119, 120, 122, 123, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  7,   8,  10,  12,  13,  15,  18,  21,  32,  33,  34,  35,  36,  37,\n",
      "         38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  67,  69,\n",
      "         70,  77,  78,  85,  88,  89,  91,  98,  99, 101, 107, 108, 109, 110,\n",
      "        114, 115, 116, 117, 119, 120, 122, 123, 125, 126, 127])  (len = 67)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 27: layer2.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 7,  8, 10, 12, 13, 15, 18, 21])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([80]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([67, 69, 70, 77, 78, 85, 88, 89, 91])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 2, 14]) to machine 0\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 98,  99, 101, 107, 108, 109, 110, 114, 115, 116, 117, 119, 120, 122,\n",
      "        123, 125, 126, 127])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 27\n",
      "Max diff:\n",
      "tensor([6.1731])\n",
      "\n",
      "tensor([[8.2141e-04, 2.9347e-04, 2.3847e-04, 2.6116e-04, 2.4970e-04, 2.5199e-04,\n",
      "         7.4811e-04, 2.5293e-04, 1.9731e-04, 3.6800e-04, 3.4834e-04, 4.2343e-04,\n",
      "         2.6260e-04, 1.1368e-04, 7.9015e-04, 5.3321e-04, 4.3025e-04, 3.0183e-04,\n",
      "         9.5350e-04, 5.7274e-04, 4.1326e-04, 4.3226e-04, 2.4953e-04, 4.1187e-04,\n",
      "         4.6790e-04, 6.0233e-04, 2.1636e-04, 2.3892e-04, 6.0304e-04, 3.5786e-04,\n",
      "         1.6943e-04, 1.2812e-04, 1.1803e+00, 4.8041e+00, 1.8509e+00, 1.4086e+00,\n",
      "         1.2914e+00, 1.0069e+00, 1.4660e+00, 2.8627e+00, 3.1952e+00, 2.1953e+00,\n",
      "         1.2751e+00, 1.7981e+00, 6.1731e+00, 7.2176e-01, 8.8693e-01, 2.7719e+00,\n",
      "         2.0669e+00, 1.0854e+00, 1.9334e+00, 4.9274e+00, 1.5736e+00, 1.6221e+00,\n",
      "         2.3207e+00, 1.5085e+00, 1.3689e+00, 1.7658e+00, 1.5894e+00, 2.8536e+00,\n",
      "         2.5584e+00, 3.1699e+00, 1.5879e+00, 9.3352e-01, 1.3752e-03, 2.0718e-03,\n",
      "         3.1992e-03, 3.1759e-03, 6.5780e-04, 1.3495e-03, 9.7811e-04, 2.2911e-03,\n",
      "         1.6409e-03, 1.0764e-03, 1.4237e-02, 2.8444e-03, 7.0612e-03, 3.9725e-04,\n",
      "         3.9430e-03, 9.1876e-04, 2.3286e-03, 1.9700e-03, 8.5331e-04, 1.7464e-03,\n",
      "         1.8864e-03, 1.0703e-03, 8.0861e-04, 4.1214e-03, 2.0595e-03, 9.7454e-04,\n",
      "         1.3601e-03, 3.3544e-03, 8.9782e-04, 5.6018e-03, 1.5463e-03, 1.6063e-03,\n",
      "         1.4031e+00, 1.0055e-01, 1.1949e+00, 1.1350e+00, 5.7026e-01, 4.7876e-01,\n",
      "         1.1561e-01, 2.1204e-01, 5.4165e-02, 1.0247e+00, 3.9882e-02, 2.3396e-01,\n",
      "         5.4750e-01, 1.2859e-01, 3.2530e-01, 1.3719e+00, 1.0891e+00, 6.0705e-01,\n",
      "         4.0706e-02, 1.5318e-01, 1.1100e+00, 1.6481e+00, 1.0394e+00, 3.3588e-01,\n",
      "         2.7411e-01, 2.6312e-01, 8.4722e-01, 8.2238e-01, 1.3406e+00, 1.3878e+00,\n",
      "         1.4184e+00, 1.7208e+00]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 28: layer2.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 28\n",
      "Max diff:\n",
      "tensor([1.4461])\n",
      "\n",
      "tensor([[2.4450e-04, 8.6586e-05, 6.1728e-05, 6.5493e-05, 6.8048e-05, 7.1373e-05,\n",
      "         2.0696e-04, 6.9261e-05, 5.0248e-05, 9.2382e-05, 9.5842e-05, 1.1750e-04,\n",
      "         7.0021e-05, 2.7407e-05, 2.4989e-04, 1.2737e-04, 1.0899e-04, 8.0772e-05,\n",
      "         2.4892e-04, 1.5927e-04, 1.5009e-04, 1.1239e-04, 7.0099e-05, 1.1089e-04,\n",
      "         1.1578e-04, 1.6256e-04, 5.5206e-05, 6.8029e-05, 1.6966e-04, 9.4863e-05,\n",
      "         4.8932e-05, 3.6435e-05, 4.6330e-01, 1.1502e+00, 6.6792e-01, 8.5604e-01,\n",
      "         5.0643e-01, 3.8787e-01, 5.8601e-01, 7.4548e-01, 1.4461e+00, 1.1285e+00,\n",
      "         3.8006e-01, 4.5320e-01, 1.0646e+00, 2.8235e-01, 1.9342e-01, 1.2378e+00,\n",
      "         7.0710e-01, 2.7314e-01, 7.0223e-01, 1.0378e+00, 5.0054e-01, 6.4034e-01,\n",
      "         6.4463e-01, 6.7893e-01, 4.5132e-01, 5.7630e-01, 2.3969e-01, 8.3725e-01,\n",
      "         9.0558e-01, 9.5238e-01, 5.6724e-01, 2.9495e-01, 3.5202e-04, 5.2346e-04,\n",
      "         7.2756e-04, 8.0752e-04, 1.7245e-04, 3.5522e-04, 2.3492e-04, 6.2794e-04,\n",
      "         4.2091e-04, 2.8603e-04, 2.2366e-03, 6.8979e-04, 1.5937e-03, 9.8231e-05,\n",
      "         1.0480e-03, 2.5245e-04, 5.9005e-04, 5.2389e-04, 2.1114e-04, 3.9764e-04,\n",
      "         3.4139e-04, 2.6716e-04, 2.0632e-04, 1.0653e-03, 4.0152e-04, 2.5992e-04,\n",
      "         3.4024e-04, 9.4597e-04, 2.4194e-04, 1.5099e-03, 4.2801e-04, 3.6994e-04,\n",
      "         2.3684e-01, 2.0629e-02, 1.8522e-01, 1.0181e-01, 1.3807e-01, 8.3482e-02,\n",
      "         2.4533e-02, 5.2710e-02, 1.2874e-02, 2.4084e-01, 9.4921e-03, 5.2164e-02,\n",
      "         1.4334e-01, 3.0553e-02, 7.3433e-02, 2.2139e-01, 8.0880e-02, 1.0744e-01,\n",
      "         9.5408e-03, 3.4122e-02, 1.6069e-01, 2.9534e-01, 1.2119e-01, 8.5981e-02,\n",
      "         5.4350e-02, 1.5735e-02, 3.1441e-01, 1.3046e-01, 1.7393e-01, 3.0434e-01,\n",
      "         1.8617e-01, 6.1596e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 29: layer2.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 29\n",
      "Max diff:\n",
      "tensor([1.0646])\n",
      "\n",
      "tensor([[2.4450e-04, 8.6586e-05, 2.5972e-07, 0.0000e+00, 6.8048e-05, 7.1373e-05,\n",
      "         0.0000e+00, 6.9261e-05, 5.0248e-05, 9.2382e-05, 9.5842e-05, 1.1750e-04,\n",
      "         7.0021e-05, 2.7407e-05, 2.4989e-04, 1.2737e-04, 1.0899e-04, 8.0772e-05,\n",
      "         2.4892e-04, 1.5927e-04, 1.5009e-04, 1.1239e-04, 7.0099e-05, 0.0000e+00,\n",
      "         0.0000e+00, 1.6256e-04, 1.8113e-05, 6.8029e-05, 1.6966e-04, 2.0856e-05,\n",
      "         4.8932e-05, 3.6435e-05, 4.0598e-01, 2.2149e-01, 5.3279e-01, 5.9484e-01,\n",
      "         3.4181e-01, 3.2294e-01, 4.4272e-01, 3.1052e-01, 7.3430e-01, 9.0971e-01,\n",
      "         1.6481e-01, 4.3016e-01, 1.0646e+00, 2.5300e-01, 0.0000e+00, 8.9820e-01,\n",
      "         2.2906e-02, 0.0000e+00, 4.6809e-01, 9.6652e-01, 2.1830e-01, 0.0000e+00,\n",
      "         5.1942e-01, 6.4681e-01, 3.2003e-01, 1.8099e-01, 0.0000e+00, 0.0000e+00,\n",
      "         7.4981e-01, 6.2147e-01, 3.9128e-01, 1.8574e-01, 1.8449e-04, 1.5886e-04,\n",
      "         0.0000e+00, 4.2978e-04, 3.2703e-05, 7.1201e-05, 1.1150e-05, 0.0000e+00,\n",
      "         9.8801e-05, 1.0801e-04, 6.4223e-04, 2.8861e-04, 1.0006e-03, 8.2483e-05,\n",
      "         4.9828e-04, 1.1481e-04, 0.0000e+00, 2.5052e-04, 1.3000e-04, 0.0000e+00,\n",
      "         1.2991e-04, 8.5655e-05, 1.2248e-04, 3.5546e-04, 0.0000e+00, 2.5295e-05,\n",
      "         0.0000e+00, 2.8648e-04, 0.0000e+00, 5.0002e-04, 0.0000e+00, 1.0835e-04,\n",
      "         5.7041e-02, 0.0000e+00, 4.0207e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4084e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0880e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0543e-02, 1.5454e-01, 0.0000e+00, 9.9894e-02, 1.4025e-01,\n",
      "         3.6518e-02, 2.1658e-01]])\n",
      "tensor([  0,   1,   2,   4,   5,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  25,  26,  27,  28,  29,  30,  31,\n",
      "         32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "         47,  48,  50,  51,  52,  54,  55,  56,  57,  60,  61,  62,  63,  64,\n",
      "         65,  67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,  79,  81,\n",
      "         82,  84,  85,  86,  87,  89,  91,  93,  95,  96,  98, 105, 112, 121,\n",
      "        122, 124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   4,   5,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  25,  26,  27,  28,  29,  30,  31,\n",
      "         32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "         47,  50,  51,  52,  54,  55,  56,  57,  60,  61,  62,  63,  64,  65,\n",
      "         67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,  79,  81,  82,\n",
      "         84,  85,  86,  87,  89,  91,  93,  95,  96,  98, 105, 112, 121, 122,\n",
      "        124, 125, 126, 127])  (len = 88)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 30: layer2.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "        20, 21, 22, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51,\n",
      "        52, 54, 55, 56, 57, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([4]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85,\n",
      "        86, 87, 89, 91, 93, 95])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  98, 105, 112, 121, 122, 124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 30\n",
      "Max diff:\n",
      "tensor([2.3218])\n",
      "\n",
      "tensor([[2.6342e-05, 9.0020e-06, 2.4155e-05, 2.5876e-05, 6.2611e-03, 3.3813e-05,\n",
      "         9.8627e-06, 2.7031e-05, 4.5545e-05, 3.5161e-05, 2.8487e-05, 3.1337e-05,\n",
      "         1.6391e-05, 1.5658e-05, 3.0924e-05, 4.1343e-05, 2.7569e-05, 1.7082e-05,\n",
      "         3.5264e-05, 2.6318e-05, 1.1994e-04, 3.0782e-05, 1.6916e-05, 2.2616e-05,\n",
      "         2.3186e-05, 1.9976e-05, 2.2050e-05, 1.5751e-05, 3.7229e-05, 2.3402e-05,\n",
      "         3.2537e-05, 2.6718e-05, 1.6566e+00, 7.0235e-01, 1.4430e+00, 1.2384e+00,\n",
      "         1.4104e+00, 1.4630e+00, 9.9792e-01, 1.4823e+00, 1.2641e+00, 6.8185e-01,\n",
      "         1.2172e+00, 1.1864e+00, 7.7907e-01, 1.2009e+00, 8.5626e-01, 1.6069e+00,\n",
      "         1.4688e+00, 1.5233e+00, 1.1695e+00, 9.7448e-01, 7.5193e-01, 1.7772e+00,\n",
      "         1.0319e+00, 8.6014e-01, 9.5902e-01, 1.0488e+00, 6.1352e-01, 1.0628e+00,\n",
      "         1.3352e+00, 2.3218e+00, 1.3138e+00, 7.9097e-01, 7.6172e-05, 2.5139e-05,\n",
      "         9.6675e-05, 1.4893e-04, 8.9679e-05, 1.7402e-04, 1.1886e-04, 1.7158e-05,\n",
      "         4.8921e-05, 4.1879e-05, 1.2094e-04, 1.1563e-04, 2.5508e-05, 1.1414e-04,\n",
      "         1.8681e-05, 4.8893e-05, 2.6833e-05, 1.4011e-05, 3.0203e-05, 4.4904e-05,\n",
      "         4.6786e-05, 8.9867e-05, 3.4901e-05, 3.7667e-05, 1.4405e-04, 1.3227e-04,\n",
      "         9.7765e-05, 1.5075e-04, 4.2941e-05, 4.5142e-05, 4.9464e-05, 2.5951e-05,\n",
      "         2.4736e-01, 1.9176e-01, 1.3117e-01, 5.6449e-02, 1.7508e-01, 3.7914e-01,\n",
      "         1.0279e-01, 1.5775e-01, 1.1812e-01, 2.4374e-01, 1.5784e-02, 1.6037e-01,\n",
      "         1.4819e-01, 1.9554e-01, 1.8044e-01, 2.4888e-02, 2.3840e-01, 2.6492e-01,\n",
      "         1.9067e-01, 1.0900e-01, 1.2382e-01, 2.1000e-01, 4.3514e-02, 1.4878e-01,\n",
      "         1.4737e-01, 3.5465e-01, 1.8742e-01, 1.7089e-01, 1.5425e-01, 1.5489e-01,\n",
      "         2.2833e-01, 2.6691e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 31: layer2.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 31\n",
      "Max diff:\n",
      "tensor([1.5284])\n",
      "\n",
      "tensor([[8.7265e-06, 2.4177e-06, 6.3702e-06, 6.5435e-06, 1.7557e-03, 1.1384e-05,\n",
      "         2.8312e-06, 8.4359e-06, 1.7270e-05, 1.4201e-05, 1.0243e-05, 1.1858e-05,\n",
      "         5.6690e-06, 4.5300e-06, 8.7349e-06, 1.6827e-05, 8.4974e-06, 4.9323e-06,\n",
      "         1.2413e-05, 8.6874e-06, 3.4675e-05, 1.1613e-05, 4.6217e-06, 7.5772e-06,\n",
      "         6.2170e-06, 5.3504e-06, 6.6236e-06, 5.1558e-06, 1.4331e-05, 8.3111e-06,\n",
      "         1.0625e-05, 9.8571e-06, 3.4738e-01, 2.6365e-01, 6.7420e-01, 2.2559e-01,\n",
      "         1.5284e+00, 8.0411e-01, 8.5648e-01, 8.1504e-01, 4.3221e-01, 2.5041e-01,\n",
      "         5.4767e-01, 6.7437e-01, 4.2213e-01, 4.1809e-01, 5.5833e-01, 9.6590e-01,\n",
      "         7.0476e-01, 7.1612e-01, 3.0600e-01, 2.8860e-01, 3.1796e-01, 9.4280e-01,\n",
      "         6.1247e-01, 2.7235e-01, 1.7976e-01, 4.0192e-01, 5.5075e-01, 7.2624e-01,\n",
      "         6.3463e-01, 1.1761e+00, 6.2473e-01, 3.3335e-01, 2.1140e-05, 7.2047e-06,\n",
      "         4.0188e-05, 2.5995e-05, 1.8578e-05, 6.1358e-05, 3.4465e-05, 4.0811e-06,\n",
      "         1.0585e-05, 1.1416e-05, 5.5602e-05, 2.3019e-05, 7.8708e-06, 3.5517e-05,\n",
      "         4.9956e-06, 1.7367e-05, 7.8995e-06, 4.5374e-06, 9.7677e-06, 9.5125e-06,\n",
      "         1.8179e-05, 1.5710e-05, 9.3170e-06, 9.6466e-06, 3.5131e-05, 2.4963e-05,\n",
      "         4.3496e-05, 3.0776e-05, 1.2294e-05, 1.0291e-05, 1.9059e-05, 7.2499e-06,\n",
      "         9.0136e-02, 1.0281e-01, 3.8361e-02, 8.2400e-05, 1.7704e-02, 2.1191e-01,\n",
      "         2.2893e-02, 8.2327e-02, 1.7796e-02, 1.2739e-01, 4.4710e-03, 8.7710e-02,\n",
      "         2.0881e-02, 3.4757e-02, 7.8233e-02, 8.0143e-03, 7.4978e-02, 1.1381e-01,\n",
      "         6.9421e-02, 3.3083e-03, 2.4242e-02, 5.9894e-02, 1.2123e-02, 1.1751e-01,\n",
      "         1.1481e-02, 1.9522e-01, 2.9524e-02, 5.7989e-02, 6.2681e-02, 4.5811e-02,\n",
      "         4.3661e-02, 5.7058e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 32: layer2.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 32\n",
      "Max diff:\n",
      "tensor([4.2236])\n",
      "\n",
      "tensor([[8.7265e-06, 2.4177e-06, 6.3702e-06, 6.5435e-06, 1.7557e-03, 1.1384e-05,\n",
      "         2.8312e-06, 1.3803e-02, 1.1952e-03, 1.4201e-05, 6.4535e-04, 1.1858e-05,\n",
      "         1.7040e-03, 2.1233e-04, 8.7349e-06, 1.9693e-03, 8.4974e-06, 4.9323e-06,\n",
      "         6.1541e-04, 8.6874e-06, 3.4675e-05, 1.3717e-03, 4.6217e-06, 7.5772e-06,\n",
      "         6.2170e-06, 5.3504e-06, 6.6236e-06, 5.1558e-06, 1.4331e-05, 8.3111e-06,\n",
      "         1.0625e-05, 9.8571e-06, 3.4775e-01, 2.6365e-01, 6.7466e-01, 2.2577e-01,\n",
      "         1.5284e+00, 8.0437e-01, 4.2236e+00, 8.1504e-01, 4.3221e-01, 2.5041e-01,\n",
      "         5.4767e-01, 6.7433e-01, 4.2217e-01, 4.1809e-01, 5.5824e-01, 9.6616e-01,\n",
      "         7.0500e-01, 7.1636e-01, 3.0615e-01, 2.8860e-01, 3.1828e-01, 9.4290e-01,\n",
      "         6.1242e-01, 2.7235e-01, 1.7976e-01, 4.0192e-01, 5.5075e-01, 7.2621e-01,\n",
      "         6.3463e-01, 1.1761e+00, 6.2473e-01, 3.3335e-01, 2.1140e-05, 7.2047e-06,\n",
      "         4.0188e-05, 3.8269e-03, 1.8578e-05, 6.0512e-03, 5.7724e-03, 4.0811e-06,\n",
      "         1.0585e-05, 1.1416e-05, 5.5602e-05, 2.3019e-05, 7.8708e-06, 1.5207e-03,\n",
      "         1.5390e-03, 1.7367e-05, 7.8995e-06, 4.5374e-06, 9.7677e-06, 9.5125e-06,\n",
      "         1.8179e-05, 5.0322e-03, 9.3170e-06, 9.6466e-06, 4.7702e-03, 4.2990e-03,\n",
      "         4.3496e-05, 1.9251e-03, 1.2294e-05, 1.0291e-05, 1.9059e-05, 7.2499e-06,\n",
      "         9.0136e-02, 1.0281e-01, 3.8361e-02, 1.3176e-02, 1.7704e-02, 2.1191e-01,\n",
      "         2.2893e-02, 8.2327e-02, 1.7796e-02, 1.2739e-01, 4.4710e-03, 8.7710e-02,\n",
      "         2.3687e-02, 3.7123e-02, 7.5107e-02, 8.0143e-03, 7.4978e-02, 1.1381e-01,\n",
      "         5.6795e-02, 1.9747e+00, 2.4242e-02, 5.8229e-02, 1.2123e-02, 1.6723e-01,\n",
      "         1.8470e-02, 1.9522e-01, 2.9524e-02, 4.9358e-02, 6.2681e-02, 4.5811e-02,\n",
      "         4.8352e-02, 5.5771e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 33: layer2.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 33\n",
      "Max diff:\n",
      "tensor([4.2100])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 7.3684e-08, 0.0000e+00, 3.0277e-04, 0.0000e+00,\n",
      "         0.0000e+00, 1.3803e-02, 1.1952e-03, 0.0000e+00, 6.4535e-04, 1.1858e-05,\n",
      "         1.7040e-03, 0.0000e+00, 0.0000e+00, 1.9693e-03, 0.0000e+00, 0.0000e+00,\n",
      "         6.1541e-04, 0.0000e+00, 0.0000e+00, 1.3717e-03, 0.0000e+00, 7.5772e-06,\n",
      "         4.3958e-07, 0.0000e+00, 6.6236e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.2613e-01, 1.9660e-01, 6.7466e-01, 2.2577e-01,\n",
      "         1.4285e+00, 8.0437e-01, 4.2100e+00, 5.8922e-01, 2.2253e-01, 2.5041e-01,\n",
      "         4.9547e-01, 6.7433e-01, 3.9604e-01, 1.0516e-01, 5.5824e-01, 9.6616e-01,\n",
      "         7.0500e-01, 6.6613e-01, 2.9792e-01, 2.8860e-01, 3.1828e-01, 8.2794e-01,\n",
      "         6.1242e-01, 1.3215e-01, 1.0884e-01, 1.9032e-01, 4.2533e-01, 7.2621e-01,\n",
      "         4.6073e-01, 9.4110e-01, 4.9202e-01, 2.4001e-01, 2.1140e-05, 0.0000e+00,\n",
      "         0.0000e+00, 3.8269e-03, 0.0000e+00, 6.0512e-03, 2.6144e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5602e-05, 2.3019e-05, 7.8708e-06, 1.5207e-03,\n",
      "         5.0127e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.0322e-03, 0.0000e+00, 0.0000e+00, 4.7702e-03, 4.2990e-03,\n",
      "         0.0000e+00, 1.9251e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2499e-06,\n",
      "         8.5761e-02, 3.3750e-02, 2.9753e-02, 1.3176e-02, 0.0000e+00, 2.1191e-01,\n",
      "         0.0000e+00, 4.7903e-02, 0.0000e+00, 1.2739e-01, 0.0000e+00, 7.8237e-02,\n",
      "         2.3687e-02, 3.7123e-02, 7.5107e-02, 0.0000e+00, 7.4978e-02, 4.8190e-02,\n",
      "         5.6795e-02, 1.9747e+00, 1.0553e-02, 5.8229e-02, 0.0000e+00, 1.6723e-01,\n",
      "         1.8470e-02, 1.9522e-01, 2.8298e-02, 4.9358e-02, 5.7755e-02, 1.3476e-03,\n",
      "         4.8352e-02, 4.2069e-02]])\n",
      "tensor([  2,   4,   7,   8,  10,  11,  12,  15,  18,  21,  23,  24,  26,  32,\n",
      "         33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
      "         47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  67,  69,  70,  74,  75,  76,  77,  78,  85,  88,\n",
      "         89,  91,  95,  96,  97,  98,  99, 101, 103, 105, 107, 108, 109, 110,\n",
      "        112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127])\n",
      "\n",
      "failing Cout = tensor([  2,   4,   7,   8,  10,  11,  12,  15,  18,  21,  23,  24,  26,  32,\n",
      "         33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
      "         47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  67,  69,  70,  74,  75,  76,  77,  78,  85,  88,\n",
      "         89,  91,  95,  96,  97,  98,  99, 101, 103, 105, 107, 108, 109, 110,\n",
      "        112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127])  (len = 85)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 34: layer3.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 2,  4,  7,  8, 10, 11, 12, 15, 18, 21, 23, 24, 26])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([64, 67, 69, 70, 74, 75, 76, 77, 85, 88, 89, 91, 95])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([ 96,  97,  98,  99, 101, 103, 105, 107, 108, 109, 110, 112, 113, 114,\n",
      "        115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 34\n",
      "Max diff:\n",
      "tensor([5.6248])\n",
      "\n",
      "tensor([[6.7957e-04, 5.0757e-04, 2.1374e-04, 1.9884e-04, 1.7678e-04, 7.7845e-04,\n",
      "         3.1387e-04, 2.0389e-04, 2.7210e-04, 4.6537e-04, 2.2818e-04, 1.7306e-04,\n",
      "         4.5118e-04, 5.8367e-04, 4.0345e-04, 1.9357e-04, 3.3428e-04, 4.9364e-04,\n",
      "         2.6715e-04, 2.3294e-04, 3.9025e-04, 2.7093e-04, 2.0898e-04, 4.7500e-04,\n",
      "         2.0371e-04, 2.2123e-04, 4.4819e-04, 3.0362e-04, 2.1216e-04, 1.5931e-04,\n",
      "         4.7379e-04, 4.6623e-04, 1.7261e-04, 3.0883e-04, 2.8348e-04, 3.2195e-04,\n",
      "         2.2738e-04, 2.8634e-04, 2.9427e-04, 2.2518e-04, 4.8639e-04, 4.0925e-04,\n",
      "         3.7604e-04, 2.2366e-04, 4.0597e-04, 5.5221e-04, 1.3970e-04, 1.8616e-04,\n",
      "         1.5142e-04, 2.2323e-04, 6.5987e-04, 2.0451e-04, 3.9814e-04, 2.5922e-04,\n",
      "         1.8484e-04, 3.1698e-04, 1.8146e-04, 4.7389e-04, 3.4636e-04, 3.0208e-04,\n",
      "         2.9740e-04, 1.7978e-04, 1.7498e-04, 5.0336e-04, 3.8875e+00, 5.0773e-01,\n",
      "         1.1238e+00, 2.9825e+00, 2.0814e+00, 2.9066e+00, 4.7037e+00, 3.8140e+00,\n",
      "         4.1735e+00, 4.5857e+00, 5.6248e+00, 1.9299e+00, 4.5074e+00, 2.1731e+00,\n",
      "         1.9725e+00, 1.4964e+00, 1.2193e+00, 2.8125e+00, 1.7506e+00, 1.9716e+00,\n",
      "         3.0375e+00, 1.6335e+00, 1.3080e+00, 1.3461e+00, 2.9096e+00, 4.2959e+00,\n",
      "         2.1970e+00, 1.7353e+00, 3.6917e-01, 1.6665e+00, 1.5165e+00, 1.7494e+00,\n",
      "         2.6976e+00, 1.4170e+00, 1.7424e+00, 1.5002e+00, 1.9204e+00, 2.4534e+00,\n",
      "         1.6438e+00, 2.3966e+00, 2.5052e+00, 2.1054e+00, 4.1862e+00, 3.0149e+00,\n",
      "         2.5482e+00, 1.2590e+00, 2.9306e+00, 3.1980e+00, 3.3390e+00, 3.9865e+00,\n",
      "         2.8933e+00, 2.2337e+00, 1.3783e+00, 4.1828e+00, 2.5770e+00, 3.2258e+00,\n",
      "         2.7714e+00, 2.9651e+00, 1.8722e+00, 3.7124e+00, 2.7003e+00, 1.9750e+00,\n",
      "         2.6712e+00, 1.8247e+00, 2.2611e-04, 9.8109e-03, 2.6228e-04, 8.7760e-04,\n",
      "         2.4009e-04, 8.7795e-04, 3.7470e-03, 7.2088e-03, 1.1066e-03, 2.7011e-03,\n",
      "         7.9300e-04, 1.4176e-03, 3.5197e-03, 8.6269e-03, 1.5974e-03, 9.0272e-03,\n",
      "         8.7019e-03, 5.0200e-03, 5.3524e-04, 6.4790e-04, 3.3408e-03, 2.8360e-03,\n",
      "         8.9731e-03, 1.3139e-02, 4.6940e-04, 3.2713e-03, 6.6118e-04, 6.9079e-04,\n",
      "         4.5718e-04, 7.0004e-04, 6.0707e-04, 1.4119e-03, 4.7524e-04, 1.0979e-03,\n",
      "         6.0591e-04, 9.6093e-04, 1.3371e-02, 6.1337e-04, 4.8878e-03, 4.3222e-04,\n",
      "         9.4268e-03, 6.6317e-04, 4.5877e-03, 2.9823e-03, 3.6352e-04, 5.2916e-04,\n",
      "         3.6432e-04, 1.2832e-02, 3.0270e-03, 5.9633e-04, 4.0152e-04, 2.2352e-03,\n",
      "         5.1868e-04, 8.4927e-03, 1.3041e-03, 5.5133e-04, 1.0663e-03, 4.4211e-03,\n",
      "         5.2655e-03, 1.1639e-02, 1.1512e-02, 5.1408e-04, 1.5864e-03, 1.1807e-03,\n",
      "         2.1479e+00, 1.8683e+00, 9.1666e-01, 1.8759e-01, 9.1619e-02, 1.7465e+00,\n",
      "         2.7189e-01, 4.5538e-01, 1.8748e+00, 3.4017e+00, 2.0569e+00, 2.2420e+00,\n",
      "         1.3862e+00, 2.8863e-02, 9.8016e-02, 1.6765e+00, 1.5950e+00, 5.0362e-01,\n",
      "         2.4652e+00, 2.9179e-01, 1.7997e+00, 9.2351e-01, 2.0031e+00, 4.1028e-01,\n",
      "         3.6427e-01, 1.3819e+00, 8.6141e-02, 6.7666e-01, 1.1213e+00, 1.4137e+00,\n",
      "         2.1312e+00, 1.2712e+00, 7.5730e-02, 1.1928e-01, 6.9018e-01, 1.5826e+00,\n",
      "         9.7520e-01, 7.6359e-02, 1.0051e-01, 1.1873e+00, 7.2606e-01, 1.5505e+00,\n",
      "         2.5065e+00, 1.1315e+00, 8.9820e-01, 3.1826e-01, 1.7100e+00, 1.7196e+00,\n",
      "         1.1304e-01, 1.4888e+00, 2.3543e-01, 1.6096e+00, 2.4549e+00, 1.7919e-01,\n",
      "         3.0694e-01, 8.9897e-02, 2.7275e+00, 9.1764e-01, 2.9464e-01, 1.9044e+00,\n",
      "         1.0213e+00, 1.4090e+00, 2.4030e+00, 1.2053e+00]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 35: layer3.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 35\n",
      "Max diff:\n",
      "tensor([1.5571])\n",
      "\n",
      "tensor([[1.8865e-04, 1.2851e-04, 5.8855e-05, 5.4397e-05, 4.1859e-05, 2.1141e-04,\n",
      "         8.7913e-05, 5.2389e-05, 7.1320e-05, 1.1993e-04, 5.0964e-05, 4.2710e-05,\n",
      "         1.1118e-04, 1.5596e-04, 1.0204e-04, 4.8003e-05, 8.1111e-05, 1.3472e-04,\n",
      "         6.8990e-05, 5.8329e-05, 1.0587e-04, 7.5778e-05, 5.4547e-05, 1.1574e-04,\n",
      "         5.4592e-05, 5.2833e-05, 1.2701e-04, 7.7998e-05, 5.5172e-05, 3.9355e-05,\n",
      "         1.2118e-04, 1.1481e-04, 4.4405e-05, 8.2658e-05, 7.8477e-05, 8.3787e-05,\n",
      "         5.5349e-05, 7.1243e-05, 7.3303e-05, 6.0834e-05, 1.3793e-04, 1.1481e-04,\n",
      "         1.0610e-04, 6.0396e-05, 1.0869e-04, 1.3095e-04, 3.6906e-05, 4.9047e-05,\n",
      "         3.9806e-05, 5.1308e-05, 1.6252e-04, 5.4898e-05, 9.8171e-05, 6.7059e-05,\n",
      "         4.6287e-05, 7.9566e-05, 4.5054e-05, 1.2032e-04, 9.0450e-05, 7.3643e-05,\n",
      "         7.8917e-05, 4.6734e-05, 4.3430e-05, 1.2305e-04, 1.1836e+00, 1.3136e-01,\n",
      "         3.9429e-01, 1.0036e+00, 4.6549e-01, 1.1070e+00, 9.4107e-01, 9.5902e-01,\n",
      "         1.2892e+00, 1.0416e+00, 1.5571e+00, 5.3361e-01, 1.0830e+00, 7.2637e-01,\n",
      "         6.0879e-01, 5.4690e-01, 3.5714e-01, 8.3085e-01, 3.6490e-01, 6.2767e-01,\n",
      "         9.4208e-01, 4.4058e-01, 3.5867e-01, 4.0518e-01, 8.0554e-01, 1.5488e+00,\n",
      "         7.0184e-01, 5.1081e-01, 9.8489e-02, 5.2721e-01, 5.4825e-01, 4.9727e-01,\n",
      "         8.3569e-01, 4.7473e-01, 4.3089e-01, 5.8622e-01, 6.1328e-01, 7.7549e-01,\n",
      "         4.2988e-01, 9.4330e-01, 6.8013e-01, 7.8427e-01, 1.5353e+00, 1.0638e+00,\n",
      "         7.0723e-01, 3.5304e-01, 7.0221e-01, 1.1896e+00, 7.7346e-01, 1.2988e+00,\n",
      "         9.4340e-01, 7.6679e-01, 3.4348e-01, 8.8282e-01, 6.6318e-01, 4.5808e-01,\n",
      "         8.3027e-01, 8.9144e-01, 5.6079e-01, 8.4088e-01, 8.3474e-01, 6.5069e-01,\n",
      "         7.1495e-01, 5.0362e-01, 5.6296e-05, 2.1786e-03, 7.1453e-05, 2.1527e-04,\n",
      "         6.2790e-05, 2.2116e-04, 6.6668e-04, 3.3549e-03, 2.9309e-04, 5.7249e-04,\n",
      "         2.0119e-04, 3.6949e-04, 6.9465e-04, 2.4267e-03, 3.5060e-04, 1.2297e-03,\n",
      "         1.3247e-03, 1.1111e-03, 1.4075e-04, 1.6869e-04, 6.0374e-04, 6.0512e-04,\n",
      "         2.5578e-03, 2.7816e-03, 1.2545e-04, 4.2162e-04, 1.6298e-04, 1.7874e-04,\n",
      "         1.2292e-04, 1.7915e-04, 1.5305e-04, 3.9117e-04, 1.2780e-04, 2.7820e-04,\n",
      "         1.5374e-04, 2.3834e-04, 2.1873e-03, 1.4907e-04, 1.2688e-03, 1.0134e-04,\n",
      "         4.8790e-03, 1.6471e-04, 1.2050e-03, 7.8461e-04, 9.8336e-05, 1.3578e-04,\n",
      "         9.3328e-05, 2.4852e-03, 5.2608e-04, 1.5139e-04, 9.5354e-05, 5.0092e-04,\n",
      "         1.3040e-04, 1.4061e-03, 3.0278e-04, 1.4359e-04, 2.8370e-04, 8.0517e-04,\n",
      "         9.7799e-04, 4.6054e-03, 1.6201e-03, 1.2621e-04, 4.2628e-04, 2.3863e-04,\n",
      "         1.9870e-01, 4.6612e-01, 2.0050e-01, 4.6163e-02, 2.6296e-02, 3.7378e-01,\n",
      "         6.0980e-02, 5.3928e-02, 3.9579e-01, 5.2567e-01, 2.9087e-01, 4.4388e-01,\n",
      "         4.2660e-01, 6.8573e-03, 2.3874e-02, 1.7388e-01, 3.1087e-01, 1.1541e-01,\n",
      "         6.5971e-01, 7.7959e-02, 1.6596e-01, 1.3244e-01, 4.0820e-01, 9.0812e-02,\n",
      "         4.5939e-02, 1.7505e-01, 2.0479e-02, 2.2693e-01, 2.3325e-01, 1.4161e-01,\n",
      "         4.7155e-01, 1.2162e-01, 2.0388e-02, 2.9091e-02, 1.4873e-01, 2.9972e-01,\n",
      "         1.7365e-01, 2.0344e-02, 2.5689e-02, 2.3630e-01, 1.2038e-01, 3.2351e-01,\n",
      "         3.6847e-01, 2.3579e-01, 1.0821e-01, 5.5792e-02, 4.4502e-01, 1.7921e-01,\n",
      "         2.7231e-02, 5.1082e-01, 5.0343e-02, 2.0853e-01, 4.7285e-01, 4.5242e-02,\n",
      "         6.7042e-02, 2.4200e-02, 5.2366e-01, 1.3214e-01, 6.3680e-02, 1.8349e-01,\n",
      "         3.1579e-01, 2.4619e-01, 3.6940e-01, 3.5898e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 36: layer3.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 36\n",
      "Max diff:\n",
      "tensor([1.5353])\n",
      "\n",
      "tensor([[0.0000e+00, 1.2851e-04, 0.0000e+00, 5.4397e-05, 4.1859e-05, 2.1141e-04,\n",
      "         8.7913e-05, 2.9247e-05, 7.1320e-05, 9.8479e-05, 5.0964e-05, 4.2710e-05,\n",
      "         1.1118e-04, 1.5596e-04, 1.0204e-04, 4.8003e-05, 8.1111e-05, 0.0000e+00,\n",
      "         6.8990e-05, 5.8329e-05, 1.0587e-04, 0.0000e+00, 5.4547e-05, 1.1574e-04,\n",
      "         5.4592e-05, 5.2833e-05, 1.2701e-04, 0.0000e+00, 0.0000e+00, 1.4073e-05,\n",
      "         1.2118e-04, 1.1481e-04, 4.4405e-05, 0.0000e+00, 7.8477e-05, 8.3787e-05,\n",
      "         5.5349e-05, 5.5971e-05, 7.3303e-05, 6.0834e-05, 1.3793e-04, 1.1481e-04,\n",
      "         1.0610e-04, 0.0000e+00, 1.0869e-04, 1.3095e-04, 0.0000e+00, 4.9047e-05,\n",
      "         0.0000e+00, 5.1308e-05, 1.6252e-04, 1.4548e-05, 9.8171e-05, 6.7059e-05,\n",
      "         4.6287e-05, 0.0000e+00, 4.5054e-05, 1.2032e-04, 0.0000e+00, 7.3643e-05,\n",
      "         7.8917e-05, 4.6734e-05, 0.0000e+00, 1.2305e-04, 7.0470e-01, 0.0000e+00,\n",
      "         1.6186e-01, 0.0000e+00, 4.6549e-01, 7.8106e-01, 9.4107e-01, 9.5902e-01,\n",
      "         5.0672e-01, 1.0416e+00, 8.1332e-01, 1.4926e-01, 1.1994e-01, 0.0000e+00,\n",
      "         2.0168e-01, 2.0913e-01, 9.1581e-02, 2.1277e-01, 1.4300e-01, 0.0000e+00,\n",
      "         1.0708e-03, 0.0000e+00, 3.5867e-01, 4.0518e-01, 8.0554e-01, 1.0703e+00,\n",
      "         4.2439e-01, 4.4343e-01, 0.0000e+00, 3.1364e-01, 0.0000e+00, 3.7001e-01,\n",
      "         3.7734e-01, 8.1260e-02, 1.7782e-01, 3.8800e-01, 3.3001e-01, 4.7721e-01,\n",
      "         4.2919e-01, 8.4807e-01, 6.8013e-01, 2.2478e-01, 1.5353e+00, 7.8107e-01,\n",
      "         3.8756e-01, 2.1354e-01, 4.8339e-01, 1.3348e-01, 7.7346e-01, 0.0000e+00,\n",
      "         5.0441e-01, 5.1325e-01, 2.6041e-01, 5.8486e-01, 0.0000e+00, 0.0000e+00,\n",
      "         3.2913e-01, 8.9144e-01, 0.0000e+00, 1.5216e-01, 3.6147e-01, 5.5428e-01,\n",
      "         6.7756e-01, 5.0362e-01, 5.3909e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8395e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0551e-03, 0.0000e+00, 0.0000e+00,\n",
      "         1.3247e-03, 0.0000e+00, 1.1508e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.5578e-03, 0.0000e+00, 0.0000e+00, 8.4401e-05, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1452e-03, 0.0000e+00, 9.8056e-04, 0.0000e+00,\n",
      "         4.8790e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8336e-05, 0.0000e+00,\n",
      "         9.3328e-05, 0.0000e+00, 0.0000e+00, 1.0646e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9593e-05,\n",
      "         0.0000e+00, 0.0000e+00, 1.4195e-03, 0.0000e+00, 0.0000e+00, 1.7397e-04,\n",
      "         0.0000e+00, 2.0019e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6918e-01,\n",
      "         0.0000e+00, 0.0000e+00, 1.1288e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3656e-02, 0.0000e+00, 0.0000e+00, 2.0535e-03, 0.0000e+00, 4.5396e-02,\n",
      "         3.4499e-01, 0.0000e+00, 1.6596e-01, 4.6618e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.5472e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3512e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7224e-01, 1.2038e-01, 0.0000e+00,\n",
      "         0.0000e+00, 3.7892e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0007e-02,\n",
      "         0.0000e+00, 5.1082e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3066e-01, 0.0000e+00, 0.0000e+00,\n",
      "         2.5703e-01, 0.0000e+00, 3.6940e-01, 3.0457e-01]])\n",
      "tensor([  1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  18,  19,  20,  22,  23,  24,  25,  26,  29,  30,  31,  32,  34,\n",
      "         35,  36,  37,  38,  39,  40,  41,  42,  44,  45,  47,  49,  50,  51,\n",
      "         52,  53,  54,  56,  57,  59,  60,  61,  63,  64,  66,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  78,  79,  80,  81,  82,  84,  86,  87,\n",
      "         88,  89,  90,  91,  93,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 120,\n",
      "        121, 123, 124, 125, 126, 127, 128, 135, 141, 144, 146, 150, 153, 164,\n",
      "        166, 168, 172, 174, 177, 185, 188, 191, 193, 197, 200, 204, 207, 209,\n",
      "        210, 212, 213, 222, 227, 231, 232, 235, 239, 241, 249, 252, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  18,  19,  20,  22,  23,  24,  25,  26,  29,  30,  31,  32,  34,\n",
      "         35,  36,  37,  38,  39,  40,  41,  42,  44,  45,  47,  49,  50,  51,\n",
      "         52,  53,  54,  56,  57,  59,  60,  61,  63,  64,  66,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  78,  81,  82,  86,  87,  88,  89,  90,\n",
      "         91,  93,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 114, 115, 116, 120, 121, 123, 124, 125,\n",
      "        126, 127, 128, 135, 141, 144, 146, 150, 153, 164, 166, 168, 172, 174,\n",
      "        177, 185, 188, 191, 193, 197, 200, 204, 207, 209, 210, 212, 213, 227,\n",
      "        231, 232, 235, 239, 241, 249, 252, 254, 255])  (len = 135)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 37: layer3.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20,\n",
      "        22, 23, 24, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
      "        44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  66,  68,  69,  70,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
      "         81,  82,  84,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        114, 115, 116, 117, 120, 121, 123, 124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 135, 141, 144, 146, 150, 153, 164, 166, 168, 172, 174, 177, 185,\n",
      "        188, 191])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([193, 197, 200, 204, 207, 209, 210, 212, 213, 222, 227, 231, 232, 235,\n",
      "        239, 241, 249, 252, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 37\n",
      "Max diff:\n",
      "tensor([4.0293])\n",
      "\n",
      "tensor([[3.8432e-05, 3.0832e-05, 1.8132e-05, 3.9808e-05, 3.6582e-05, 5.4352e-05,\n",
      "         2.5161e-05, 1.8696e-05, 1.9446e-05, 1.0851e-05, 2.3653e-05, 1.4829e-05,\n",
      "         2.0195e-05, 2.1885e-05, 2.8539e-05, 9.0515e-06, 1.9050e-05, 1.4251e-05,\n",
      "         9.7459e-06, 2.1512e-05, 1.2230e-05, 3.8555e-05, 4.1619e-05, 2.7694e-05,\n",
      "         2.3297e-05, 3.2175e-05, 3.9309e-05, 2.3026e-05, 2.2648e-05, 1.5595e-05,\n",
      "         2.8959e-05, 1.4869e-05, 2.7893e-05, 3.0635e-05, 2.0138e-05, 7.7739e-05,\n",
      "         5.1066e-05, 3.7324e-05, 1.6316e-05, 5.9437e-05, 3.2224e-05, 3.3177e-05,\n",
      "         2.2483e-05, 3.7562e-05, 3.1874e-05, 4.4774e-05, 3.3213e-05, 5.6662e-06,\n",
      "         1.8829e-05, 2.2141e-05, 1.4611e-05, 3.9073e-05, 3.2183e-05, 2.2500e-05,\n",
      "         2.2752e-05, 5.9158e-05, 4.6816e-05, 1.3223e-05, 2.4039e-05, 4.7766e-05,\n",
      "         5.4155e-05, 3.9659e-05, 2.6144e-05, 8.3714e-06, 1.1772e+00, 1.3486e+00,\n",
      "         1.4973e+00, 1.2926e+00, 2.1390e+00, 1.6929e+00, 1.1692e+00, 2.3108e+00,\n",
      "         1.8411e+00, 1.6046e+00, 2.3407e+00, 1.2799e+00, 1.4704e+00, 2.4669e+00,\n",
      "         1.2151e+00, 2.3820e+00, 1.8045e+00, 2.5739e+00, 2.7680e+00, 4.0293e+00,\n",
      "         1.6780e+00, 1.9395e+00, 1.7412e+00, 1.5808e+00, 1.7631e+00, 2.1131e+00,\n",
      "         3.7789e+00, 2.8045e+00, 2.3711e+00, 2.0313e+00, 3.2451e+00, 3.6307e+00,\n",
      "         2.0512e+00, 2.5721e+00, 2.3417e+00, 2.9396e+00, 1.5365e+00, 1.8952e+00,\n",
      "         1.3535e+00, 3.3024e+00, 1.1031e+00, 1.1387e+00, 1.4188e+00, 2.6449e+00,\n",
      "         1.4733e+00, 1.2748e+00, 1.2016e+00, 2.3568e+00, 1.4599e+00, 1.1899e+00,\n",
      "         2.1635e+00, 2.3585e+00, 1.5476e+00, 2.3908e+00, 1.7276e+00, 2.4321e+00,\n",
      "         1.0969e+00, 2.0395e+00, 1.7458e+00, 1.8861e+00, 1.4611e+00, 1.3490e+00,\n",
      "         3.4938e+00, 1.1928e+00, 4.3740e-03, 3.8209e-03, 4.6122e-03, 1.1874e-04,\n",
      "         2.2430e-03, 2.5164e-03, 2.3120e-03, 4.9291e-03, 1.9135e-04, 8.6361e-04,\n",
      "         3.7430e-03, 7.0837e-04, 2.5205e-04, 3.0077e-03, 2.5246e-04, 3.7020e-03,\n",
      "         2.0233e-03, 3.4758e-03, 4.4125e-03, 3.7286e-03, 1.0622e-04, 2.2546e-03,\n",
      "         2.2493e-03, 2.5543e-03, 2.8226e-03, 1.9558e-03, 1.5683e-03, 6.0096e-04,\n",
      "         1.6593e-03, 1.9497e-04, 3.0422e-03, 4.6602e-05, 3.4792e-03, 4.7344e-03,\n",
      "         5.5781e-03, 2.3255e-03, 1.8739e-03, 1.2829e-04, 2.3545e-03, 5.2145e-03,\n",
      "         7.5144e-04, 3.1163e-03, 2.4791e-03, 4.3789e-03, 2.6881e-03, 3.4238e-04,\n",
      "         5.3469e-03, 1.4533e-04, 5.5955e-03, 4.7175e-03, 3.6262e-03, 1.6803e-04,\n",
      "         1.8517e-03, 2.1218e-04, 1.2763e-04, 6.3079e-03, 2.0709e-03, 3.8828e-03,\n",
      "         1.8460e-04, 1.8639e-03, 2.2052e-04, 5.2615e-03, 7.8626e-04, 4.1701e-03,\n",
      "         1.9839e-02, 6.3788e-02, 4.6184e-01, 2.9928e-01, 4.6567e-01, 4.4287e-01,\n",
      "         2.1607e-01, 2.2580e-01, 3.9399e-01, 2.2033e-01, 3.5798e-01, 6.2778e-01,\n",
      "         3.5294e-02, 3.6045e-01, 4.5205e-01, 5.2380e-01, 3.1155e-02, 2.8352e-01,\n",
      "         3.2890e-01, 5.0887e-01, 5.0443e-01, 4.3280e-01, 5.3913e-02, 3.8753e-01,\n",
      "         1.5639e-01, 5.1366e-01, 5.6167e-01, 2.4802e-01, 5.4421e-01, 2.8762e-01,\n",
      "         2.2137e-01, 6.9597e-01, 5.4702e-01, 1.6929e-02, 1.8916e-01, 4.3332e-01,\n",
      "         2.9168e-02, 2.8881e-01, 4.5831e-01, 4.3993e-01, 2.9904e-01, 4.1843e-01,\n",
      "         1.0018e-01, 3.4672e-02, 2.4734e-01, 2.8162e-01, 3.5396e-01, 2.0648e-02,\n",
      "         5.4718e-01, 5.0539e-01, 3.7365e-01, 4.7833e-02, 3.8047e-01, 3.4557e-01,\n",
      "         7.5415e-01, 1.6826e-01, 4.0143e-01, 6.8989e-01, 3.1615e-02, 1.2838e-02,\n",
      "         4.2609e-02, 4.0667e-01, 2.8106e-01, 3.3178e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 38: layer3.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 38\n",
      "Max diff:\n",
      "tensor([1.9505])\n",
      "\n",
      "tensor([[1.1379e-05, 9.5027e-06, 6.1397e-06, 1.2842e-05, 1.1357e-05, 1.6336e-05,\n",
      "         7.6164e-06, 5.7509e-06, 6.5155e-06, 3.2559e-06, 7.3593e-06, 4.6678e-06,\n",
      "         5.9083e-06, 7.1209e-06, 9.3225e-06, 2.3330e-06, 5.9567e-06, 3.9916e-06,\n",
      "         2.9964e-06, 6.8825e-06, 3.4794e-06, 1.2573e-05, 1.2982e-05, 8.3754e-06,\n",
      "         7.6145e-06, 9.6621e-06, 1.1099e-05, 7.1311e-06, 6.6385e-06, 5.3796e-06,\n",
      "         8.1575e-06, 4.5933e-06, 8.4378e-06, 1.0132e-05, 6.8378e-06, 2.5449e-05,\n",
      "         1.6676e-05, 1.0575e-05, 5.2154e-06, 1.9848e-05, 1.0831e-05, 8.6604e-06,\n",
      "         7.0753e-06, 1.3360e-05, 9.5526e-06, 1.3750e-05, 1.0562e-05, 1.5805e-06,\n",
      "         5.1456e-06, 6.9868e-06, 4.5020e-06, 1.1947e-05, 9.1800e-06, 6.9356e-06,\n",
      "         7.2047e-06, 1.8820e-05, 1.3979e-05, 4.3181e-06, 6.9565e-06, 1.4532e-05,\n",
      "         1.6658e-05, 1.3134e-05, 8.5123e-06, 2.0517e-06, 6.0880e-01, 6.7374e-01,\n",
      "         9.5484e-01, 6.3078e-01, 8.3061e-01, 8.5419e-01, 5.7393e-01, 1.0782e+00,\n",
      "         9.4684e-01, 8.8794e-01, 1.2107e+00, 7.5213e-01, 8.1867e-01, 9.6875e-01,\n",
      "         6.4043e-01, 9.8641e-01, 9.0742e-01, 1.5509e+00, 1.2401e+00, 1.9505e+00,\n",
      "         7.8245e-01, 8.2662e-01, 7.8659e-01, 8.2886e-01, 1.0490e+00, 9.0903e-01,\n",
      "         6.6578e-01, 1.8810e+00, 9.2799e-01, 8.0147e-01, 1.7179e+00, 1.5770e+00,\n",
      "         9.3223e-01, 1.2646e+00, 1.1508e+00, 1.3437e+00, 5.7127e-01, 1.0020e+00,\n",
      "         6.7568e-01, 1.3599e+00, 5.8503e-01, 6.8343e-01, 5.7982e-01, 1.2927e+00,\n",
      "         8.3825e-01, 7.1011e-01, 6.1577e-01, 7.9925e-01, 6.6421e-01, 3.9324e-01,\n",
      "         6.5299e-01, 1.0955e+00, 7.7135e-01, 1.4429e+00, 7.2518e-01, 1.2436e+00,\n",
      "         5.5432e-01, 1.0761e+00, 1.0704e+00, 8.7660e-01, 5.6801e-01, 5.8630e-01,\n",
      "         1.4709e+00, 8.0005e-01, 8.4334e-04, 7.7892e-04, 1.5049e-03, 3.5150e-05,\n",
      "         4.4066e-04, 8.4667e-04, 8.0292e-04, 1.0889e-03, 5.2225e-05, 2.0934e-04,\n",
      "         7.9369e-04, 1.5770e-04, 7.8138e-05, 6.5078e-04, 7.8389e-05, 7.5252e-04,\n",
      "         7.1278e-04, 1.4227e-03, 8.8853e-04, 1.3110e-03, 3.2216e-05, 1.1458e-03,\n",
      "         5.9998e-04, 7.5768e-04, 7.5695e-04, 8.7039e-04, 6.6963e-04, 1.7908e-04,\n",
      "         4.9376e-04, 4.7859e-05, 1.7236e-03, 1.1200e-05, 1.3604e-03, 1.5551e-03,\n",
      "         2.2377e-03, 1.0047e-03, 5.7489e-04, 3.6735e-05, 8.7824e-04, 1.5843e-03,\n",
      "         1.9854e-04, 1.4935e-03, 6.5062e-04, 1.4949e-03, 5.9491e-04, 1.0557e-04,\n",
      "         2.6198e-03, 3.5781e-05, 1.4059e-03, 1.4178e-03, 9.3701e-04, 3.9864e-05,\n",
      "         4.8634e-04, 6.0055e-05, 3.7603e-05, 3.3643e-03, 4.3574e-04, 1.4822e-03,\n",
      "         4.9120e-05, 1.2784e-03, 6.1730e-05, 1.0606e-03, 1.8049e-04, 4.8993e-04,\n",
      "         4.7154e-03, 1.6970e-02, 1.2219e-01, 1.6021e-01, 1.2192e-01, 1.8773e-01,\n",
      "         3.3001e-02, 8.3419e-02, 7.0775e-02, 7.9028e-02, 1.4004e-01, 3.7786e-01,\n",
      "         1.1147e-02, 1.6303e-01, 1.7200e-01, 3.6808e-01, 8.8293e-03, 1.0480e-01,\n",
      "         1.2081e-01, 1.6714e-01, 1.5637e-01, 2.0165e-01, 1.4871e-02, 1.5316e-01,\n",
      "         9.7438e-03, 1.7651e-01, 1.7148e-01, 1.3269e-01, 3.0298e-01, 1.0220e-01,\n",
      "         4.5940e-02, 2.5163e-01, 1.5647e-01, 4.0364e-03, 4.0982e-02, 1.7166e-01,\n",
      "         7.2371e-03, 6.2106e-02, 1.6754e-01, 1.7718e-01, 1.0008e-01, 2.4267e-01,\n",
      "         3.7541e-02, 1.0625e-02, 4.4348e-02, 1.6277e-01, 1.2475e-01, 6.0916e-03,\n",
      "         3.0270e-01, 1.4253e-01, 8.4751e-02, 1.2247e-02, 1.0770e-01, 1.1002e-01,\n",
      "         6.4694e-02, 4.5137e-02, 5.1798e-02, 2.8108e-01, 8.3962e-03, 3.4926e-03,\n",
      "         1.3224e-02, 1.4156e-01, 1.3120e-01, 1.0452e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 39: layer3.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([67]) to machine 1\n",
      "\t\t sending C_out tensor([182]) to machine 2\n",
      "\t\t sending C_out tensor([202, 208, 218, 234, 243, 247, 252]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 4,  7,  8, 10, 12, 13, 18, 22, 24, 28, 32, 40, 44, 52, 57, 61]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([199, 243, 251]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 7,  9, 13, 16, 17, 21, 27, 29, 35, 36, 37, 58]) to machine 0\n",
      "\t\t sending C_out tensor([ 69, 115]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([231, 249]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  3, 14, 15, 20, 22, 29, 30, 34, 38, 54, 58, 61]) to machine 0\n",
      "\t\t sending C_out tensor([ 77,  86, 111]) to machine 1\n",
      "\t\t sending C_out tensor([155, 186]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 39\n",
      "Max diff:\n",
      "tensor([1.9986])\n",
      "\n",
      "tensor([[9.9864e-05, 8.6966e-05, 7.0350e-05, 2.0258e-04, 1.4623e-03, 3.3586e-04,\n",
      "         1.7418e-04, 2.9528e-04, 2.0114e-04, 1.7469e-05, 1.6269e-04, 4.3369e-05,\n",
      "         3.1960e-03, 1.8117e-04, 3.3074e-04, 1.4570e-04, 1.5467e-04, 1.3772e-04,\n",
      "         2.0984e-04, 8.6567e-05, 2.0412e-04, 5.6548e-05, 1.5249e-03, 2.1757e-04,\n",
      "         3.3895e-04, 1.1139e-04, 2.6495e-04, 2.8251e-04, 9.4117e-05, 1.5129e-04,\n",
      "         9.9335e-05, 2.1446e-04, 8.1800e-04, 2.3601e-04, 2.0000e-04, 1.8378e-04,\n",
      "         3.4164e-04, 1.9992e-04, 1.8511e-04, 4.7700e-05, 2.4600e-04, 3.5539e-05,\n",
      "         1.7462e-04, 8.2530e-05, 8.6548e-04, 1.3747e-04, 3.2114e-04, 6.2848e-05,\n",
      "         1.5103e-05, 3.7196e-04, 1.3214e-04, 1.3823e-04, 1.0081e-03, 2.2848e-04,\n",
      "         2.4307e-04, 1.4607e-04, 2.4035e-04, 9.9400e-05, 2.4039e-04, 2.4248e-04,\n",
      "         3.7241e-05, 2.6190e-04, 1.6876e-04, 1.1133e-04, 7.7087e-01, 4.4210e-01,\n",
      "         6.0836e-01, 3.2830e-01, 6.0972e-01, 4.3051e-01, 3.9981e-01, 5.1174e-01,\n",
      "         5.1950e-01, 1.3153e+00, 5.3020e-01, 4.3827e-01, 5.8974e-01, 8.0654e-01,\n",
      "         2.9834e-01, 6.0856e-01, 2.0211e-01, 1.9986e+00, 4.9559e-01, 1.1105e+00,\n",
      "         3.7199e-01, 4.2315e-01, 5.5654e-01, 8.0187e-01, 5.1666e-01, 7.7618e-01,\n",
      "         7.4721e-01, 1.0786e+00, 9.2718e-01, 5.8021e-01, 1.3242e+00, 1.2015e+00,\n",
      "         3.2580e-01, 3.5165e-01, 1.0436e+00, 6.1232e-01, 5.6150e-01, 8.6658e-01,\n",
      "         7.7804e-01, 4.5747e-01, 1.0241e+00, 4.7763e-01, 3.8233e-01, 5.7628e-01,\n",
      "         1.2031e+00, 5.7462e-01, 6.1950e-01, 2.1930e-01, 6.8953e-01, 1.2752e+00,\n",
      "         6.0187e-01, 9.0296e-01, 3.0010e-01, 3.8427e-01, 4.2522e-01, 1.1172e+00,\n",
      "         1.1631e+00, 3.8177e-01, 1.3227e+00, 3.5062e-01, 6.8500e-01, 3.5792e-01,\n",
      "         7.7042e-01, 6.1056e-01, 2.2877e-03, 2.6011e-03, 5.0314e-04, 2.3588e-04,\n",
      "         3.3718e-03, 8.9277e-04, 3.5107e-04, 5.1286e-03, 8.4302e-05, 7.0302e-04,\n",
      "         3.0487e-04, 5.5595e-04, 2.3645e-04, 2.2164e-03, 1.5825e-04, 3.1724e-03,\n",
      "         3.9243e-03, 6.1532e-04, 2.7708e-03, 5.8891e-03, 1.1340e-04, 6.0367e-04,\n",
      "         1.4669e-03, 1.3107e-03, 2.8013e-03, 1.1592e-04, 1.0082e-03, 3.7066e-04,\n",
      "         1.7534e-03, 4.4441e-04, 9.2909e-05, 8.8321e-05, 2.0009e-03, 4.5435e-03,\n",
      "         4.9553e-03, 4.0635e-04, 2.7177e-03, 1.0203e-04, 1.3195e-03, 4.8192e-03,\n",
      "         9.6287e-04, 3.5313e-03, 4.6745e-03, 3.4068e-03, 2.5031e-03, 3.8173e-04,\n",
      "         2.1070e-03, 1.8881e-04, 1.2259e-03, 2.9089e-03, 4.3979e-03, 2.4714e-04,\n",
      "         6.0304e-04, 8.2286e-05, 1.5867e-04, 2.7598e-03, 2.6479e-03, 4.2844e-03,\n",
      "         1.0234e-04, 2.9205e-04, 1.3261e-04, 2.1275e-03, 4.2679e-04, 1.0128e-03,\n",
      "         7.1595e-02, 1.5187e-01, 3.5624e-01, 3.3223e-01, 1.0448e-01, 7.9332e-02,\n",
      "         7.6991e-02, 2.7500e-01, 1.6332e-01, 3.3450e-01, 1.6075e-01, 5.6085e-02,\n",
      "         6.1645e-03, 1.3641e-01, 2.3920e-01, 1.6240e-01, 5.3188e-02, 2.2245e-01,\n",
      "         5.0453e-01, 1.3493e-01, 5.8949e-01, 9.7564e-02, 1.4439e-01, 3.3451e-02,\n",
      "         5.4868e-01, 2.1320e-01, 4.4539e-01, 4.3292e-01, 1.3145e-01, 1.0407e-01,\n",
      "         1.8846e-02, 5.0836e-01, 5.0335e-01, 1.4417e-02, 3.5233e-01, 4.6505e-01,\n",
      "         6.4528e-02, 2.4414e-01, 4.2770e-01, 1.0562e-01, 3.1838e-01, 1.7522e-01,\n",
      "         6.2114e-02, 2.9939e-02, 1.4364e-01, 2.7293e-01, 5.1305e-02, 2.2746e-02,\n",
      "         8.5182e-02, 3.0589e-01, 2.0344e-01, 7.8755e-02, 3.6880e-02, 1.1977e-01,\n",
      "         6.2105e-01, 5.5645e-02, 8.9388e-02, 1.6556e-01, 2.8138e-02, 4.2250e-02,\n",
      "         3.2713e-02, 8.0716e-02, 2.3065e-01, 6.8011e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 40: layer3.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 40\n",
      "Max diff:\n",
      "tensor([1.0216])\n",
      "\n",
      "tensor([[2.5148e-05, 2.2214e-05, 1.9107e-05, 8.2055e-05, 4.0331e-03, 9.2170e-05,\n",
      "         4.3886e-05, 4.2116e-04, 5.3277e-05, 1.5069e-05, 1.5263e-04, 1.1005e-05,\n",
      "         1.8120e-03, 1.0910e-04, 4.0782e-04, 3.5108e-05, 3.7718e-05, 3.4756e-05,\n",
      "         1.3427e-04, 2.1397e-05, 2.7298e-03, 1.5503e-05, 4.1713e-03, 5.6394e-05,\n",
      "         1.0168e-04, 3.0341e-05, 7.2993e-05, 6.9670e-05, 2.5871e-04, 2.9398e-04,\n",
      "         2.4952e-05, 5.5283e-05, 3.1255e-03, 5.9079e-05, 7.3981e-04, 2.6434e-03,\n",
      "         8.5570e-05, 7.9177e-04, 3.0763e-04, 1.2524e-05, 8.7457e-05, 8.4601e-06,\n",
      "         4.0007e-05, 2.0212e-05, 8.4906e-04, 3.7093e-05, 8.5201e-05, 1.4702e-05,\n",
      "         3.8990e-06, 9.9249e-05, 3.3673e-05, 3.8750e-05, 9.7759e-04, 5.7806e-05,\n",
      "         8.2416e-05, 3.3835e-05, 6.2482e-05, 1.3166e-04, 2.3414e-04, 6.2816e-05,\n",
      "         8.8196e-06, 1.6560e-04, 4.6370e-05, 2.6574e-05, 4.3584e-01, 2.7466e-01,\n",
      "         2.9428e-01, 1.1365e-01, 2.8062e-01, 1.8394e-01, 1.6037e-01, 2.0788e-01,\n",
      "         1.9523e-01, 6.2964e-01, 2.3259e-01, 1.8766e-01, 1.9658e-01, 4.5998e-01,\n",
      "         1.3700e-01, 2.5619e-01, 6.6587e-02, 1.0216e+00, 1.7625e-01, 5.7270e-01,\n",
      "         9.9750e-02, 2.0853e-01, 3.7656e-01, 1.7132e-01, 1.4543e-01, 4.5448e-01,\n",
      "         4.9826e-01, 8.1143e-01, 5.0278e-01, 3.0589e-01, 6.5556e-01, 7.1253e-01,\n",
      "         1.2389e-01, 1.5152e-01, 5.8052e-01, 2.8003e-01, 1.5487e-01, 3.9417e-01,\n",
      "         3.6172e-01, 2.7303e-01, 1.2352e-01, 1.0904e-01, 2.0747e-01, 3.4580e-01,\n",
      "         3.8984e-01, 2.1331e-01, 3.7329e-01, 7.0326e-01, 2.5413e-01, 8.7785e-01,\n",
      "         3.0866e-01, 4.1749e-01, 9.5030e-02, 1.1913e-01, 1.7636e-01, 5.0700e-01,\n",
      "         5.6197e-01, 1.3659e-01, 7.9083e-01, 1.1505e-01, 5.1072e-01, 1.3980e-01,\n",
      "         3.1634e-01, 2.2006e-01, 6.7512e-04, 7.9653e-04, 4.4573e-05, 6.1790e-05,\n",
      "         1.6191e-03, 7.3753e-05, 5.7369e-06, 1.3316e-03, 2.6993e-05, 1.3762e-04,\n",
      "         4.4405e-06, 8.6166e-05, 5.9500e-05, 7.4977e-04, 4.0835e-05, 1.2328e-03,\n",
      "         1.7993e-03, 1.0645e-04, 8.4962e-04, 2.6329e-03, 3.1047e-05, 7.7039e-06,\n",
      "         3.8436e-04, 3.9808e-04, 1.0595e-03, 1.3337e-06, 1.0768e-04, 9.4832e-04,\n",
      "         3.6385e-04, 1.1354e-04, 3.3900e-07, 2.1074e-05, 9.0878e-04, 2.0061e-03,\n",
      "         2.4711e-03, 4.6566e-06, 1.1218e-03, 2.3976e-05, 2.9419e-04, 1.8116e-03,\n",
      "         3.0715e-04, 1.5863e-03, 1.6972e-03, 1.0096e-03, 7.0539e-04, 9.8094e-05,\n",
      "         4.2047e-04, 4.3483e-05, 3.2511e-04, 4.2279e-04, 1.0986e-03, 5.7347e-05,\n",
      "         8.5622e-05, 2.1145e-05, 3.5618e-05, 1.1628e-03, 1.1229e-03, 2.3353e-03,\n",
      "         1.2577e-04, 1.6652e-06, 3.3732e-05, 9.5132e-04, 1.3079e-04, 4.0992e-04,\n",
      "         1.6595e-02, 3.7046e-02, 1.5636e-01, 1.0965e-01, 1.7881e-02, 2.9977e-03,\n",
      "         1.1600e-02, 8.3058e-01, 3.1971e-02, 6.5818e-02, 4.8287e-02, 6.5081e-05,\n",
      "         1.7030e-03, 3.0172e-03, 3.0994e-06, 8.3126e-02, 1.2643e-02, 1.0185e-01,\n",
      "         1.7470e-01, 2.8867e-02, 2.3479e-01, 3.2561e-05, 3.3516e-02, 8.0431e-04,\n",
      "         4.3211e-01, 1.5774e-02, 2.0932e-01, 3.2390e-01, 3.7782e-02, 6.5798e-04,\n",
      "         5.4990e-04, 2.2247e-01, 2.0125e-01, 3.3525e-03, 1.3216e-01, 5.6169e-02,\n",
      "         1.5691e-02, 8.3333e-02, 1.6537e-01, 1.5910e-02, 5.5834e-02, 3.1132e-02,\n",
      "         1.4628e-02, 7.8231e-03, 1.4415e-02, 8.4463e-02, 2.7052e-04, 5.5946e-03,\n",
      "         1.7711e-02, 1.1241e-01, 6.1889e-02, 7.9927e-02, 5.5833e-03, 3.2586e-03,\n",
      "         4.9306e-01, 1.6357e-02, 2.3381e-02, 6.2721e-02, 7.1575e-03, 1.0568e-02,\n",
      "         9.0594e-03, 8.9709e-04, 6.7365e-02, 2.9368e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 41: layer3.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 41\n",
      "Max diff:\n",
      "tensor([2.4966])\n",
      "\n",
      "tensor([[2.2736e-05, 2.3121e-05, 1.7244e-05, 7.5703e-05, 4.0444e-03, 8.3521e-05,\n",
      "         4.5824e-05, 4.2033e-04, 5.5272e-05, 1.7516e-05, 1.5745e-04, 1.0781e-05,\n",
      "         1.8175e-03, 1.0810e-04, 4.0958e-04, 3.3700e-05, 3.5901e-05, 3.5047e-05,\n",
      "         1.3592e-04, 2.3513e-05, 2.7307e-03, 1.6047e-05, 4.1806e-03, 5.7746e-05,\n",
      "         1.0829e-04, 3.3218e-05, 7.6797e-05, 7.0490e-05, 2.5696e-04, 2.9197e-04,\n",
      "         2.2518e-05, 5.6483e-05, 3.1314e-03, 5.7068e-05, 7.4211e-04, 2.6570e-03,\n",
      "         8.0034e-05, 7.9752e-04, 3.0527e-04, 2.1320e-05, 9.2953e-05, 1.4452e-05,\n",
      "         4.3781e-05, 3.0341e-05, 8.4653e-04, 3.1065e-05, 7.9442e-05, 1.5200e-05,\n",
      "         6.3183e-06, 9.7917e-05, 3.3998e-05, 3.5593e-05, 9.8176e-04, 5.8654e-05,\n",
      "         8.1848e-05, 2.6628e-05, 6.3422e-05, 1.3047e-04, 2.3797e-04, 5.7273e-05,\n",
      "         2.2361e-05, 1.5739e-04, 5.1726e-05, 2.6807e-05, 8.1346e-01, 7.4108e-01,\n",
      "         1.0480e+00, 6.7133e-01, 1.0751e+00, 8.2405e-01, 6.9812e-01, 1.0690e+00,\n",
      "         9.5778e-01, 1.2316e+00, 1.1720e+00, 8.7129e-01, 8.9287e-01, 1.2068e+00,\n",
      "         7.1992e-01, 8.1040e-01, 9.2915e-01, 2.4966e+00, 1.2035e+00, 2.3093e+00,\n",
      "         7.3910e-01, 8.1598e-01, 9.4577e-01, 8.8699e-01, 9.6038e-01, 1.2062e+00,\n",
      "         9.8350e-01, 1.5038e+00, 9.1221e-01, 5.6878e-01, 2.0385e+00, 1.9368e+00,\n",
      "         9.6253e-01, 1.3906e+00, 6.5152e-01, 1.6238e+00, 6.3543e-01, 1.0166e+00,\n",
      "         4.2022e-01, 1.5513e+00, 5.6484e-01, 7.4320e-01, 5.2353e-01, 1.2612e+00,\n",
      "         1.2281e+00, 7.5868e-01, 7.8494e-01, 7.6208e-01, 9.0087e-01, 9.4644e-01,\n",
      "         7.6706e-01, 1.3625e+00, 7.6100e-01, 1.4034e+00, 8.4001e-01, 1.7506e+00,\n",
      "         7.6339e-01, 1.0748e+00, 1.0066e+00, 8.3386e-01, 8.3879e-01, 5.7308e-01,\n",
      "         1.2877e+00, 6.6973e-01, 1.3263e-03, 7.2724e-04, 1.5284e-03, 8.1336e-05,\n",
      "         1.9532e-03, 8.5363e-04, 7.9972e-04, 2.0446e-03, 7.6324e-05, 3.0956e-04,\n",
      "         7.9472e-04, 2.0280e-04, 9.8214e-05, 1.2549e-03, 1.0708e-04, 1.7130e-03,\n",
      "         2.0752e-03, 1.4486e-03, 1.4497e-03, 2.6669e-03, 4.3765e-05, 1.1492e-03,\n",
      "         7.6941e-04, 9.8262e-04, 1.0847e-03, 8.7132e-04, 7.1162e-04, 8.6968e-04,\n",
      "         6.9138e-04, 1.4994e-04, 1.7234e-03, 2.5923e-05, 1.7638e-03, 3.3584e-03,\n",
      "         2.0819e-03, 1.0042e-03, 1.3871e-03, 5.0504e-05, 8.9002e-04, 3.0558e-03,\n",
      "         4.4723e-04, 2.8528e-03, 1.8809e-03, 2.2001e-03, 1.0887e-03, 1.8346e-04,\n",
      "         2.9636e-03, 7.0034e-05, 1.6302e-03, 1.6500e-03, 1.8276e-03, 8.5002e-05,\n",
      "         5.3602e-04, 5.8830e-05, 5.5123e-05, 3.7773e-03, 1.4571e-03, 3.3437e-03,\n",
      "         9.8258e-05, 1.2793e-03, 8.3316e-05, 1.2629e-03, 2.9422e-04, 6.6134e-04,\n",
      "         1.9708e-02, 4.2443e-02, 1.5899e-01, 1.6713e-01, 1.2346e-01, 1.8781e-01,\n",
      "         2.7158e-02, 8.1121e-01, 5.4589e-02, 1.1579e-01, 1.4799e-01, 3.7789e-01,\n",
      "         1.2256e-02, 1.6303e-01, 1.7200e-01, 3.6576e-01, 1.7305e-02, 1.4635e-01,\n",
      "         1.5753e-01, 1.7431e-01, 3.1429e-01, 2.0166e-01, 4.3572e-02, 1.5303e-01,\n",
      "         4.3060e-01, 1.8474e-01, 3.0490e-01, 3.6715e-01, 3.0244e-01, 1.0242e-01,\n",
      "         4.5646e-02, 2.5764e-01, 2.7452e-01, 5.4253e-03, 1.5350e-01, 1.8643e-01,\n",
      "         1.9244e-02, 1.2311e-01, 2.1032e-01, 1.7646e-01, 1.3581e-01, 2.3171e-01,\n",
      "         4.1524e-02, 1.3850e-02, 4.7056e-02, 1.6113e-01, 1.2487e-01, 8.9404e-03,\n",
      "         2.9759e-01, 2.1140e-01, 6.3405e-02, 8.0122e-02, 1.0919e-01, 1.0859e-01,\n",
      "         5.2627e-01, 4.1935e-02, 5.2035e-02, 2.7661e-01, 1.1446e-02, 1.1370e-02,\n",
      "         1.2668e-02, 1.4120e-01, 1.6106e-01, 2.7836e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 42: layer3.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 42\n",
      "Max diff:\n",
      "tensor([2.4966])\n",
      "\n",
      "tensor([[2.2736e-05, 0.0000e+00, 0.0000e+00, 6.0193e-05, 4.0444e-03, 8.3521e-05,\n",
      "         4.5824e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.4014e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7307e-03, 1.6047e-05, 4.1806e-03, 5.7746e-05,\n",
      "         0.0000e+00, 3.3218e-05, 7.6797e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.1314e-03, 0.0000e+00, 0.0000e+00, 2.6570e-03,\n",
      "         8.0034e-05, 7.9752e-04, 3.0527e-04, 2.1320e-05, 0.0000e+00, 1.4452e-05,\n",
      "         1.4411e-05, 3.0341e-05, 1.4186e-04, 3.1065e-05, 0.0000e+00, 6.0583e-07,\n",
      "         4.9709e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8176e-04, 0.0000e+00,\n",
      "         0.0000e+00, 2.6628e-05, 6.3422e-05, 0.0000e+00, 2.3797e-04, 5.7273e-05,\n",
      "         2.2361e-05, 0.0000e+00, 5.1726e-05, 0.0000e+00, 5.9415e-01, 8.9827e-02,\n",
      "         8.2905e-01, 3.1984e-01, 4.8817e-01, 2.6908e-01, 3.8722e-01, 6.7098e-01,\n",
      "         4.8256e-01, 7.4459e-01, 1.0741e+00, 4.6138e-01, 3.5513e-01, 9.9603e-01,\n",
      "         7.1992e-01, 0.0000e+00, 9.2915e-01, 2.4966e+00, 1.2035e+00, 5.6335e-01,\n",
      "         5.3799e-01, 4.2840e-01, 5.2236e-01, 7.6186e-01, 7.8610e-01, 1.2062e+00,\n",
      "         8.2842e-01, 0.0000e+00, 4.7388e-01, 3.6250e-01, 1.2623e+00, 1.9368e+00,\n",
      "         8.8117e-01, 1.3906e+00, 0.0000e+00, 1.0638e+00, 6.3543e-01, 1.0166e+00,\n",
      "         2.3074e-01, 1.5309e+00, 4.5292e-01, 7.4320e-01, 5.2353e-01, 1.2267e+00,\n",
      "         5.5385e-01, 2.6772e-01, 4.0565e-01, 7.5969e-01, 9.0087e-01, 5.9837e-01,\n",
      "         7.6706e-01, 1.3625e+00, 5.9967e-01, 1.4034e+00, 7.6604e-01, 1.6905e+00,\n",
      "         7.6339e-01, 5.3309e-01, 1.4746e-03, 4.3313e-01, 2.4508e-01, 5.6252e-01,\n",
      "         1.2877e+00, 1.6752e-01, 7.4693e-04, 0.0000e+00, 1.3106e-03, 6.0122e-05,\n",
      "         1.6672e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2549e-03, 0.0000e+00, 1.7130e-03,\n",
      "         1.6755e-03, 1.3423e-03, 1.3637e-03, 0.0000e+00, 0.0000e+00, 1.1492e-03,\n",
      "         0.0000e+00, 0.0000e+00, 1.0847e-03, 8.7132e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7234e-03, 0.0000e+00, 1.3208e-03, 0.0000e+00,\n",
      "         0.0000e+00, 9.4362e-04, 1.3050e-03, 0.0000e+00, 8.9002e-04, 1.4241e-03,\n",
      "         0.0000e+00, 0.0000e+00, 5.7913e-04, 1.3965e-03, 0.0000e+00, 0.0000e+00,\n",
      "         1.0636e-03, 0.0000e+00, 0.0000e+00, 8.7543e-04, 0.0000e+00, 0.0000e+00,\n",
      "         4.0831e-04, 0.0000e+00, 0.0000e+00, 3.7773e-03, 1.4571e-03, 3.3437e-03,\n",
      "         0.0000e+00, 1.2611e-03, 0.0000e+00, 1.2629e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5899e-01, 1.1396e-01, 1.0469e-01, 1.5450e-01,\n",
      "         2.7158e-02, 8.1121e-01, 4.1197e-02, 9.8648e-02, 0.0000e+00, 7.2817e-02,\n",
      "         0.0000e+00, 8.7676e-02, 1.7200e-01, 2.3455e-01, 0.0000e+00, 1.6007e-02,\n",
      "         1.3392e-01, 1.7431e-01, 3.1429e-01, 2.0166e-01, 0.0000e+00, 7.7720e-02,\n",
      "         4.3060e-01, 1.8474e-01, 3.0490e-01, 0.0000e+00, 8.0154e-02, 1.0242e-01,\n",
      "         0.0000e+00, 0.0000e+00, 2.7452e-01, 0.0000e+00, 0.0000e+00, 1.4757e-01,\n",
      "         0.0000e+00, 0.0000e+00, 2.1032e-01, 0.0000e+00, 1.4906e-02, 2.3171e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9345e-02, 0.0000e+00, 0.0000e+00,\n",
      "         1.3115e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0559e-01, 7.3540e-02,\n",
      "         5.2627e-01, 0.0000e+00, 5.2035e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.2442e-01, 1.6106e-01, 0.0000e+00]])\n",
      "tensor([  0,   3,   4,   5,   6,  12,  20,  21,  22,  23,  25,  26,  32,  35,\n",
      "         36,  37,  38,  39,  41,  42,  43,  44,  45,  47,  48,  52,  55,  56,\n",
      "         58,  59,  60,  62,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         74,  75,  76,  77,  78,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "         89,  90,  92,  93,  94,  95,  96,  97,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 141,\n",
      "        143, 144, 145, 146, 149, 152, 153, 158, 160, 163, 164, 166, 167, 170,\n",
      "        171, 174, 177, 180, 183, 184, 185, 187, 189, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 203, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216,\n",
      "        217, 218, 220, 221, 224, 227, 230, 232, 233, 237, 240, 244, 245, 246,\n",
      "        248, 253, 254])\n",
      "\n",
      "failing Cout = tensor([  0,   3,   4,   5,   6,  12,  20,  21,  22,  23,  25,  26,  32,  35,\n",
      "         36,  37,  38,  39,  41,  42,  43,  44,  45,  47,  48,  52,  55,  56,\n",
      "         58,  59,  60,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
      "         75,  76,  77,  78,  80,  81,  82,  84,  85,  87,  88,  89,  90,  92,\n",
      "         93,  94,  95,  96,  97,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 124, 125, 126, 127, 128, 130, 131, 132, 141, 143, 144, 145, 146,\n",
      "        149, 152, 153, 158, 160, 163, 164, 166, 167, 170, 171, 174, 177, 180,\n",
      "        183, 184, 185, 187, 189, 194, 195, 196, 197, 198, 199, 200, 201, 203,\n",
      "        205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 220, 221,\n",
      "        224, 227, 230, 232, 233, 237, 240, 244, 245, 246, 248, 253, 254])  (len = 153)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 43: layer3.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  3,  4,  5,  6, 12, 20, 21, 22, 23, 25, 26, 32, 35, 36, 37, 38, 39,\n",
      "        41, 42, 43, 44, 45, 47, 48, 52, 55, 56, 58, 59, 60, 62])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  92,  93,  94,\n",
      "         95,  96,  97,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 130, 131, 132, 141, 143, 144, 145, 146, 149, 152, 153, 158, 160,\n",
      "        163, 164, 166, 167, 170, 171, 174, 177, 180, 183, 184, 185, 187, 189])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 209, 210,\n",
      "        211, 212, 213, 215, 216, 217, 218, 220, 221, 224, 227, 230, 232, 233,\n",
      "        237, 240, 244, 245, 246, 248, 253, 254])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 43\n",
      "Max diff:\n",
      "tensor([8.4528])\n",
      "\n",
      "tensor([[3.9305e-04, 2.2656e-04, 2.0963e-04, 3.4533e-04, 2.0287e-04, 3.3853e-04,\n",
      "         6.9296e-05, 9.7926e-05, 3.8078e-04, 7.2911e-05, 1.2217e-04, 2.2327e-04,\n",
      "         1.5131e-04, 6.9429e-05, 8.6864e-05, 7.5976e-05, 6.1652e-05, 2.9833e-04,\n",
      "         1.0717e-04, 8.2004e-05, 7.2389e-05, 1.4403e-04, 1.4413e-04, 6.4055e-05,\n",
      "         3.1439e-04, 1.3404e-04, 1.6423e-04, 1.8756e-04, 1.4635e-04, 1.1709e-04,\n",
      "         2.1944e-04, 7.5651e-05, 2.4887e-04, 3.1383e-04, 2.9877e-04, 3.0262e-04,\n",
      "         3.5651e-04, 5.1594e-05, 1.4187e-04, 1.2665e-04, 1.1022e-04, 1.8790e-04,\n",
      "         1.1258e-04, 1.2929e-04, 1.0155e-04, 3.1635e-04, 1.5721e-04, 2.6348e-04,\n",
      "         2.0536e-04, 9.0440e-05, 1.6827e-04, 1.3407e-04, 8.9598e-05, 3.7357e-04,\n",
      "         3.0697e-04, 1.9971e-04, 2.8156e-04, 4.1328e-04, 2.9864e-04, 1.1919e-04,\n",
      "         2.8732e-04, 2.3261e-04, 1.1385e-04, 1.6780e-04, 2.4008e+00, 3.0513e+00,\n",
      "         2.0112e+00, 3.2381e+00, 6.7893e+00, 6.5346e+00, 4.1065e+00, 4.0949e+00,\n",
      "         4.2798e+00, 5.3259e+00, 3.3495e+00, 2.8290e+00, 3.5890e+00, 2.0773e+00,\n",
      "         4.1328e+00, 3.2431e+00, 5.0912e+00, 5.8222e+00, 6.9662e+00, 2.4622e+00,\n",
      "         4.6526e+00, 1.9980e+00, 4.5676e+00, 4.2933e+00, 2.8292e+00, 2.0011e+00,\n",
      "         2.0979e+00, 2.1474e+00, 7.8113e+00, 3.5965e+00, 4.6227e+00, 4.5110e+00,\n",
      "         5.0466e+00, 2.1754e+00, 3.4577e+00, 6.9103e+00, 4.8108e+00, 5.5623e+00,\n",
      "         3.0384e+00, 3.4070e+00, 3.8885e+00, 1.9584e+00, 6.3401e+00, 3.4026e+00,\n",
      "         2.6823e+00, 8.4528e+00, 3.9122e+00, 3.2245e+00, 6.7325e-01, 5.5876e+00,\n",
      "         2.3372e+00, 6.5100e+00, 4.3773e+00, 3.5721e+00, 2.2458e+00, 2.6051e+00,\n",
      "         4.2166e+00, 3.8234e+00, 3.9473e+00, 4.0813e+00, 3.9284e+00, 2.9080e+00,\n",
      "         2.5661e+00, 3.7720e+00, 3.9926e-04, 4.5493e-04, 1.9184e-03, 6.7985e-03,\n",
      "         1.0288e-03, 1.1147e-03, 2.7425e-03, 6.6106e-04, 5.5170e-03, 1.5544e-03,\n",
      "         3.2650e-03, 7.5802e-04, 5.3591e-04, 1.3664e-03, 8.9729e-03, 5.7024e-03,\n",
      "         6.3120e-03, 5.7957e-03, 8.0402e-03, 1.5814e-03, 5.3501e-03, 3.6675e-04,\n",
      "         2.5132e-03, 1.1086e-03, 1.5557e-03, 2.7553e-04, 6.2560e-03, 6.6897e-04,\n",
      "         2.6272e-04, 3.3686e-04, 8.2452e-03, 4.8686e-03, 3.1445e-04, 5.8234e-03,\n",
      "         4.7313e-04, 5.1445e-03, 5.2452e-04, 4.9789e-03, 5.8045e-03, 2.9345e-03,\n",
      "         4.6536e-04, 5.2118e-04, 1.9254e-03, 4.6270e-04, 2.6339e-04, 2.9333e-03,\n",
      "         3.6514e-04, 3.1413e-03, 2.9491e-04, 5.8354e-04, 4.5377e-04, 1.8982e-04,\n",
      "         5.7806e-03, 8.0187e-03, 2.8713e-04, 2.9688e-03, 3.3336e-03, 1.7396e-03,\n",
      "         2.6404e-03, 6.1756e-03, 4.1503e-04, 1.5682e-03, 4.6276e-04, 4.2996e-04,\n",
      "         1.1666e-01, 7.3606e-01, 1.4887e-01, 3.8237e-01, 1.5587e-01, 2.3251e-01,\n",
      "         1.2346e+00, 6.4167e-02, 8.5245e-02, 7.3945e-02, 2.6670e+00, 1.6289e+00,\n",
      "         5.0744e-01, 7.4290e-01, 7.3382e-01, 4.9438e-02, 1.6141e-01, 8.7731e-02,\n",
      "         6.1474e-02, 1.9839e+00, 2.2692e-01, 3.0158e-01, 2.0045e+00, 9.1259e-01,\n",
      "         2.3502e-01, 6.9170e-02, 1.3914e+00, 1.5425e-01, 1.2030e+00, 7.4620e-02,\n",
      "         7.2702e-01, 1.0679e+00, 1.0937e+00, 3.2801e-01, 4.4478e-01, 4.7872e-01,\n",
      "         7.3984e-01, 6.5539e-01, 1.2142e-01, 1.8449e+00, 9.0252e-02, 9.4465e-01,\n",
      "         6.5257e-01, 5.9683e-01, 1.1656e+00, 1.7586e-01, 1.1088e-01, 4.3643e-01,\n",
      "         1.1557e+00, 2.8614e-01, 9.0614e-02, 1.1152e-01, 6.2752e-01, 2.9110e-01,\n",
      "         3.0588e-01, 3.4037e-01, 2.9637e-01, 1.9221e-01, 4.5653e-01, 1.3710e+00,\n",
      "         4.4711e-01, 8.7729e-01, 6.1632e-02, 3.0430e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 44: layer3.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 44\n",
      "Max diff:\n",
      "tensor([2.6845])\n",
      "\n",
      "tensor([[1.1295e-04, 6.1159e-05, 5.4214e-05, 1.0479e-04, 5.3167e-05, 9.3391e-05,\n",
      "         1.8383e-05, 2.6353e-05, 1.2353e-04, 2.0883e-05, 3.4384e-05, 7.0356e-05,\n",
      "         4.1851e-05, 1.9106e-05, 2.2209e-05, 1.9168e-05, 1.6333e-05, 7.8454e-05,\n",
      "         2.7055e-05, 2.3293e-05, 2.0553e-05, 4.0939e-05, 4.0054e-05, 1.7179e-05,\n",
      "         8.5125e-05, 3.7144e-05, 4.8702e-05, 4.7714e-05, 3.5282e-05, 3.3848e-05,\n",
      "         7.3565e-05, 2.0274e-05, 7.0024e-05, 8.6160e-05, 9.2827e-05, 8.8457e-05,\n",
      "         1.0160e-04, 1.4255e-05, 3.5283e-05, 3.6014e-05, 3.3529e-05, 5.3242e-05,\n",
      "         2.8504e-05, 3.4858e-05, 2.5126e-05, 8.6741e-05, 4.3475e-05, 6.6235e-05,\n",
      "         5.4041e-05, 2.2791e-05, 4.3837e-05, 4.0291e-05, 2.6906e-05, 1.1728e-04,\n",
      "         9.4444e-05, 5.5967e-05, 8.3698e-05, 1.1902e-04, 8.1298e-05, 3.6156e-05,\n",
      "         8.1619e-05, 6.9164e-05, 3.1195e-05, 5.2471e-05, 6.2888e-01, 9.6732e-01,\n",
      "         7.4652e-01, 1.0633e+00, 2.0271e+00, 1.7362e+00, 1.6311e+00, 1.1974e+00,\n",
      "         1.3874e+00, 1.5127e+00, 1.0804e+00, 8.1629e-01, 1.4251e+00, 6.5112e-01,\n",
      "         8.8437e-01, 1.1587e+00, 1.9274e+00, 1.9415e+00, 2.5906e+00, 6.9755e-01,\n",
      "         1.4228e+00, 7.4301e-01, 1.5573e+00, 1.3847e+00, 7.9435e-01, 8.3276e-01,\n",
      "         6.3319e-01, 2.0136e-01, 2.1947e+00, 1.3513e+00, 1.7304e+00, 1.3007e+00,\n",
      "         1.4030e+00, 5.5680e-01, 1.4861e+00, 2.2823e+00, 1.4995e+00, 1.8555e+00,\n",
      "         1.4372e+00, 9.6113e-01, 9.6900e-01, 5.0167e-01, 2.0626e+00, 1.0784e+00,\n",
      "         7.7633e-01, 2.6845e+00, 1.7735e+00, 9.2890e-01, 1.5514e-01, 1.5526e+00,\n",
      "         6.3193e-01, 1.2404e+00, 9.9923e-01, 9.6171e-01, 3.8392e-01, 7.2739e-01,\n",
      "         1.4103e+00, 1.0951e+00, 9.0188e-01, 1.2610e+00, 9.9072e-01, 1.0655e+00,\n",
      "         7.9473e-01, 1.2113e+00, 1.1973e-04, 1.0706e-04, 3.0683e-04, 1.6086e-03,\n",
      "         2.6094e-04, 2.4614e-04, 7.0062e-04, 1.8549e-04, 7.6354e-04, 4.3401e-04,\n",
      "         6.0125e-04, 2.1684e-04, 1.3928e-04, 3.8471e-04, 1.9967e-03, 1.2348e-03,\n",
      "         1.3535e-03, 1.2405e-03, 1.7979e-03, 3.5658e-04, 6.3667e-04, 9.5081e-05,\n",
      "         5.7031e-04, 2.5997e-04, 3.2759e-04, 6.8298e-05, 1.8215e-03, 1.8322e-04,\n",
      "         6.1866e-05, 8.8409e-05, 2.0238e-03, 8.8546e-04, 8.3632e-05, 8.6153e-04,\n",
      "         1.2508e-04, 8.6639e-04, 1.4529e-04, 8.5574e-04, 1.7982e-03, 6.5355e-04,\n",
      "         1.3281e-04, 1.4862e-04, 4.1796e-04, 1.3459e-04, 6.6424e-05, 6.5890e-04,\n",
      "         1.0237e-04, 4.4306e-04, 7.4796e-05, 1.4731e-04, 1.3152e-04, 4.4363e-05,\n",
      "         1.4465e-03, 1.1739e-03, 7.4260e-05, 6.7008e-04, 4.0230e-04, 3.2642e-04,\n",
      "         5.3246e-04, 6.1443e-04, 1.0623e-04, 2.6003e-04, 1.3621e-04, 1.0936e-04,\n",
      "         3.1171e-02, 1.4338e-01, 4.1129e-02, 7.6639e-02, 4.1443e-02, 3.5252e-02,\n",
      "         2.3228e-01, 1.7056e-02, 2.0750e-02, 2.0933e-02, 7.0598e-01, 5.5285e-01,\n",
      "         8.0206e-02, 1.7748e-01, 2.2194e-01, 1.1661e-02, 4.3970e-02, 2.5052e-02,\n",
      "         1.5083e-02, 5.4193e-01, 5.0692e-02, 8.0574e-02, 5.2336e-01, 1.8590e-01,\n",
      "         5.6337e-02, 1.9365e-02, 1.8399e-01, 4.1206e-02, 3.6818e-01, 2.0263e-02,\n",
      "         9.6248e-02, 3.1141e-01, 3.6926e-01, 8.5988e-02, 1.0592e-01, 8.9760e-02,\n",
      "         2.1599e-01, 2.0757e-01, 3.1973e-02, 3.2006e-01, 2.4223e-02, 2.1174e-01,\n",
      "         1.8699e-01, 1.6343e-01, 3.3030e-01, 4.6358e-02, 3.1566e-02, 1.3472e-01,\n",
      "         2.8593e-01, 5.6069e-02, 2.1864e-02, 2.8710e-02, 2.1699e-01, 8.1963e-02,\n",
      "         8.0086e-02, 6.1532e-02, 6.6987e-02, 5.7630e-02, 9.0885e-02, 2.5174e-01,\n",
      "         8.3368e-02, 2.6294e-01, 1.5916e-02, 8.1022e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 45: layer3.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 45\n",
      "Max diff:\n",
      "tensor([1.4861])\n",
      "\n",
      "tensor([[1.1295e-04, 6.1159e-05, 5.4214e-05, 1.0479e-04, 5.3167e-05, 9.3391e-05,\n",
      "         1.8383e-05, 0.0000e+00, 1.2353e-04, 0.0000e+00, 3.4384e-05, 7.0356e-05,\n",
      "         4.1851e-05, 0.0000e+00, 2.2209e-05, 1.9168e-05, 1.6333e-05, 6.2366e-05,\n",
      "         2.7055e-05, 2.3293e-05, 2.0553e-05, 4.0939e-05, 4.0054e-05, 0.0000e+00,\n",
      "         8.5125e-05, 3.7144e-05, 4.8702e-05, 2.0863e-05, 3.0151e-05, 3.3848e-05,\n",
      "         7.3565e-05, 0.0000e+00, 7.0024e-05, 8.6160e-05, 9.2827e-05, 8.8457e-05,\n",
      "         1.0160e-04, 0.0000e+00, 8.4415e-06, 3.6014e-05, 3.3529e-05, 5.3242e-05,\n",
      "         2.8504e-05, 3.4858e-05, 1.6944e-05, 8.6741e-05, 4.3475e-05, 6.6235e-05,\n",
      "         5.4041e-05, 0.0000e+00, 3.3474e-05, 4.0291e-05, 2.6906e-05, 1.1728e-04,\n",
      "         9.4444e-05, 5.5967e-05, 8.3698e-05, 1.1902e-04, 8.1298e-05, 3.6156e-05,\n",
      "         8.1619e-05, 6.9164e-05, 3.0315e-05, 5.2471e-05, 3.4304e-01, 7.2681e-01,\n",
      "         5.7660e-01, 1.0633e+00, 7.3770e-01, 0.0000e+00, 1.2053e-01, 4.5875e-01,\n",
      "         1.2444e+00, 1.3647e+00, 3.7984e-01, 3.5942e-01, 6.7519e-01, 5.5651e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7481e-01, 0.0000e+00, 1.5635e-01,\n",
      "         0.0000e+00, 0.0000e+00, 2.1367e-01, 6.2211e-01, 5.2769e-01, 1.4195e-01,\n",
      "         4.8648e-01, 0.0000e+00, 0.0000e+00, 9.5087e-01, 0.0000e+00, 2.0163e-01,\n",
      "         1.4030e+00, 2.5454e-01, 1.4861e+00, 8.4901e-01, 3.2130e-01, 2.4846e-01,\n",
      "         3.4439e-01, 6.3441e-01, 8.5055e-03, 3.7435e-01, 0.0000e+00, 4.2021e-01,\n",
      "         7.7633e-01, 5.2493e-01, 4.7655e-01, 9.2890e-01, 0.0000e+00, 0.0000e+00,\n",
      "         3.6266e-01, 2.4456e-01, 7.3356e-01, 7.8960e-01, 3.7599e-01, 4.8466e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5730e-02, 1.1047e-01, 3.8028e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6086e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5789e-05, 0.0000e+00, 4.8169e-05,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4650e-03, 6.8460e-04,\n",
      "         7.8595e-04, 8.5799e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.7607e-05, 0.0000e+00, 0.0000e+00, 1.2688e-03, 0.0000e+00,\n",
      "         1.4513e-05, 0.0000e+00, 1.3465e-03, 7.3536e-04, 0.0000e+00, 4.4110e-04,\n",
      "         0.0000e+00, 8.6639e-04, 0.0000e+00, 8.5574e-04, 1.2106e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8085e-05, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1852e-05, 0.0000e+00,\n",
      "         1.2606e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6047e-05, 0.0000e+00, 2.2355e-05,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0719e-02,\n",
      "         0.0000e+00, 0.0000e+00, 1.6131e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0574e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.5740e-03, 1.6047e-01, 2.0847e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.2949e-01, 6.5610e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2825e-01,\n",
      "         1.7170e-01, 3.5354e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6468e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.5171e-02, 4.9107e-02, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   8,  10,  11,  12,  14,  15,  16,\n",
      "         17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  30,  32,\n",
      "         33,  34,  35,  36,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n",
      "         48,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
      "         63,  64,  65,  66,  67,  68,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         81,  83,  86,  87,  88,  89,  90,  93,  95,  96,  97,  98,  99, 100,\n",
      "        101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 114, 115, 116, 117,\n",
      "        118, 119, 123, 124, 125, 131, 135, 137, 142, 143, 144, 145, 151, 154,\n",
      "        156, 158, 159, 161, 163, 165, 166, 172, 178, 180, 189, 191, 203, 206,\n",
      "        213, 222, 223, 224, 228, 229, 233, 234, 235, 244, 252, 253])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   8,  10,  11,  12,  14,  15,  16,\n",
      "         17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  30,  32,\n",
      "         33,  34,  35,  36,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n",
      "         48,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
      "         63,  64,  65,  66,  67,  68,  71,  72,  73,  74,  75,  76,  77,  83,\n",
      "         87,  89,  90,  93,  95,  96,  97,  98,  99, 101, 102, 103, 105, 107,\n",
      "        108, 110, 111, 114, 115, 116, 117, 118, 119, 123, 124, 125, 131, 135,\n",
      "        137, 142, 143, 144, 145, 151, 154, 156, 158, 159, 161, 163, 165, 166,\n",
      "        172, 178, 180, 189, 191, 203, 206, 213, 222, 223, 224, 228, 229, 233,\n",
      "        234, 244, 252, 253])  (len = 130)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 46: layer3.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41,\n",
      "        42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
      "        61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  70,  71,  72,  73,  74,  75,  76,  77,  81,\n",
      "         83,  86,  87,  88,  89,  90,  93,  95,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 107, 108, 109, 110, 111, 114, 115, 116, 117, 118,\n",
      "        119, 124, 125])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([131, 135, 137, 142, 143, 144, 145, 151, 154, 156, 158, 159, 161, 163,\n",
      "        165, 166, 172, 178, 180, 189, 191])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([203, 206, 213, 222, 223, 224, 228, 229, 233, 234, 235, 244, 252, 253])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 46\n",
      "Max diff:\n",
      "tensor([3.1529])\n",
      "\n",
      "tensor([[4.5560e-05, 4.6933e-05, 1.0712e-05, 4.4152e-05, 1.6602e-05, 3.1810e-05,\n",
      "         3.1552e-05, 1.9004e-05, 8.7067e-05, 4.9604e-05, 6.2712e-05, 1.1596e-04,\n",
      "         6.6917e-05, 4.6391e-05, 2.7837e-05, 3.2868e-05, 6.4120e-05, 1.2251e-05,\n",
      "         6.3617e-05, 7.2472e-05, 4.0066e-05, 7.2502e-05, 6.4045e-05, 8.7835e-05,\n",
      "         4.8026e-05, 3.1989e-05, 6.4857e-05, 1.7378e-05, 8.4476e-06, 5.1282e-05,\n",
      "         1.9127e-05, 3.0264e-05, 1.0354e-05, 4.9334e-05, 2.8178e-05, 1.0242e-04,\n",
      "         6.8814e-05, 4.9052e-05, 3.3773e-05, 7.7609e-05, 7.6909e-05, 2.0556e-05,\n",
      "         2.3079e-05, 4.3299e-05, 2.1929e-05, 4.3668e-05, 9.2080e-06, 5.2569e-05,\n",
      "         7.2094e-06, 1.3963e-05, 4.0081e-05, 5.2877e-05, 2.9022e-05, 9.3058e-05,\n",
      "         6.5172e-05, 9.2387e-05, 7.0740e-05, 2.4896e-05, 2.3754e-05, 1.0067e-04,\n",
      "         8.5525e-05, 6.0474e-05, 2.0629e-05, 1.6359e-05, 1.1817e+00, 1.2855e+00,\n",
      "         1.6730e+00, 9.7199e-01, 1.3623e+00, 1.7446e+00, 1.2282e+00, 1.0456e+00,\n",
      "         8.8176e-01, 1.8898e+00, 2.1851e+00, 1.8050e+00, 1.8084e+00, 1.0399e+00,\n",
      "         2.1978e+00, 1.5015e+00, 1.5825e+00, 1.3281e+00, 1.2082e+00, 1.6673e+00,\n",
      "         9.5251e-01, 2.1435e+00, 1.1380e+00, 3.1529e+00, 1.9072e+00, 7.3237e-01,\n",
      "         1.1424e+00, 1.2421e+00, 1.9032e+00, 1.0001e+00, 1.8540e+00, 1.8853e+00,\n",
      "         1.5433e+00, 1.3983e+00, 8.3118e-01, 1.0894e+00, 1.2605e+00, 1.6725e+00,\n",
      "         1.5747e+00, 8.2761e-01, 2.2237e+00, 8.4077e-01, 1.3753e+00, 2.5260e+00,\n",
      "         1.6810e+00, 2.3930e+00, 2.3974e+00, 1.6228e+00, 1.5311e+00, 1.2446e+00,\n",
      "         1.2878e+00, 1.5532e+00, 1.7312e+00, 1.7687e+00, 1.9009e+00, 1.3412e+00,\n",
      "         1.6787e+00, 2.5048e+00, 2.2867e+00, 9.0522e-01, 1.0983e+00, 2.3856e+00,\n",
      "         2.0260e+00, 2.0481e+00, 2.5628e-03, 1.3692e-03, 2.1339e-03, 2.3926e-04,\n",
      "         1.7128e-03, 8.3876e-04, 7.8932e-04, 2.2238e-03, 1.9452e-04, 3.8983e-04,\n",
      "         1.2553e-03, 2.3744e-04, 2.1067e-04, 3.5542e-03, 2.0618e-04, 4.3065e-04,\n",
      "         1.4527e-03, 1.6861e-03, 1.9124e-03, 2.1093e-03, 2.4248e-04, 1.4459e-03,\n",
      "         1.4221e-03, 2.5609e-03, 1.1169e-03, 2.7046e-03, 7.0011e-04, 2.4388e-04,\n",
      "         2.3273e-03, 1.4036e-04, 3.0788e-03, 1.1907e-04, 2.2164e-03, 9.5016e-04,\n",
      "         1.6786e-03, 2.9562e-03, 1.7778e-03, 1.8569e-04, 2.0866e-03, 6.6405e-04,\n",
      "         5.4248e-04, 7.5369e-04, 1.3366e-03, 1.9951e-03, 2.8300e-03, 9.2632e-04,\n",
      "         1.5287e-03, 1.2282e-04, 2.7632e-03, 1.0076e-03, 1.5711e-03, 1.3223e-04,\n",
      "         1.5714e-03, 2.8735e-04, 6.8840e-05, 1.9726e-03, 3.2960e-03, 1.8577e-03,\n",
      "         1.8090e-04, 1.5042e-03, 5.0963e-04, 2.1571e-03, 2.2030e-04, 2.6736e-03,\n",
      "         2.7141e-02, 9.2582e-02, 1.6551e-01, 1.8675e-01, 1.9232e-01, 9.4037e-02,\n",
      "         3.1185e-01, 1.4275e-01, 2.0056e-01, 1.1443e-01, 1.6916e-01, 1.4274e-01,\n",
      "         2.6197e-01, 1.9723e-01, 1.9671e-01, 2.0117e-01, 2.1588e-02, 1.3572e-01,\n",
      "         2.6489e-01, 9.6321e-02, 1.0868e-01, 1.3252e-01, 3.8274e-02, 2.4090e-01,\n",
      "         1.3845e-01, 3.4060e-01, 1.2736e-01, 1.2285e-01, 2.4779e-01, 2.2328e-01,\n",
      "         1.2252e-01, 2.1517e-01, 1.2763e-01, 9.9572e-02, 1.4485e-01, 1.3681e-01,\n",
      "         8.3141e-02, 1.9226e-01, 4.0696e-01, 1.0802e-01, 3.4877e-01, 1.4359e-01,\n",
      "         1.8634e-01, 2.5954e-02, 2.3333e-01, 1.8542e-01, 2.0119e-01, 1.4978e-01,\n",
      "         2.0696e-01, 1.2864e-01, 1.4526e-01, 8.8462e-02, 2.2511e-01, 1.6815e-01,\n",
      "         2.7091e-01, 1.8589e-01, 1.1679e-01, 1.1219e-01, 2.2854e-02, 1.0775e-02,\n",
      "         2.3489e-01, 6.0502e-02, 1.6070e-01, 1.3205e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 47: layer3.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 47\n",
      "Max diff:\n",
      "tensor([1.3766])\n",
      "\n",
      "tensor([[1.3888e-05, 1.4611e-05, 3.5986e-06, 1.2711e-05, 4.4852e-06, 8.0466e-06,\n",
      "         8.4583e-06, 5.5023e-06, 2.7202e-05, 1.5456e-05, 2.0284e-05, 4.2677e-05,\n",
      "         1.7402e-05, 1.3221e-05, 8.0206e-06, 8.2006e-06, 1.9409e-05, 3.6936e-06,\n",
      "         1.7264e-05, 2.1771e-05, 1.2882e-05, 2.0582e-05, 1.6637e-05, 3.0290e-05,\n",
      "         1.6633e-05, 8.8252e-06, 2.3011e-05, 4.6678e-06, 2.6524e-06, 1.7308e-05,\n",
      "         4.9048e-06, 9.5032e-06, 2.9132e-06, 1.3933e-05, 8.5346e-06, 2.7277e-05,\n",
      "         2.3454e-05, 1.3571e-05, 1.0446e-05, 2.5380e-05, 2.4777e-05, 5.5705e-06,\n",
      "         6.5453e-06, 1.3154e-05, 5.7053e-06, 1.2085e-05, 2.8573e-06, 1.3938e-05,\n",
      "         1.8592e-06, 4.6492e-06, 1.1716e-05, 1.4877e-05, 8.1863e-06, 2.3213e-05,\n",
      "         1.5421e-05, 3.2134e-05, 2.6092e-05, 7.2271e-06, 6.1933e-06, 3.2485e-05,\n",
      "         2.3156e-05, 2.1815e-05, 7.1302e-06, 4.5088e-06, 4.4157e-01, 3.9220e-01,\n",
      "         6.8337e-01, 2.9381e-01, 4.3128e-01, 3.7044e-01, 5.4982e-01, 5.0257e-01,\n",
      "         4.4750e-01, 1.3427e+00, 1.3766e+00, 8.6724e-01, 8.7132e-01, 4.4065e-01,\n",
      "         1.1522e+00, 6.7022e-01, 6.9168e-01, 3.7473e-01, 4.9188e-01, 8.4570e-01,\n",
      "         3.9543e-01, 7.6085e-01, 4.3339e-01, 1.1283e+00, 1.3478e+00, 2.0493e-01,\n",
      "         4.7534e-01, 5.1178e-01, 9.4573e-01, 3.5320e-01, 5.5046e-01, 6.6431e-01,\n",
      "         4.4445e-01, 7.6264e-01, 1.4056e-01, 4.4969e-01, 2.6750e-01, 6.9827e-01,\n",
      "         2.7427e-01, 2.9616e-01, 7.2859e-01, 3.7044e-01, 4.3032e-01, 4.2416e-01,\n",
      "         6.6997e-01, 8.1887e-01, 9.5496e-01, 2.9326e-01, 6.3784e-01, 7.8374e-01,\n",
      "         5.0249e-01, 9.5003e-01, 7.6568e-01, 7.6701e-01, 6.3783e-01, 7.3297e-01,\n",
      "         5.5462e-01, 6.0982e-01, 7.0041e-01, 5.7425e-01, 3.7392e-01, 5.0356e-01,\n",
      "         8.9719e-01, 1.0243e+00, 8.9743e-04, 1.5326e-04, 7.8190e-04, 5.8478e-05,\n",
      "         8.3819e-06, 1.9372e-07, 8.2552e-06, 5.2591e-04, 4.5359e-05, 1.2478e-04,\n",
      "         5.2750e-05, 3.9510e-05, 5.2133e-05, 5.8472e-04, 5.2528e-05, 1.2845e-05,\n",
      "         5.2974e-05, 3.4271e-04, 7.2685e-04, 3.2993e-04, 6.1886e-05, 4.5728e-04,\n",
      "         3.6746e-05, 7.7736e-04, 2.2880e-04, 1.0924e-03, 1.1846e-05, 6.3036e-05,\n",
      "         1.0439e-03, 3.7368e-05, 3.1069e-04, 3.2574e-05, 2.2028e-04, 2.6226e-06,\n",
      "         2.5801e-04, 8.7398e-04, 4.1324e-04, 4.2319e-05, 8.0086e-04, 7.1339e-07,\n",
      "         1.3704e-04, 5.5246e-06, 1.2025e-05, 2.3751e-04, 1.1709e-04, 1.9930e-04,\n",
      "         3.9610e-04, 3.1627e-05, 5.6496e-04, 3.4142e-05, 1.8357e-04, 3.7273e-05,\n",
      "         5.5876e-04, 6.5520e-05, 1.6738e-05, 4.0564e-04, 8.0094e-04, 3.8204e-04,\n",
      "         4.6005e-05, 7.4750e-05, 1.0741e-04, 6.2272e-04, 6.0901e-05, 5.8976e-04,\n",
      "         6.6744e-03, 1.7964e-02, 2.1427e-02, 6.5646e-02, 6.6124e-02, 3.3572e-03,\n",
      "         1.5031e-01, 2.9625e-02, 5.3876e-02, 1.0313e-02, 9.5816e-03, 2.3062e-02,\n",
      "         1.4043e-01, 6.1905e-02, 2.3153e-02, 7.1933e-02, 5.2192e-03, 4.1393e-02,\n",
      "         7.2584e-02, 8.1300e-04, 1.3996e-02, 4.3968e-02, 7.4082e-03, 1.3952e-01,\n",
      "         1.5577e-02, 1.2474e-01, 1.0435e-02, 7.0731e-02, 7.8372e-02, 3.2508e-02,\n",
      "         6.2658e-03, 5.3109e-02, 2.4107e-03, 1.8493e-02, 2.6457e-02, 9.4335e-03,\n",
      "         1.2154e-02, 6.6623e-02, 1.2106e-01, 3.8426e-02, 5.7612e-02, 4.4861e-02,\n",
      "         1.0367e-01, 6.5509e-03, 7.9054e-02, 5.2894e-02, 6.7210e-02, 2.9490e-02,\n",
      "         4.5219e-02, 1.4998e-02, 6.2758e-03, 1.6052e-02, 1.0900e-01, 3.6375e-02,\n",
      "         1.2491e-01, 2.2067e-02, 1.0288e-02, 1.6934e-04, 6.8769e-03, 2.6553e-03,\n",
      "         1.4665e-01, 3.7128e-04, 4.7547e-02, 1.3824e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 48: layer3.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 48\n",
      "Max diff:\n",
      "tensor([2.3161])\n",
      "\n",
      "tensor([[2.7895e-05, 1.4611e-05, 3.5986e-06, 5.7753e-05, 4.0443e-03, 8.2716e-05,\n",
      "         4.9945e-05, 5.5023e-06, 2.7202e-05, 1.5456e-05, 2.0284e-05, 4.2677e-05,\n",
      "         1.7402e-05, 1.3221e-05, 8.0206e-06, 8.2006e-06, 1.9409e-05, 3.6936e-06,\n",
      "         1.7264e-05, 2.1771e-05, 2.7401e-03, 2.8331e-05, 4.1972e-03, 4.0695e-05,\n",
      "         1.6633e-05, 3.3207e-05, 9.3095e-05, 4.6678e-06, 2.6524e-06, 1.7308e-05,\n",
      "         4.9048e-06, 9.5032e-06, 3.1327e-03, 1.3933e-05, 8.5346e-06, 2.6828e-03,\n",
      "         6.4515e-05, 7.8395e-04, 3.1080e-04, 3.8639e-05, 2.4777e-05, 1.6438e-05,\n",
      "         1.0566e-05, 3.7953e-05, 1.3975e-04, 3.1590e-05, 2.8573e-06, 1.3938e-05,\n",
      "         5.0782e-06, 4.6492e-06, 1.1716e-05, 1.4877e-05, 9.7722e-04, 2.3213e-05,\n",
      "         1.5421e-05, 4.3809e-05, 6.6362e-05, 7.2271e-06, 2.3825e-04, 4.3511e-05,\n",
      "         4.0563e-05, 2.1815e-05, 4.5031e-05, 4.5088e-06, 4.9525e-01, 3.9220e-01,\n",
      "         1.1096e+00, 2.2690e-01, 7.6705e-01, 3.7044e-01, 7.9822e-01, 1.1735e+00,\n",
      "         6.1962e-01, 1.3427e+00, 2.1061e+00, 8.6941e-01, 8.7132e-01, 9.0528e-01,\n",
      "         1.5843e+00, 6.7022e-01, 6.5374e-01, 2.3161e+00, 1.2987e+00, 8.4570e-01,\n",
      "         8.1736e-01, 8.8598e-01, 4.8594e-01, 1.1941e+00, 1.2798e+00, 1.1001e+00,\n",
      "         4.7534e-01, 5.1178e-01, 1.1519e+00, 3.5320e-01, 1.5903e+00, 1.9629e+00,\n",
      "         1.0961e+00, 1.6145e+00, 1.4056e-01, 1.1688e+00, 6.0648e-01, 9.1885e-01,\n",
      "         2.7427e-01, 1.7711e+00, 7.4599e-01, 9.0969e-01, 5.8189e-01, 1.4373e+00,\n",
      "         6.6997e-01, 8.1887e-01, 9.5496e-01, 7.3004e-01, 9.1273e-01, 7.2794e-01,\n",
      "         1.1518e+00, 1.4997e+00, 7.7558e-01, 1.2386e+00, 6.2169e-01, 1.5257e+00,\n",
      "         7.4009e-01, 6.0982e-01, 7.0041e-01, 7.9700e-01, 3.7392e-01, 5.8670e-01,\n",
      "         1.0157e+00, 1.0243e+00, 1.0308e-03, 1.5326e-04, 1.4044e-03, 5.8478e-05,\n",
      "         1.6634e-03, 1.9372e-07, 8.2552e-06, 5.2591e-04, 4.5359e-05, 1.2478e-04,\n",
      "         5.2750e-05, 3.9510e-05, 5.2133e-05, 1.2180e-03, 5.2528e-05, 1.7247e-03,\n",
      "         1.6795e-03, 1.4979e-03, 1.7618e-03, 3.2993e-04, 6.1886e-05, 1.2123e-03,\n",
      "         3.6746e-05, 7.7736e-04, 9.6686e-04, 1.4461e-03, 1.1846e-05, 6.3036e-05,\n",
      "         1.0439e-03, 3.7368e-05, 1.7335e-03, 3.2574e-05, 1.3648e-03, 2.6226e-06,\n",
      "         2.5801e-04, 1.7550e-03, 1.1688e-03, 4.2319e-05, 9.3815e-04, 1.4240e-03,\n",
      "         1.3704e-04, 5.5246e-06, 5.8204e-04, 1.4341e-03, 1.1709e-04, 1.9930e-04,\n",
      "         1.0790e-03, 3.1627e-05, 5.6496e-04, 8.8283e-04, 1.8357e-04, 3.7273e-05,\n",
      "         5.0332e-04, 6.5520e-05, 1.6738e-05, 3.7580e-03, 1.4895e-03, 3.4334e-03,\n",
      "         4.6005e-05, 1.2936e-03, 1.0741e-04, 1.6529e-03, 6.0901e-05, 5.8976e-04,\n",
      "         6.6744e-03, 1.7964e-02, 1.6150e-01, 9.4086e-02, 6.6124e-02, 1.5528e-01,\n",
      "         1.5090e-01, 8.1721e-01, 6.2340e-02, 9.8580e-02, 9.5816e-03, 6.6962e-02,\n",
      "         1.4043e-01, 8.3924e-02, 1.7663e-01, 2.2883e-01, 5.2192e-03, 4.1393e-02,\n",
      "         1.3793e-01, 1.7430e-01, 3.0584e-01, 1.9774e-01, 7.4082e-03, 1.3952e-01,\n",
      "         4.3063e-01, 2.1946e-01, 3.0480e-01, 7.0731e-02, 8.7866e-02, 1.1836e-01,\n",
      "         6.2658e-03, 5.3109e-02, 2.7480e-01, 1.8493e-02, 2.6457e-02, 1.5119e-01,\n",
      "         1.2154e-02, 6.6623e-02, 2.2200e-01, 3.8426e-02, 5.7612e-02, 2.2808e-01,\n",
      "         1.0367e-01, 6.5509e-03, 7.9054e-02, 5.2894e-02, 6.7210e-02, 2.9490e-02,\n",
      "         1.1657e-01, 1.4998e-02, 6.2758e-03, 1.6052e-02, 1.7810e-01, 7.9244e-02,\n",
      "         5.4591e-01, 2.2067e-02, 5.9867e-02, 1.6934e-04, 6.8769e-03, 2.6553e-03,\n",
      "         1.4665e-01, 1.2422e-01, 1.4850e-01, 1.3824e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 49: layer3.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 49\n",
      "Max diff:\n",
      "tensor([1.9961])\n",
      "\n",
      "tensor([[2.7895e-05, 1.4611e-05, 3.5986e-06, 5.7753e-05, 4.0443e-03, 8.2716e-05,\n",
      "         4.9945e-05, 5.5023e-06, 2.7202e-05, 1.5456e-05, 2.0284e-05, 4.2677e-05,\n",
      "         1.7402e-05, 1.3221e-05, 8.0206e-06, 6.3579e-06, 1.9409e-05, 3.6936e-06,\n",
      "         1.7264e-05, 2.1771e-05, 2.7401e-03, 2.8331e-05, 4.1972e-03, 4.0695e-05,\n",
      "         1.6633e-05, 3.3207e-05, 9.3095e-05, 4.6678e-06, 2.6524e-06, 1.7308e-05,\n",
      "         0.0000e+00, 9.5032e-06, 3.1327e-03, 1.3933e-05, 8.5346e-06, 2.6828e-03,\n",
      "         6.4515e-05, 7.8395e-04, 3.1080e-04, 3.8639e-05, 2.4777e-05, 1.6438e-05,\n",
      "         0.0000e+00, 3.7953e-05, 0.0000e+00, 3.1590e-05, 2.8573e-06, 1.3938e-05,\n",
      "         0.0000e+00, 4.6492e-06, 1.1716e-05, 1.4877e-05, 9.7722e-04, 2.3213e-05,\n",
      "         0.0000e+00, 4.3809e-05, 6.6362e-05, 7.2271e-06, 2.3825e-04, 4.3511e-05,\n",
      "         4.0563e-05, 2.1815e-05, 4.5031e-05, 1.2470e-06, 3.5455e-01, 2.3115e-01,\n",
      "         8.9720e-01, 1.4133e-01, 7.2951e-01, 3.7044e-01, 4.8615e-01, 9.5094e-02,\n",
      "         4.1567e-01, 5.2178e-01, 1.2308e+00, 5.1879e-01, 3.5587e-01, 7.0800e-01,\n",
      "         9.5490e-01, 1.6119e-01, 6.5374e-01, 1.9961e+00, 1.1869e+00, 0.0000e+00,\n",
      "         4.7870e-01, 5.3251e-01, 4.5908e-01, 5.1331e-01, 3.3872e-01, 9.6118e-01,\n",
      "         4.3063e-01, 4.2035e-01, 7.2599e-01, 2.7321e-01, 1.5379e+00, 1.9629e+00,\n",
      "         8.4085e-01, 1.6145e+00, 1.6034e-02, 1.0798e+00, 6.0648e-01, 9.1885e-01,\n",
      "         1.2390e-01, 1.6629e+00, 7.4599e-01, 9.0969e-01, 5.8189e-01, 1.4373e+00,\n",
      "         5.3479e-01, 1.7624e-01, 9.0094e-02, 7.3004e-01, 9.1273e-01, 2.5789e-01,\n",
      "         1.1518e+00, 1.4997e+00, 5.3852e-01, 1.2386e+00, 5.0855e-01, 1.5257e+00,\n",
      "         7.4009e-01, 8.4003e-02, 4.1269e-01, 0.0000e+00, 1.6418e-01, 5.8670e-01,\n",
      "         1.0157e+00, 6.2544e-01, 6.2709e-04, 4.0231e-06, 1.4044e-03, 5.2674e-05,\n",
      "         1.5109e-03, 0.0000e+00, 0.0000e+00, 2.9123e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2180e-03, 4.4758e-06, 1.7247e-03,\n",
      "         1.5939e-03, 1.4979e-03, 1.3017e-03, 2.3301e-04, 0.0000e+00, 1.2123e-03,\n",
      "         0.0000e+00, 4.0827e-04, 9.6686e-04, 1.4461e-03, 0.0000e+00, 0.0000e+00,\n",
      "         8.3156e-04, 0.0000e+00, 1.7335e-03, 0.0000e+00, 1.1128e-03, 0.0000e+00,\n",
      "         6.3959e-05, 1.7550e-03, 1.1688e-03, 0.0000e+00, 9.3815e-04, 1.4240e-03,\n",
      "         1.0944e-04, 0.0000e+00, 0.0000e+00, 1.4341e-03, 0.0000e+00, 8.3715e-05,\n",
      "         1.0790e-03, 2.9640e-05, 0.0000e+00, 8.8283e-04, 0.0000e+00, 0.0000e+00,\n",
      "         5.0332e-04, 5.9949e-05, 0.0000e+00, 3.7580e-03, 1.4895e-03, 3.4334e-03,\n",
      "         0.0000e+00, 1.2936e-03, 7.7762e-05, 1.6529e-03, 0.0000e+00, 4.9119e-04,\n",
      "         0.0000e+00, 0.0000e+00, 1.0736e-01, 7.7194e-02, 6.6124e-02, 1.2773e-01,\n",
      "         1.3398e-01, 7.2909e-01, 6.2340e-02, 6.6300e-02, 0.0000e+00, 6.6962e-02,\n",
      "         1.3284e-01, 5.3373e-02, 8.5666e-02, 2.2883e-01, 0.0000e+00, 1.5200e-02,\n",
      "         1.3651e-01, 1.7430e-01, 3.0584e-01, 1.4899e-01, 0.0000e+00, 1.2171e-01,\n",
      "         4.3063e-01, 2.1946e-01, 3.0480e-01, 2.7755e-02, 8.7866e-02, 1.1836e-01,\n",
      "         0.0000e+00, 2.8936e-02, 2.7480e-01, 1.7626e-02, 0.0000e+00, 1.2706e-01,\n",
      "         0.0000e+00, 1.5477e-03, 2.2200e-01, 0.0000e+00, 0.0000e+00, 2.2808e-01,\n",
      "         1.0367e-01, 0.0000e+00, 7.9054e-02, 2.6983e-02, 6.2148e-02, 0.0000e+00,\n",
      "         1.1657e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7810e-01, 3.1740e-02,\n",
      "         5.4591e-01, 0.0000e+00, 5.9867e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4665e-01, 1.2422e-01, 1.4850e-01, 0.0000e+00]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  43,\n",
      "         45,  46,  47,  49,  50,  51,  52,  53,  55,  56,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  84,  85,  86,  87,  88,  89,\n",
      "         90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "        118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "        135, 141, 142, 143, 144, 145, 146, 147, 149, 151, 152, 153, 156, 158,\n",
      "        160, 162, 163, 164, 166, 167, 168, 171, 173, 174, 175, 177, 180, 181,\n",
      "        183, 184, 185, 187, 188, 189, 191, 194, 195, 196, 197, 198, 199, 200,\n",
      "        201, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217,\n",
      "        218, 219, 220, 221, 223, 224, 225, 227, 229, 230, 233, 234, 236, 237,\n",
      "        238, 240, 244, 245, 246, 248, 252, 253, 254])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  43,\n",
      "         45,  46,  47,  49,  50,  51,  52,  53,  55,  56,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "         75,  76,  77,  79,  80,  81,  82,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119,\n",
      "        120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 141,\n",
      "        142, 143, 144, 145, 146, 147, 149, 151, 152, 153, 156, 158, 160, 162,\n",
      "        163, 164, 166, 167, 168, 171, 173, 174, 175, 177, 180, 181, 183, 184,\n",
      "        185, 187, 188, 189, 191, 194, 195, 196, 197, 198, 199, 200, 201, 203,\n",
      "        204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219,\n",
      "        220, 221, 223, 224, 225, 227, 229, 230, 233, 234, 236, 237, 238, 240,\n",
      "        244, 245, 246, 248, 252, 253, 254])  (len = 203)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 50: layer4.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 43, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58,\n",
      "        59, 60, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 135, 141, 142, 143, 144, 145, 146, 147, 149,\n",
      "        151, 152, 153, 156, 158, 160, 162, 163, 164, 166, 167, 168, 171, 173,\n",
      "        174, 175, 177, 180, 181, 183, 184, 185, 187, 188, 189, 191])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 207, 209, 210,\n",
      "        211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 227,\n",
      "        230, 233, 234, 236, 237, 238, 240, 244, 245, 246, 248, 252, 253, 254])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 50\n",
      "Max diff:\n",
      "tensor([6.4321])\n",
      "\n",
      "tensor([[1.7755e-04, 2.4280e-04, 1.3110e-04, 1.8226e-04, 2.0956e-04, 2.2094e-04,\n",
      "         5.5209e-05, 1.1285e-04, 2.5804e-04, 1.9381e-04, 1.4706e-04, 2.2301e-04,\n",
      "         1.5929e-04, 2.4599e-04, 1.1016e-04, 2.3814e-04, 1.0943e-04, 1.5490e-04,\n",
      "         2.0869e-04, 2.1747e-04, 1.0031e-04, 2.4368e-04, 2.6160e-04, 1.3886e-04,\n",
      "         1.2664e-04, 1.5762e-04, 2.5624e-04, 1.9148e-04, 1.1539e-04, 2.1283e-04,\n",
      "         2.2730e-04, 1.8979e-04, 1.8737e-04, 1.7308e-04, 5.8562e-05, 2.6432e-04,\n",
      "         2.3121e-04, 2.2587e-04, 1.3418e-04, 1.7965e-04, 2.7183e-04, 5.1446e-05,\n",
      "         7.4655e-05, 1.1629e-04, 1.7186e-04, 2.1955e-04, 3.6147e-04, 1.1624e-04,\n",
      "         2.8944e-04, 1.4536e-04, 2.9907e-04, 3.6046e-04, 1.0422e-04, 1.9190e-04,\n",
      "         1.1420e-04, 1.5216e-04, 1.2401e-04, 1.1587e-04, 1.4661e-04, 1.1581e-04,\n",
      "         1.3638e-04, 1.1723e-04, 1.5242e-04, 1.1098e-04, 1.2675e-04, 1.1505e-04,\n",
      "         3.5241e-04, 3.8719e-04, 1.2593e-04, 2.4334e-04, 1.0390e-04, 5.1320e-04,\n",
      "         2.7031e-04, 1.5597e-04, 1.9225e-04, 3.8272e-04, 2.6721e-04, 3.0670e-04,\n",
      "         7.0538e-05, 1.8863e-04, 6.3315e-05, 1.9005e-04, 1.2125e-04, 1.2226e-04,\n",
      "         3.0968e-04, 3.3337e-04, 1.8317e-04, 2.0051e-04, 1.6172e-04, 1.0166e-04,\n",
      "         1.4870e-04, 1.3091e-04, 1.5259e-04, 2.0851e-04, 2.3565e-04, 1.9372e-04,\n",
      "         2.3225e-04, 3.9616e-04, 8.3864e-05, 1.5944e-04, 1.2502e-04, 2.0698e-04,\n",
      "         2.6762e-04, 1.0023e-04, 1.4715e-04, 2.9729e-04, 3.5894e-04, 2.3609e-04,\n",
      "         3.2160e-04, 2.3097e-04, 2.5131e-04, 8.9832e-05, 3.0129e-04, 3.1660e-04,\n",
      "         2.3994e-04, 3.2994e-04, 6.8642e-05, 1.5390e-04, 1.5862e-04, 1.0984e-04,\n",
      "         1.3699e-04, 6.5893e-05, 1.9413e-04, 9.6895e-05, 9.4563e-05, 2.0292e-04,\n",
      "         1.9696e-04, 3.8418e-04, 2.3258e+00, 5.3032e+00, 2.6072e+00, 1.5879e+00,\n",
      "         5.8277e+00, 1.1225e+00, 2.2711e+00, 1.4639e+00, 3.6981e+00, 2.9168e+00,\n",
      "         3.1906e+00, 3.5578e+00, 2.8686e+00, 2.4601e+00, 3.5472e+00, 2.1707e+00,\n",
      "         2.7266e+00, 4.1539e+00, 3.4786e+00, 1.6079e+00, 2.1154e+00, 1.2956e+00,\n",
      "         2.1551e+00, 1.8928e+00, 4.9219e+00, 1.9943e+00, 3.4821e+00, 3.9339e+00,\n",
      "         3.8515e+00, 3.9735e+00, 1.2634e+00, 2.4629e+00, 2.9840e+00, 3.9190e+00,\n",
      "         3.3874e+00, 3.7710e+00, 4.3910e+00, 5.2759e+00, 1.8679e+00, 3.8044e+00,\n",
      "         2.6122e+00, 1.4894e+00, 2.4455e+00, 2.4975e+00, 1.5023e+00, 2.6548e+00,\n",
      "         1.5862e+00, 5.0281e+00, 1.2901e+00, 4.0032e+00, 2.6688e+00, 1.4467e+00,\n",
      "         2.2457e+00, 2.0307e+00, 2.5325e+00, 2.5989e+00, 3.1942e+00, 3.4481e+00,\n",
      "         3.4795e+00, 4.0807e+00, 1.7637e+00, 2.3119e+00, 4.3485e+00, 1.9878e+00,\n",
      "         1.5468e+00, 2.2560e+00, 1.3529e+00, 3.6545e+00, 3.5501e+00, 2.4292e+00,\n",
      "         3.0457e+00, 2.8085e+00, 2.2018e+00, 2.3598e+00, 3.3586e+00, 3.8674e+00,\n",
      "         3.6145e+00, 2.7373e+00, 3.7638e+00, 3.5726e+00, 2.6072e+00, 4.1682e+00,\n",
      "         1.4927e+00, 3.7926e+00, 2.6078e+00, 2.1372e+00, 2.3628e+00, 1.7061e+00,\n",
      "         2.9295e+00, 3.9191e+00, 1.6747e+00, 1.7565e+00, 2.0964e+00, 1.8799e+00,\n",
      "         1.8905e+00, 4.7258e+00, 1.5463e+00, 1.4162e+00, 3.3979e+00, 1.5679e+00,\n",
      "         4.4779e+00, 1.9767e+00, 3.3628e+00, 2.8572e+00, 2.1012e+00, 1.3479e+00,\n",
      "         1.8513e+00, 6.4321e+00, 5.1917e+00, 3.1432e+00, 3.4100e+00, 3.0711e+00,\n",
      "         2.4232e+00, 1.8158e+00, 2.3036e+00, 2.0742e+00, 1.8534e+00, 1.8544e+00,\n",
      "         1.8402e+00, 2.1711e+00, 3.0246e+00, 1.6501e+00, 2.2541e+00, 1.9182e+00,\n",
      "         5.7872e+00, 1.6505e+00, 5.3975e+00, 1.4937e+00, 6.2308e-04, 2.2664e-03,\n",
      "         4.2348e-03, 6.5928e-03, 1.7583e-03, 3.9487e-04, 8.4308e-04, 2.9510e-03,\n",
      "         6.3008e-03, 4.3446e-03, 3.5733e-03, 2.6145e-03, 3.5613e-03, 3.0589e-03,\n",
      "         1.1725e-03, 5.6216e-03, 4.3097e-03, 2.0586e-03, 6.4493e-03, 6.0040e-04,\n",
      "         4.4441e-03, 5.0794e-03, 3.8874e-03, 3.2119e-03, 2.8728e-03, 3.2053e-03,\n",
      "         5.0774e-03, 2.0070e-03, 2.1736e-03, 3.5086e-03, 1.8114e-03, 5.6422e-03,\n",
      "         3.6267e-03, 1.6837e-03, 3.2563e-03, 2.6017e-03, 6.3119e-03, 2.9215e-03,\n",
      "         2.4431e-03, 1.3507e-03, 5.6592e-03, 3.3985e-03, 2.9670e-03, 5.1131e-03,\n",
      "         4.4153e-03, 6.5982e-04, 2.3413e-03, 6.8059e-03, 5.5721e-04, 6.5677e-03,\n",
      "         2.4914e-03, 4.9728e-03, 2.9590e-03, 5.1947e-03, 5.9404e-03, 2.4895e-03,\n",
      "         1.3397e-03, 4.0078e-03, 7.2263e-03, 3.8116e-03, 5.6283e-03, 3.5877e-03,\n",
      "         4.8144e-04, 2.2473e-03, 4.0741e-03, 7.0391e-03, 4.4204e-03, 2.4099e-03,\n",
      "         1.5057e-03, 2.8908e-03, 2.0914e-03, 8.4461e-03, 4.4588e-03, 7.0939e-03,\n",
      "         3.2833e-04, 3.6648e-04, 2.7219e-03, 6.9250e-03, 6.8119e-04, 1.0357e-03,\n",
      "         5.5007e-03, 4.0743e-04, 3.5988e-04, 1.6243e-03, 4.4684e-03, 4.6837e-04,\n",
      "         4.3954e-03, 4.0988e-03, 8.1480e-04, 4.4718e-03, 1.0006e-03, 4.4408e-03,\n",
      "         9.6130e-04, 4.4534e-03, 3.2114e-03, 2.6114e-03, 1.9680e-03, 6.5088e-04,\n",
      "         2.4227e-03, 2.9910e-03, 5.2650e-03, 2.3604e-03, 5.0714e-03, 2.1936e-03,\n",
      "         5.0573e-03, 9.2098e-04, 4.3100e-03, 2.9169e-03, 2.7642e-03, 4.9354e-03,\n",
      "         4.6778e-03, 6.5467e-03, 2.6070e-03, 2.8507e-03, 4.8250e-03, 3.0808e-03,\n",
      "         7.7169e-03, 5.7405e-03, 4.0759e-03, 2.7030e-03, 7.3380e-03, 7.0682e-03,\n",
      "         1.4023e-03, 1.9092e-03, 2.4166e-03, 1.0908e-03, 3.8928e-03, 4.1901e-03,\n",
      "         7.6761e-01, 1.0928e+00, 1.0195e-01, 4.6379e-01, 7.5028e-01, 6.9863e-01,\n",
      "         2.9958e-01, 1.0837e+00, 6.6367e-01, 1.5473e-01, 4.7827e-01, 9.9567e-01,\n",
      "         8.7013e-01, 1.4557e+00, 1.1522e+00, 9.5658e-01, 5.0689e-01, 8.0432e-01,\n",
      "         2.7980e-01, 2.5543e-01, 4.4008e-01, 8.9502e-01, 1.3153e+00, 5.8550e-01,\n",
      "         7.3954e-01, 1.0425e+00, 6.7274e-01, 1.1596e+00, 7.1257e-01, 1.0131e+00,\n",
      "         9.3476e-01, 9.6143e-01, 6.0833e-01, 1.5024e+00, 7.3017e-01, 8.9465e-01,\n",
      "         8.6336e-01, 1.0734e+00, 1.6142e-01, 2.6953e-01, 7.9247e-01, 1.1452e+00,\n",
      "         7.9049e-01, 5.4120e-01, 8.4894e-01, 9.2488e-01, 5.0118e-01, 7.6792e-01,\n",
      "         4.5950e-01, 1.7505e-01, 7.1121e-01, 3.7744e-01, 5.0602e-01, 8.4415e-01,\n",
      "         4.9022e-01, 4.4508e-01, 1.0678e+00, 9.0154e-01, 1.1862e+00, 4.8461e-01,\n",
      "         7.3417e-01, 7.8367e-01, 3.3552e-01, 6.7987e-01, 3.3377e-01, 3.8882e-01,\n",
      "         9.1232e-01, 4.0942e-01, 8.5793e-01, 6.6868e-01, 2.0209e-01, 1.1131e+00,\n",
      "         3.4158e-01, 3.3757e-01, 2.2339e-01, 4.4900e-01, 1.1133e+00, 1.4962e+00,\n",
      "         5.2206e-01, 2.7480e-01, 1.6310e+00, 5.1742e-01, 1.1129e+00, 7.7153e-01,\n",
      "         1.7599e+00, 4.9590e-01, 1.8586e-01, 8.9841e-01, 8.4644e-01, 2.1031e-01,\n",
      "         6.9484e-01, 1.1909e+00, 2.3169e-01, 8.7227e-01, 5.2489e-01, 1.3536e+00,\n",
      "         2.0529e-01, 6.1228e-01, 6.8320e-01, 2.2923e-01, 1.5568e+00, 8.9090e-01,\n",
      "         4.2488e-01, 1.2332e+00, 5.3763e-01, 1.0091e+00, 1.1683e-01, 7.2895e-01,\n",
      "         4.2233e-01, 1.0193e+00, 1.2766e+00, 9.1259e-01, 5.2393e-01, 4.7814e-01,\n",
      "         7.2986e-01, 5.6947e-01, 6.9790e-01, 2.6832e-01, 7.8204e-01, 5.0576e-01,\n",
      "         5.1396e-01, 2.2929e-01, 1.3876e+00, 6.5015e-01, 1.0330e+00, 3.5235e-01,\n",
      "         9.1782e-01, 1.0253e+00]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 51: layer4.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 51\n",
      "Max diff:\n",
      "tensor([1.8239])\n",
      "\n",
      "tensor([[4.9332e-05, 6.1467e-05, 3.5567e-05, 4.8809e-05, 5.5837e-05, 6.2764e-05,\n",
      "         1.4249e-05, 3.0059e-05, 7.4837e-05, 5.1823e-05, 3.9566e-05, 6.0886e-05,\n",
      "         5.0180e-05, 6.9465e-05, 3.1725e-05, 6.8527e-05, 3.1024e-05, 4.2007e-05,\n",
      "         5.7032e-05, 5.7381e-05, 2.9117e-05, 6.6744e-05, 7.2340e-05, 3.6565e-05,\n",
      "         3.0535e-05, 4.4193e-05, 7.0686e-05, 5.4298e-05, 3.2339e-05, 6.0577e-05,\n",
      "         6.1171e-05, 5.4084e-05, 5.3965e-05, 4.8941e-05, 1.6000e-05, 7.2358e-05,\n",
      "         5.9613e-05, 6.1948e-05, 3.6119e-05, 4.8450e-05, 7.3012e-05, 1.4953e-05,\n",
      "         1.9796e-05, 3.4148e-05, 4.9960e-05, 6.0989e-05, 9.8636e-05, 3.0035e-05,\n",
      "         7.7792e-05, 4.0380e-05, 7.9490e-05, 1.0260e-04, 2.7745e-05, 5.5019e-05,\n",
      "         2.9549e-05, 4.0753e-05, 3.4312e-05, 3.0119e-05, 4.3679e-05, 2.9194e-05,\n",
      "         3.7886e-05, 3.2775e-05, 4.1805e-05, 2.9139e-05, 3.3449e-05, 3.3069e-05,\n",
      "         9.6361e-05, 1.0002e-04, 3.3705e-05, 6.9864e-05, 2.9407e-05, 1.5032e-04,\n",
      "         7.4141e-05, 4.5206e-05, 5.3229e-05, 1.0358e-04, 7.0688e-05, 8.7637e-05,\n",
      "         2.0236e-05, 5.5671e-05, 1.8727e-05, 5.8241e-05, 3.2948e-05, 3.3587e-05,\n",
      "         8.5781e-05, 8.5696e-05, 5.2205e-05, 5.3991e-05, 4.5799e-05, 2.7129e-05,\n",
      "         4.1291e-05, 4.0010e-05, 3.9093e-05, 5.6030e-05, 5.8200e-05, 5.0280e-05,\n",
      "         6.1691e-05, 1.0820e-04, 2.4132e-05, 4.6091e-05, 3.3313e-05, 5.5142e-05,\n",
      "         7.5954e-05, 2.6230e-05, 4.0881e-05, 7.6097e-05, 9.2523e-05, 6.1657e-05,\n",
      "         8.4738e-05, 5.4546e-05, 7.1920e-05, 2.2745e-05, 8.9396e-05, 8.5666e-05,\n",
      "         6.1095e-05, 1.0513e-04, 1.9997e-05, 4.1850e-05, 4.3362e-05, 2.9756e-05,\n",
      "         3.9283e-05, 1.7702e-05, 5.5382e-05, 2.4154e-05, 2.6099e-05, 5.8835e-05,\n",
      "         5.3742e-05, 1.0356e-04, 7.7540e-01, 1.2913e+00, 5.6445e-01, 5.5937e-01,\n",
      "         1.3885e+00, 3.4024e-01, 6.1227e-01, 3.7992e-01, 1.1706e+00, 7.6176e-01,\n",
      "         1.1260e+00, 6.7004e-01, 8.3813e-01, 6.5901e-01, 9.9501e-01, 6.0777e-01,\n",
      "         6.3777e-01, 1.0969e+00, 7.2784e-01, 5.2152e-01, 5.5391e-01, 2.3149e-01,\n",
      "         5.6478e-01, 6.0225e-01, 1.2406e+00, 6.6961e-01, 9.3857e-01, 1.1404e+00,\n",
      "         9.4018e-01, 9.6485e-01, 3.3973e-01, 5.3726e-01, 9.3393e-01, 1.1828e+00,\n",
      "         8.4511e-01, 1.0294e+00, 1.2258e+00, 1.8221e+00, 4.1188e-01, 7.6104e-01,\n",
      "         6.6488e-01, 3.7349e-01, 6.1043e-01, 7.2701e-01, 4.3796e-01, 7.9985e-01,\n",
      "         3.9594e-01, 1.0730e+00, 3.6940e-01, 1.1367e+00, 6.8675e-01, 3.9540e-01,\n",
      "         5.6701e-01, 5.2258e-01, 7.3232e-01, 5.8029e-01, 8.2182e-01, 1.0434e+00,\n",
      "         9.4593e-01, 1.0367e+00, 5.0811e-01, 7.0034e-01, 1.0328e+00, 4.6648e-01,\n",
      "         3.5446e-01, 4.2524e-01, 3.7446e-01, 8.3977e-01, 8.6229e-01, 6.7728e-01,\n",
      "         6.4530e-01, 8.4658e-01, 5.5865e-01, 7.4449e-01, 1.1208e+00, 1.2902e+00,\n",
      "         1.1080e+00, 7.4982e-01, 1.0600e+00, 9.2089e-01, 7.9111e-01, 1.2101e+00,\n",
      "         4.3321e-01, 8.6749e-01, 8.5991e-01, 5.7807e-01, 6.0256e-01, 5.0771e-01,\n",
      "         6.4002e-01, 1.1638e+00, 4.5594e-01, 4.9907e-01, 5.1210e-01, 4.9273e-01,\n",
      "         5.0116e-01, 1.4660e+00, 3.2337e-01, 4.0877e-01, 9.1976e-01, 3.7435e-01,\n",
      "         1.6975e+00, 6.6242e-01, 1.0885e+00, 7.6504e-01, 5.1449e-01, 3.4531e-01,\n",
      "         4.8768e-01, 1.8239e+00, 1.4063e+00, 1.0130e+00, 9.6070e-01, 7.1102e-01,\n",
      "         6.2433e-01, 4.9359e-01, 7.8686e-01, 6.3891e-01, 6.8275e-01, 3.3946e-01,\n",
      "         5.0781e-01, 7.4596e-01, 7.1301e-01, 5.8998e-01, 6.7243e-01, 5.2415e-01,\n",
      "         1.5598e+00, 4.9058e-01, 1.3548e+00, 4.4617e-01, 1.6006e-04, 4.2397e-04,\n",
      "         7.4258e-04, 9.6513e-04, 3.3329e-04, 1.0416e-04, 1.9046e-04, 4.6137e-04,\n",
      "         1.4073e-03, 1.4345e-03, 7.3397e-04, 3.4022e-04, 7.2057e-04, 4.6083e-04,\n",
      "         2.7107e-04, 1.2448e-03, 8.7028e-04, 2.8007e-04, 8.6488e-04, 1.4812e-04,\n",
      "         1.2088e-03, 9.3538e-04, 7.5516e-04, 7.7599e-04, 9.3174e-04, 4.2041e-04,\n",
      "         1.2156e-03, 2.2092e-04, 4.8819e-04, 1.1667e-03, 4.1419e-04, 1.8637e-03,\n",
      "         5.5692e-04, 3.5915e-04, 7.3291e-04, 7.0530e-04, 1.1874e-03, 9.1434e-04,\n",
      "         7.8858e-04, 3.2327e-04, 1.8455e-03, 3.3164e-04, 6.0944e-04, 1.4892e-03,\n",
      "         1.3494e-03, 1.6749e-04, 4.8219e-04, 1.4943e-03, 1.4161e-04, 1.2596e-03,\n",
      "         4.5377e-04, 6.5977e-04, 9.6251e-04, 8.8207e-04, 7.5454e-04, 3.6658e-04,\n",
      "         2.7874e-04, 2.5433e-04, 1.6904e-03, 9.4786e-04, 1.2330e-03, 8.3259e-04,\n",
      "         1.2453e-04, 3.9758e-04, 1.3770e-03, 1.0482e-03, 8.0535e-04, 3.0084e-04,\n",
      "         3.3320e-04, 6.5021e-04, 2.5575e-04, 2.5361e-03, 1.5343e-03, 1.1966e-03,\n",
      "         7.8583e-05, 9.3743e-05, 4.9278e-04, 8.9779e-04, 1.8633e-04, 2.7727e-04,\n",
      "         1.7241e-03, 9.9741e-05, 9.4693e-05, 3.4490e-04, 5.2527e-04, 1.0984e-04,\n",
      "         1.4124e-03, 8.1825e-04, 2.0988e-04, 6.4792e-04, 2.6756e-04, 1.1007e-03,\n",
      "         2.5824e-04, 5.7522e-04, 7.4080e-04, 3.4647e-04, 6.1828e-04, 1.8110e-04,\n",
      "         5.0304e-04, 6.3890e-04, 1.0675e-03, 5.2188e-04, 1.6084e-03, 5.1226e-04,\n",
      "         8.7649e-04, 2.5172e-04, 6.7057e-04, 6.4372e-04, 5.8898e-04, 1.3319e-03,\n",
      "         4.6328e-04, 1.5261e-03, 4.6765e-04, 5.6202e-04, 1.2356e-03, 4.3046e-04,\n",
      "         1.6273e-03, 1.5659e-03, 1.1689e-03, 2.1680e-04, 1.3837e-03, 1.1192e-03,\n",
      "         2.1932e-04, 3.8345e-04, 6.3597e-04, 2.5401e-04, 1.2595e-03, 1.1147e-03,\n",
      "         1.5093e-01, 7.0063e-02, 2.4238e-02, 1.0300e-01, 1.9644e-01, 2.1963e-01,\n",
      "         7.2857e-02, 1.8099e-01, 1.6960e-01, 4.0925e-02, 1.1185e-01, 2.1675e-01,\n",
      "         2.1216e-01, 5.3617e-01, 2.9252e-01, 3.6212e-01, 9.7748e-02, 4.0648e-01,\n",
      "         7.8904e-02, 7.2033e-02, 1.1581e-01, 2.0958e-01, 3.7944e-01, 6.9177e-02,\n",
      "         2.1954e-01, 1.4717e-01, 1.9256e-01, 2.1738e-01, 1.1990e-01, 2.4738e-01,\n",
      "         1.8144e-01, 2.1891e-01, 1.4807e-01, 3.3343e-01, 2.8809e-01, 2.3418e-01,\n",
      "         1.2680e-01, 1.8791e-01, 4.3453e-02, 6.8853e-02, 5.3375e-02, 3.3390e-01,\n",
      "         1.4421e-01, 1.8612e-01, 2.9553e-01, 1.5266e-01, 1.1658e-01, 1.9071e-01,\n",
      "         1.2933e-01, 4.4200e-02, 1.9327e-01, 9.5607e-02, 1.4304e-01, 2.2241e-01,\n",
      "         1.2966e-01, 1.1984e-01, 4.3869e-01, 2.7343e-01, 3.1198e-01, 1.1386e-01,\n",
      "         2.3978e-01, 1.6612e-01, 1.0073e-01, 1.2950e-01, 1.2542e-01, 1.2461e-01,\n",
      "         1.9226e-01, 9.9429e-02, 2.2096e-01, 1.6754e-01, 5.5109e-02, 3.2057e-01,\n",
      "         1.0449e-01, 1.2209e-01, 9.6543e-02, 1.1594e-01, 2.5092e-01, 5.0730e-01,\n",
      "         1.1870e-01, 5.4104e-02, 4.3121e-01, 7.7875e-02, 2.7266e-01, 1.9147e-01,\n",
      "         5.3780e-01, 8.3907e-02, 5.0108e-02, 2.4166e-01, 2.1340e-01, 5.4700e-02,\n",
      "         2.0115e-01, 3.6049e-01, 6.3670e-02, 3.4429e-01, 1.2106e-01, 4.8091e-01,\n",
      "         5.1451e-02, 1.3284e-01, 3.1598e-01, 6.0275e-02, 3.5506e-01, 2.5453e-01,\n",
      "         1.6502e-01, 2.2185e-01, 7.8335e-02, 1.5725e-01, 3.2571e-02, 1.2551e-01,\n",
      "         9.4186e-02, 2.6776e-01, 1.5177e-01, 1.7431e-01, 1.4190e-01, 1.4713e-01,\n",
      "         1.7971e-01, 1.0989e-01, 2.4950e-01, 8.0270e-02, 1.8742e-01, 1.7551e-01,\n",
      "         1.5007e-01, 6.2090e-02, 3.0749e-01, 2.1333e-01, 2.0922e-01, 1.2975e-01,\n",
      "         1.5028e-01, 1.7122e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 52: layer4.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 52\n",
      "Max diff:\n",
      "tensor([1.5598])\n",
      "\n",
      "tensor([[4.9332e-05, 6.1467e-05, 3.5567e-05, 4.8809e-05, 5.5837e-05, 6.2764e-05,\n",
      "         1.4249e-05, 3.0059e-05, 7.4837e-05, 5.1823e-05, 3.9566e-05, 6.0886e-05,\n",
      "         5.0180e-05, 6.9465e-05, 3.1725e-05, 6.8527e-05, 3.1024e-05, 4.2007e-05,\n",
      "         5.7032e-05, 5.7381e-05, 2.9117e-05, 6.4902e-05, 7.2340e-05, 3.6565e-05,\n",
      "         2.2331e-05, 4.4193e-05, 7.0686e-05, 5.4298e-05, 3.2339e-05, 6.0577e-05,\n",
      "         6.1171e-05, 5.4084e-05, 5.2920e-05, 4.8941e-05, 1.6000e-05, 6.0083e-05,\n",
      "         1.1015e-05, 6.1948e-05, 3.6119e-05, 4.8450e-05, 7.3012e-05, 1.4953e-05,\n",
      "         1.9796e-05, 3.4148e-05, 4.9960e-05, 6.0989e-05, 6.2339e-05, 3.0035e-05,\n",
      "         5.2201e-05, 4.0380e-05, 7.9490e-05, 1.0260e-04, 1.6199e-05, 5.5019e-05,\n",
      "         2.9549e-05, 4.0753e-05, 3.4312e-05, 3.0119e-05, 4.3679e-05, 1.8133e-05,\n",
      "         3.7886e-05, 3.2775e-05, 4.1805e-05, 2.9139e-05, 3.3449e-05, 3.3069e-05,\n",
      "         9.6361e-05, 8.1716e-05, 3.3705e-05, 6.9864e-05, 2.9407e-05, 1.3025e-04,\n",
      "         7.4141e-05, 4.5206e-05, 4.3694e-05, 9.0042e-05, 7.0688e-05, 8.7637e-05,\n",
      "         2.0236e-05, 5.5671e-05, 1.8727e-05, 5.8241e-05, 3.2948e-05, 3.3587e-05,\n",
      "         8.0127e-05, 8.3024e-05, 4.9134e-05, 5.3991e-05, 4.5799e-05, 5.7835e-07,\n",
      "         4.1291e-05, 4.0010e-05, 3.9093e-05, 5.6030e-05, 5.8200e-05, 5.0280e-05,\n",
      "         6.1691e-05, 1.0820e-04, 1.3959e-05, 4.6091e-05, 3.3313e-05, 5.5142e-05,\n",
      "         7.5954e-05, 2.6230e-05, 4.0881e-05, 7.6097e-05, 5.9145e-05, 6.1657e-05,\n",
      "         8.4738e-05, 1.3973e-05, 7.1920e-05, 2.2745e-05, 8.9396e-05, 8.5666e-05,\n",
      "         4.4249e-05, 1.0513e-04, 1.9997e-05, 4.1850e-05, 3.2152e-05, 2.9756e-05,\n",
      "         3.9283e-05, 1.7702e-05, 5.5382e-05, 0.0000e+00, 2.6099e-05, 5.8835e-05,\n",
      "         5.3742e-05, 1.0356e-04, 5.3162e-01, 0.0000e+00, 0.0000e+00, 5.5937e-01,\n",
      "         2.8139e-01, 2.6720e-01, 6.1227e-01, 4.2791e-02, 0.0000e+00, 1.5164e-01,\n",
      "         8.4892e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9501e-01, 0.0000e+00,\n",
      "         5.1207e-01, 8.3258e-01, 5.9205e-01, 4.2756e-01, 1.5700e-01, 0.0000e+00,\n",
      "         6.9044e-02, 3.3480e-01, 8.5644e-01, 4.4061e-02, 3.6623e-02, 0.0000e+00,\n",
      "         0.0000e+00, 9.6485e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.1327e-01, 8.8607e-01, 0.0000e+00, 1.3962e+00, 2.1826e-01, 1.6861e-01,\n",
      "         3.5721e-01, 3.7349e-01, 0.0000e+00, 6.0859e-02, 2.1815e-01, 0.0000e+00,\n",
      "         2.6395e-01, 1.0730e+00, 2.3375e-01, 1.1367e+00, 6.8675e-01, 1.2179e-01,\n",
      "         5.6701e-01, 0.0000e+00, 1.1751e-01, 5.8029e-01, 1.7895e-01, 8.0133e-01,\n",
      "         0.0000e+00, 4.1309e-01, 2.6542e-01, 0.0000e+00, 0.0000e+00, 1.5224e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6229e-01, 6.4792e-01,\n",
      "         1.7235e-01, 5.2184e-01, 5.5865e-01, 0.0000e+00, 0.0000e+00, 1.2902e+00,\n",
      "         4.7829e-01, 0.0000e+00, 7.5437e-01, 1.1778e-01, 0.0000e+00, 1.2101e+00,\n",
      "         1.8980e-01, 5.1208e-01, 4.5244e-01, 0.0000e+00, 6.0256e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.2846e-01, 4.9907e-01, 6.8389e-02, 0.0000e+00,\n",
      "         4.5737e-01, 1.4660e+00, 3.2337e-01, 0.0000e+00, 7.3217e-01, 3.2872e-01,\n",
      "         3.0481e-01, 1.6996e-01, 6.1397e-01, 0.0000e+00, 3.9840e-01, 3.3927e-01,\n",
      "         1.3177e-01, 8.7936e-01, 1.4063e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.8686e-01, 2.1267e-01, 0.0000e+00, 0.0000e+00,\n",
      "         1.1464e-01, 7.4596e-01, 7.1301e-01, 1.1877e-01, 4.7217e-01, 3.7020e-01,\n",
      "         1.5598e+00, 2.5878e-01, 4.6479e-01, 2.4141e-01, 0.0000e+00, 9.1143e-05,\n",
      "         0.0000e+00, 1.9493e-04, 3.3329e-04, 0.0000e+00, 0.0000e+00, 4.5268e-04,\n",
      "         2.7257e-04, 3.7942e-04, 7.3397e-04, 0.0000e+00, 5.5547e-04, 0.0000e+00,\n",
      "         0.0000e+00, 5.7545e-05, 8.7028e-04, 2.8007e-04, 2.3479e-04, 0.0000e+00,\n",
      "         1.0535e-03, 9.3538e-04, 6.1736e-04, 0.0000e+00, 9.3174e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4567e-04, 0.0000e+00, 1.8637e-03,\n",
      "         0.0000e+00, 0.0000e+00, 7.3291e-04, 0.0000e+00, 5.3282e-04, 9.1434e-04,\n",
      "         7.8858e-04, 0.0000e+00, 1.8455e-03, 3.1206e-04, 0.0000e+00, 5.7156e-04,\n",
      "         1.3494e-03, 0.0000e+00, 0.0000e+00, 1.1203e-03, 0.0000e+00, 1.2596e-03,\n",
      "         4.5377e-04, 6.5977e-04, 9.6251e-04, 7.1205e-04, 0.0000e+00, 3.6658e-04,\n",
      "         0.0000e+00, 2.5433e-04, 8.5311e-04, 3.1382e-04, 4.5065e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.7073e-04, 4.4464e-04, 8.0535e-04, 3.0084e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5361e-03, 8.2074e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9779e-04, 0.0000e+00, 0.0000e+00,\n",
      "         7.3266e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4124e-03, 8.1825e-04, 0.0000e+00, 6.4792e-04, 3.6159e-05, 9.0152e-07,\n",
      "         0.0000e+00, 3.6058e-04, 0.0000e+00, 3.4053e-04, 2.1752e-05, 0.0000e+00,\n",
      "         0.0000e+00, 6.3890e-04, 3.2226e-04, 0.0000e+00, 1.0117e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.7057e-04, 0.0000e+00, 5.8898e-04, 7.8883e-04,\n",
      "         0.0000e+00, 3.1129e-04, 0.0000e+00, 5.6202e-04, 7.6282e-04, 2.0092e-04,\n",
      "         5.1135e-04, 1.2277e-03, 1.1689e-03, 0.0000e+00, 6.2142e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2595e-03, 1.1147e-03,\n",
      "         0.0000e+00, 1.4572e-02, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1185e-01, 0.0000e+00,\n",
      "         2.1216e-01, 0.0000e+00, 7.6311e-02, 4.5095e-02, 2.5686e-02, 1.9603e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8606e-02, 0.0000e+00, 2.2334e-02,\n",
      "         0.0000e+00, 0.0000e+00, 1.9256e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4435e-01, 1.7403e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3375e-02, 0.0000e+00,\n",
      "         0.0000e+00, 1.8612e-01, 0.0000e+00, 0.0000e+00, 9.4897e-02, 1.9071e-01,\n",
      "         1.2933e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2276e-03, 0.0000e+00,\n",
      "         0.0000e+00, 8.3346e-02, 0.0000e+00, 3.4039e-02, 0.0000e+00, 1.1386e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2950e-01, 7.6482e-02, 1.2461e-01,\n",
      "         0.0000e+00, 9.9429e-02, 0.0000e+00, 1.6754e-01, 0.0000e+00, 0.0000e+00,\n",
      "         1.0449e-01, 0.0000e+00, 9.6543e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7875e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3311e-02, 1.7749e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2170e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.4651e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3595e-01, 0.0000e+00, 7.8335e-02, 3.0679e-02, 0.0000e+00, 0.0000e+00,\n",
      "         1.7190e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6339e-02, 0.0000e+00,\n",
      "         0.0000e+00, 6.3588e-02, 0.0000e+00, 0.0000e+00, 1.0809e-01, 1.7551e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8491e-02, 7.0574e-02, 0.0000e+00,\n",
      "         0.0000e+00, 1.6863e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126,\n",
      "        127, 128, 131, 132, 133, 134, 135, 137, 138, 142, 144, 145, 146, 147,\n",
      "        148, 150, 151, 152, 153, 154, 157, 162, 163, 165, 166, 167, 168, 169,\n",
      "        171, 172, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187,\n",
      "        188, 191, 196, 197, 198, 199, 200, 203, 204, 206, 207, 209, 210, 211,\n",
      "        212, 214, 218, 219, 220, 222, 223, 224, 226, 227, 228, 229, 230, 232,\n",
      "        233, 234, 235, 236, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 257, 259, 260, 263, 264, 265, 266, 268, 271, 272, 273, 274,\n",
      "        276, 277, 278, 280, 285, 287, 290, 292, 293, 294, 296, 297, 299, 300,\n",
      "        303, 305, 306, 307, 308, 309, 311, 313, 314, 315, 316, 320, 321, 322,\n",
      "        323, 327, 328, 333, 336, 342, 343, 345, 346, 347, 349, 351, 352, 355,\n",
      "        356, 358, 362, 364, 365, 367, 369, 370, 371, 372, 373, 374, 376, 382,\n",
      "        383, 385, 387, 394, 396, 398, 399, 400, 401, 405, 407, 410, 418, 419,\n",
      "        424, 427, 430, 431, 432, 436, 439, 441, 443, 447, 448, 449, 451, 453,\n",
      "        456, 458, 465, 471, 472, 477, 482, 486, 488, 489, 492, 496, 499, 502,\n",
      "        503, 507, 508, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126,\n",
      "        127, 128, 131, 133, 134, 137, 138, 142, 144, 145, 146, 147, 148, 150,\n",
      "        151, 152, 157, 162, 163, 165, 166, 167, 168, 169, 172, 174, 175, 176,\n",
      "        177, 178, 179, 180, 182, 183, 184, 185, 188, 191, 196, 197, 198, 199,\n",
      "        200, 203, 204, 206, 209, 210, 211, 212, 214, 218, 219, 220, 222, 223,\n",
      "        224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 242, 243, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255, 257, 259, 260, 263, 264, 265,\n",
      "        266, 268, 271, 272, 273, 274, 276, 277, 278, 280, 285, 287, 290, 292,\n",
      "        293, 294, 296, 297, 299, 300, 303, 305, 306, 307, 308, 309, 311, 313,\n",
      "        314, 315, 316, 320, 321, 322, 323, 327, 328, 333, 336, 342, 343, 345,\n",
      "        346, 347, 349, 351, 352, 355, 356, 358, 362, 364, 365, 367, 369, 370,\n",
      "        371, 372, 373, 374, 376, 382, 383, 385, 387, 394, 396, 398, 399, 400,\n",
      "        401, 405, 407, 410, 418, 419, 424, 427, 430, 431, 432, 436, 439, 441,\n",
      "        443, 447, 448, 449, 451, 453, 456, 458, 465, 471, 472, 477, 482, 486,\n",
      "        488, 489, 496, 499, 502, 503, 507, 508, 511])  (len = 317)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 53: layer4.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126,\n",
      "        127])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 131, 132, 133, 134, 135, 137, 138, 142, 144, 145, 146, 147, 148,\n",
      "        150, 151, 152, 153, 154, 157, 162, 163, 165, 166, 167, 168, 169, 171,\n",
      "        172, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 187, 188, 191,\n",
      "        196, 197, 198, 199, 200, 203, 204, 206, 207, 209, 210, 211, 212, 214,\n",
      "        218, 219, 220, 222, 223, 224, 226, 227, 228, 229, 230, 232, 233, 234,\n",
      "        235, 236, 242, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([257, 259, 260, 263, 264, 265, 266, 268, 271, 272, 273, 274, 276, 277,\n",
      "        278, 280, 285, 287, 290, 292, 293, 294, 296, 297, 299, 300, 303, 305,\n",
      "        306, 307, 308, 309, 311, 313, 314, 315, 316, 320, 321, 322, 323, 327,\n",
      "        328, 333, 336, 342, 343, 345, 346, 347, 349, 351, 352, 355, 356, 358,\n",
      "        362, 364, 365, 367, 369, 370, 371, 372, 373, 374, 376, 382, 383])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([385, 387, 394, 396, 398, 399, 401, 405, 407, 410, 418, 419, 424, 427,\n",
      "        430, 431, 432, 436, 439, 441, 443, 447, 448, 449, 451, 453, 456, 458,\n",
      "        465, 471, 472, 477, 482, 486, 488, 489, 492, 496, 499, 502, 503, 507,\n",
      "        508, 511])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 53\n",
      "Max diff:\n",
      "tensor([5.9597])\n",
      "\n",
      "tensor([[8.7798e-05, 3.0138e-05, 5.0310e-06, 8.4095e-05, 3.5614e-05, 4.4614e-05,\n",
      "         8.0033e-06, 9.8944e-05, 5.0571e-06, 3.5949e-05, 7.7570e-06, 8.5458e-06,\n",
      "         2.2754e-05, 9.0361e-05, 1.9355e-06, 1.0425e-04, 2.5641e-05, 3.9488e-05,\n",
      "         3.8274e-05, 6.5163e-05, 1.9677e-05, 8.4043e-05, 2.3529e-05, 1.2759e-05,\n",
      "         2.3693e-05, 1.7703e-05, 8.1800e-05, 6.9797e-05, 8.4870e-05, 2.2620e-05,\n",
      "         6.6079e-05, 2.1871e-05, 1.2137e-05, 7.6517e-05, 9.1821e-05, 6.7666e-05,\n",
      "         1.8016e-05, 5.3470e-06, 4.9626e-06, 6.1393e-05, 9.9037e-06, 2.1111e-05,\n",
      "         7.1853e-05, 3.7621e-06, 1.2489e-05, 3.7126e-05, 7.1041e-05, 7.9237e-06,\n",
      "         1.9316e-05, 5.5477e-05, 8.2329e-06, 1.3120e-05, 8.3923e-05, 9.9726e-06,\n",
      "         9.4816e-05, 6.3665e-05, 9.0241e-05, 5.0001e-05, 7.6648e-06, 4.5460e-05,\n",
      "         6.3851e-05, 5.4175e-06, 5.7206e-05, 2.0386e-05, 1.5631e-05, 1.3236e-05,\n",
      "         1.6019e-05, 7.8037e-05, 7.0639e-05, 5.9150e-05, 1.4089e-05, 2.5973e-05,\n",
      "         1.8358e-05, 3.9816e-05, 3.4932e-05, 6.3945e-06, 1.2235e-05, 7.2137e-05,\n",
      "         3.0953e-05, 1.2137e-05, 8.8692e-05, 9.3793e-06, 5.9307e-06, 6.2972e-05,\n",
      "         1.1490e-05, 8.5145e-05, 3.6806e-05, 2.6386e-05, 2.1700e-05, 8.5142e-06,\n",
      "         1.1057e-04, 1.2357e-05, 7.4329e-06, 4.3668e-05, 8.3953e-05, 1.0400e-04,\n",
      "         6.3530e-06, 6.7346e-05, 1.0017e-05, 9.1016e-05, 1.7170e-05, 3.6493e-05,\n",
      "         7.1563e-06, 1.1371e-04, 2.4912e-05, 8.7082e-05, 8.5570e-05, 7.0478e-06,\n",
      "         4.5449e-05, 9.1910e-05, 7.8388e-05, 6.0640e-05, 5.6304e-05, 8.7786e-06,\n",
      "         2.7880e-05, 5.0686e-05, 9.5218e-05, 1.7233e-05, 7.8436e-06, 5.3689e-05,\n",
      "         4.2886e-05, 5.5470e-05, 3.9838e-05, 2.2985e-05, 1.4819e-05, 5.6013e-05,\n",
      "         2.5839e-05, 7.6871e-06, 1.4672e+00, 3.8615e+00, 2.4700e+00, 3.0073e+00,\n",
      "         2.2667e+00, 3.1164e+00, 1.4977e+00, 2.2817e+00, 2.3617e+00, 1.5449e+00,\n",
      "         2.7295e+00, 2.0556e+00, 1.1829e+00, 2.1526e+00, 2.8417e+00, 3.2909e+00,\n",
      "         1.2086e+00, 2.9406e+00, 2.8565e+00, 1.4501e+00, 3.6261e+00, 2.9618e+00,\n",
      "         2.0960e+00, 3.0905e+00, 2.5523e+00, 2.0269e+00, 2.9759e+00, 3.0501e+00,\n",
      "         6.6406e-01, 3.5070e+00, 1.4943e+00, 2.9604e+00, 1.3580e+00, 2.6146e+00,\n",
      "         1.6531e+00, 1.6874e+00, 1.7835e+00, 3.0050e+00, 2.9985e+00, 1.9174e+00,\n",
      "         3.0040e+00, 1.1663e+00, 2.0297e+00, 4.2006e+00, 2.2836e+00, 1.4174e+00,\n",
      "         2.6416e+00, 2.3982e+00, 2.8671e+00, 3.0841e+00, 3.1714e+00, 4.5962e+00,\n",
      "         1.6171e+00, 3.4708e+00, 3.0607e+00, 1.9669e+00, 2.1604e+00, 2.0824e+00,\n",
      "         1.7690e+00, 4.4923e+00, 2.2905e+00, 1.7490e+00, 2.2803e+00, 4.0144e+00,\n",
      "         2.7216e+00, 3.8774e+00, 1.6669e+00, 4.1375e+00, 3.1245e+00, 1.8997e+00,\n",
      "         2.9110e+00, 2.3206e+00, 4.3598e+00, 2.4428e+00, 1.9629e+00, 2.5338e+00,\n",
      "         4.5939e+00, 4.5913e+00, 3.8766e+00, 2.9461e+00, 1.9466e+00, 2.6890e+00,\n",
      "         2.1935e+00, 1.7790e+00, 2.2053e+00, 2.1252e+00, 1.5372e+00, 2.8159e+00,\n",
      "         1.1122e+00, 2.7658e+00, 1.5810e+00, 1.5690e+00, 4.3198e+00, 2.7154e+00,\n",
      "         1.9392e+00, 1.2690e+00, 3.5942e+00, 2.6769e+00, 2.2657e+00, 1.7088e+00,\n",
      "         3.4243e+00, 3.7524e+00, 5.9597e+00, 3.5230e+00, 1.7971e+00, 2.6649e+00,\n",
      "         2.7457e+00, 2.3197e+00, 1.5083e+00, 2.9316e+00, 2.3167e+00, 1.7290e+00,\n",
      "         3.0377e+00, 1.5006e+00, 1.1902e+00, 3.6359e+00, 1.0946e+00, 1.9306e+00,\n",
      "         2.7460e+00, 1.8927e+00, 2.5218e+00, 1.7938e+00, 4.4512e+00, 1.7574e+00,\n",
      "         2.2260e+00, 1.0921e+00, 3.3795e+00, 1.8364e+00, 3.8946e-04, 4.1342e-03,\n",
      "         4.1851e-03, 3.4097e-04, 4.8599e-04, 2.4393e-03, 7.4489e-03, 3.4935e-03,\n",
      "         5.7054e-04, 8.9109e-04, 5.7771e-03, 2.2577e-04, 5.7983e-03, 4.8085e-03,\n",
      "         4.1279e-03, 5.1179e-03, 2.7941e-03, 3.8332e-03, 4.2777e-03, 4.2239e-03,\n",
      "         3.3022e-03, 2.0914e-03, 3.4175e-03, 4.1121e-04, 9.2340e-03, 3.2558e-03,\n",
      "         7.0753e-03, 3.3761e-03, 1.4139e-03, 3.9451e-03, 2.2222e-03, 4.1583e-04,\n",
      "         2.5758e-04, 4.8428e-03, 2.6590e-03, 6.6374e-03, 5.3203e-04, 2.8980e-03,\n",
      "         5.1036e-03, 6.1557e-03, 1.0898e-03, 2.3103e-03, 5.6273e-04, 4.1142e-03,\n",
      "         3.4202e-03, 3.6639e-04, 6.9795e-03, 2.2342e-03, 6.6104e-03, 4.1527e-04,\n",
      "         7.9165e-03, 7.0947e-04, 6.4645e-03, 4.9931e-04, 6.8350e-03, 6.1798e-03,\n",
      "         5.2395e-03, 3.0661e-03, 4.9999e-04, 9.6612e-03, 1.2496e-03, 5.5450e-04,\n",
      "         1.9438e-03, 3.2184e-04, 5.7325e-03, 2.6746e-03, 8.8281e-03, 5.0917e-03,\n",
      "         2.9027e-03, 5.4294e-04, 1.8057e-04, 3.0365e-03, 4.6096e-03, 4.9206e-03,\n",
      "         4.9734e-04, 3.4721e-03, 4.5910e-03, 7.1180e-04, 7.0810e-04, 2.8279e-03,\n",
      "         4.1991e-04, 3.7756e-03, 2.4383e-03, 1.1718e-03, 4.3753e-03, 2.9984e-03,\n",
      "         7.6365e-03, 3.4180e-03, 3.2339e-04, 5.4682e-03, 3.0731e-04, 2.8905e-04,\n",
      "         6.4701e-04, 3.5233e-03, 3.7837e-03, 1.1692e-03, 3.6788e-04, 3.3169e-03,\n",
      "         6.3148e-03, 6.1071e-04, 4.1842e-03, 4.9484e-03, 3.8773e-04, 6.4032e-03,\n",
      "         3.2611e-03, 5.2524e-03, 5.0206e-03, 3.3753e-03, 2.4861e-04, 3.8549e-04,\n",
      "         1.8028e-03, 4.6456e-04, 4.4827e-03, 1.4031e-03, 2.0579e-03, 3.4222e-04,\n",
      "         3.6352e-03, 9.6507e-03, 4.3360e-03, 3.4229e-03, 3.0872e-04, 4.6712e-04,\n",
      "         2.3251e-03, 3.7727e-03, 5.5853e-04, 4.2470e-03, 7.8307e-03, 3.6708e-04,\n",
      "         4.9390e-01, 3.1480e-01, 2.9525e-01, 3.6069e-01, 4.7456e-01, 3.3979e-01,\n",
      "         1.5515e-01, 2.3149e-01, 1.7265e-02, 2.6185e-01, 4.0910e-01, 2.2810e-01,\n",
      "         1.8528e-01, 3.2722e-01, 3.1270e-01, 3.3465e-01, 3.8048e-01, 2.4361e-01,\n",
      "         2.6757e-01, 4.6733e-01, 3.4864e-01, 1.9684e-01, 4.9466e-01, 3.1137e-01,\n",
      "         5.5750e-01, 4.6237e-01, 4.3689e-01, 2.3523e-01, 1.9633e-01, 2.6133e-01,\n",
      "         2.8258e-01, 4.6536e-01, 2.3291e-01, 2.1476e-01, 5.6804e-01, 1.9180e-01,\n",
      "         3.0056e-01, 3.9129e-01, 1.8158e-01, 2.9072e-01, 1.9445e-01, 2.0870e-01,\n",
      "         1.1751e-01, 2.2548e-01, 4.2115e-01, 1.7510e-01, 8.1858e-02, 2.4068e-01,\n",
      "         2.1798e-01, 6.3807e-01, 2.6766e-01, 4.6381e-01, 1.6791e-01, 1.6678e-01,\n",
      "         2.0424e-01, 2.7414e-01, 3.0579e-01, 1.5540e-01, 1.8762e-01, 5.5798e-01,\n",
      "         1.9504e-01, 2.8671e-01, 2.0017e-01, 3.6157e-01, 2.7278e-01, 3.4165e-01,\n",
      "         4.7207e-01, 3.7137e-01, 3.9107e-01, 2.5885e-01, 2.0716e-01, 3.5404e-01,\n",
      "         1.7582e-01, 2.5834e-01, 2.2702e-01, 2.3203e-01, 3.7879e-01, 4.0876e-01,\n",
      "         2.9767e-01, 3.4467e-01, 3.6550e-01, 5.0961e-01, 3.1602e-01, 2.9972e-01,\n",
      "         5.3669e-01, 2.4540e-01, 2.2174e-01, 5.3503e-01, 2.5006e-01, 3.8045e-01,\n",
      "         6.3179e-01, 1.5501e-01, 3.9463e-01, 9.6026e-03, 1.7378e-01, 3.3376e-01,\n",
      "         3.9993e-01, 2.1247e-01, 5.1421e-01, 4.8172e-01, 3.2508e-01, 2.8706e-01,\n",
      "         4.8253e-01, 2.6740e-01, 4.1165e-01, 2.5985e-01, 2.1002e-01, 3.4682e-01,\n",
      "         5.7064e-01, 1.4829e-01, 4.3211e-01, 2.2267e-01, 2.7848e-01, 3.9093e-01,\n",
      "         1.8262e-01, 1.8970e-01, 1.1297e-01, 7.1906e-01, 2.1285e-01, 1.8310e-01,\n",
      "         3.3128e-01, 3.6701e-01, 5.5199e-01, 3.1013e-01, 2.5825e-01, 2.3539e-01,\n",
      "         1.7597e-01, 2.9940e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 54: layer4.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 54\n",
      "Max diff:\n",
      "tensor([2.3362])\n",
      "\n",
      "tensor([[3.1259e-05, 8.7582e-06, 1.3802e-06, 2.6939e-05, 1.0261e-05, 1.3653e-05,\n",
      "         1.9991e-06, 2.6851e-05, 1.4156e-06, 1.0497e-05, 2.0526e-06, 2.6561e-06,\n",
      "         6.0210e-06, 2.7047e-05, 4.7684e-07, 2.6489e-05, 7.2262e-06, 1.2612e-05,\n",
      "         1.0053e-05, 1.7256e-05, 5.3262e-06, 2.3694e-05, 6.2886e-06, 3.5993e-06,\n",
      "         7.6368e-06, 4.7749e-06, 2.4690e-05, 2.0875e-05, 2.2776e-05, 6.3498e-06,\n",
      "         1.9397e-05, 7.2643e-06, 3.3043e-06, 2.4290e-05, 2.4289e-05, 1.4931e-05,\n",
      "         5.5870e-06, 1.4151e-06, 1.3653e-06, 1.7096e-05, 2.7651e-06, 6.4317e-06,\n",
      "         2.5611e-05, 9.1386e-07, 3.7360e-06, 1.0122e-05, 1.6266e-05, 2.1355e-06,\n",
      "         5.3030e-06, 1.5534e-05, 2.1670e-06, 4.0058e-06, 2.4287e-05, 2.6058e-06,\n",
      "         2.7997e-05, 1.9194e-05, 3.0017e-05, 1.4710e-05, 1.9995e-06, 1.5317e-05,\n",
      "         1.5523e-05, 1.5260e-06, 1.7229e-05, 5.6401e-06, 4.5395e-06, 3.5027e-06,\n",
      "         4.9458e-06, 2.5459e-05, 1.9459e-05, 1.6839e-05, 3.8128e-06, 7.2643e-06,\n",
      "         5.3582e-06, 1.1461e-05, 1.0674e-05, 1.7304e-06, 3.2559e-06, 1.9019e-05,\n",
      "         9.5936e-06, 3.2885e-06, 2.7975e-05, 2.9340e-06, 1.6866e-06, 1.9765e-05,\n",
      "         3.3118e-06, 2.3486e-05, 9.9121e-06, 8.4783e-06, 6.9626e-06, 2.6235e-06,\n",
      "         3.3206e-05, 3.4403e-06, 1.8586e-06, 1.3618e-05, 2.4755e-05, 2.9571e-05,\n",
      "         1.6480e-06, 2.1176e-05, 2.6431e-06, 3.4008e-05, 5.1432e-06, 1.1201e-05,\n",
      "         2.0529e-06, 3.8352e-05, 6.9458e-06, 2.5264e-05, 2.4266e-05, 2.0424e-06,\n",
      "         1.3164e-05, 2.5669e-05, 2.2058e-05, 1.6754e-05, 1.5285e-05, 2.5139e-06,\n",
      "         7.6881e-06, 1.2876e-05, 2.9163e-05, 5.1558e-06, 2.1625e-06, 1.7453e-05,\n",
      "         1.2647e-05, 1.5764e-05, 1.1075e-05, 6.5812e-06, 4.4239e-06, 1.9947e-05,\n",
      "         7.6881e-06, 2.0936e-06, 4.1959e-01, 8.4127e-01, 4.8281e-01, 1.5704e+00,\n",
      "         8.2081e-01, 1.2090e+00, 3.5173e-01, 6.3683e-01, 8.1804e-01, 6.8321e-01,\n",
      "         6.8080e-01, 6.3138e-01, 1.4570e-01, 3.4801e-01, 7.3865e-01, 1.7367e+00,\n",
      "         3.3535e-01, 1.4552e+00, 1.2875e+00, 5.5856e-01, 2.0330e+00, 7.0080e-01,\n",
      "         9.8457e-01, 1.5228e+00, 8.6989e-01, 4.0281e-01, 1.0073e+00, 8.9637e-01,\n",
      "         1.7361e-01, 8.7721e-01, 5.0073e-01, 1.4663e+00, 1.7987e-01, 8.4046e-01,\n",
      "         5.7056e-01, 3.4805e-01, 5.2640e-01, 8.7296e-01, 1.1553e+00, 6.1302e-01,\n",
      "         1.4816e+00, 2.8769e-01, 8.0234e-01, 1.2074e+00, 4.7646e-01, 4.4158e-01,\n",
      "         6.8932e-01, 1.1802e+00, 7.3263e-01, 8.7638e-01, 1.0591e+00, 2.3362e+00,\n",
      "         6.6539e-01, 1.7148e+00, 1.5016e+00, 8.1651e-01, 5.5367e-01, 8.2577e-01,\n",
      "         4.3457e-01, 1.6836e+00, 1.1602e+00, 3.9343e-01, 1.2347e+00, 1.0576e+00,\n",
      "         8.6648e-01, 1.5217e+00, 5.1734e-01, 1.5546e+00, 1.2844e+00, 6.8359e-01,\n",
      "         1.1468e+00, 4.8129e-01, 1.4315e+00, 9.1717e-01, 6.3732e-01, 6.9377e-01,\n",
      "         1.1961e+00, 1.8912e+00, 1.3221e+00, 8.3371e-01, 5.3012e-01, 1.4170e+00,\n",
      "         1.0655e+00, 8.2186e-01, 4.8178e-01, 1.5574e+00, 4.0042e-01, 1.0774e+00,\n",
      "         3.6845e-01, 1.4536e+00, 5.1491e-01, 4.2614e-01, 1.7288e+00, 9.9748e-01,\n",
      "         7.1605e-01, 3.8602e-01, 1.9192e+00, 1.1809e+00, 1.0700e+00, 5.4437e-01,\n",
      "         1.2242e+00, 8.1222e-01, 2.1838e+00, 9.1466e-01, 6.3410e-01, 1.3317e+00,\n",
      "         9.0782e-01, 9.3411e-01, 3.0293e-01, 1.0448e+00, 7.7353e-01, 4.8234e-01,\n",
      "         1.0133e+00, 6.1458e-01, 4.4335e-01, 1.1557e+00, 3.1121e-01, 6.2640e-01,\n",
      "         1.0556e+00, 5.6807e-01, 9.5379e-01, 9.0962e-01, 1.4691e+00, 9.7739e-01,\n",
      "         1.1913e+00, 1.8441e-01, 1.0790e+00, 6.0724e-01, 1.1886e-04, 8.5154e-04,\n",
      "         1.7330e-03, 8.2616e-05, 1.3264e-04, 4.5176e-04, 2.3801e-03, 5.5322e-04,\n",
      "         1.6192e-04, 2.0143e-04, 9.7728e-04, 5.5209e-05, 1.7991e-03, 1.0896e-03,\n",
      "         1.0462e-03, 1.4231e-03, 5.6135e-04, 7.8201e-04, 8.8931e-04, 8.3429e-04,\n",
      "         1.1265e-03, 4.2868e-04, 4.1100e-04, 1.1531e-04, 3.2480e-03, 3.3835e-04,\n",
      "         1.6122e-03, 8.7948e-04, 2.5784e-04, 1.2463e-03, 3.8204e-04, 1.1154e-04,\n",
      "         6.9454e-05, 2.1467e-03, 3.8616e-04, 2.0211e-03, 6.4105e-05, 9.8987e-04,\n",
      "         1.3762e-03, 2.1739e-03, 2.2747e-04, 5.3340e-04, 1.6308e-04, 1.8103e-03,\n",
      "         4.9905e-04, 9.0003e-05, 2.4661e-03, 5.3181e-04, 1.6648e-03, 1.0844e-04,\n",
      "         1.5740e-03, 1.9939e-04, 1.4938e-03, 1.3590e-04, 2.0103e-03, 1.1598e-03,\n",
      "         1.4463e-03, 6.1098e-04, 1.3049e-04, 8.0502e-04, 2.2545e-04, 1.3415e-04,\n",
      "         5.5872e-04, 8.4095e-05, 1.4627e-03, 8.0669e-04, 3.2379e-03, 3.0779e-04,\n",
      "         5.5370e-04, 1.6329e-04, 5.2668e-05, 9.2292e-04, 1.8277e-03, 1.2801e-03,\n",
      "         1.2416e-04, 8.9756e-04, 9.7167e-04, 1.5267e-04, 2.0283e-04, 6.3527e-04,\n",
      "         1.0145e-04, 1.2036e-03, 1.0565e-03, 2.5882e-04, 1.3589e-03, 5.2851e-04,\n",
      "         2.4192e-03, 7.6759e-04, 8.2508e-05, 1.7905e-03, 8.5615e-05, 7.5862e-05,\n",
      "         1.8529e-04, 8.0627e-04, 9.5493e-04, 2.7031e-04, 1.1066e-04, 7.0655e-04,\n",
      "         2.8218e-03, 1.3164e-04, 1.5196e-03, 9.3949e-04, 1.0110e-04, 1.4572e-03,\n",
      "         1.0690e-03, 1.7148e-03, 1.7331e-03, 1.0375e-03, 7.3113e-05, 1.1014e-04,\n",
      "         2.9108e-04, 1.2007e-04, 1.7790e-03, 8.1211e-07, 6.6519e-04, 1.0183e-04,\n",
      "         1.0834e-03, 2.4782e-03, 6.6345e-04, 1.1865e-03, 7.6510e-05, 9.3728e-05,\n",
      "         6.0448e-04, 1.2804e-03, 1.5270e-04, 1.6334e-03, 1.8188e-03, 1.1567e-04,\n",
      "         1.9643e-01, 7.1347e-02, 4.6573e-02, 1.2609e-01, 2.3983e-01, 7.7021e-02,\n",
      "         3.8582e-02, 5.1838e-02, 5.3160e-03, 7.0166e-02, 9.3326e-02, 8.2714e-02,\n",
      "         8.7274e-02, 1.2196e-01, 1.0061e-01, 1.5465e-01, 1.5469e-01, 3.1762e-02,\n",
      "         1.0003e-01, 1.5400e-01, 1.6170e-01, 6.8252e-02, 1.1718e-01, 1.5551e-01,\n",
      "         1.4772e-01, 1.4173e-01, 1.7710e-01, 9.2997e-02, 4.5784e-02, 9.8235e-02,\n",
      "         5.0615e-02, 1.6719e-01, 7.8909e-02, 5.9165e-02, 1.4466e-01, 7.8881e-02,\n",
      "         1.4058e-01, 9.1636e-02, 4.7383e-02, 7.9763e-02, 7.3897e-02, 6.7851e-02,\n",
      "         2.6756e-02, 9.1503e-02, 1.3158e-01, 6.5928e-02, 1.3946e-02, 9.0570e-02,\n",
      "         6.5757e-02, 2.5373e-01, 8.7537e-02, 1.4437e-01, 7.7642e-02, 6.4606e-02,\n",
      "         6.0170e-02, 1.2999e-01, 1.5276e-01, 3.6725e-02, 6.9660e-02, 2.6562e-01,\n",
      "         7.4299e-02, 9.2282e-02, 8.2586e-02, 1.0268e-01, 1.0504e-01, 1.2870e-01,\n",
      "         1.6136e-01, 1.5102e-01, 1.3315e-01, 7.3215e-02, 6.6962e-02, 1.1513e-01,\n",
      "         6.0533e-02, 1.0846e-01, 1.0294e-01, 4.8280e-02, 1.0659e-01, 1.1895e-01,\n",
      "         1.2467e-01, 1.3494e-01, 1.1407e-01, 2.3323e-01, 2.0433e-02, 7.9709e-02,\n",
      "         1.6152e-01, 5.7026e-02, 7.4805e-02, 2.7042e-01, 1.1457e-01, 1.0021e-01,\n",
      "         2.2623e-01, 6.9595e-02, 1.2771e-01, 2.4211e-03, 7.5577e-02, 1.1401e-01,\n",
      "         1.6752e-01, 6.6644e-02, 1.0861e-01, 1.1967e-01, 7.2583e-02, 1.2084e-01,\n",
      "         1.9502e-01, 8.8033e-02, 1.8128e-01, 5.8033e-02, 7.8285e-02, 1.3124e-01,\n",
      "         2.3349e-01, 1.8013e-02, 1.9683e-01, 6.9884e-02, 9.3961e-02, 1.2581e-01,\n",
      "         6.1143e-02, 6.3859e-02, 4.9534e-02, 2.8978e-01, 8.0456e-02, 6.0281e-02,\n",
      "         1.3136e-01, 1.2579e-01, 2.6644e-01, 1.2995e-01, 7.4032e-02, 7.7006e-02,\n",
      "         2.5434e-02, 1.0416e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 55: layer4.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([250]) to machine 1\n",
      "\t\t sending C_out tensor([344, 355, 357]) to machine 2\n",
      "\t\t sending C_out tensor([409]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([ 60,  61,  76,  89,  96, 117, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([262, 300, 313, 342, 353, 369]) to machine 2\n",
      "\t\t sending C_out tensor([399, 403, 417, 419, 435, 450, 455, 459, 484, 510]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([ 25,  58,  67,  87, 100, 123, 127]) to machine 0\n",
      "\t\t sending C_out tensor([141, 149, 150, 152, 165, 184, 238, 239, 240]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([419]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  4,  39,  53,  61,  70,  81,  86,  96, 118, 123]) to machine 0\n",
      "\t\t sending C_out tensor([129, 130, 134, 137, 138, 140, 141, 147, 153, 154, 160, 171, 174, 177,\n",
      "        178, 181, 188, 189, 204, 206, 207, 211, 212, 213, 214, 215, 216, 221,\n",
      "        224, 229, 232, 236, 240, 244, 246, 251, 252, 254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([262, 269, 280, 310, 313, 314, 322, 354, 369, 378]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 55\n",
      "Max diff:\n",
      "tensor([1.4162])\n",
      "\n",
      "tensor([[4.3266e-05, 8.5186e-05, 2.4241e-05, 5.3994e-05, 1.1194e-03, 6.8430e-05,\n",
      "         5.3627e-05, 4.3808e-05, 9.0652e-05, 3.6087e-05, 2.3247e-05, 7.1266e-05,\n",
      "         1.1336e-04, 7.6158e-05, 8.1314e-05, 7.5936e-05, 9.0074e-05, 2.8286e-05,\n",
      "         1.8548e-05, 4.6480e-05, 7.3943e-05, 1.3322e-04, 1.3554e-05, 3.2587e-05,\n",
      "         1.4175e-04, 3.7377e-05, 3.3822e-05, 7.0985e-05, 5.6315e-05, 5.5667e-05,\n",
      "         9.7403e-05, 5.0073e-05, 4.3461e-05, 5.1521e-05, 3.4856e-05, 4.5106e-05,\n",
      "         6.3796e-05, 4.3079e-05, 4.2958e-05, 4.8517e-04, 3.8765e-05, 2.9096e-05,\n",
      "         3.6849e-05, 3.2953e-05, 3.7916e-05, 1.2702e-04, 5.0776e-05, 3.3399e-05,\n",
      "         1.1361e-04, 5.9061e-05, 1.1163e-04, 7.5966e-05, 1.7768e-05, 2.8547e-04,\n",
      "         2.8804e-05, 3.1810e-05, 2.9750e-05, 8.9841e-05, 7.7969e-05, 1.0089e-04,\n",
      "         4.8845e-03, 7.6779e-05, 1.3008e-04, 5.3012e-05, 3.4068e-05, 6.3453e-05,\n",
      "         2.0994e-05, 7.1310e-05, 1.8774e-05, 5.8247e-05, 3.0273e-05, 7.3709e-05,\n",
      "         9.4339e-05, 6.7998e-05, 9.7737e-05, 2.4883e-05, 1.3438e-04, 3.4798e-05,\n",
      "         1.2997e-04, 1.0771e-05, 2.3741e-05, 1.1417e-05, 1.0457e-05, 7.6108e-05,\n",
      "         5.9973e-05, 4.5689e-05, 2.6671e-04, 5.8375e-05, 5.0539e-05, 7.6540e-05,\n",
      "         7.3049e-05, 4.3159e-05, 5.6086e-05, 1.1321e-04, 7.1881e-05, 2.7271e-05,\n",
      "         1.5054e-04, 7.3943e-05, 1.8969e-05, 4.4901e-05, 5.3835e-05, 5.7548e-05,\n",
      "         1.8478e-05, 3.0158e-05, 3.9887e-05, 2.3447e-05, 7.5310e-05, 8.4070e-06,\n",
      "         4.6689e-05, 9.1584e-05, 1.1346e-04, 4.4588e-05, 2.3812e-05, 5.5335e-05,\n",
      "         4.7202e-05, 8.8369e-05, 9.2100e-05, 8.8700e-03, 3.2331e-04, 7.9066e-05,\n",
      "         6.5636e-05, 4.2261e-05, 3.9604e-05, 2.4832e-03, 2.3134e-05, 3.4079e-04,\n",
      "         5.9135e-05, 7.9715e-05, 5.3224e-01, 5.7948e-01, 1.1552e+00, 5.1384e-01,\n",
      "         3.6428e-01, 4.8614e-01, 6.6654e-01, 8.8849e-01, 5.4029e-01, 4.5558e-01,\n",
      "         3.9595e-01, 5.2283e-01, 4.3707e-01, 6.0744e-01, 7.0413e-01, 7.5030e-01,\n",
      "         5.3265e-01, 7.6181e-01, 3.6844e-01, 6.7190e-01, 5.3296e-01, 6.9262e-01,\n",
      "         9.5640e-01, 1.0026e+00, 7.6003e-01, 5.1224e-01, 7.5592e-01, 5.6529e-01,\n",
      "         4.5819e-01, 5.8238e-01, 5.3516e-01, 6.0139e-01, 2.7426e-01, 5.1719e-01,\n",
      "         7.9819e-01, 4.2117e-01, 5.4920e-01, 9.8222e-01, 4.6859e-01, 6.3206e-01,\n",
      "         7.4996e-01, 7.3951e-01, 4.9278e-01, 1.4162e+00, 6.0362e-01, 6.0774e-01,\n",
      "         3.7305e-01, 1.0491e+00, 6.9040e-01, 9.3079e-01, 5.1864e-01, 1.1682e+00,\n",
      "         8.5917e-01, 4.6778e-01, 1.2040e+00, 5.9114e-01, 9.3868e-01, 4.8999e-01,\n",
      "         5.6462e-01, 5.3736e-01, 9.1980e-01, 3.5922e-01, 5.0244e-01, 5.5369e-01,\n",
      "         7.4807e-01, 5.9727e-01, 4.5472e-01, 5.3740e-01, 7.7650e-01, 4.3382e-01,\n",
      "         5.6819e-01, 6.8649e-01, 5.7856e-01, 4.2005e-01, 5.4346e-01, 2.4187e-01,\n",
      "         6.6474e-01, 5.4563e-01, 1.1812e+00, 8.0018e-01, 1.1463e+00, 4.3776e-01,\n",
      "         1.2196e+00, 1.4041e+00, 5.4809e-01, 1.0166e+00, 7.2194e-01, 4.7375e-01,\n",
      "         1.0576e-01, 6.3494e-01, 4.0434e-01, 1.9651e-01, 4.4477e-01, 5.2582e-01,\n",
      "         5.1790e-01, 8.2755e-01, 5.6353e-01, 6.1800e-01, 5.5571e-01, 5.1427e-01,\n",
      "         9.3862e-01, 7.3208e-01, 3.4650e-01, 4.7773e-01, 8.5059e-01, 5.2657e-01,\n",
      "         5.2766e-01, 3.7836e-01, 5.8526e-01, 1.3582e+00, 1.0516e+00, 4.1170e-01,\n",
      "         7.9405e-01, 5.6036e-01, 5.9138e-01, 5.6962e-01, 5.3460e-01, 8.4423e-01,\n",
      "         7.6099e-01, 6.5282e-01, 6.6934e-01, 3.9066e-01, 8.4713e-01, 6.6150e-01,\n",
      "         4.0707e-01, 3.8448e-01, 5.0682e-01, 4.7243e-01, 1.2884e-04, 3.8025e-03,\n",
      "         3.0734e-04, 6.2699e-05, 1.1770e-04, 6.1636e-04, 1.3253e-01, 6.1692e-04,\n",
      "         1.2393e-04, 6.3378e-04, 1.4623e-03, 1.8344e-04, 8.9841e-04, 1.2345e-01,\n",
      "         7.4825e-04, 3.3140e-04, 2.1057e-03, 3.2704e-04, 1.6366e-04, 7.1801e-04,\n",
      "         5.9997e-04, 4.0731e-04, 1.8451e-03, 3.2542e-04, 2.6128e-03, 1.4396e-03,\n",
      "         1.3430e-03, 3.0519e-03, 1.3518e-03, 2.3425e-03, 2.6425e-04, 1.0225e-04,\n",
      "         2.2995e-04, 1.4564e-03, 8.6990e-04, 3.9251e-04, 6.5655e-04, 1.0994e-03,\n",
      "         2.3180e-03, 7.5186e-04, 4.8845e-04, 7.5842e-04, 1.8676e-04, 4.2297e-04,\n",
      "         3.3583e-01, 4.2636e-04, 1.6564e-03, 2.2349e-03, 4.8815e-04, 5.9651e-05,\n",
      "         2.3729e-03, 1.2069e-04, 8.8358e-04, 6.0210e-05, 8.2353e-04, 9.4232e-04,\n",
      "         6.6353e-04, 2.7314e-01, 4.5558e-05, 1.6080e-03, 5.9180e-04, 2.0877e-04,\n",
      "         5.6975e-04, 1.4174e-04, 1.7004e-03, 7.5014e-04, 1.4960e-01, 1.2382e-03,\n",
      "         1.0996e-03, 1.3419e-04, 6.3315e-05, 1.6972e-03, 1.7024e-03, 5.4479e-04,\n",
      "         1.5124e-04, 5.5247e-04, 2.4261e-03, 2.2147e-04, 9.3020e-05, 9.6560e-04,\n",
      "         4.7863e-05, 6.1122e-04, 1.0427e-03, 4.0618e-04, 5.6859e-04, 3.6756e-03,\n",
      "         3.2528e-03, 7.4754e-04, 9.5982e-05, 2.3027e-03, 6.7921e-05, 7.9734e-05,\n",
      "         2.5102e-04, 1.2727e-03, 3.4748e-04, 5.5681e-04, 2.7669e-04, 7.1190e-02,\n",
      "         5.2661e-02, 3.9416e-04, 2.2733e-04, 9.6774e-04, 9.0797e-05, 3.5562e-04,\n",
      "         5.3243e-04, 2.3597e-03, 4.4684e-04, 8.0775e-04, 1.0455e-04, 5.6891e-05,\n",
      "         1.0273e-03, 1.4145e-04, 1.2903e-03, 6.9286e-02, 1.3261e-03, 6.6280e-05,\n",
      "         4.2067e-04, 4.2547e-04, 4.8611e-04, 5.8989e-04, 1.2758e-04, 2.9139e-04,\n",
      "         1.9282e-02, 6.3464e-04, 1.3066e-04, 1.5510e-03, 6.5193e-04, 1.4049e-04,\n",
      "         1.3316e-01, 2.6729e-02, 1.2916e-01, 1.6146e-01, 8.5938e-02, 5.4965e-01,\n",
      "         3.0474e-01, 6.3285e-02, 3.9324e-02, 1.4578e-01, 2.5359e-01, 1.8130e-01,\n",
      "         3.2171e-01, 3.1865e-02, 2.8396e-02, 1.1189e-01, 2.1992e-01, 1.7231e-01,\n",
      "         5.8446e-02, 3.0144e-01, 7.9251e-02, 2.4934e-01, 4.2926e-01, 4.4708e-02,\n",
      "         3.3684e-01, 6.3079e-02, 1.1649e-01, 8.9511e-02, 4.3633e-02, 1.1129e-01,\n",
      "         3.1496e-01, 1.5075e-01, 3.4981e-01, 1.8775e-01, 2.3406e-01, 5.9917e-02,\n",
      "         2.2638e-01, 7.8953e-02, 4.3381e-02, 1.1182e-01, 1.8014e-01, 5.4066e-01,\n",
      "         1.9587e-01, 1.4340e-01, 2.2459e-01, 1.3598e-01, 1.5639e-01, 2.1498e-01,\n",
      "         1.6682e-01, 7.6430e-02, 4.6636e-01, 2.0715e-01, 7.0185e-02, 5.0375e-01,\n",
      "         1.2223e-01, 1.1183e-01, 1.1588e-01, 2.7034e-01, 9.1908e-02, 2.9135e-02,\n",
      "         5.0431e-01, 4.7584e-01, 1.5363e-01, 1.0786e-01, 4.6909e-01, 3.2121e-01,\n",
      "         3.5612e-01, 5.9539e-02, 4.7276e-02, 9.1673e-02, 2.2877e-01, 8.1238e-02,\n",
      "         2.7439e-01, 1.2426e-01, 2.3629e-02, 3.0241e-01, 1.2731e-01, 9.1089e-02,\n",
      "         1.2257e-01, 1.0991e-01, 1.4648e-01, 9.6649e-02, 5.7074e-01, 9.9761e-02,\n",
      "         1.2865e-01, 8.1924e-02, 5.7021e-02, 3.0637e-01, 2.3130e-01, 2.4781e-01,\n",
      "         5.5614e-02, 2.8837e-01, 1.7021e-01, 1.6891e-02, 1.0333e-01, 2.5865e-01,\n",
      "         5.6453e-01, 3.5375e-01, 2.6928e-01, 1.1692e-01, 2.2955e-01, 1.6904e-01,\n",
      "         1.2912e-01, 6.6207e-02, 1.5730e-01, 1.2220e-01, 4.3595e-01, 4.4242e-02,\n",
      "         6.7332e-02, 8.6109e-02, 9.6108e-02, 2.3286e-01, 7.9375e-02, 1.2758e-01,\n",
      "         2.6298e-01, 9.8707e-02, 1.3667e-01, 5.2318e-02, 5.6579e-02, 1.9393e-01,\n",
      "         1.8484e-01, 1.4541e-01, 4.3410e-02, 6.9459e-02, 9.4462e-02, 2.1791e-01,\n",
      "         4.2498e-01, 5.7338e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 56: layer4.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 56\n",
      "Max diff:\n",
      "tensor([2.0568])\n",
      "\n",
      "tensor([[9.6550e-06, 1.8763e-05, 5.3551e-06, 1.0733e-05, 2.0217e-03, 1.3730e-05,\n",
      "         1.2737e-05, 9.9000e-06, 1.9133e-05, 7.6303e-06, 5.0180e-06, 1.3996e-05,\n",
      "         2.0161e-05, 1.5662e-05, 1.9566e-05, 1.7442e-05, 2.1230e-05, 5.8673e-06,\n",
      "         3.8089e-06, 9.3523e-06, 1.5805e-05, 2.4203e-05, 3.0957e-06, 6.3833e-06,\n",
      "         2.7883e-05, 1.2182e-05, 6.8750e-06, 1.4587e-05, 1.2873e-05, 1.0831e-05,\n",
      "         2.0672e-05, 1.0405e-05, 9.5442e-06, 1.0427e-05, 7.9442e-06, 8.8206e-06,\n",
      "         1.2506e-05, 1.0139e-05, 9.3756e-06, 3.7299e-04, 8.7954e-06, 6.1260e-06,\n",
      "         7.5549e-06, 7.9260e-06, 7.8417e-06, 2.6855e-05, 1.1705e-05, 7.3873e-06,\n",
      "         2.3790e-05, 1.1906e-05, 2.5554e-05, 1.6078e-05, 3.7979e-06, 2.1280e-04,\n",
      "         6.2296e-06, 6.4559e-06, 5.6736e-06, 1.8609e-05, 1.8610e-05, 1.8783e-05,\n",
      "         1.3025e-03, 7.2282e-05, 2.5975e-05, 1.2128e-05, 6.8005e-06, 1.4380e-05,\n",
      "         4.3251e-06, 1.3541e-05, 4.2962e-06, 1.1977e-05, 6.6248e-05, 1.4342e-05,\n",
      "         2.0012e-05, 1.3378e-05, 2.0169e-05, 5.6848e-06, 7.5387e-05, 6.9086e-06,\n",
      "         2.6040e-05, 2.1681e-06, 5.1567e-06, 2.5511e-06, 2.1122e-06, 1.4187e-05,\n",
      "         1.2735e-05, 1.0123e-05, 5.4154e-04, 4.0667e-04, 1.0305e-05, 1.0423e-05,\n",
      "         1.5128e-05, 9.7689e-06, 1.3341e-05, 2.3321e-05, 1.4332e-05, 5.5572e-06,\n",
      "         8.0474e-05, 1.3486e-05, 3.8985e-06, 8.5160e-06, 1.2908e-05, 1.1401e-05,\n",
      "         4.0997e-06, 6.4299e-06, 8.7353e-06, 4.9472e-06, 1.6413e-05, 1.8049e-06,\n",
      "         9.4920e-06, 1.9139e-05, 2.3428e-05, 9.6476e-06, 5.0379e-06, 1.1997e-05,\n",
      "         1.0412e-05, 1.9510e-05, 1.8670e-05, 4.3182e-03, 2.1330e-04, 1.6179e-05,\n",
      "         1.3245e-05, 8.6986e-06, 7.9488e-06, 1.8341e-04, 5.0762e-06, 6.5143e-05,\n",
      "         1.2621e-05, 3.3572e-05, 1.4048e-01, 2.0370e-01, 6.8614e-01, 2.7870e-01,\n",
      "         1.7080e-01, 1.3051e-01, 2.0274e-01, 3.0060e-01, 2.3979e-01, 2.2579e-01,\n",
      "         1.2606e-01, 1.7155e-01, 3.9403e-01, 3.4831e-01, 2.2112e-01, 2.6134e-01,\n",
      "         2.0486e-01, 1.8449e-01, 1.1872e-01, 2.6496e-01, 2.1161e-01, 1.9276e-01,\n",
      "         2.5331e-01, 3.4138e-01, 2.7412e-01, 2.0568e+00, 3.0697e-01, 2.1164e-01,\n",
      "         1.4466e-01, 1.4886e-01, 7.9019e-02, 2.6131e-01, 1.0179e-01, 1.9948e-01,\n",
      "         2.6263e-01, 9.6195e-02, 1.9419e-01, 3.7278e-01, 9.6766e-02, 1.4714e-01,\n",
      "         1.8620e-01, 2.2975e-01, 1.4141e-01, 4.1361e-01, 1.7318e-01, 1.7793e-01,\n",
      "         7.6131e-02, 4.0515e-01, 1.6157e-01, 3.2565e-01, 2.8349e-01, 5.5592e-01,\n",
      "         3.6447e-01, 5.4551e-01, 4.6910e-01, 2.0826e-01, 3.3155e-01, 2.1184e-01,\n",
      "         1.7782e-01, 2.4915e-01, 6.0106e-01, 7.9526e-01, 2.1846e-01, 1.6440e-01,\n",
      "         1.9273e-01, 3.2245e-01, 1.2406e-01, 1.8066e-01, 2.3617e-01, 1.9316e-01,\n",
      "         1.7046e-01, 1.6426e-01, 1.4399e-01, 2.0808e-01, 2.5321e-01, 6.8619e-02,\n",
      "         2.4909e-01, 1.8061e-01, 6.0639e-01, 2.5637e-01, 3.5499e-01, 2.1783e-01,\n",
      "         5.1336e-01, 5.1318e-01, 1.6236e-01, 3.2003e-01, 2.0306e-01, 2.2214e-01,\n",
      "         2.3124e-02, 2.7431e-01, 9.6556e-02, 4.1829e-02, 1.2709e-01, 1.5483e-01,\n",
      "         2.0624e-01, 2.9682e-01, 1.5478e-01, 1.5070e-01, 2.3722e-01, 1.3465e-01,\n",
      "         3.5548e-01, 2.8731e-01, 8.0447e-02, 1.8276e-01, 2.8851e-01, 1.2061e-01,\n",
      "         2.1064e-01, 6.0745e-02, 7.2874e-01, 3.5764e-01, 4.5414e-01, 1.3435e-01,\n",
      "         3.1781e-01, 1.8434e-01, 1.5001e-01, 1.7600e-01, 2.1093e-01, 1.9581e-01,\n",
      "         3.5624e-01, 2.1463e-01, 2.5654e-01, 1.3331e-01, 2.4967e-01, 1.0754e+00,\n",
      "         6.9922e-01, 1.1544e-01, 2.7791e-01, 1.8538e-01, 2.7413e-05, 6.6158e-04,\n",
      "         2.4233e-06, 1.5358e-05, 2.4844e-05, 1.6235e-04, 1.0127e-01, 1.0799e-04,\n",
      "         2.0601e-05, 1.7346e-04, 4.5034e-04, 4.0032e-05, 2.3097e-04, 5.2967e-01,\n",
      "         1.0131e-04, 3.3793e-05, 6.6699e-04, 1.0476e-04, 2.6971e-06, 3.9934e-04,\n",
      "         2.2363e-04, 7.5251e-06, 3.5867e-04, 7.3876e-05, 6.3971e-04, 4.7080e-04,\n",
      "         4.0526e-04, 1.3114e-04, 4.2001e-04, 1.0665e-04, 3.1255e-05, 2.2221e-05,\n",
      "         5.0131e-05, 1.0606e-05, 2.6835e-04, 4.9565e-05, 1.0917e-04, 5.0186e-04,\n",
      "         4.4033e-06, 2.2214e-04, 1.7457e-04, 2.2380e-04, 5.2065e-05, 7.4863e-05,\n",
      "         4.0582e-01, 1.1373e-04, 1.7095e-04, 2.7911e-04, 8.2916e-06, 1.3422e-05,\n",
      "         9.8816e-04, 2.4566e-05, 2.7481e-04, 1.2491e-05, 1.3433e-04, 1.1566e-04,\n",
      "         1.3193e-04, 3.2969e-01, 1.2584e-05, 4.5365e-04, 1.7994e-04, 4.6775e-05,\n",
      "         1.5996e-05, 3.1820e-05, 6.1573e-04, 1.9832e-04, 4.9670e-01, 2.5178e-04,\n",
      "         3.5435e-04, 2.5980e-05, 1.4029e-05, 3.2708e-05, 1.5762e-04, 9.9666e-05,\n",
      "         3.6541e-05, 1.3745e-04, 5.1995e-04, 5.0392e-05, 1.4659e-05, 1.4286e-04,\n",
      "         1.1026e-05, 9.7059e-05, 2.8834e-04, 1.4599e-04, 1.8328e-06, 1.0735e-03,\n",
      "         7.7492e-04, 1.2450e-04, 1.6513e-05, 4.2505e-04, 1.6344e-05, 2.0720e-05,\n",
      "         5.7954e-05, 2.0544e-04, 3.1592e-05, 1.6984e-04, 5.0411e-05, 3.7383e-02,\n",
      "         1.3491e-01, 3.0062e-04, 2.1011e-06, 3.2121e-04, 2.0616e-05, 3.2615e-06,\n",
      "         1.3402e-04, 8.3327e-04, 2.6636e-07, 2.1370e-04, 2.2097e-05, 1.1977e-05,\n",
      "         2.2110e-04, 2.9004e-05, 3.4942e-04, 1.0693e-02, 2.5883e-05, 1.4199e-05,\n",
      "         3.2309e-05, 1.0523e-04, 9.7839e-05, 2.2452e-04, 2.6241e-05, 5.8703e-05,\n",
      "         2.5441e-04, 2.5247e-04, 3.2820e-05, 7.4580e-06, 1.5484e-04, 3.2509e-05,\n",
      "         3.1158e-02, 6.0320e-05, 2.7445e-02, 2.0723e-02, 1.7883e-04, 1.2611e-01,\n",
      "         8.6636e-02, 2.7760e-02, 9.3482e-03, 1.9292e-02, 4.4350e-02, 4.6906e-02,\n",
      "         1.1453e-01, 1.1192e-04, 6.4448e-04, 2.0572e-02, 3.8192e-02, 3.8384e-02,\n",
      "         1.4544e-02, 2.4367e-01, 8.4429e-03, 5.7604e-02, 1.4493e-01, 3.7577e-03,\n",
      "         8.4223e-02, 6.7154e-03, 3.9330e-02, 2.2205e-02, 4.5006e-04, 3.1203e-02,\n",
      "         9.6683e-02, 1.8077e-02, 1.1662e-01, 5.2645e-02, 9.4037e-03, 1.4825e-02,\n",
      "         6.7135e-02, 2.1471e-03, 8.5932e-03, 2.4800e-02, 6.3381e-02, 1.7656e-01,\n",
      "         3.0827e-02, 1.2655e-02, 9.2048e-02, 3.7735e-02, 4.8374e-02, 4.5904e-02,\n",
      "         2.8088e-02, 1.5279e-02, 1.1646e-01, 1.0325e-01, 1.3517e-02, 1.3994e-01,\n",
      "         4.9018e-03, 2.4485e-02, 3.4006e-02, 5.7640e-02, 6.6949e-03, 5.8033e-04,\n",
      "         8.1034e-02, 7.6948e-02, 2.3609e-02, 1.0349e-03, 1.0551e-01, 1.2520e-01,\n",
      "         1.3492e-01, 5.0004e-04, 1.3538e-05, 1.5813e-02, 6.6088e-02, 1.5583e-03,\n",
      "         1.1009e-01, 3.3273e-02, 2.0239e-04, 7.8341e-02, 4.9021e-03, 1.5816e-02,\n",
      "         3.6044e-04, 4.4056e-03, 2.6956e-02, 3.8076e-03, 3.6579e-02, 6.5228e-04,\n",
      "         1.5322e-02, 3.8490e-02, 1.2979e-04, 8.6952e-02, 5.9677e-02, 5.8754e-02,\n",
      "         9.7254e-03, 5.9236e-02, 6.0264e-02, 4.1888e-03, 8.5155e-05, 4.7016e-02,\n",
      "         1.9442e-01, 4.4981e-02, 7.3595e-02, 4.8059e-02, 5.0017e-02, 4.5370e-02,\n",
      "         8.1090e-03, 1.8175e-02, 4.2613e-02, 1.8741e-03, 1.1950e-01, 3.5019e-03,\n",
      "         3.4946e-03, 2.2190e-02, 7.7143e-03, 5.4616e-02, 7.1721e-04, 1.3505e-02,\n",
      "         1.3579e-02, 1.3419e-02, 1.6090e-02, 4.8180e-04, 1.3769e-02, 2.7083e-03,\n",
      "         5.3279e-02, 2.2483e-02, 1.6326e-03, 3.1142e-03, 1.5553e-02, 4.4524e-02,\n",
      "         1.0774e-01, 1.5559e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 57: layer4.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 57\n",
      "Max diff:\n",
      "tensor([2.5990])\n",
      "\n",
      "tensor([[3.5867e-05, 1.1513e-05, 5.9884e-06, 2.3192e-05, 2.0205e-03, 7.9572e-06,\n",
      "         1.0738e-05, 2.7932e-05, 1.9187e-05, 7.9973e-06, 5.8301e-06, 1.1340e-05,\n",
      "         1.7777e-05, 3.1397e-05, 1.9341e-05, 3.9170e-05, 1.8440e-05, 1.1393e-05,\n",
      "         1.2667e-05, 8.2385e-06, 1.5549e-05, 1.8705e-05, 6.7353e-06, 6.6590e-06,\n",
      "         3.2775e-05, 1.5247e-05, 2.5909e-05, 1.5536e-05, 2.1901e-05, 7.4282e-06,\n",
      "         1.5514e-05, 6.6683e-06, 1.0390e-05, 1.6736e-05, 2.2784e-05, 2.1581e-05,\n",
      "         1.1973e-05, 1.0658e-05, 9.6690e-06, 3.9008e-04, 8.9277e-06, 8.1360e-06,\n",
      "         2.8269e-05, 7.5898e-06, 4.8615e-06, 2.2665e-05, 8.2552e-06, 8.2143e-06,\n",
      "         2.5317e-05, 8.3670e-06, 2.6260e-05, 1.3783e-05, 2.5740e-05, 2.1315e-04,\n",
      "         2.7645e-05, 1.5583e-05, 2.7647e-05, 1.3668e-05, 1.7812e-05, 3.4099e-05,\n",
      "         1.3113e-03, 7.2284e-05, 1.8294e-05, 1.6071e-05, 4.1984e-06, 1.5087e-05,\n",
      "         5.7463e-06, 2.4922e-05, 2.1182e-05, 2.5947e-05, 6.7320e-05, 9.7305e-06,\n",
      "         1.4653e-05, 8.0988e-06, 1.6809e-05, 6.9644e-06, 7.6255e-05, 1.8854e-05,\n",
      "         1.8158e-05, 4.2366e-06, 2.3872e-05, 5.4324e-06, 3.1143e-06, 1.0025e-05,\n",
      "         1.0438e-05, 2.9789e-05, 5.4842e-04, 4.0873e-04, 1.1329e-05, 1.0915e-05,\n",
      "         2.6478e-05, 1.1820e-05, 1.1483e-05, 1.5319e-05, 3.0601e-05, 3.2689e-05,\n",
      "         8.1304e-05, 1.1327e-05, 4.2878e-06, 3.6221e-05, 1.4007e-05, 1.2442e-05,\n",
      "         4.9095e-06, 3.7335e-05, 1.2939e-05, 2.9160e-05, 1.5993e-05, 2.1495e-06,\n",
      "         1.9813e-05, 4.0496e-05, 1.6184e-05, 1.4139e-05, 1.2586e-05, 9.8478e-06,\n",
      "         1.4067e-05, 1.3505e-05, 2.5745e-05, 4.3230e-03, 2.1397e-04, 1.0490e-05,\n",
      "         1.2502e-05, 1.6708e-05, 1.2420e-05, 1.8074e-04, 4.6566e-06, 8.4220e-05,\n",
      "         1.2068e-05, 3.2477e-05, 3.5454e-01, 1.0450e+00, 3.9093e-01, 1.6497e+00,\n",
      "         9.5298e-01, 1.2801e+00, 5.4197e-01, 6.2378e-01, 1.0578e+00, 7.3450e-01,\n",
      "         6.7681e-01, 6.7304e-01, 3.8854e-01, 6.0677e-01, 8.2663e-01, 1.9891e+00,\n",
      "         5.1506e-01, 1.6307e+00, 1.3961e+00, 5.6398e-01, 2.1720e+00, 7.9423e-01,\n",
      "         9.4352e-01, 1.8642e+00, 1.0059e+00, 2.1765e+00, 1.0589e+00, 1.1080e+00,\n",
      "         3.0946e-01, 9.2955e-01, 5.3088e-01, 1.5424e+00, 1.7476e-01, 8.5015e-01,\n",
      "         5.8994e-01, 2.5185e-01, 6.9768e-01, 1.1875e+00, 1.2279e+00, 6.3089e-01,\n",
      "         1.4252e+00, 2.4511e-01, 7.2323e-01, 1.3510e+00, 4.6678e-01, 5.5003e-01,\n",
      "         6.2965e-01, 1.4713e+00, 8.9420e-01, 1.0609e+00, 9.3802e-01, 2.5990e+00,\n",
      "         9.4913e-01, 2.2603e+00, 1.7100e+00, 9.2906e-01, 8.8119e-01, 9.0827e-01,\n",
      "         5.5020e-01, 1.5939e+00, 6.7798e-01, 7.7698e-01, 1.1816e+00, 1.1810e+00,\n",
      "         9.6729e-01, 1.3727e+00, 5.7621e-01, 1.6942e+00, 1.4371e+00, 6.3504e-01,\n",
      "         1.2635e+00, 6.2562e-01, 1.5006e+00, 1.0698e+00, 7.1301e-01, 7.5872e-01,\n",
      "         1.1412e+00, 2.0341e+00, 1.7334e+00, 8.9939e-01, 3.5731e-01, 1.4689e+00,\n",
      "         1.3576e+00, 1.1789e+00, 5.8049e-01, 1.7762e+00, 3.6182e-01, 1.0106e+00,\n",
      "         3.8043e-01, 1.6776e+00, 6.0465e-01, 4.5185e-01, 1.6848e+00, 1.0817e+00,\n",
      "         6.0764e-01, 6.8284e-01, 2.0740e+00, 1.1031e+00, 1.2435e+00, 6.0085e-01,\n",
      "         1.5796e+00, 1.0205e+00, 2.2486e+00, 9.2380e-01, 7.7444e-01, 1.3522e+00,\n",
      "         1.1185e+00, 9.7577e-01, 6.3906e-01, 1.2691e+00, 1.1978e+00, 5.8532e-01,\n",
      "         1.1862e+00, 5.3353e-01, 3.9002e-01, 1.1664e+00, 4.4062e-01, 7.6197e-01,\n",
      "         1.2846e+00, 4.4982e-01, 1.0804e+00, 9.6604e-01, 1.6273e+00, 1.4669e+00,\n",
      "         1.4978e+00, 2.5039e-01, 1.0143e+00, 6.2957e-01, 1.1018e-04, 9.2685e-04,\n",
      "         1.7309e-03, 7.0922e-05, 1.2334e-04, 4.8178e-04, 1.0365e-01, 5.2804e-04,\n",
      "         1.6761e-04, 2.4128e-04, 1.0987e-03, 4.6104e-05, 1.8146e-03, 5.2950e-01,\n",
      "         1.0911e-03, 1.4400e-03, 6.4176e-04, 7.9554e-04, 8.9057e-04, 1.2336e-03,\n",
      "         1.0659e-03, 4.3178e-04, 5.6487e-04, 8.2619e-05, 3.2679e-03, 7.4632e-04,\n",
      "         1.4884e-03, 9.3059e-04, 5.0811e-04, 1.2989e-03, 3.6263e-04, 1.1598e-04,\n",
      "         8.7969e-05, 2.1439e-03, 3.6098e-04, 2.0290e-03, 8.0615e-05, 1.0748e-03,\n",
      "         1.3792e-03, 2.1012e-03, 1.8450e-04, 6.2147e-04, 1.6645e-04, 1.8252e-03,\n",
      "         4.0577e-01, 1.0923e-04, 2.4654e-03, 8.1092e-04, 1.6683e-03, 1.0078e-04,\n",
      "         1.8541e-03, 2.0599e-04, 1.5309e-03, 1.3413e-04, 2.1113e-03, 1.1244e-03,\n",
      "         1.5309e-03, 3.2997e-01, 1.3404e-04, 1.0475e-03, 2.1720e-04, 1.0844e-04,\n",
      "         5.6222e-04, 8.7351e-05, 1.6452e-03, 8.3210e-04, 4.9346e-01, 5.5958e-04,\n",
      "         4.5443e-04, 1.5023e-04, 5.3257e-05, 9.3871e-04, 1.8733e-03, 1.2854e-03,\n",
      "         1.1086e-04, 9.1934e-04, 7.7939e-04, 1.5323e-04, 2.1748e-04, 5.7697e-04,\n",
      "         1.0004e-04, 1.1390e-03, 9.5177e-04, 3.1345e-04, 1.3599e-03, 9.6300e-04,\n",
      "         2.4662e-03, 7.7832e-04, 8.7239e-05, 1.9658e-03, 8.8219e-05, 6.7413e-05,\n",
      "         2.0278e-04, 7.9583e-04, 9.4444e-04, 2.0593e-04, 1.0225e-04, 3.7377e-02,\n",
      "         1.3483e-01, 3.7065e-04, 1.5193e-03, 9.8377e-04, 1.0093e-04, 1.4588e-03,\n",
      "         1.0364e-03, 1.8145e-03, 1.7329e-03, 1.0552e-03, 6.2674e-05, 1.0350e-04,\n",
      "         4.0168e-04, 1.2524e-04, 1.9435e-03, 1.0693e-02, 6.6793e-04, 9.9920e-05,\n",
      "         1.0751e-03, 2.5020e-03, 6.5905e-04, 1.2683e-03, 6.5848e-05, 8.6337e-05,\n",
      "         7.6926e-04, 1.2518e-03, 1.2935e-04, 1.6350e-03, 1.9736e-03, 1.1713e-04,\n",
      "         1.9603e-01, 7.1287e-02, 7.3292e-02, 1.2882e-01, 2.4000e-01, 2.0313e-01,\n",
      "         7.9371e-02, 5.4851e-02, 8.9918e-03, 7.4504e-02, 8.4825e-02, 6.6975e-02,\n",
      "         9.6731e-02, 1.2199e-01, 1.0066e-01, 1.5626e-01, 1.4160e-01, 2.8316e-02,\n",
      "         9.1793e-02, 2.2897e-01, 1.5676e-01, 9.0453e-02, 8.1640e-02, 1.5587e-01,\n",
      "         1.8914e-01, 1.3891e-01, 1.6592e-01, 1.0018e-01, 4.5765e-02, 1.1165e-01,\n",
      "         1.0713e-01, 1.6845e-01, 1.2004e-01, 6.2877e-02, 1.3917e-01, 7.4365e-02,\n",
      "         1.2369e-01, 9.1645e-02, 4.3194e-02, 7.4947e-02, 1.1428e-01, 1.9534e-01,\n",
      "         3.3190e-02, 8.9111e-02, 1.5995e-01, 7.9656e-02, 3.9843e-02, 9.7261e-02,\n",
      "         9.2021e-02, 2.6901e-01, 1.5669e-01, 1.8033e-01, 7.9367e-02, 1.5054e-01,\n",
      "         5.8153e-02, 1.3025e-01, 1.2743e-01, 4.7259e-02, 7.1780e-02, 2.6562e-01,\n",
      "         1.3104e-01, 1.2275e-01, 7.1307e-02, 1.0249e-01, 1.4016e-01, 1.6241e-01,\n",
      "         1.4510e-01, 1.5052e-01, 1.3314e-01, 8.2115e-02, 8.8072e-02, 1.1456e-01,\n",
      "         1.1825e-01, 1.0812e-01, 1.0313e-01, 1.2662e-01, 1.0797e-01, 1.2541e-01,\n",
      "         1.2476e-01, 1.3526e-01, 1.1497e-01, 2.3487e-01, 4.6606e-02, 7.9865e-02,\n",
      "         1.6175e-01, 7.4802e-02, 7.4874e-02, 2.4604e-01, 9.8059e-02, 1.4993e-01,\n",
      "         2.2973e-01, 9.8803e-02, 1.1228e-01, 4.0859e-03, 7.5663e-02, 1.0041e-01,\n",
      "         1.1384e-01, 5.3306e-02, 9.5035e-02, 9.7530e-02, 1.0091e-01, 1.4314e-01,\n",
      "         1.9549e-01, 8.4216e-02, 1.8054e-01, 5.8831e-02, 7.7954e-02, 1.3039e-01,\n",
      "         2.3214e-01, 3.4885e-02, 1.9717e-01, 5.6214e-02, 9.3878e-02, 1.2143e-01,\n",
      "         5.8060e-02, 6.1417e-02, 6.5624e-02, 2.9026e-01, 8.1857e-02, 6.0999e-02,\n",
      "         1.3649e-01, 1.3753e-01, 2.6632e-01, 1.2988e-01, 6.3173e-02, 8.5240e-02,\n",
      "         1.2340e-01, 9.6904e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 58: layer4.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 58\n",
      "Max diff:\n",
      "tensor([1.8857])\n",
      "\n",
      "tensor([[1.2978e-06, 8.5777e-06, 0.0000e+00, 1.6959e-06, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.9113e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.2217e-06, 0.0000e+00, 1.4966e-05, 0.0000e+00, 6.1011e-06,\n",
      "         9.6136e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3002e-06, 2.6710e-06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1952e-06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3192e-06, 0.0000e+00, 0.0000e+00,\n",
      "         2.3896e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2143e-06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6589e-05, 0.0000e+00,\n",
      "         1.0822e-06, 2.8349e-06, 4.7609e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.4944e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.1551e-06, 1.9890e-05, 0.0000e+00, 0.0000e+00,\n",
      "         1.4653e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1286e-06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2531e-06,\n",
      "         0.0000e+00, 1.2900e-05, 0.0000e+00, 4.0873e-04, 0.0000e+00, 0.0000e+00,\n",
      "         1.1217e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2584e-05, 8.6045e-06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3900e-06, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.6882e-05, 1.2939e-05, 1.1931e-05, 4.4541e-06, 0.0000e+00,\n",
      "         1.9813e-05, 2.3205e-05, 1.6184e-05, 0.0000e+00, 8.5204e-06, 0.0000e+00,\n",
      "         0.0000e+00, 1.3505e-05, 3.3714e-07, 0.0000e+00, 0.0000e+00, 1.0490e-05,\n",
      "         0.0000e+00, 6.3330e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8376e-05,\n",
      "         4.6445e-06, 0.0000e+00, 0.0000e+00, 9.2902e-01, 0.0000e+00, 1.3467e+00,\n",
      "         0.0000e+00, 6.9278e-01, 2.6970e-01, 0.0000e+00, 6.7679e-01, 3.0226e-01,\n",
      "         3.5151e-01, 0.0000e+00, 1.9762e-01, 5.4943e-01, 1.3542e-01, 0.0000e+00,\n",
      "         2.8581e-01, 0.0000e+00, 0.0000e+00, 1.8754e-01, 2.2357e-01, 5.9989e-01,\n",
      "         0.0000e+00, 0.0000e+00, 2.7450e-01, 1.8857e+00, 0.0000e+00, 1.9071e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1935e+00, 0.0000e+00, 8.5015e-01,\n",
      "         0.0000e+00, 2.4894e-01, 6.9768e-01, 0.0000e+00, 3.6317e-01, 4.4150e-01,\n",
      "         0.0000e+00, 4.6489e-02, 0.0000e+00, 0.0000e+00, 4.6678e-01, 2.1268e-01,\n",
      "         2.9116e-01, 0.0000e+00, 6.6639e-01, 5.2474e-01, 9.3802e-01, 0.0000e+00,\n",
      "         2.5912e-01, 0.0000e+00, 1.7786e-01, 0.0000e+00, 6.4175e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.2620e-01, 3.3387e-01, 6.2552e-01, 9.3604e-01,\n",
      "         0.0000e+00, 0.0000e+00, 4.3774e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1386e-01, 0.0000e+00, 4.6607e-01, 1.2449e-01, 7.2282e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2203e-01, 0.0000e+00,\n",
      "         0.0000e+00, 9.0732e-02, 2.1422e-01, 0.0000e+00, 1.3605e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5185e-01, 7.2674e-01, 4.8713e-01,\n",
      "         0.0000e+00, 2.4792e-01, 0.0000e+00, 9.6620e-01, 7.3609e-01, 5.3293e-01,\n",
      "         3.9618e-01, 4.7957e-01, 0.0000e+00, 6.1919e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.7577e-01, 6.3906e-01, 0.0000e+00, 1.0885e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1998e-01, 3.9002e-01, 8.5974e-01, 8.2649e-02, 0.0000e+00,\n",
      "         9.0090e-01, 4.0108e-02, 0.0000e+00, 1.3556e-01, 0.0000e+00, 1.4918e-01,\n",
      "         0.0000e+00, 6.5395e-02, 6.4427e-01, 6.2957e-01, 0.0000e+00, 0.0000e+00,\n",
      "         5.9611e-04, 0.0000e+00, 0.0000e+00, 4.8178e-04, 0.0000e+00, 5.2804e-04,\n",
      "         0.0000e+00, 0.0000e+00, 9.2301e-04, 0.0000e+00, 1.8146e-03, 5.2950e-01,\n",
      "         1.0911e-03, 1.7287e-04, 5.7547e-04, 2.9624e-05, 8.9057e-04, 1.2336e-03,\n",
      "         1.0659e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4408e-04, 7.4632e-04,\n",
      "         0.0000e+00, 5.7194e-04, 0.0000e+00, 8.7476e-04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.1439e-03, 3.5910e-04, 2.0290e-03, 0.0000e+00, 1.0748e-03,\n",
      "         1.0659e-03, 5.1704e-04, 0.0000e+00, 6.1122e-04, 0.0000e+00, 0.0000e+00,\n",
      "         3.3881e-01, 0.0000e+00, 2.4321e-03, 0.0000e+00, 3.1585e-04, 0.0000e+00,\n",
      "         8.1688e-04, 0.0000e+00, 1.0181e-03, 0.0000e+00, 0.0000e+00, 4.2813e-04,\n",
      "         5.0331e-04, 2.7324e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.3846e-04, 0.0000e+00, 1.6452e-03, 5.8138e-04, 3.4986e-01, 5.5958e-04,\n",
      "         4.5443e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3337e-04, 1.2854e-03,\n",
      "         0.0000e+00, 8.8443e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1390e-03, 8.8304e-04, 2.2563e-04, 1.3599e-03, 0.0000e+00,\n",
      "         1.0648e-03, 2.0523e-04, 0.0000e+00, 1.9658e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.7839e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7377e-02,\n",
      "         1.3483e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.1773e-04, 0.0000e+00, 1.7329e-03, 1.0552e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5823e-03, 0.0000e+00, 4.3131e-04, 0.0000e+00,\n",
      "         3.4405e-04, 2.1509e-04, 6.5905e-04, 1.2683e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4930e-05, 0.0000e+00, 0.0000e+00, 1.9736e-03, 0.0000e+00,\n",
      "         1.9603e-01, 7.1287e-02, 7.3292e-02, 1.2882e-01, 2.4000e-01, 0.0000e+00,\n",
      "         0.0000e+00, 5.2621e-02, 0.0000e+00, 6.5692e-03, 0.0000e+00, 6.6505e-02,\n",
      "         0.0000e+00, 1.2199e-01, 0.0000e+00, 1.1913e-01, 4.6470e-03, 0.0000e+00,\n",
      "         0.0000e+00, 1.7546e-01, 4.2081e-02, 0.0000e+00, 0.0000e+00, 1.2827e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5765e-02, 2.4146e-02,\n",
      "         0.0000e+00, 1.0817e-01, 7.3917e-02, 6.2877e-02, 0.0000e+00, 7.4365e-02,\n",
      "         1.0636e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1428e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1142e-02, 0.0000e+00, 0.0000e+00,\n",
      "         3.5843e-02, 2.6901e-01, 3.9246e-03, 1.8033e-01, 7.9367e-02, 0.0000e+00,\n",
      "         0.0000e+00, 1.3025e-01, 9.8037e-02, 0.0000e+00, 0.0000e+00, 2.6562e-01,\n",
      "         7.9211e-02, 0.0000e+00, 6.3194e-02, 1.0249e-01, 0.0000e+00, 1.6241e-01,\n",
      "         1.4510e-01, 8.1996e-02, 1.3314e-01, 8.2115e-02, 0.0000e+00, 1.0692e-01,\n",
      "         0.0000e+00, 1.0812e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.0598e-02, 8.9960e-02, 2.0372e-02, 7.9865e-02,\n",
      "         8.1841e-02, 7.4802e-02, 6.4681e-02, 2.4604e-01, 9.8059e-02, 1.1130e-01,\n",
      "         2.2973e-01, 0.0000e+00, 6.6189e-02, 0.0000e+00, 7.5663e-02, 9.7114e-02,\n",
      "         4.3947e-02, 0.0000e+00, 0.0000e+00, 9.7530e-02, 0.0000e+00, 1.0264e-01,\n",
      "         8.6574e-02, 5.2478e-02, 0.0000e+00, 4.1895e-02, 0.0000e+00, 4.4333e-02,\n",
      "         7.6266e-02, 1.0946e-02, 3.7761e-02, 4.1164e-02, 1.3805e-02, 1.2143e-01,\n",
      "         0.0000e+00, 2.1972e-02, 0.0000e+00, 1.2013e-01, 8.1704e-02, 2.3383e-02,\n",
      "         1.3649e-01, 0.0000e+00, 1.4770e-01, 0.0000e+00, 0.0000e+00, 8.5240e-02,\n",
      "         0.0000e+00, 0.0000e+00]])\n",
      "tensor([  0,   1,   3,   7,  13,  15,  17,  18,  27,  28,  34,  39,  42,  47,\n",
      "         52,  54,  55,  56,  62,  68,  69,  72,  77,  83,  85,  87,  90,  94,\n",
      "         95,  99, 103, 104, 105, 106, 108, 109, 110, 112, 115, 116, 119, 121,\n",
      "        125, 126, 129, 131, 133, 134, 136, 137, 138, 140, 141, 142, 144, 147,\n",
      "        148, 149, 152, 153, 155, 159, 161, 163, 164, 166, 167, 169, 172, 173,\n",
      "        174, 176, 177, 178, 180, 182, 184, 188, 189, 190, 191, 194, 199, 201,\n",
      "        202, 203, 208, 211, 212, 214, 219, 220, 221, 223, 225, 226, 227, 228,\n",
      "        229, 231, 235, 236, 238, 241, 242, 243, 244, 246, 247, 249, 251, 253,\n",
      "        254, 255, 258, 261, 263, 266, 268, 269, 270, 271, 272, 273, 274, 275,\n",
      "        276, 280, 281, 283, 285, 289, 290, 291, 293, 294, 295, 297, 300, 302,\n",
      "        304, 306, 308, 311, 312, 313, 318, 320, 321, 322, 323, 324, 328, 329,\n",
      "        331, 337, 338, 339, 340, 342, 343, 345, 349, 353, 354, 360, 362, 363,\n",
      "        368, 370, 372, 373, 374, 375, 379, 382, 384, 385, 386, 387, 388, 391,\n",
      "        393, 395, 397, 399, 400, 403, 404, 407, 412, 413, 415, 416, 417, 419,\n",
      "        420, 424, 429, 432, 433, 434, 435, 436, 439, 440, 443, 444, 446, 447,\n",
      "        449, 450, 451, 452, 453, 455, 457, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 476, 478, 479, 480, 483, 485, 486, 487, 489, 491,\n",
      "        492, 493, 494, 495, 496, 497, 499, 501, 502, 503, 504, 506, 509])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   3,   7,  13,  15,  17,  18,  27,  28,  34,  39,  42,  47,\n",
      "         52,  54,  55,  56,  62,  68,  69,  72,  77,  83,  85,  87,  90,  94,\n",
      "         95,  99, 103, 104, 105, 106, 108, 109, 110, 112, 115, 116, 119, 121,\n",
      "        125, 126, 129, 131, 133, 134, 136, 137, 138, 140, 141, 142, 144, 147,\n",
      "        148, 149, 152, 153, 155, 159, 161, 163, 164, 167, 169, 172, 173, 174,\n",
      "        176, 177, 178, 184, 188, 189, 190, 191, 194, 199, 201, 202, 203, 208,\n",
      "        211, 212, 214, 219, 221, 223, 225, 226, 227, 228, 229, 231, 235, 236,\n",
      "        241, 242, 243, 244, 246, 247, 249, 251, 253, 254, 255, 258, 261, 263,\n",
      "        266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 280, 281, 283, 285,\n",
      "        289, 290, 291, 293, 294, 295, 297, 300, 302, 304, 306, 308, 311, 312,\n",
      "        313, 318, 320, 321, 322, 323, 324, 328, 329, 331, 337, 338, 339, 340,\n",
      "        342, 343, 345, 349, 353, 354, 360, 362, 363, 368, 370, 372, 373, 374,\n",
      "        375, 379, 382, 384, 385, 386, 387, 388, 391, 393, 395, 397, 399, 400,\n",
      "        403, 404, 407, 412, 413, 415, 416, 417, 419, 420, 424, 429, 432, 433,\n",
      "        434, 435, 436, 439, 440, 443, 444, 446, 447, 449, 450, 451, 452, 453,\n",
      "        455, 457, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 476,\n",
      "        478, 479, 480, 483, 485, 486, 487, 489, 491, 492, 493, 494, 495, 496,\n",
      "        497, 499, 501, 502, 503, 504, 506, 509])  (len = 246)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 59: layer4.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   3,   7,  13,  15,  17,  18,  27,  28,  34,  39,  42,  47,\n",
      "         52,  54,  55,  56,  62,  68,  69,  72,  77,  83,  85,  87,  90,  94,\n",
      "         95,  99, 103, 104, 105, 106, 108, 109, 110, 112, 115, 116, 119, 121,\n",
      "        125, 126])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([129, 131, 133, 134, 136, 137, 138, 140, 141, 142, 144, 147, 149, 152,\n",
      "        153, 159, 161, 163, 164, 166, 167, 172, 173, 174, 176, 177, 178, 180,\n",
      "        182, 184, 188, 190, 191, 194, 199, 201, 203, 208, 211, 214, 219, 220,\n",
      "        221, 223, 225, 226, 227, 228, 229, 231, 235, 236, 238, 242, 243, 244,\n",
      "        246, 249, 251, 253, 254, 255])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([258, 261, 263, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 280,\n",
      "        281, 283, 285, 289, 290, 291, 293, 294, 295, 297, 300, 302, 304, 306,\n",
      "        308, 311, 312, 313, 318, 320, 321, 322, 323, 324, 328, 329, 331, 337,\n",
      "        338, 339, 340, 342, 343, 345, 349, 353, 354, 360, 362, 363, 368, 370,\n",
      "        372, 373, 374, 375, 379, 382])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 391, 393, 395, 397, 399, 403, 404, 407, 412,\n",
      "        413, 415, 416, 417, 419, 420, 424, 429, 432, 433, 434, 435, 436, 439,\n",
      "        440, 443, 444, 446, 447, 449, 450, 451, 452, 453, 455, 457, 464, 466,\n",
      "        467, 468, 469, 470, 471, 472, 473, 474, 476, 478, 479, 480, 483, 485,\n",
      "        486, 487, 489, 491, 492, 493, 494, 495, 496, 497, 499, 501, 502, 503,\n",
      "        504, 506, 509])\n",
      "\t\t-Saving input for later...\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 59\n",
      "Max diff:\n",
      "tensor([5.1553])\n",
      "\n",
      "tensor([[1.7132e-05, 1.3845e-06, 4.8119e-06, 3.4412e-06, 3.6859e-06, 2.0405e-05,\n",
      "         9.9208e-06, 2.7802e-06, 3.6834e-06, 1.5316e-05, 5.2691e-06, 4.0357e-05,\n",
      "         1.7177e-06, 1.3656e-06, 2.9083e-06, 1.9607e-06, 3.5190e-06, 3.4947e-05,\n",
      "         3.5024e-05, 2.0081e-06, 9.6747e-06, 1.7702e-05, 6.7331e-06, 1.0121e-05,\n",
      "         2.3651e-06, 6.4464e-06, 7.8887e-05, 5.8256e-06, 4.2788e-05, 1.6024e-05,\n",
      "         1.6242e-05, 1.6016e-06, 1.1718e-06, 1.9066e-05, 2.6974e-05, 6.8997e-06,\n",
      "         4.4750e-06, 3.3100e-05, 6.2363e-06, 4.4244e-06, 3.5222e-06, 3.6340e-05,\n",
      "         2.7793e-05, 1.8389e-05, 8.5982e-06, 1.2483e-06, 5.0453e-06, 2.5880e-05,\n",
      "         1.5009e-05, 4.5063e-06, 5.9884e-06, 5.9209e-06, 3.3261e-06, 3.1863e-06,\n",
      "         5.3197e-07, 3.5950e-06, 1.2986e-05, 5.6766e-06, 9.5423e-06, 2.9622e-06,\n",
      "         2.8862e-06, 2.2857e-06, 1.8519e-06, 2.2865e-06, 6.5912e-06, 4.2575e-05,\n",
      "         3.1063e-06, 5.2643e-06, 1.5030e-05, 1.3110e-06, 1.3137e-05, 3.1823e-06,\n",
      "         1.4802e-06, 4.8591e-06, 2.4679e-05, 1.4854e-06, 8.5765e-06, 2.7576e-05,\n",
      "         2.0566e-06, 4.3106e-06, 1.8736e-06, 2.3778e-06, 2.8310e-05, 3.2574e-06,\n",
      "         1.3019e-05, 2.8773e-06, 2.0756e-05, 2.2146e-06, 4.5192e-06, 2.3229e-06,\n",
      "         1.3445e-05, 3.6248e-06, 4.0346e-06, 8.4976e-06, 3.6450e-06, 2.5748e-05,\n",
      "         1.7141e-05, 6.1028e-06, 1.7133e-06, 3.4345e-05, 1.2867e-06, 3.3048e-06,\n",
      "         1.8688e-06, 1.1538e-05, 3.7791e-05, 2.0369e-05, 4.0310e-06, 1.0835e-05,\n",
      "         2.7788e-06, 2.7478e-06, 3.5177e-05, 2.1936e-05, 2.6892e-06, 3.4063e-06,\n",
      "         1.5988e-05, 1.9534e-05, 1.3952e-06, 4.1053e-06, 1.0572e-05, 6.0615e-06,\n",
      "         2.6443e-05, 3.2368e-06, 3.1151e-06, 2.9285e-06, 5.8692e-06, 3.9446e-06,\n",
      "         3.6428e-05, 4.5858e-06, 3.0633e+00, 1.2629e+00, 2.0957e+00, 1.7972e+00,\n",
      "         1.9105e+00, 1.3066e+00, 2.0619e+00, 1.8253e+00, 9.8928e-01, 1.0126e+00,\n",
      "         2.3512e+00, 1.5195e+00, 1.6583e+00, 8.5677e-02, 1.2516e+00, 2.0507e+00,\n",
      "         1.5826e+00, 2.1813e+00, 1.2545e+00, 1.3358e+00, 2.5783e+00, 1.1776e+00,\n",
      "         3.3084e+00, 5.1553e+00, 2.7500e+00, 1.9310e+00, 1.0309e-01, 2.0496e+00,\n",
      "         1.6100e+00, 2.8533e+00, 1.1683e+00, 6.4338e-01, 1.9386e+00, 1.6055e+00,\n",
      "         1.4845e+00, 6.0207e-02, 1.9627e+00, 2.1573e+00, 3.0644e+00, 1.2076e+00,\n",
      "         1.3643e+00, 1.8379e+00, 1.3559e+00, 1.9620e+00, 1.4477e+00, 1.9549e+00,\n",
      "         2.1898e+00, 1.1222e+00, 1.6194e+00, 2.0885e+00, 7.7624e-01, 1.4710e+00,\n",
      "         2.7303e+00, 1.3593e+00, 4.5385e+00, 2.3301e+00, 1.8387e+00, 1.9222e+00,\n",
      "         1.5885e+00, 2.2399e+00, 6.7254e-01, 1.5176e+00, 1.5025e+00, 1.2321e+00,\n",
      "         2.2109e+00, 2.1857e+00, 1.4695e+00, 1.1420e+00, 1.1936e+00, 2.6227e+00,\n",
      "         8.6758e-01, 1.7270e+00, 3.0185e+00, 2.9398e+00, 2.0547e+00, 1.1193e+00,\n",
      "         1.3658e+00, 1.5823e+00, 3.0152e+00, 1.7164e-01, 2.2881e-01, 2.3413e+00,\n",
      "         1.3853e+00, 1.9675e+00, 3.3152e-01, 5.0832e+00, 1.2057e+00, 1.2116e+00,\n",
      "         1.4159e+00, 2.2047e+00, 4.9077e+00, 1.8168e+00, 2.7694e+00, 1.4930e+00,\n",
      "         1.3811e+00, 2.8541e+00, 1.3582e+00, 2.0376e+00, 8.8309e-01, 2.0088e+00,\n",
      "         1.5349e+00, 1.6537e+00, 1.0835e+00, 2.0369e+00, 4.5277e+00, 1.2515e+00,\n",
      "         2.2417e+00, 1.7579e+00, 4.7284e-02, 2.2649e+00, 1.7150e+00, 1.2042e+00,\n",
      "         6.9042e-01, 2.4274e+00, 2.1027e+00, 1.3159e+00, 2.0255e+00, 2.1549e+00,\n",
      "         1.6519e+00, 1.4553e+00, 2.4890e+00, 2.8694e+00, 1.3440e+00, 2.1557e+00,\n",
      "         1.7061e+00, 3.5356e+00, 3.0270e+00, 3.0874e+00, 4.9508e-01, 6.7637e-01,\n",
      "         5.2441e-01, 3.6482e-02, 4.5494e-02, 8.6536e-01, 3.7360e-02, 6.6523e-01,\n",
      "         1.8578e-01, 2.2793e-01, 4.1606e-02, 1.2000e-02, 9.6838e-02, 2.9956e-02,\n",
      "         6.9776e-01, 5.4758e-01, 5.1838e-02, 8.2364e-02, 3.6635e-02, 3.4064e-02,\n",
      "         6.4646e-02, 4.7761e-02, 1.6621e-01, 2.9445e-01, 5.7892e-01, 4.5629e-02,\n",
      "         2.4177e-02, 7.9052e-02, 2.7125e-02, 4.2079e-01, 4.8777e-02, 3.4066e-01,\n",
      "         5.3933e-01, 1.0176e-01, 4.5858e-02, 3.9374e-01, 3.8113e-02, 1.9214e-01,\n",
      "         6.2725e-02, 8.7573e-02, 4.8138e-02, 6.0895e-02, 9.7103e-02, 1.2361e+00,\n",
      "         3.4798e-02, 4.0038e-02, 4.2433e-02, 8.7129e-01, 6.0065e-01, 7.2992e-02,\n",
      "         1.1045e-01, 5.0014e-02, 1.8665e-01, 4.2307e-02, 3.0136e-01, 3.1948e-01,\n",
      "         3.1611e-01, 2.0831e-01, 2.5779e-02, 8.0940e-02, 3.2996e-02, 6.5353e-01,\n",
      "         6.6337e-02, 5.4081e-02, 2.6696e-01, 3.3720e-02, 3.4495e-02, 3.6896e-01,\n",
      "         6.1847e-02, 6.5835e-01, 7.4617e-02, 3.2623e-02, 5.0161e-02, 1.7826e-01,\n",
      "         3.7602e-02, 1.5176e-01, 4.7011e-01, 6.4707e-02, 5.1617e-01, 9.5368e-02,\n",
      "         3.5016e-01, 3.0523e-01, 3.0143e-01, 2.9394e-01, 3.3451e-01, 9.5268e-03,\n",
      "         2.4188e-01, 2.1940e-01, 5.9322e-01, 2.9235e-01, 2.1509e-01, 1.8662e-01,\n",
      "         1.9677e-01, 4.5912e-01, 2.7394e-01, 4.6500e-02, 3.5990e-02, 8.1187e-01,\n",
      "         3.9502e-02, 4.5103e-02, 2.7865e-02, 2.3257e-02, 2.3901e-02, 1.7019e-02,\n",
      "         9.0168e-02, 6.5051e-01, 6.3088e-01, 3.9485e-02, 1.9743e-01, 2.7033e-01,\n",
      "         7.4576e-02, 6.0805e-02, 1.3468e-02, 4.3745e-02, 4.6356e-02, 3.2440e-01,\n",
      "         2.1470e-01, 1.2298e-01, 6.0724e-01, 6.9536e-02, 1.6927e-01, 6.2974e-01,\n",
      "         5.8991e-02, 5.3838e-02, 4.7789e-01, 4.5156e-02, 7.2952e-02, 6.2840e-01,\n",
      "         1.4837e-01, 8.3171e-01, 4.4452e-01, 1.1870e+00, 5.1371e-01, 7.3730e-01,\n",
      "         2.1120e-01, 7.7216e-02, 1.0064e-01, 2.7790e-01, 5.8455e-01, 6.6652e-02,\n",
      "         8.8759e-02, 8.9321e-01, 5.8063e-01, 3.4574e-01, 4.9351e-01, 9.3514e-01,\n",
      "         4.7678e-01, 9.2172e-02, 5.1808e-01, 6.2148e-01, 2.2842e-01, 6.7394e-01,\n",
      "         7.4269e-01, 1.1061e+00, 1.0374e+00, 1.0341e+00, 6.7435e-02, 9.9198e-01,\n",
      "         9.0554e-01, 8.6630e-01, 6.4395e-01, 4.7549e-01, 1.3161e-01, 5.6188e-01,\n",
      "         6.9199e-01, 1.9332e-01, 1.0469e-01, 1.1210e+00, 1.0713e-01, 9.9106e-01,\n",
      "         1.1556e-01, 6.8431e-02, 4.9657e-01, 9.5491e-01, 1.5027e-01, 7.2239e-02,\n",
      "         5.9547e-01, 8.1172e-01, 8.8968e-02, 7.7289e-01, 5.6280e-01, 8.0204e-01,\n",
      "         4.6697e-01, 7.6682e-01, 8.5858e-01, 7.9333e-01, 7.8523e-01, 7.9928e-02,\n",
      "         1.0725e+00, 1.0120e-01, 1.4260e+00, 1.2555e+00, 9.8536e-02, 8.9349e-01,\n",
      "         9.7053e-01, 7.3194e-02, 3.8258e-01, 2.9004e-01, 1.1262e+00, 3.4843e-01,\n",
      "         1.2358e-01, 4.5543e-01, 9.1469e-02, 1.0247e+00, 5.9461e-02, 7.1573e-01,\n",
      "         6.7195e-01, 7.3080e-01, 7.5824e-02, 8.0695e-02, 7.6757e-02, 1.0892e+00,\n",
      "         9.2778e-01, 3.5391e-01, 1.2726e-01, 4.9394e-01, 9.7747e-01, 3.6975e-01,\n",
      "         8.0544e-01, 1.0947e-01, 2.9094e-01, 4.3495e-01, 7.1008e-02, 6.8927e-01,\n",
      "         7.5118e-01, 1.0032e+00, 1.0030e-01, 8.9673e-01, 1.0826e+00, 2.1561e-01,\n",
      "         6.4996e-02, 6.2822e-01, 4.6429e-01, 1.6754e-01, 3.9456e-01, 4.2341e-01,\n",
      "         1.0777e+00, 8.8745e-01, 6.2106e-01, 3.1727e-01, 8.1883e-02, 4.7324e-01,\n",
      "         1.2646e-01, 9.3596e-02, 1.7529e-01, 1.8819e-01, 1.0036e-01, 7.9273e-01,\n",
      "         6.7733e-02, 1.0573e+00, 7.2551e-01, 6.0678e-02, 1.0032e+00, 4.8173e-01,\n",
      "         6.0263e-01, 5.5994e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 60: layer4.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 60\n",
      "Max diff:\n",
      "tensor([2.8761])\n",
      "\n",
      "tensor([[3.9712e-06, 3.4925e-07, 1.6219e-06, 7.9721e-07, 9.8720e-07, 9.8944e-06,\n",
      "         3.6359e-06, 7.0594e-07, 1.1474e-06, 5.4166e-06, 1.4165e-06, 1.0878e-05,\n",
      "         4.1700e-07, 3.3982e-07, 6.7696e-07, 5.0914e-07, 9.2119e-07, 1.2878e-05,\n",
      "         8.4606e-06, 4.8848e-07, 3.3490e-06, 4.4517e-06, 2.7679e-06, 3.2485e-06,\n",
      "         5.5227e-07, 3.0547e-06, 3.4861e-05, 1.5898e-06, 1.0800e-05, 4.5002e-06,\n",
      "         5.2229e-06, 4.2515e-07, 2.8894e-07, 5.0720e-06, 8.9332e-06, 1.8571e-06,\n",
      "         1.0515e-06, 1.0155e-05, 1.6121e-06, 1.0814e-06, 8.8569e-07, 9.7584e-06,\n",
      "         6.7379e-06, 6.0983e-06, 2.3281e-06, 3.0035e-07, 1.4512e-06, 8.2217e-06,\n",
      "         4.3437e-06, 1.3441e-06, 1.4235e-06, 1.4782e-06, 8.1572e-07, 7.5856e-07,\n",
      "         1.3178e-07, 8.9081e-07, 4.3586e-06, 1.4529e-06, 2.3339e-06, 7.4157e-07,\n",
      "         6.8955e-07, 5.6729e-07, 4.4110e-07, 5.5903e-07, 1.7085e-06, 1.3110e-05,\n",
      "         9.2573e-07, 1.3809e-06, 5.2303e-06, 3.2480e-07, 3.9972e-06, 8.4110e-07,\n",
      "         3.6997e-07, 1.1995e-06, 8.5942e-06, 3.7951e-07, 2.4186e-06, 6.7325e-06,\n",
      "         4.9965e-07, 1.0447e-06, 4.5565e-07, 6.1101e-07, 8.0690e-06, 7.6392e-07,\n",
      "         3.1786e-06, 6.7160e-07, 6.3218e-06, 5.8860e-07, 1.8850e-06, 6.2131e-07,\n",
      "         4.9770e-06, 1.6391e-06, 1.2591e-06, 3.1218e-06, 9.8161e-07, 6.7791e-06,\n",
      "         4.9546e-06, 1.8042e-06, 4.3935e-07, 9.5256e-06, 3.3202e-07, 7.7125e-07,\n",
      "         4.8589e-07, 6.0424e-06, 9.4357e-06, 7.9423e-06, 9.9052e-07, 3.0883e-06,\n",
      "         7.2923e-07, 7.0245e-07, 8.7651e-06, 5.8506e-06, 6.3446e-07, 9.6275e-07,\n",
      "         7.0110e-06, 5.1502e-06, 3.7625e-07, 1.0030e-06, 2.6641e-06, 1.4026e-06,\n",
      "         6.5742e-06, 1.0263e-06, 7.5623e-07, 8.7917e-07, 1.3844e-06, 1.1115e-06,\n",
      "         8.7358e-06, 1.1665e-06, 2.4917e+00, 2.0888e-01, 8.8836e-01, 4.4556e-01,\n",
      "         9.6761e-01, 2.0681e-01, 5.5296e-01, 3.3583e-01, 4.1446e-01, 2.3300e-01,\n",
      "         6.8520e-01, 4.9306e-01, 7.9179e-01, 1.9595e-02, 3.0422e-01, 1.6426e+00,\n",
      "         5.4128e-01, 6.7943e-01, 1.0410e+00, 9.0225e-01, 4.0386e-01, 4.1402e-01,\n",
      "         9.8598e-01, 2.7733e+00, 1.7013e+00, 5.6513e-01, 2.6470e-02, 8.9079e-01,\n",
      "         5.4228e-01, 7.6487e-01, 3.1452e-01, 1.3921e-01, 8.1242e-01, 6.0657e-01,\n",
      "         3.2850e-01, 1.4756e-02, 8.2473e-01, 9.4638e-01, 6.2930e-01, 3.9424e-01,\n",
      "         9.3782e-01, 5.5431e-01, 3.5179e-01, 5.9623e-01, 2.1903e-01, 1.0091e+00,\n",
      "         1.0417e+00, 3.1217e-01, 6.3903e-01, 1.0053e+00, 3.1418e-01, 3.9647e-01,\n",
      "         8.9334e-01, 2.4141e-01, 2.8761e+00, 7.2111e-01, 9.9664e-01, 8.5436e-01,\n",
      "         1.0499e+00, 6.3667e-01, 3.4757e-01, 6.9128e-01, 6.3588e-01, 3.0742e-01,\n",
      "         3.7965e-01, 8.2314e-01, 5.6597e-01, 2.3791e-01, 5.2098e-01, 5.5811e-01,\n",
      "         2.6511e-01, 6.7245e-01, 1.4810e+00, 5.4656e-01, 9.5435e-01, 1.7944e-01,\n",
      "         9.0428e-01, 1.9934e-01, 1.8949e+00, 4.2622e-02, 5.7419e-02, 2.7152e-01,\n",
      "         3.9778e-01, 3.9982e-01, 7.6581e-02, 1.2594e+00, 2.3072e-01, 3.3553e-01,\n",
      "         4.1802e-01, 1.2486e+00, 1.5730e+00, 6.6221e-01, 9.5032e-01, 2.7594e-01,\n",
      "         4.6026e-01, 1.4044e+00, 5.5521e-01, 6.3526e-01, 1.4726e-01, 5.9923e-01,\n",
      "         4.0903e-01, 7.3359e-01, 2.1742e-01, 5.0015e-01, 1.7437e+00, 3.3022e-01,\n",
      "         5.3367e-01, 7.6103e-01, 1.1086e-02, 5.6594e-01, 3.3012e-01, 6.4127e-01,\n",
      "         1.9573e-01, 5.4237e-01, 4.1340e-01, 3.7616e-01, 1.2134e+00, 6.9682e-01,\n",
      "         7.5287e-01, 2.8738e-01, 1.5972e+00, 8.5946e-01, 3.1678e-01, 2.9359e-01,\n",
      "         7.9064e-01, 3.7441e-01, 9.5170e-01, 1.2294e+00, 1.5368e-01, 2.1062e-01,\n",
      "         1.1572e-01, 8.9123e-03, 1.1463e-02, 2.1957e-01, 9.3047e-03, 9.3426e-02,\n",
      "         6.8712e-02, 1.5927e-01, 1.0215e-02, 3.1611e-03, 2.7240e-02, 7.2706e-03,\n",
      "         1.5839e-01, 1.3833e-01, 1.4534e-02, 1.2789e-02, 8.6871e-03, 7.9214e-03,\n",
      "         1.6046e-02, 1.3304e-02, 2.9320e-02, 8.8936e-02, 2.1412e-01, 1.0331e-02,\n",
      "         6.0922e-03, 2.2202e-02, 7.2421e-03, 1.2634e-01, 1.2342e-02, 9.9462e-02,\n",
      "         1.4480e-01, 2.4565e-02, 1.2644e-02, 1.2436e-01, 9.0796e-03, 6.3265e-02,\n",
      "         1.5604e-02, 2.2555e-02, 1.1742e-02, 1.5518e-02, 1.8577e-02, 3.8113e-01,\n",
      "         8.5521e-03, 1.0825e-02, 1.0818e-02, 2.6091e-01, 2.5061e-01, 1.5371e-02,\n",
      "         3.1862e-02, 1.2402e-02, 2.1710e-02, 1.0153e-02, 5.6278e-02, 8.6887e-02,\n",
      "         1.1013e-01, 7.6097e-02, 6.9637e-03, 1.6906e-02, 8.3932e-03, 1.4489e-01,\n",
      "         1.5580e-02, 1.7699e-02, 9.3008e-02, 8.4525e-03, 8.7327e-03, 1.1547e-01,\n",
      "         1.3711e-02, 2.0407e-01, 1.6134e-02, 8.8822e-03, 1.3251e-02, 3.1011e-02,\n",
      "         9.5086e-03, 3.8860e-02, 1.5324e-01, 1.5431e-02, 1.7465e-01, 2.0752e-02,\n",
      "         9.5183e-02, 6.7384e-02, 7.8171e-02, 7.7995e-02, 1.0987e-01, 2.2657e-03,\n",
      "         5.2377e-02, 5.4450e-02, 2.8867e-01, 6.9548e-02, 7.3455e-02, 4.9772e-02,\n",
      "         3.6092e-02, 1.0072e-01, 4.9371e-02, 1.2441e-02, 8.9607e-03, 1.7589e-01,\n",
      "         9.5951e-03, 1.1056e-02, 7.1590e-03, 5.6808e-03, 5.9670e-03, 4.3236e-03,\n",
      "         1.2936e-02, 2.6441e-01, 1.6206e-01, 9.6078e-03, 3.0638e-02, 8.5181e-02,\n",
      "         1.8350e-02, 1.4494e-02, 3.4039e-03, 1.2404e-02, 1.1144e-02, 6.8000e-02,\n",
      "         6.7850e-02, 1.9853e-02, 7.6666e-02, 1.6223e-02, 2.1318e-02, 3.9896e-01,\n",
      "         1.6959e-02, 1.1587e-02, 1.1173e-01, 1.1834e-02, 2.8590e-02, 2.2644e-01,\n",
      "         3.9341e-02, 3.7247e-01, 1.3025e-01, 2.5611e-01, 7.6033e-02, 1.5089e-01,\n",
      "         3.9974e-02, 2.0315e-02, 2.6074e-02, 5.8031e-02, 1.0554e-01, 1.5553e-02,\n",
      "         1.9889e-02, 1.5885e-01, 2.4499e-01, 7.7887e-02, 2.0534e-01, 2.2775e-01,\n",
      "         1.1431e-01, 2.2150e-02, 1.0351e-01, 2.4781e-01, 4.2176e-02, 1.3738e-01,\n",
      "         1.6413e-01, 2.8646e-01, 2.8670e-01, 2.2011e-01, 1.6246e-02, 2.2544e-01,\n",
      "         1.7395e-01, 2.5008e-01, 1.4325e-01, 9.2135e-02, 3.3459e-02, 4.5020e-02,\n",
      "         1.2909e-01, 5.0609e-02, 2.7285e-02, 2.2002e-01, 2.6534e-02, 1.5905e-01,\n",
      "         2.6466e-02, 1.6480e-02, 9.5837e-02, 1.8057e-01, 2.9611e-02, 2.3176e-02,\n",
      "         7.7577e-02, 4.8300e-01, 2.0806e-02, 1.9998e-01, 1.6929e-01, 3.0340e-01,\n",
      "         2.1453e-02, 1.8219e-01, 1.3459e-01, 7.2042e-02, 4.0543e-01, 1.8019e-02,\n",
      "         2.3218e-01, 3.0568e-02, 2.4835e-01, 3.2751e-01, 2.3210e-02, 2.5935e-01,\n",
      "         2.8172e-01, 1.7927e-02, 5.5766e-02, 1.6334e-01, 1.7263e-01, 1.5399e-01,\n",
      "         3.2988e-02, 1.8513e-01, 2.1547e-02, 3.4552e-01, 1.5335e-02, 2.2418e-01,\n",
      "         2.2745e-01, 1.1308e-01, 1.7935e-02, 1.9120e-02, 1.9381e-02, 4.6998e-01,\n",
      "         4.0714e-01, 8.8193e-02, 3.4658e-02, 5.5222e-02, 2.7882e-01, 5.1867e-02,\n",
      "         2.0329e-01, 2.6986e-02, 4.3002e-02, 6.2685e-02, 2.2855e-02, 2.0127e-01,\n",
      "         4.0520e-01, 2.6673e-01, 2.2980e-02, 2.2839e-01, 1.8821e-01, 5.2894e-02,\n",
      "         1.8368e-02, 1.8957e-01, 6.5309e-02, 4.7774e-02, 6.1869e-02, 1.5330e-01,\n",
      "         2.7872e-01, 2.8695e-01, 1.5938e-01, 6.3519e-02, 1.9254e-02, 1.5828e-01,\n",
      "         2.9674e-02, 2.5653e-02, 3.8272e-02, 3.5601e-02, 3.2714e-02, 2.6028e-01,\n",
      "         1.7251e-02, 3.6175e-01, 2.1003e-01, 1.5548e-02, 2.8363e-01, 8.4090e-02,\n",
      "         1.1649e-01, 1.6912e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 61: layer4.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 61\n",
      "Max diff:\n",
      "tensor([1.6426])\n",
      "\n",
      "tensor([[3.9712e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8720e-07, 9.8944e-06,\n",
      "         3.6359e-06, 0.0000e+00, 1.1474e-06, 5.4166e-06, 1.4165e-06, 1.0878e-05,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2878e-05,\n",
      "         8.4606e-06, 0.0000e+00, 3.3490e-06, 4.4517e-06, 0.0000e+00, 3.2485e-06,\n",
      "         0.0000e+00, 3.0547e-06, 3.4861e-05, 0.0000e+00, 1.0800e-05, 4.5002e-06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0720e-06, 8.9332e-06, 1.8571e-06,\n",
      "         0.0000e+00, 1.0155e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7584e-06,\n",
      "         6.7379e-06, 6.0983e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2217e-06,\n",
      "         4.3437e-06, 0.0000e+00, 1.4235e-06, 1.3263e-06, 0.0000e+00, 7.5856e-07,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3339e-06, 0.0000e+00,\n",
      "         4.1770e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7085e-06, 1.3110e-05,\n",
      "         0.0000e+00, 0.0000e+00, 5.2303e-06, 0.0000e+00, 3.9972e-06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.5942e-06, 0.0000e+00, 0.0000e+00, 6.7325e-06,\n",
      "         4.9965e-07, 1.0447e-06, 0.0000e+00, 0.0000e+00, 8.0690e-06, 0.0000e+00,\n",
      "         3.1786e-06, 0.0000e+00, 6.3218e-06, 5.8860e-07, 1.8850e-06, 0.0000e+00,\n",
      "         4.9770e-06, 1.6391e-06, 0.0000e+00, 3.1218e-06, 0.0000e+00, 6.7791e-06,\n",
      "         4.9546e-06, 0.0000e+00, 0.0000e+00, 9.5256e-06, 0.0000e+00, 7.7125e-07,\n",
      "         0.0000e+00, 6.0424e-06, 9.4357e-06, 7.9423e-06, 9.9052e-07, 3.0883e-06,\n",
      "         7.2923e-07, 0.0000e+00, 8.7651e-06, 5.8506e-06, 0.0000e+00, 0.0000e+00,\n",
      "         7.0110e-06, 5.1502e-06, 0.0000e+00, 0.0000e+00, 2.6641e-06, 1.4026e-06,\n",
      "         6.5742e-06, 1.0263e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.7358e-06, 1.1665e-06, 0.0000e+00, 0.0000e+00, 6.3465e-01, 4.1542e-02,\n",
      "         1.3530e-01, 0.0000e+00, 4.5373e-01, 3.3583e-01, 0.0000e+00, 1.7898e-01,\n",
      "         0.0000e+00, 1.9647e-01, 1.3391e-01, 0.0000e+00, 2.1824e-02, 1.6426e+00,\n",
      "         2.6941e-01, 4.2415e-01, 2.9961e-01, 9.0225e-01, 0.0000e+00, 0.0000e+00,\n",
      "         2.4675e-01, 1.5434e+00, 0.0000e+00, 3.9122e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9696e-01,\n",
      "         6.7720e-02, 0.0000e+00, 8.2473e-01, 2.2910e-01, 0.0000e+00, 3.9424e-01,\n",
      "         9.3782e-01, 0.0000e+00, 3.5179e-01, 7.1806e-02, 1.7120e-01, 8.8350e-01,\n",
      "         1.0417e+00, 3.1217e-01, 3.1474e-01, 7.6710e-01, 1.6857e-01, 3.9647e-01,\n",
      "         5.8922e-01, 1.9791e-01, 0.0000e+00, 5.4655e-01, 2.7538e-01, 0.0000e+00,\n",
      "         1.0499e+00, 6.3667e-01, 0.0000e+00, 6.5688e-01, 5.7484e-01, 0.0000e+00,\n",
      "         3.7965e-01, 2.1830e-01, 1.9153e-01, 2.3791e-01, 4.0258e-02, 0.0000e+00,\n",
      "         0.0000e+00, 2.6506e-01, 7.7189e-01, 4.3998e-01, 1.0316e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.1690e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7152e-01,\n",
      "         1.8727e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1112e-01, 1.4257e-01,\n",
      "         0.0000e+00, 1.0626e+00, 0.0000e+00, 6.8648e-02, 7.3253e-01, 1.4659e-01,\n",
      "         4.4264e-02, 7.5044e-01, 0.0000e+00, 2.1536e-01, 1.8068e-02, 5.1471e-01,\n",
      "         8.9802e-02, 6.9015e-01, 0.0000e+00, 0.0000e+00, 6.2365e-01, 0.0000e+00,\n",
      "         4.8318e-01, 2.8760e-01, 0.0000e+00, 4.0209e-01, 9.0355e-02, 2.4389e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8619e-01, 0.0000e+00, 0.0000e+00,\n",
      "         3.0303e-01, 0.0000e+00, 1.5821e+00, 5.9440e-01, 9.6050e-02, 2.9359e-01,\n",
      "         2.9794e-01, 0.0000e+00, 9.5170e-01, 0.0000e+00, 1.5368e-01, 0.0000e+00,\n",
      "         3.9041e-02, 0.0000e+00, 0.0000e+00, 1.4046e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5927e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.7856e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4569e-02, 4.1777e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1595e-01, 0.0000e+00, 3.7259e-02,\n",
      "         1.0068e-01, 0.0000e+00, 0.0000e+00, 3.1964e-02, 0.0000e+00, 6.2152e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5258e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7834e-03, 1.9932e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1367e-02,\n",
      "         6.1538e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.5674e-02, 0.0000e+00, 0.0000e+00, 1.1547e-01,\n",
      "         0.0000e+00, 2.0847e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1326e-02, 1.3381e-02, 0.0000e+00, 3.1849e-02, 0.0000e+00, 0.0000e+00,\n",
      "         2.4697e-02, 5.4450e-02, 2.3469e-01, 0.0000e+00, 1.0228e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3178e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3768e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9896e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6817e-02, 1.6141e-01,\n",
      "         0.0000e+00, 0.0000e+00, 3.2756e-02, 0.0000e+00, 0.0000e+00, 8.9091e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3336e-01, 0.0000e+00, 1.1366e-01, 8.7146e-03,\n",
      "         3.6896e-02, 0.0000e+00, 6.9751e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5581e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.8521e-03, 0.0000e+00, 2.6520e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2088e-02, 1.3085e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0828e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5100e-01, 0.0000e+00, 1.5399e-01,\n",
      "         0.0000e+00, 1.3293e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5195e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1667e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3561e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.3149e-02, 0.0000e+00, 0.0000e+00, 8.1917e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.6777e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]])\n",
      "tensor([  0,   4,   5,   6,   8,   9,  10,  11,  17,  18,  20,  21,  23,  25,\n",
      "         26,  28,  29,  33,  34,  35,  37,  41,  42,  43,  47,  48,  50,  51,\n",
      "         53,  58,  60,  64,  65,  68,  70,  74,  77,  78,  79,  82,  84,  86,\n",
      "         87,  88,  90,  91,  93,  95,  96,  99, 101, 103, 104, 105, 106, 107,\n",
      "        108, 110, 111, 114, 115, 118, 119, 120, 121, 126, 127, 130, 131, 132,\n",
      "        134, 135, 137, 139, 140, 142, 143, 144, 145, 146, 147, 150, 151, 153,\n",
      "        161, 162, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177,\n",
      "        178, 179, 180, 181, 183, 184, 186, 187, 189, 190, 192, 193, 194, 195,\n",
      "        196, 199, 200, 201, 202, 205, 209, 210, 214, 215, 217, 219, 220, 221,\n",
      "        222, 223, 225, 226, 227, 228, 229, 232, 234, 235, 237, 238, 239, 243,\n",
      "        246, 248, 249, 250, 251, 252, 254, 256, 258, 261, 265, 271, 279, 280,\n",
      "        285, 287, 288, 291, 293, 299, 303, 304, 311, 312, 320, 323, 325, 336,\n",
      "        337, 339, 342, 343, 344, 346, 361, 365, 377, 382, 383, 386, 389, 398,\n",
      "        400, 401, 402, 404, 408, 415, 417, 441, 442, 447, 453, 455, 457, 461,\n",
      "        479, 483, 494, 497, 506])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   6,   8,   9,  10,  11,  17,  18,  20,  21,  23,  25,\n",
      "         26,  28,  29,  33,  34,  35,  37,  41,  42,  43,  47,  48,  50,  51,\n",
      "         53,  58,  60,  64,  65,  68,  70,  74,  77,  78,  79,  82,  84,  86,\n",
      "         87,  88,  90,  91,  93,  95,  96,  99, 101, 103, 104, 105, 106, 107,\n",
      "        108, 110, 111, 114, 115, 118, 119, 120, 121, 126, 127, 130, 131, 132,\n",
      "        134, 135, 137, 139, 140, 142, 143, 144, 145, 146, 147, 150, 153, 161,\n",
      "        162, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 183, 184, 186, 187, 190, 192, 193, 194, 195, 196, 199,\n",
      "        200, 201, 202, 205, 209, 214, 219, 220, 221, 223, 225, 226, 227, 228,\n",
      "        229, 234, 235, 237, 238, 239, 243, 246, 248, 249, 250, 251, 252, 254,\n",
      "        256, 258, 261, 265, 271, 279, 280, 285, 287, 288, 291, 293, 299, 303,\n",
      "        304, 311, 312, 320, 323, 325, 336, 337, 339, 342, 343, 344, 346, 361,\n",
      "        365, 377, 382, 383, 386, 389, 398, 400, 402, 404, 408, 417, 441, 442,\n",
      "        447, 453, 455, 457, 479, 483, 494, 497, 506])  (len = 191)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 62: layer4.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   4,   5,   6,   8,   9,  10,  11,  17,  18,  20,  21,  23,  25,\n",
      "         26,  28,  29,  33,  34,  35,  37,  41,  42,  43,  47,  48,  50,  51,\n",
      "         53,  58,  60,  64,  65,  68,  70,  74,  77,  78,  79,  82,  84,  86,\n",
      "         87,  88,  90,  91,  93,  95,  96,  99, 101, 103, 104, 105, 106, 107,\n",
      "        108, 110, 111, 114, 115, 118, 119, 120, 121, 126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([131, 134, 135, 137, 139, 143, 144, 145, 146, 147, 151, 153, 161, 162,\n",
      "        164, 167, 168, 170, 172, 173, 174, 175, 176, 178, 179, 180, 181, 183,\n",
      "        184, 186, 187, 189, 190, 192, 194, 195, 199, 201, 205, 209, 210, 214,\n",
      "        215, 217, 220, 221, 222, 227, 228, 229, 232, 234, 235, 237, 238, 239,\n",
      "        243, 246, 248, 249, 250, 251, 252, 254])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 261, 265, 271, 279, 280, 285, 287, 288, 291, 293, 299, 304, 311,\n",
      "        312, 320, 323, 325, 336, 337, 339, 342, 343, 344, 346, 361, 365, 377,\n",
      "        382, 383])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([386, 389, 398, 400, 401, 402, 404, 408, 415, 417, 441, 442, 447, 453,\n",
      "        455, 457, 461, 479, 483, 494, 497, 506])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 62\n",
      "Max diff:\n",
      "tensor([6.2906])\n",
      "\n",
      "tensor([[8.4937e-07, 3.6508e-07, 1.8328e-06, 1.7732e-06, 3.6657e-06, 3.4422e-06,\n",
      "         4.0978e-07, 4.1127e-06, 2.9802e-06, 1.2964e-06, 3.1432e-07, 9.3877e-07,\n",
      "         1.2219e-06, 1.0282e-06, 2.8610e-06, 3.8743e-06, 1.6093e-06, 7.2271e-06,\n",
      "         3.1292e-07, 2.1607e-06, 7.0035e-07, 1.7583e-06, 4.8578e-06, 2.9504e-06,\n",
      "         2.2501e-06, 3.8147e-06, 2.8014e-06, 2.5332e-07, 1.9073e-06, 1.0878e-06,\n",
      "         3.1292e-06, 1.5497e-06, 1.8030e-06, 3.3230e-06, 2.0415e-06, 7.1526e-07,\n",
      "         8.4937e-07, 4.7963e-07, 5.5134e-06, 3.2485e-06, 1.9073e-06, 2.3842e-06,\n",
      "         2.0862e-06, 5.5507e-07, 5.2154e-07, 5.5134e-07, 2.1234e-07, 2.3693e-06,\n",
      "         1.6093e-06, 1.7285e-06, 1.5199e-06, 1.2517e-06, 2.3246e-06, 1.3858e-06,\n",
      "         1.0431e-06, 5.2527e-07, 2.5034e-06, 1.1362e-06, 3.6359e-06, 1.9819e-06,\n",
      "         1.7881e-06, 8.3745e-06, 2.4438e-06, 4.0233e-07, 4.0084e-06, 6.1840e-07,\n",
      "         1.8477e-06, 1.4603e-06, 3.9190e-06, 1.6540e-06, 3.3379e-06, 1.8775e-06,\n",
      "         7.0035e-07, 7.0035e-07, 2.9504e-06, 6.4671e-06, 2.2501e-06, 4.8578e-06,\n",
      "         5.0664e-07, 1.5274e-06, 4.0978e-06, 1.3709e-06, 7.5996e-07, 4.4703e-07,\n",
      "         2.9653e-06, 3.2336e-06, 3.5465e-06, 2.8014e-06, 2.4438e-06, 1.6987e-06,\n",
      "         5.9903e-06, 2.9206e-06, 2.9057e-06, 1.0133e-06, 2.5183e-06, 3.1143e-06,\n",
      "         1.2387e-07, 4.0829e-06, 1.7136e-06, 1.3113e-06, 5.2154e-07, 1.1027e-06,\n",
      "         1.1325e-06, 4.6343e-06, 7.3016e-07, 1.7285e-06, 3.1888e-06, 2.3395e-06,\n",
      "         1.2219e-06, 4.5449e-06, 2.7716e-06, 4.6045e-06, 7.1526e-07, 1.1325e-06,\n",
      "         3.0696e-06, 9.4622e-07, 4.6194e-07, 1.4603e-06, 5.3942e-06, 1.4380e-06,\n",
      "         9.0897e-07, 3.2187e-06, 5.4836e-06, 4.7684e-07, 2.3693e-06, 5.5134e-07,\n",
      "         2.7120e-06, 5.7789e-07, 5.6426e-01, 2.6816e+00, 1.1793e+00, 2.0586e+00,\n",
      "         4.9343e+00, 1.2562e+00, 3.1097e+00, 3.2301e+00, 1.4220e+00, 1.6569e+00,\n",
      "         1.8634e+00, 4.6328e+00, 7.6335e-01, 1.5062e+00, 1.5727e+00, 3.0261e+00,\n",
      "         1.3212e+00, 4.2642e+00, 4.0641e+00, 2.6189e+00, 2.1301e+00, 3.1099e+00,\n",
      "         1.4474e+00, 1.9402e+00, 1.2319e+00, 1.4213e+00, 1.5156e+00, 1.7441e+00,\n",
      "         2.5724e+00, 2.2567e+00, 2.4574e+00, 1.4604e+00, 2.5967e+00, 1.0231e+00,\n",
      "         2.4015e+00, 2.4279e+00, 3.1503e+00, 1.8364e+00, 8.5158e-01, 1.9569e+00,\n",
      "         1.4356e+00, 1.8375e+00, 2.9105e+00, 2.3556e+00, 2.3741e+00, 1.7112e+00,\n",
      "         1.5592e+00, 2.9050e+00, 3.3449e+00, 3.5274e+00, 3.1616e+00, 1.9679e+00,\n",
      "         1.7310e+00, 1.5854e+00, 2.1436e+00, 1.1726e+00, 3.3880e+00, 1.3201e+00,\n",
      "         6.2906e+00, 1.8338e+00, 1.8755e+00, 1.3650e+00, 2.3126e+00, 3.9022e+00,\n",
      "         1.9902e+00, 2.7019e+00, 3.0337e+00, 4.5125e+00, 2.1898e+00, 1.7586e+00,\n",
      "         1.5855e+00, 1.7776e+00, 1.3179e+00, 3.1103e+00, 2.3244e+00, 2.7689e+00,\n",
      "         1.7270e+00, 1.9525e+00, 1.1601e+00, 2.1371e+00, 7.5722e-01, 1.4559e+00,\n",
      "         1.3596e+00, 2.0545e+00, 2.8005e+00, 4.0975e+00, 2.3197e+00, 2.4111e+00,\n",
      "         2.8868e+00, 3.0004e+00, 6.0095e+00, 3.2873e+00, 2.5986e+00, 1.9027e+00,\n",
      "         1.4816e+00, 3.1076e+00, 9.0247e-01, 1.9478e+00, 2.5587e+00, 1.3259e+00,\n",
      "         1.7374e+00, 1.2060e+00, 2.0998e+00, 1.5736e+00, 8.5598e-01, 1.4928e+00,\n",
      "         2.5513e+00, 2.3432e+00, 1.6658e+00, 2.3279e+00, 1.0143e+00, 2.7529e+00,\n",
      "         3.3648e+00, 5.7143e+00, 2.1338e+00, 2.3254e+00, 1.4722e+00, 1.7701e+00,\n",
      "         2.1899e+00, 1.8169e+00, 1.9712e+00, 2.0230e+00, 2.0600e+00, 1.4744e+00,\n",
      "         1.9557e+00, 1.6247e+00, 4.4267e+00, 1.5697e+00, 2.3931e-01, 4.0410e-01,\n",
      "         4.0539e-01, 3.7400e-02, 4.5988e-02, 3.6862e-01, 2.4672e-01, 2.8937e-01,\n",
      "         3.9024e-01, 1.1514e-01, 2.9604e-01, 1.5702e-02, 2.6110e-01, 5.3585e-01,\n",
      "         4.3161e-01, 2.9012e-01, 4.6025e-01, 2.5344e-01, 2.4138e-01, 1.5826e-01,\n",
      "         2.1045e-01, 2.6898e-01, 2.8793e-01, 3.4552e-02, 1.5356e-01, 1.7731e-01,\n",
      "         2.3553e-01, 1.7353e-01, 3.1420e-01, 3.0160e-01, 2.4083e-01, 2.5254e-01,\n",
      "         8.7930e-02, 1.8736e-01, 4.3027e-01, 1.0631e-01, 1.0160e-01, 4.1729e-01,\n",
      "         2.5964e-01, 2.4195e-01, 1.0696e-01, 1.6398e-01, 2.2055e-01, 4.1121e-01,\n",
      "         3.4831e-01, 3.1054e-01, 4.0762e-01, 2.6364e-01, 3.1609e-01, 5.7414e-02,\n",
      "         2.0170e-01, 1.8667e-01, 1.3004e-01, 3.9631e-02, 2.6248e-01, 4.7937e-01,\n",
      "         2.4259e-01, 2.0983e-01, 2.7500e-02, 4.3503e-02, 1.4259e-01, 4.6905e-02,\n",
      "         2.2777e-01, 2.0409e-02, 3.0807e-01, 3.7806e-01, 4.3295e-01, 4.3768e-01,\n",
      "         1.8854e-01, 5.5636e-02, 3.3140e-01, 3.1571e-01, 2.6345e-01, 1.8415e-01,\n",
      "         2.8161e-02, 3.4156e-01, 3.1950e-01, 1.0174e-01, 1.3578e-01, 2.3827e-01,\n",
      "         2.2477e-01, 3.8128e-01, 4.8579e-01, 3.9603e-01, 3.2712e-01, 3.8912e-01,\n",
      "         2.4420e-01, 3.5866e-01, 1.5442e-02, 1.0350e-01, 1.0620e-02, 4.9151e-01,\n",
      "         4.8049e-02, 2.2484e-01, 2.8888e-01, 2.4745e-01, 4.0695e-01, 4.2732e-01,\n",
      "         3.1836e-01, 4.1294e-02, 2.5704e-01, 3.5795e-01, 4.3421e-01, 3.5956e-01,\n",
      "         4.5240e-01, 2.0632e-01, 2.8977e-01, 3.8386e-01, 1.0542e-01, 3.0037e-01,\n",
      "         2.4741e-01, 1.8620e-01, 1.5024e-01, 3.6493e-01, 1.8820e-01, 2.5399e-02,\n",
      "         1.4013e-01, 3.7521e-01, 1.3666e-01, 4.7645e-01, 2.9780e-01, 3.7403e-02,\n",
      "         2.1020e-01, 2.1395e-01, 3.3497e-02, 1.5640e-01, 2.5027e-01, 5.7275e-02,\n",
      "         1.0919e-01, 1.0439e-01, 1.3843e-01, 1.6965e-01, 9.9218e-02, 2.1834e-01,\n",
      "         2.1331e-01, 6.3182e-02, 1.5681e-02, 1.2275e-01, 1.6084e-01, 1.2061e-01,\n",
      "         1.9425e-01, 1.0966e-01, 1.4505e-01, 9.2195e-02, 1.4660e-01, 2.5722e-01,\n",
      "         1.7563e-01, 1.2910e-01, 1.4222e-01, 9.9012e-02, 9.0075e-02, 1.5015e-01,\n",
      "         9.3843e-02, 1.1178e-01, 1.2097e-01, 2.2771e-01, 1.8766e-01, 2.6477e-01,\n",
      "         1.9816e-01, 1.7178e-01, 9.6793e-02, 2.5613e-01, 2.7177e-01, 1.8123e-01,\n",
      "         2.8189e-01, 2.5610e-01, 1.9632e-01, 1.8159e-01, 1.2443e-01, 2.2108e-01,\n",
      "         1.4773e-01, 2.5773e-01, 2.1962e-01, 2.4053e-01, 2.2738e-01, 2.2563e-01,\n",
      "         9.0221e-02, 1.6103e-01, 6.3301e-02, 1.0466e-01, 1.1666e-01, 1.1357e-01,\n",
      "         1.6154e-01, 1.7271e-01, 1.0321e-01, 1.5623e-01, 1.9141e-01, 1.2741e-01,\n",
      "         1.3523e-01, 3.2490e-01, 2.1485e-01, 1.1012e-01, 5.9144e-02, 7.2891e-02,\n",
      "         1.9060e-01, 1.0357e-01, 2.1945e-01, 2.0435e-01, 1.8086e-01, 1.8735e-01,\n",
      "         2.1765e-01, 2.3851e-01, 6.7126e-02, 7.1935e-02, 1.4211e-01, 1.4313e-01,\n",
      "         1.2998e-01, 2.3925e-01, 6.4820e-02, 9.9152e-02, 7.6091e-02, 3.0376e-01,\n",
      "         9.9465e-02, 5.6997e-02, 1.6468e-01, 1.0963e-01, 1.7090e-01, 2.4013e-01,\n",
      "         8.4197e-02, 1.6931e-01, 2.1842e-01, 6.7479e-02, 1.7772e-01, 2.0949e-01,\n",
      "         1.0138e-01, 1.6905e-01, 1.3342e-01, 9.6049e-02, 3.4773e-01, 2.1085e-01,\n",
      "         1.0309e-01, 2.0527e-01, 3.5727e-02, 1.2283e-01, 1.6188e-01, 1.3716e-01,\n",
      "         1.5240e-01, 8.0693e-02, 2.4836e-01, 2.3060e-01, 9.6210e-02, 1.9659e-01,\n",
      "         1.2274e-01, 2.0060e-01, 1.1826e-01, 2.3232e-01, 1.3300e-01, 8.5410e-02,\n",
      "         1.3575e-01, 2.0593e-01, 1.8626e-01, 1.8186e-01, 2.0299e-01, 1.2457e-01,\n",
      "         8.5097e-02, 1.4762e-01]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 63: layer4.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 63\n",
      "Max diff:\n",
      "tensor([2.9728])\n",
      "\n",
      "tensor([[2.4308e-07, 9.2201e-08, 5.6997e-07, 4.8056e-07, 1.4976e-06, 8.6613e-07,\n",
      "         9.7090e-08, 9.7230e-07, 7.3761e-07, 3.7998e-07, 7.8915e-08, 3.0175e-07,\n",
      "         5.0478e-07, 2.5262e-07, 6.8732e-07, 1.1139e-06, 3.9116e-07, 3.0287e-06,\n",
      "         8.1956e-08, 6.2585e-07, 1.6950e-07, 4.4703e-07, 1.2144e-06, 9.7603e-07,\n",
      "         6.3889e-07, 1.0133e-06, 6.5193e-07, 1.1461e-07, 5.1409e-07, 3.1479e-07,\n",
      "         7.8976e-07, 4.6939e-07, 4.9360e-07, 7.9535e-07, 5.3830e-07, 1.8254e-07,\n",
      "         2.0326e-07, 1.2014e-07, 1.4789e-06, 1.0282e-06, 5.6997e-07, 7.3016e-07,\n",
      "         6.2957e-07, 1.3714e-07, 2.1048e-07, 1.4156e-07, 5.4017e-08, 7.1526e-07,\n",
      "         4.2468e-07, 5.0664e-07, 3.4180e-07, 3.7439e-07, 6.4075e-07, 3.2596e-07,\n",
      "         2.4587e-07, 1.6950e-07, 6.3889e-07, 3.1479e-07, 8.8289e-07, 5.7369e-07,\n",
      "         4.2841e-07, 1.8254e-06, 7.8976e-07, 8.8476e-08, 1.3765e-06, 2.0862e-07,\n",
      "         5.8860e-07, 4.6380e-07, 1.0915e-06, 4.4703e-07, 8.1025e-07, 6.2212e-07,\n",
      "         1.3597e-07, 2.0489e-07, 7.6741e-07, 1.7248e-06, 5.8673e-07, 1.6466e-06,\n",
      "         1.7369e-07, 4.0606e-07, 1.0617e-06, 3.1665e-07, 1.8161e-07, 1.5646e-07,\n",
      "         7.4506e-07, 8.3819e-07, 1.0692e-06, 9.4622e-07, 7.8604e-07, 4.1351e-07,\n",
      "         1.4864e-06, 8.0839e-07, 7.4506e-07, 3.3900e-07, 7.0035e-07, 8.6054e-07,\n",
      "         3.0268e-08, 1.2293e-06, 4.6380e-07, 3.3900e-07, 1.3039e-07, 3.2224e-07,\n",
      "         2.5146e-07, 1.2014e-06, 1.6019e-07, 4.1164e-07, 7.9535e-07, 5.7183e-07,\n",
      "         3.0547e-07, 1.2852e-06, 7.0035e-07, 1.3262e-06, 1.6019e-07, 3.3528e-07,\n",
      "         7.9349e-07, 2.1420e-07, 1.1921e-07, 4.0326e-07, 1.7434e-06, 3.7998e-07,\n",
      "         2.1234e-07, 8.0466e-07, 2.0713e-06, 1.3784e-07, 5.8673e-07, 1.3132e-07,\n",
      "         6.7428e-07, 1.4296e-07, 7.5782e-02, 4.2420e-01, 1.4212e-01, 5.5805e-01,\n",
      "         3.4155e-01, 1.8208e-01, 2.1015e+00, 7.3185e-01, 2.6825e-01, 4.6739e-02,\n",
      "         1.3288e-01, 1.3307e+00, 1.3158e-02, 2.7138e-01, 6.4417e-01, 3.5654e-01,\n",
      "         5.0112e-01, 9.5081e-01, 2.1443e+00, 6.3291e-01, 3.0608e-01, 4.7709e-01,\n",
      "         8.0482e-01, 4.1344e-01, 1.9411e-01, 4.6769e-01, 3.9686e-01, 2.7062e-01,\n",
      "         8.3333e-01, 3.9876e-01, 3.6198e-01, 4.4036e-01, 1.1125e-01, 4.9205e-01,\n",
      "         9.6989e-01, 1.1913e+00, 1.5844e+00, 4.1296e-01, 2.4340e-01, 2.2057e-01,\n",
      "         3.3148e-01, 5.4443e-01, 1.0588e+00, 5.1252e-01, 9.0059e-01, 1.8137e-01,\n",
      "         5.3389e-01, 1.0557e+00, 1.3725e+00, 1.5160e+00, 1.1422e+00, 3.0203e-01,\n",
      "         3.5786e-01, 5.5422e-01, 8.2585e-01, 2.0254e-01, 2.0222e+00, 1.0984e+00,\n",
      "         1.7348e+00, 2.8855e-01, 4.7194e-01, 3.1758e-01, 3.3635e-01, 7.1179e-01,\n",
      "         3.7023e-01, 1.8755e+00, 1.0680e+00, 1.2480e+00, 4.6499e-01, 5.4364e-01,\n",
      "         2.7402e-01, 9.1822e-01, 7.7092e-02, 1.1358e+00, 1.7527e+00, 7.0826e-01,\n",
      "         9.3822e-01, 3.2405e-01, 2.5005e-01, 5.4390e-01, 2.4500e-01, 1.9110e-01,\n",
      "         2.8099e-01, 3.8267e-01, 7.8440e-01, 8.6240e-01, 7.2309e-01, 1.8292e+00,\n",
      "         1.3233e+00, 9.1585e-01, 1.4429e+00, 8.4990e-01, 1.7199e+00, 6.3002e-01,\n",
      "         9.1232e-01, 1.6481e+00, 3.5075e-01, 6.0500e-01, 5.0910e-01, 9.0105e-01,\n",
      "         3.4532e-01, 2.4821e-01, 6.8844e-01, 3.9948e-01, 3.2051e-01, 2.0586e-01,\n",
      "         6.3593e-01, 5.3238e-01, 4.1885e-01, 9.9770e-01, 7.6241e-01, 3.9846e-01,\n",
      "         1.4084e+00, 2.9728e+00, 4.3455e-01, 1.9777e-01, 4.4476e-01, 9.4251e-01,\n",
      "         8.2869e-01, 5.9751e-01, 4.7963e-01, 5.5747e-01, 5.6444e-01, 6.0866e-01,\n",
      "         4.9543e-01, 3.0671e-01, 1.0619e+00, 3.0784e-01, 4.9763e-02, 1.7639e-01,\n",
      "         1.3896e-01, 8.1129e-03, 1.3553e-02, 9.2912e-02, 5.9884e-02, 8.7250e-02,\n",
      "         1.4898e-01, 2.9449e-02, 7.0886e-02, 3.6879e-03, 3.9313e-02, 1.9123e-01,\n",
      "         2.0550e-01, 5.8578e-02, 1.0674e-01, 3.8573e-02, 7.1271e-02, 2.9654e-02,\n",
      "         2.5893e-02, 5.5775e-02, 1.0315e-01, 8.3942e-03, 8.1701e-02, 3.9872e-02,\n",
      "         8.3318e-02, 4.6680e-02, 9.6053e-02, 1.2404e-01, 6.5832e-02, 9.6580e-02,\n",
      "         1.7189e-02, 9.1333e-02, 3.0646e-02, 6.6136e-03, 1.9774e-02, 6.2488e-02,\n",
      "         5.6804e-02, 1.0760e-01, 1.7273e-02, 2.9248e-02, 6.4520e-02, 1.9599e-01,\n",
      "         1.1008e-01, 1.2125e-01, 1.4429e-01, 4.4442e-02, 1.2704e-01, 1.6214e-02,\n",
      "         1.8606e-02, 4.8565e-02, 1.5847e-03, 9.4752e-03, 6.7402e-02, 3.0110e-01,\n",
      "         1.2362e-01, 8.9133e-02, 6.8615e-03, 4.1361e-04, 2.4383e-02, 1.4352e-02,\n",
      "         5.8741e-02, 5.5019e-03, 8.4658e-02, 1.7692e-01, 1.1744e-01, 1.1769e-01,\n",
      "         9.4068e-03, 1.4943e-02, 1.8224e-01, 5.3526e-02, 3.0480e-02, 5.3303e-02,\n",
      "         5.9752e-03, 1.2153e-01, 1.5391e-01, 2.4880e-02, 7.8467e-02, 1.2229e-01,\n",
      "         6.9563e-02, 7.9108e-02, 1.3317e-01, 1.2190e-01, 3.0707e-02, 1.7354e-01,\n",
      "         7.9329e-02, 1.3293e-01, 3.9708e-03, 2.9137e-03, 2.4945e-03, 2.2550e-01,\n",
      "         1.3024e-02, 7.1556e-02, 1.3808e-01, 1.2326e-01, 1.8669e-01, 1.7702e-01,\n",
      "         4.8700e-02, 9.6398e-03, 9.6331e-02, 7.6558e-02, 1.4150e-01, 1.8035e-01,\n",
      "         2.4347e-01, 2.5733e-03, 1.2020e-01, 1.9171e-01, 2.4529e-02, 6.0626e-02,\n",
      "         8.5402e-02, 4.0947e-02, 2.0040e-02, 6.5292e-02, 1.0628e-01, 6.0092e-03,\n",
      "         2.1166e-02, 1.7897e-01, 2.0424e-03, 1.4881e-01, 8.2658e-02, 8.9548e-03,\n",
      "         3.8452e-02, 1.4435e-02, 9.4663e-03, 5.2904e-02, 2.0727e-03, 1.4429e-02,\n",
      "         3.5563e-02, 2.7324e-02, 2.6663e-02, 6.1022e-02, 4.8925e-02, 8.1174e-02,\n",
      "         5.0957e-02, 6.9578e-04, 4.3134e-03, 5.7959e-02, 3.3295e-02, 3.5885e-02,\n",
      "         5.6711e-02, 1.9617e-02, 7.5046e-02, 1.2914e-02, 1.8845e-02, 6.6125e-02,\n",
      "         7.4985e-02, 4.0214e-02, 5.7539e-02, 1.6550e-03, 2.1220e-02, 8.3662e-02,\n",
      "         4.7077e-02, 3.3508e-02, 2.5607e-02, 7.0090e-02, 5.7503e-02, 8.3952e-02,\n",
      "         8.2970e-02, 4.7137e-02, 1.9216e-02, 5.8063e-02, 6.9348e-02, 2.9723e-02,\n",
      "         1.0712e-01, 7.2047e-02, 4.1913e-02, 2.3964e-02, 2.6332e-02, 6.6458e-02,\n",
      "         3.7385e-02, 7.0659e-02, 9.3696e-02, 7.7333e-02, 4.4766e-02, 8.7596e-02,\n",
      "         3.2273e-02, 4.7957e-02, 2.7617e-02, 3.1979e-02, 3.3234e-02, 3.2213e-02,\n",
      "         5.0553e-02, 6.9739e-02, 1.9595e-02, 4.9787e-02, 5.6139e-02, 4.9846e-02,\n",
      "         4.8573e-02, 1.1538e-01, 6.9230e-02, 2.8083e-02, 4.9281e-03, 2.3700e-02,\n",
      "         5.9674e-02, 4.1825e-02, 9.1803e-02, 5.7987e-02, 5.3632e-02, 8.9464e-02,\n",
      "         5.5007e-02, 5.9393e-02, 2.3639e-02, 1.5823e-02, 3.3760e-02, 4.7597e-02,\n",
      "         5.8692e-02, 9.9596e-02, 5.0238e-02, 4.6413e-02, 2.8971e-02, 4.8072e-02,\n",
      "         1.1803e-02, 1.9556e-02, 6.2819e-02, 3.2683e-02, 6.6640e-02, 5.3378e-02,\n",
      "         1.3218e-02, 7.7236e-02, 4.8214e-02, 1.2195e-02, 6.1785e-02, 7.2373e-02,\n",
      "         2.1272e-02, 5.7775e-02, 3.3943e-02, 1.4869e-02, 1.5990e-01, 1.1938e-01,\n",
      "         3.1000e-02, 5.1574e-02, 5.3061e-03, 1.1452e-02, 6.3663e-02, 2.9680e-02,\n",
      "         6.1112e-02, 1.9171e-02, 4.9422e-02, 6.5749e-02, 3.8830e-02, 8.9530e-02,\n",
      "         3.1627e-02, 7.9216e-02, 4.2866e-02, 7.7360e-02, 2.3711e-02, 9.0758e-03,\n",
      "         5.6402e-02, 7.8724e-02, 5.8566e-02, 2.0102e-02, 6.5723e-02, 1.7782e-02,\n",
      "         1.8191e-02, 3.0319e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 64: layer4.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 64\n",
      "Max diff:\n",
      "tensor([3.0739])\n",
      "\n",
      "tensor([[1.4063e-06, 8.5467e-06, 5.6997e-07, 1.9036e-06, 1.4976e-06, 8.6613e-07,\n",
      "         9.7090e-08, 3.3416e-06, 7.3761e-07, 3.7998e-07, 7.8915e-08, 3.0175e-07,\n",
      "         5.0478e-07, 8.0792e-06, 6.8732e-07, 1.5409e-05, 3.9116e-07, 6.5323e-06,\n",
      "         9.5419e-06, 6.2585e-07, 1.6950e-07, 4.4703e-07, 1.2144e-06, 9.7603e-07,\n",
      "         6.3889e-07, 1.0133e-06, 6.5193e-07, 5.2429e-06, 2.4540e-06, 3.1479e-07,\n",
      "         7.8976e-07, 4.6939e-07, 4.9360e-07, 7.9535e-07, 5.9162e-06, 1.8254e-07,\n",
      "         2.0326e-07, 1.2014e-07, 1.4789e-06, 2.9001e-06, 5.6997e-07, 7.3016e-07,\n",
      "         2.3898e-05, 1.3714e-07, 2.1048e-07, 1.4156e-07, 5.4017e-08, 8.4946e-06,\n",
      "         4.2468e-07, 5.0664e-07, 3.4180e-07, 3.7439e-07, 1.6593e-05, 3.2596e-07,\n",
      "         9.8906e-07, 2.8489e-06, 4.4107e-06, 3.1479e-07, 8.8289e-07, 5.7369e-07,\n",
      "         4.2841e-07, 1.8254e-06, 1.5198e-05, 8.8476e-08, 1.3765e-06, 2.0862e-07,\n",
      "         5.8860e-07, 4.6380e-07, 2.6487e-06, 1.9890e-05, 8.1025e-07, 6.2212e-07,\n",
      "         1.4694e-05, 2.0489e-07, 7.6741e-07, 1.7248e-06, 5.8673e-07, 4.7651e-06,\n",
      "         1.7369e-07, 4.0606e-07, 1.0617e-06, 3.1665e-07, 1.8161e-07, 3.2093e-06,\n",
      "         7.4506e-07, 1.2954e-05, 1.0692e-06, 4.0817e-04, 7.8604e-07, 4.1351e-07,\n",
      "         1.2026e-05, 8.0839e-07, 7.4506e-07, 3.3900e-07, 1.3074e-05, 9.0040e-06,\n",
      "         3.0268e-08, 1.2293e-06, 4.6380e-07, 3.3248e-06, 1.3039e-07, 3.2224e-07,\n",
      "         2.5146e-07, 2.6999e-05, 1.3030e-05, 1.1715e-05, 4.1174e-06, 5.7183e-07,\n",
      "         1.9981e-05, 2.3330e-05, 1.6429e-05, 1.3262e-06, 8.4233e-06, 3.3528e-07,\n",
      "         7.9349e-07, 1.3426e-05, 3.8743e-07, 4.0326e-07, 1.7434e-06, 1.0393e-05,\n",
      "         2.1234e-07, 8.0466e-07, 2.0713e-06, 1.3784e-07, 5.8673e-07, 1.8314e-05,\n",
      "         5.0925e-06, 1.4296e-07, 7.5782e-02, 9.2539e-01, 1.4212e-01, 7.8862e-01,\n",
      "         3.4155e-01, 7.0267e-01, 2.1015e+00, 7.3185e-01, 5.3203e-01, 3.4745e-01,\n",
      "         3.4210e-01, 1.3307e+00, 1.8568e-01, 6.2160e-01, 6.4417e-01, 3.5654e-01,\n",
      "         6.3881e-01, 9.5081e-01, 2.1443e+00, 8.2045e-01, 2.7540e-01, 1.0569e+00,\n",
      "         8.0482e-01, 4.1344e-01, 3.0276e-01, 2.0664e+00, 3.9686e-01, 4.6133e-01,\n",
      "         8.3333e-01, 3.9876e-01, 3.6198e-01, 1.2011e+00, 1.1125e-01, 1.0047e+00,\n",
      "         9.6989e-01, 1.1675e+00, 1.2634e+00, 4.1296e-01, 3.7884e-01, 3.8941e-01,\n",
      "         3.3148e-01, 5.9092e-01, 1.0588e+00, 5.1252e-01, 9.0059e-01, 3.4157e-01,\n",
      "         6.1742e-01, 1.0557e+00, 1.3725e+00, 1.2055e+00, 2.0802e+00, 3.0203e-01,\n",
      "         3.5786e-01, 5.5422e-01, 8.2585e-01, 2.0254e-01, 2.0222e+00, 1.0984e+00,\n",
      "         1.7348e+00, 2.8855e-01, 5.3988e-01, 5.1486e-01, 5.9626e-01, 1.2831e+00,\n",
      "         3.7023e-01, 1.8755e+00, 1.1030e+00, 1.2480e+00, 4.6499e-01, 5.4364e-01,\n",
      "         2.7402e-01, 9.1822e-01, 7.7092e-02, 1.1358e+00, 1.7527e+00, 3.7211e-01,\n",
      "         9.3822e-01, 3.2405e-01, 2.5005e-01, 5.4390e-01, 2.9193e-01, 1.9110e-01,\n",
      "         2.8099e-01, 3.8267e-01, 7.8440e-01, 8.6240e-01, 7.2309e-01, 1.8292e+00,\n",
      "         1.3233e+00, 9.1585e-01, 1.4429e+00, 8.7800e-01, 1.7199e+00, 5.0634e-01,\n",
      "         9.1232e-01, 1.6481e+00, 3.5075e-01, 1.3909e+00, 5.2719e-01, 9.0105e-01,\n",
      "         4.2708e-01, 4.9531e-01, 6.8844e-01, 6.5841e-01, 3.2051e-01, 2.0586e-01,\n",
      "         6.3593e-01, 1.4356e+00, 9.8698e-01, 9.9770e-01, 7.6241e-01, 3.9846e-01,\n",
      "         1.4084e+00, 3.0739e+00, 8.2457e-01, 1.0358e+00, 4.4476e-01, 9.4251e-01,\n",
      "         1.2297e+00, 5.9751e-01, 4.7963e-01, 6.9303e-01, 5.6444e-01, 6.0866e-01,\n",
      "         4.9543e-01, 3.0671e-01, 1.3711e+00, 9.0251e-01, 4.9763e-02, 1.7639e-01,\n",
      "         1.3896e-01, 8.1129e-03, 1.3553e-02, 9.2748e-02, 5.9884e-02, 8.6722e-02,\n",
      "         1.4898e-01, 2.9449e-02, 6.9986e-02, 3.6879e-03, 3.8923e-02, 4.1143e-01,\n",
      "         2.0550e-01, 5.8578e-02, 1.0674e-01, 3.8573e-02, 7.1271e-02, 2.8915e-02,\n",
      "         2.5893e-02, 5.5775e-02, 1.0315e-01, 8.3942e-03, 8.1701e-02, 3.9778e-02,\n",
      "         8.3318e-02, 4.6680e-02, 9.6053e-02, 1.2404e-01, 6.5832e-02, 9.6580e-02,\n",
      "         1.7189e-02, 9.1333e-02, 3.0646e-02, 5.8506e-03, 1.9774e-02, 6.3314e-02,\n",
      "         5.7756e-02, 1.0760e-01, 1.7273e-02, 2.9248e-02, 6.4520e-02, 1.9599e-01,\n",
      "         3.6803e-01, 1.2125e-01, 1.4429e-01, 4.4442e-02, 1.2704e-01, 1.6214e-02,\n",
      "         1.8606e-02, 4.8565e-02, 1.7304e-03, 9.4752e-03, 6.7402e-02, 3.0110e-01,\n",
      "         1.2362e-01, 2.6895e-01, 6.8615e-03, 4.1361e-04, 2.4383e-02, 1.4352e-02,\n",
      "         5.8741e-02, 5.5019e-03, 8.5252e-02, 1.7692e-01, 3.6702e-01, 1.1732e-01,\n",
      "         9.6779e-03, 1.4943e-02, 1.8224e-01, 5.3526e-02, 3.0480e-02, 5.4412e-02,\n",
      "         5.9752e-03, 1.2153e-01, 1.5391e-01, 2.4880e-02, 7.8467e-02, 1.2229e-01,\n",
      "         6.9563e-02, 7.9163e-02, 1.3368e-01, 1.2200e-01, 3.1034e-02, 1.7354e-01,\n",
      "         7.9329e-02, 1.3293e-01, 3.9708e-03, 2.7047e-03, 2.4945e-03, 2.2550e-01,\n",
      "         1.3024e-02, 7.1556e-02, 1.3808e-01, 1.2326e-01, 1.8669e-01, 1.7702e-01,\n",
      "         1.8353e-01, 9.6398e-03, 9.6331e-02, 7.6558e-02, 1.4150e-01, 1.8035e-01,\n",
      "         2.4347e-01, 2.5733e-03, 1.2043e-01, 1.9217e-01, 2.4529e-02, 6.0626e-02,\n",
      "         8.5402e-02, 4.0947e-02, 2.0040e-02, 6.5292e-02, 1.0628e-01, 6.0092e-03,\n",
      "         2.1166e-02, 1.7897e-01, 1.4780e-03, 1.4881e-01, 8.2658e-02, 8.9548e-03,\n",
      "         3.8452e-02, 1.4435e-02, 9.4663e-03, 5.2904e-02, 2.0668e-03, 1.4429e-02,\n",
      "         1.9242e-01, 8.5569e-02, 6.4171e-02, 1.5099e-01, 2.6160e-01, 8.1174e-02,\n",
      "         5.0957e-02, 5.2580e-02, 4.3134e-03, 5.7959e-02, 3.3295e-02, 8.7696e-02,\n",
      "         5.6711e-02, 1.2638e-01, 7.5046e-02, 1.0871e-01, 1.8845e-02, 6.6125e-02,\n",
      "         7.4985e-02, 1.5130e-01, 5.8653e-02, 1.6550e-03, 2.1220e-02, 1.2537e-01,\n",
      "         4.7077e-02, 3.3508e-02, 2.5607e-02, 7.0090e-02, 6.6370e-02, 8.3952e-02,\n",
      "         8.2970e-02, 1.2438e-01, 8.1655e-02, 8.9956e-02, 6.9348e-02, 7.2258e-02,\n",
      "         1.5833e-01, 7.2047e-02, 4.1913e-02, 2.3964e-02, 1.3077e-01, 6.6458e-02,\n",
      "         3.7385e-02, 7.0659e-02, 9.3696e-02, 7.7333e-02, 4.4766e-02, 8.7596e-02,\n",
      "         3.2273e-02, 2.9677e-01, 2.7617e-02, 2.0655e-01, 9.9725e-02, 3.2213e-02,\n",
      "         5.0553e-02, 1.5702e-01, 1.1410e-01, 4.9787e-02, 5.6139e-02, 2.9589e-01,\n",
      "         1.0992e-01, 1.1538e-01, 6.9230e-02, 9.9765e-02, 4.9281e-03, 1.6066e-01,\n",
      "         1.8519e-01, 9.4246e-02, 2.2494e-01, 1.2516e-01, 5.3632e-02, 1.8270e-01,\n",
      "         5.5007e-02, 1.4178e-01, 2.3639e-02, 1.5823e-02, 3.3760e-02, 4.7597e-02,\n",
      "         5.8692e-02, 9.9596e-02, 7.3253e-02, 9.3225e-02, 2.9063e-02, 1.0500e-01,\n",
      "         7.9270e-02, 8.1660e-02, 7.7884e-02, 2.7872e-01, 1.2107e-01, 1.4404e-01,\n",
      "         2.3882e-01, 7.7236e-02, 1.0523e-01, 1.2195e-02, 1.1798e-01, 1.1168e-01,\n",
      "         4.5529e-02, 5.7775e-02, 3.3943e-02, 1.1181e-01, 1.5990e-01, 1.7881e-01,\n",
      "         9.2469e-02, 5.1574e-02, 5.3061e-03, 4.6894e-02, 6.3663e-02, 5.3511e-02,\n",
      "         9.6448e-02, 1.9171e-02, 4.9422e-02, 8.2856e-02, 3.8830e-02, 1.7721e-01,\n",
      "         3.1627e-02, 7.9216e-02, 4.2866e-02, 1.5794e-01, 9.2409e-02, 2.7713e-02,\n",
      "         1.9289e-01, 7.8724e-02, 2.0346e-01, 2.0102e-02, 6.5723e-02, 8.8304e-02,\n",
      "         1.8191e-02, 3.0319e-02]])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 65: layer4.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 65\n",
      "Max diff:\n",
      "tensor([1.8047])\n",
      "\n",
      "tensor([[1.4063e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7987e-07, 4.8988e-07,\n",
      "         6.3796e-08, 0.0000e+00, 0.0000e+00, 1.9604e-07, 5.6956e-08, 1.7724e-07,\n",
      "         3.7625e-07, 8.0792e-06, 0.0000e+00, 0.0000e+00, 2.5053e-07, 0.0000e+00,\n",
      "         6.2017e-06, 3.2363e-07, 9.6858e-08, 1.9558e-07, 0.0000e+00, 0.0000e+00,\n",
      "         2.7986e-07, 4.8801e-07, 3.6275e-07, 5.2429e-06, 2.4540e-06, 1.3877e-07,\n",
      "         0.0000e+00, 2.3190e-07, 3.1223e-07, 0.0000e+00, 5.9162e-06, 1.0990e-07,\n",
      "         1.3411e-07, 0.0000e+00, 0.0000e+00, 2.9001e-06, 0.0000e+00, 0.0000e+00,\n",
      "         2.3898e-05, 8.2597e-08, 1.1362e-07, 7.5903e-08, 0.0000e+00, 6.3782e-06,\n",
      "         1.8440e-07, 1.7602e-07, 1.5739e-07, 1.7136e-07, 1.6593e-05, 0.0000e+00,\n",
      "         9.8906e-07, 0.0000e+00, 2.9635e-06, 0.0000e+00, 0.0000e+00, 2.4959e-07,\n",
      "         1.6019e-07, 0.0000e+00, 1.5198e-05, 5.8208e-08, 0.0000e+00, 1.5112e-07,\n",
      "         3.0338e-07, 1.8568e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6461e-07,\n",
      "         5.7938e-06, 1.0617e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7651e-06,\n",
      "         1.0710e-07, 1.9977e-07, 0.0000e+00, 1.3132e-07, 1.0710e-07, 3.2093e-06,\n",
      "         3.3865e-07, 1.1803e-05, 0.0000e+00, 4.0817e-04, 4.6915e-07, 1.9372e-07,\n",
      "         7.0208e-06, 0.0000e+00, 0.0000e+00, 1.6578e-07, 0.0000e+00, 9.0040e-06,\n",
      "         0.0000e+00, 0.0000e+00, 1.6392e-07, 3.3248e-06, 6.4872e-08, 2.0186e-07,\n",
      "         1.2480e-07, 2.6999e-05, 7.6604e-06, 9.8040e-06, 0.0000e+00, 3.2084e-07,\n",
      "         1.1098e-05, 0.0000e+00, 1.6429e-05, 0.0000e+00, 7.3183e-06, 1.3015e-07,\n",
      "         0.0000e+00, 1.3426e-05, 3.8743e-07, 2.7940e-07, 8.4611e-07, 1.0393e-05,\n",
      "         1.0105e-07, 3.3155e-07, 1.0245e-06, 9.0338e-08, 2.9895e-07, 1.8314e-05,\n",
      "         1.9297e-06, 0.0000e+00, 7.5782e-02, 2.8931e-02, 3.7938e-02, 7.8862e-01,\n",
      "         1.0670e-01, 7.0267e-01, 1.8047e+00, 6.4589e-02, 5.1050e-01, 3.4745e-01,\n",
      "         3.4210e-01, 3.6367e-01, 1.8255e-01, 2.8974e-01, 5.6431e-02, 0.0000e+00,\n",
      "         6.3881e-01, 0.0000e+00, 1.5419e+00, 4.4214e-01, 0.0000e+00, 9.1355e-01,\n",
      "         0.0000e+00, 0.0000e+00, 1.5746e-01, 1.2250e+00, 0.0000e+00, 2.9878e-02,\n",
      "         5.2137e-01, 3.9876e-01, 0.0000e+00, 1.2011e+00, 0.0000e+00, 1.0047e+00,\n",
      "         3.9137e-01, 1.1415e+00, 8.2669e-01, 0.0000e+00, 3.7884e-01, 3.8941e-01,\n",
      "         1.5382e-01, 5.9092e-01, 6.4826e-01, 3.1974e-01, 8.5509e-01, 3.0939e-01,\n",
      "         6.1742e-01, 3.9569e-01, 1.0682e-01, 0.0000e+00, 7.0034e-01, 0.0000e+00,\n",
      "         2.1240e-01, 5.1910e-01, 4.4577e-01, 0.0000e+00, 6.9904e-01, 1.0025e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.3988e-01, 3.1758e-01, 5.1092e-01, 1.2831e+00,\n",
      "         2.4457e-01, 1.4363e+00, 3.2226e-01, 0.0000e+00, 0.0000e+00, 1.8184e-01,\n",
      "         0.0000e+00, 7.1557e-01, 5.4660e-02, 0.0000e+00, 5.5408e-01, 2.1040e-01,\n",
      "         4.4669e-01, 3.5439e-02, 0.0000e+00, 5.4390e-01, 2.9193e-01, 0.0000e+00,\n",
      "         1.5504e-01, 0.0000e+00, 1.7430e-01, 0.0000e+00, 4.5123e-01, 1.3713e+00,\n",
      "         1.2441e+00, 0.0000e+00, 0.0000e+00, 8.7800e-01, 1.7199e+00, 4.3694e-01,\n",
      "         8.1505e-01, 4.2834e-01, 3.5075e-01, 4.9186e-01, 4.0381e-01, 4.9472e-01,\n",
      "         4.2708e-01, 2.6470e-01, 2.4779e-01, 5.2826e-01, 4.1054e-03, 1.0100e-02,\n",
      "         6.3593e-01, 1.1186e+00, 9.8698e-01, 7.4708e-01, 3.6054e-01, 0.0000e+00,\n",
      "         1.3773e+00, 1.0019e-01, 6.0825e-01, 9.7283e-01, 3.4435e-01, 9.4251e-01,\n",
      "         8.8564e-01, 0.0000e+00, 0.0000e+00, 8.9631e-02, 3.8278e-01, 6.0866e-01,\n",
      "         1.9121e-01, 0.0000e+00, 8.5966e-01, 6.2777e-01, 0.0000e+00, 1.8914e-02,\n",
      "         9.6453e-02, 0.0000e+00, 0.0000e+00, 9.2748e-02, 0.0000e+00, 8.6722e-02,\n",
      "         4.9811e-02, 0.0000e+00, 2.7003e-02, 0.0000e+00, 1.8894e-02, 3.5057e-01,\n",
      "         2.6789e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2017e-02, 2.8915e-02,\n",
      "         1.9385e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9875e-02, 3.8342e-02,\n",
      "         0.0000e+00, 1.3913e-02, 0.0000e+00, 5.7598e-02, 0.0000e+00, 3.2207e-02,\n",
      "         0.0000e+00, 4.9794e-02, 7.7345e-03, 5.8506e-03, 0.0000e+00, 6.3314e-02,\n",
      "         2.2125e-02, 8.6949e-03, 0.0000e+00, 1.8765e-02, 2.1206e-02, 0.0000e+00,\n",
      "         7.6085e-02, 2.6918e-02, 1.0453e-01, 0.0000e+00, 4.3143e-02, 0.0000e+00,\n",
      "         1.7143e-03, 5.0416e-03, 1.7304e-03, 0.0000e+00, 0.0000e+00, 2.1992e-02,\n",
      "         4.1784e-02, 1.6206e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.8993e-02, 0.0000e+00, 4.5079e-02, 1.2814e-01, 1.2357e-01, 1.0118e-01,\n",
      "         9.6779e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8620e-02, 5.4412e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2271e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3368e-01, 1.2200e-01, 3.1034e-02, 0.0000e+00,\n",
      "         6.1857e-02, 9.4628e-03, 0.0000e+00, 2.7047e-03, 1.0337e-03, 0.0000e+00,\n",
      "         0.0000e+00, 4.3240e-02, 0.0000e+00, 2.3576e-02, 0.0000e+00, 2.1942e-02,\n",
      "         1.8353e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5901e-02,\n",
      "         7.0506e-02, 0.0000e+00, 5.7138e-02, 1.6239e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.6511e-02, 0.0000e+00, 2.9863e-02, 0.0000e+00,\n",
      "         1.0021e-02, 0.0000e+00, 1.4780e-03, 0.0000e+00, 1.3388e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0668e-03, 0.0000e+00,\n",
      "         1.9242e-01, 8.5569e-02, 6.4171e-02, 1.5099e-01, 1.9706e-01, 4.1950e-02,\n",
      "         0.0000e+00, 5.2580e-02, 2.3591e-03, 2.4927e-02, 1.2962e-02, 8.7696e-02,\n",
      "         3.6300e-02, 1.2638e-01, 6.8722e-02, 1.0205e-01, 3.2827e-03, 5.5349e-02,\n",
      "         5.3238e-02, 1.5130e-01, 5.8653e-02, 6.2480e-04, 1.7314e-02, 1.2537e-01,\n",
      "         4.7077e-02, 1.6578e-02, 0.0000e+00, 3.5038e-02, 4.0443e-02, 2.9915e-02,\n",
      "         0.0000e+00, 1.2438e-01, 8.1655e-02, 8.9956e-02, 0.0000e+00, 7.2258e-02,\n",
      "         1.5833e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3077e-01, 0.0000e+00,\n",
      "         1.4991e-02, 3.0086e-02, 5.7736e-02, 6.5370e-02, 1.4426e-02, 3.3496e-02,\n",
      "         2.3826e-02, 2.9677e-01, 2.1248e-02, 2.0655e-01, 9.9725e-02, 2.3591e-04,\n",
      "         1.3757e-02, 1.5702e-01, 1.1410e-01, 2.0111e-02, 1.2652e-02, 2.9589e-01,\n",
      "         1.0992e-01, 1.2000e-02, 4.2153e-02, 7.3769e-02, 0.0000e+00, 1.6066e-01,\n",
      "         1.8519e-01, 9.4246e-02, 1.4619e-01, 1.2516e-01, 0.0000e+00, 1.8270e-01,\n",
      "         0.0000e+00, 1.4178e-01, 2.3639e-02, 1.5823e-02, 0.0000e+00, 2.9367e-02,\n",
      "         3.7097e-02, 4.6834e-02, 7.3253e-02, 9.3225e-02, 2.9063e-02, 1.0500e-01,\n",
      "         7.9270e-02, 8.1660e-02, 7.7884e-02, 2.7872e-01, 1.2107e-01, 1.4404e-01,\n",
      "         2.3882e-01, 3.7655e-02, 1.0523e-01, 2.1614e-03, 1.1798e-01, 1.1168e-01,\n",
      "         4.5529e-02, 4.4870e-02, 6.6605e-03, 1.1181e-01, 6.3365e-02, 1.7881e-01,\n",
      "         9.2469e-02, 4.4974e-02, 4.6082e-03, 4.6894e-02, 2.7882e-02, 0.0000e+00,\n",
      "         9.6448e-02, 0.0000e+00, 3.4486e-02, 5.5922e-02, 2.4223e-02, 1.4102e-01,\n",
      "         0.0000e+00, 2.6059e-02, 2.1818e-02, 6.4459e-02, 9.2409e-02, 2.7713e-02,\n",
      "         8.4217e-02, 2.4761e-02, 1.3800e-01, 7.1498e-04, 0.0000e+00, 8.8304e-02,\n",
      "         1.8191e-02, 1.8417e-02]])\n",
      "tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 144, 146, 147, 149, 152, 153, 155, 156, 157, 159,\n",
      "        161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "        176, 178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192, 193, 194,\n",
      "        197, 199, 200, 202, 203, 204, 205, 207, 208, 210, 212, 214, 215, 216,\n",
      "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 249,\n",
      "        250, 251, 252, 254, 255, 257, 258, 261, 263, 264, 266, 268, 269, 270,\n",
      "        274, 275, 276, 280, 281, 283, 285, 287, 289, 290, 291, 293, 294, 295,\n",
      "        297, 298, 300, 301, 302, 304, 306, 307, 308, 311, 312, 313, 318, 320,\n",
      "        321, 322, 323, 324, 328, 329, 334, 338, 339, 340, 342, 343, 345, 346,\n",
      "        349, 351, 353, 354, 359, 360, 362, 363, 368, 370, 372, 374, 376, 382,\n",
      "        384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413,\n",
      "        415, 416, 417, 419, 420, 424, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        449, 450, 451, 452, 453, 455, 457, 458, 459, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
      "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 494, 495,\n",
      "        496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 141, 142, 144, 146, 147, 149, 152, 153, 155, 156, 157, 159, 161,\n",
      "        162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "        178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192, 193, 194, 197,\n",
      "        199, 200, 202, 203, 204, 205, 207, 208, 210, 212, 214, 215, 216, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 249, 250,\n",
      "        251, 254, 255, 257, 258, 261, 263, 264, 266, 268, 269, 270, 274, 275,\n",
      "        276, 280, 281, 283, 285, 287, 289, 290, 291, 293, 294, 295, 297, 300,\n",
      "        301, 302, 304, 306, 307, 308, 311, 312, 313, 318, 320, 321, 323, 324,\n",
      "        328, 329, 334, 338, 339, 340, 342, 343, 345, 346, 349, 351, 353, 354,\n",
      "        359, 360, 362, 363, 368, 370, 372, 374, 376, 382, 384, 385, 386, 387,\n",
      "        388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403,\n",
      "        404, 405, 406, 407, 408, 409, 411, 412, 413, 415, 416, 417, 419, 420,\n",
      "        424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438,\n",
      "        439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450, 451, 452, 453,\n",
      "        455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "        485, 486, 487, 488, 489, 490, 492, 494, 495, 496, 497, 499, 500, 501,\n",
      "        502, 503, 504, 505, 506, 507, 509, 510, 511])  (len = 359)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 66: avg_pool2d\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126])\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 130, 131, 133, 134, 136, 137, 138, 140, 141, 142, 144, 147, 149,\n",
      "        152, 153, 156, 157, 159, 161, 163, 164, 166, 167, 168, 169, 171, 172,\n",
      "        173, 174, 176, 178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192,\n",
      "        193, 194, 197, 199, 200, 202, 203, 204, 205, 207, 208, 210, 214, 215,\n",
      "        216, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 240, 242, 243, 244, 245, 246, 249, 250,\n",
      "        251, 252, 254, 255])\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([257, 258, 261, 263, 264, 266, 268, 269, 270, 274, 275, 276, 280, 281,\n",
      "        283, 285, 287, 290, 291, 293, 295, 297, 298, 301, 302, 304, 306, 307,\n",
      "        308, 311, 312, 313, 318, 320, 321, 322, 323, 324, 328, 329, 334, 338,\n",
      "        339, 340, 342, 345, 346, 349, 351, 353, 354, 359, 360, 362, 363, 368,\n",
      "        370, 372, 374, 376, 382])\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413, 415,\n",
      "        416, 417, 419, 420, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450,\n",
      "        451, 452, 453, 455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 494, 495, 496, 497,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511])\n",
      "\t\t-average pooling\n",
      "Finished execution of layer 66\n",
      "Max diff:\n",
      "tensor([0.7589])\n",
      "\n",
      "tensor([[9.4529e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2945e-07, 6.8219e-08,\n",
      "         4.6566e-10, 0.0000e+00, 0.0000e+00, 3.5507e-08, 6.2500e-09, 1.3773e-08,\n",
      "         2.8871e-08, 4.8988e-07, 0.0000e+00, 0.0000e+00, 2.8289e-08, 0.0000e+00,\n",
      "         8.0955e-07, 4.9244e-08, 7.6834e-09, 2.3749e-08, 0.0000e+00, 0.0000e+00,\n",
      "         5.5908e-08, 7.7300e-08, 5.1339e-08, 3.5448e-07, 1.1153e-07, 2.6776e-08,\n",
      "         0.0000e+00, 3.0501e-08, 4.1793e-08, 0.0000e+00, 3.4634e-07, 1.3970e-08,\n",
      "         8.1491e-09, 0.0000e+00, 0.0000e+00, 1.3411e-07, 0.0000e+00, 0.0000e+00,\n",
      "         2.8913e-06, 1.2536e-08, 2.5146e-08, 9.1968e-09, 0.0000e+00, 8.3563e-07,\n",
      "         3.4925e-08, 3.8766e-08, 2.3050e-08, 2.5029e-08, 1.8480e-06, 0.0000e+00,\n",
      "         4.1910e-08, 0.0000e+00, 2.2561e-07, 0.0000e+00, 0.0000e+00, 4.6275e-08,\n",
      "         3.3528e-08, 0.0000e+00, 1.5090e-06, 1.0594e-08, 0.0000e+00, 1.1016e-08,\n",
      "         3.9086e-08, 2.3210e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8440e-08,\n",
      "         4.6683e-08, 1.1059e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8673e-07,\n",
      "         7.5670e-09, 3.5594e-08, 0.0000e+00, 2.3050e-08, 8.8476e-09, 2.0163e-07,\n",
      "         5.6825e-08, 7.3767e-07, 0.0000e+00, 6.2485e-05, 6.0478e-08, 2.4214e-08,\n",
      "         4.3880e-07, 0.0000e+00, 0.0000e+00, 2.8405e-08, 0.0000e+00, 6.0466e-07,\n",
      "         0.0000e+00, 0.0000e+00, 1.0245e-08, 1.9139e-07, 4.0545e-09, 1.6240e-08,\n",
      "         1.6298e-08, 2.8955e-06, 1.2951e-06, 8.1700e-07, 0.0000e+00, 4.5635e-08,\n",
      "         2.4278e-06, 0.0000e+00, 1.0724e-06, 0.0000e+00, 1.5162e-06, 2.6601e-08,\n",
      "         0.0000e+00, 1.8191e-06, 1.6065e-08, 3.2247e-08, 1.3178e-07, 6.4957e-07,\n",
      "         1.9325e-08, 6.5425e-08, 1.8138e-07, 2.9104e-09, 4.7439e-08, 4.1795e-06,\n",
      "         1.7253e-07, 0.0000e+00, 2.0445e-03, 3.1862e-03, 8.0457e-05, 2.5778e-02,\n",
      "         8.7171e-03, 1.5544e-01, 7.3269e-01, 4.8732e-03, 1.5291e-01, 5.0865e-02,\n",
      "         2.1381e-02, 4.5409e-02, 1.7354e-02, 4.3908e-02, 5.6613e-03, 0.0000e+00,\n",
      "         1.2654e-01, 0.0000e+00, 2.3544e-01, 8.9299e-02, 0.0000e+00, 4.7200e-01,\n",
      "         0.0000e+00, 0.0000e+00, 2.6757e-02, 5.4972e-01, 0.0000e+00, 1.8674e-03,\n",
      "         1.3742e-01, 1.5831e-01, 0.0000e+00, 7.6802e-02, 0.0000e+00, 1.9167e-01,\n",
      "         6.6905e-02, 4.3260e-01, 3.0364e-01, 0.0000e+00, 2.5519e-02, 1.3514e-01,\n",
      "         2.3166e-02, 1.9861e-01, 1.9024e-01, 3.9121e-02, 2.9196e-01, 3.0276e-02,\n",
      "         2.1242e-01, 3.8313e-02, 5.0628e-03, 0.0000e+00, 1.0446e-01, 0.0000e+00,\n",
      "         2.3813e-02, 3.0917e-02, 4.9294e-02, 0.0000e+00, 1.4863e-01, 1.5676e-01,\n",
      "         0.0000e+00, 0.0000e+00, 5.0980e-02, 6.3718e-02, 6.7202e-02, 2.3118e-01,\n",
      "         7.4047e-02, 5.6539e-01, 2.7735e-02, 0.0000e+00, 0.0000e+00, 9.1836e-03,\n",
      "         0.0000e+00, 8.8581e-02, 3.2512e-03, 0.0000e+00, 1.3139e-01, 1.8068e-02,\n",
      "         5.4305e-02, 6.1703e-03, 0.0000e+00, 1.3242e-01, 1.2948e-02, 0.0000e+00,\n",
      "         6.7005e-03, 0.0000e+00, 1.0894e-02, 0.0000e+00, 1.1342e-01, 2.6192e-01,\n",
      "         4.8171e-01, 0.0000e+00, 0.0000e+00, 3.1084e-01, 7.5894e-01, 1.5640e-01,\n",
      "         2.7117e-01, 4.9071e-02, 5.2071e-02, 2.4395e-02, 5.5454e-02, 2.1363e-02,\n",
      "         2.4286e-02, 5.8636e-02, 4.5472e-02, 1.0655e-01, 2.5659e-04, 6.3125e-04,\n",
      "         2.5509e-01, 8.6468e-02, 4.2281e-01, 1.3121e-01, 5.9590e-02, 0.0000e+00,\n",
      "         5.2465e-01, 6.2620e-03, 6.0658e-02, 3.0363e-01, 6.8208e-02, 2.7579e-01,\n",
      "         8.6179e-02, 0.0000e+00, 0.0000e+00, 5.4644e-03, 2.5206e-02, 3.5290e-01,\n",
      "         1.1951e-02, 0.0000e+00, 1.1985e-01, 3.5081e-02, 0.0000e+00, 1.7455e-03,\n",
      "         1.5214e-02, 0.0000e+00, 0.0000e+00, 2.9769e-02, 0.0000e+00, 1.9901e-02,\n",
      "         3.1132e-03, 0.0000e+00, 3.3989e-03, 0.0000e+00, 3.0848e-03, 1.1718e-01,\n",
      "         2.3895e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1452e-03, 4.0387e-03,\n",
      "         1.2116e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0544e-03, 6.0638e-03,\n",
      "         0.0000e+00, 8.6958e-04, 0.0000e+00, 3.2218e-03, 0.0000e+00, 2.0918e-06,\n",
      "         0.0000e+00, 3.1121e-03, 1.4766e-03, 6.2862e-04, 0.0000e+00, 6.7316e-03,\n",
      "         1.3828e-03, 5.4343e-04, 0.0000e+00, 3.0035e-03, 1.3254e-03, 0.0000e+00,\n",
      "         4.7553e-03, 1.7338e-03, 3.4239e-02, 0.0000e+00, 2.6965e-03, 0.0000e+00,\n",
      "         1.7428e-04, 3.1510e-04, 1.3118e-04, 0.0000e+00, 0.0000e+00, 5.1100e-04,\n",
      "         2.3142e-03, 5.2538e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.9048e-03, 0.0000e+00, 2.1258e-03, 1.4929e-02, 7.7234e-03, 2.2190e-02,\n",
      "         3.9441e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5463e-03, 2.7795e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8777e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.6885e-02, 2.8788e-02, 5.2088e-03, 0.0000e+00,\n",
      "         9.6786e-03, 5.9142e-04, 0.0000e+00, 1.7196e-04, 1.0928e-04, 0.0000e+00,\n",
      "         0.0000e+00, 2.7025e-03, 0.0000e+00, 4.9424e-04, 0.0000e+00, 2.5481e-03,\n",
      "         9.2125e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1188e-03,\n",
      "         4.4066e-03, 0.0000e+00, 5.0795e-03, 1.3926e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.8403e-03, 0.0000e+00, 1.7131e-03, 0.0000e+00,\n",
      "         6.2632e-04, 0.0000e+00, 3.8628e-04, 0.0000e+00, 8.3676e-06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5020e-04, 0.0000e+00,\n",
      "         3.2031e-02, 4.0057e-02, 7.9486e-04, 6.7721e-02, 4.6055e-02, 5.6138e-03,\n",
      "         0.0000e+00, 2.7279e-03, 4.4678e-04, 3.8935e-03, 1.8962e-03, 9.2008e-03,\n",
      "         1.3023e-02, 2.1937e-02, 3.1401e-02, 1.8860e-02, 2.0517e-04, 3.9168e-03,\n",
      "         1.6825e-02, 2.0694e-02, 2.7220e-04, 3.9050e-05, 3.4272e-03, 2.9261e-02,\n",
      "         1.1288e-02, 1.3338e-03, 0.0000e+00, 1.1705e-02, 1.1498e-02, 5.4899e-03,\n",
      "         0.0000e+00, 2.7093e-02, 2.8946e-03, 1.9473e-02, 0.0000e+00, 2.7374e-03,\n",
      "         1.9973e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.5701e-03, 0.0000e+00,\n",
      "         9.4724e-04, 6.4692e-03, 1.3243e-02, 1.4908e-02, 3.3283e-03, 6.4677e-03,\n",
      "         2.2629e-03, 7.2430e-02, 1.1361e-03, 1.0570e-01, 1.2126e-02, 1.4744e-05,\n",
      "         7.0564e-04, 3.2637e-02, 1.0288e-02, 2.2630e-03, 7.9074e-04, 1.0860e-01,\n",
      "         2.6912e-02, 7.5001e-04, 7.7402e-03, 5.7887e-03, 0.0000e+00, 3.0738e-02,\n",
      "         4.0391e-02, 2.5093e-02, 1.0624e-02, 4.4865e-02, 0.0000e+00, 4.7658e-02,\n",
      "         0.0000e+00, 6.9128e-02, 2.2560e-03, 2.9278e-03, 0.0000e+00, 3.9092e-03,\n",
      "         1.5071e-02, 1.3470e-02, 1.6475e-02, 1.2940e-02, 4.2439e-03, 4.0381e-02,\n",
      "         2.0978e-02, 8.1073e-03, 1.5807e-02, 6.8592e-02, 2.4506e-02, 2.2402e-02,\n",
      "         1.0931e-01, 8.8074e-03, 3.3732e-02, 1.3509e-04, 4.2047e-02, 3.1326e-02,\n",
      "         2.8455e-03, 9.4687e-03, 1.6287e-04, 3.2695e-02, 9.6339e-03, 6.1751e-02,\n",
      "         9.7687e-03, 3.9590e-03, 3.4344e-04, 6.9500e-03, 8.7342e-03, 0.0000e+00,\n",
      "         1.8970e-02, 0.0000e+00, 2.1554e-03, 1.1413e-02, 2.8852e-03, 4.1494e-02,\n",
      "         0.0000e+00, 2.5607e-03, 3.4085e-03, 1.0272e-02, 2.5509e-02, 7.0904e-04,\n",
      "         2.3485e-02, 1.9278e-03, 2.2837e-02, 4.4686e-05, 0.0000e+00, 1.0034e-02,\n",
      "         4.1752e-03, 1.1524e-03]])\n",
      "tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 144, 146, 147, 149, 152, 153, 155, 156, 157, 159,\n",
      "        161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "        176, 178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192, 193, 194,\n",
      "        197, 199, 200, 202, 203, 204, 205, 207, 208, 210, 212, 214, 215, 216,\n",
      "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 249,\n",
      "        250, 251, 252, 254, 255, 257, 258, 261, 263, 264, 266, 268, 269, 270,\n",
      "        274, 275, 276, 280, 281, 283, 285, 287, 289, 290, 291, 293, 294, 295,\n",
      "        297, 298, 300, 301, 302, 304, 306, 307, 308, 311, 312, 313, 318, 320,\n",
      "        321, 322, 323, 324, 328, 329, 334, 338, 339, 340, 342, 343, 345, 346,\n",
      "        349, 351, 353, 354, 359, 360, 362, 363, 368, 370, 372, 374, 376, 382,\n",
      "        384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413,\n",
      "        415, 416, 417, 419, 420, 424, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        449, 450, 451, 452, 453, 455, 457, 458, 459, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
      "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 494, 495,\n",
      "        496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 141, 142, 144, 146, 147, 149, 152, 153, 155, 156, 157, 159, 161,\n",
      "        162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "        178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192, 193, 194, 197,\n",
      "        199, 200, 202, 203, 204, 205, 207, 208, 210, 212, 214, 215, 216, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 249, 250,\n",
      "        251, 254, 255, 257, 258, 261, 263, 264, 266, 268, 269, 270, 274, 275,\n",
      "        276, 280, 281, 283, 285, 287, 289, 290, 291, 293, 294, 295, 297, 300,\n",
      "        301, 302, 304, 306, 307, 308, 311, 312, 313, 318, 320, 321, 323, 324,\n",
      "        328, 329, 334, 338, 339, 340, 342, 343, 345, 346, 349, 351, 353, 354,\n",
      "        359, 360, 362, 363, 368, 370, 372, 374, 376, 382, 384, 385, 386, 387,\n",
      "        388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403,\n",
      "        404, 405, 406, 407, 408, 409, 411, 412, 413, 415, 416, 417, 419, 420,\n",
      "        424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438,\n",
      "        439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450, 451, 452, 453,\n",
      "        455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "        485, 486, 487, 488, 489, 490, 492, 494, 495, 496, 497, 499, 500, 501,\n",
      "        502, 503, 504, 505, 506, 507, 509, 510, 511])  (len = 359)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 67: size\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126])\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 130, 131, 133, 134, 136, 137, 138, 140, 141, 142, 144, 147, 149,\n",
      "        152, 153, 156, 157, 159, 161, 163, 164, 166, 167, 168, 169, 171, 172,\n",
      "        173, 174, 176, 178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192,\n",
      "        193, 194, 197, 199, 200, 202, 203, 204, 205, 207, 208, 210, 214, 215,\n",
      "        216, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 240, 242, 243, 244, 245, 246, 249, 250,\n",
      "        251, 252, 254, 255])\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([257, 258, 261, 263, 264, 266, 268, 269, 270, 274, 275, 276, 280, 281,\n",
      "        283, 285, 287, 290, 291, 293, 295, 297, 298, 301, 302, 304, 306, 307,\n",
      "        308, 311, 312, 313, 318, 320, 321, 322, 323, 324, 328, 329, 334, 338,\n",
      "        339, 340, 342, 345, 346, 349, 351, 353, 354, 359, 360, 362, 363, 368,\n",
      "        370, 372, 374, 376, 382])\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413, 415,\n",
      "        416, 417, 419, 420, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450,\n",
      "        451, 452, 453, 455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 494, 495, 496, 497,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511])\n",
      "\t\t-skipping\n",
      "Finished execution of layer 67\n",
      "Horizontal output is <class 'int'>. Skipping comparison\n",
      "\n",
      "Executing module 68: view\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126])\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 130, 131, 133, 134, 136, 137, 138, 140, 141, 142, 144, 147, 149,\n",
      "        152, 153, 156, 157, 159, 161, 163, 164, 166, 167, 168, 169, 171, 172,\n",
      "        173, 174, 176, 178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192,\n",
      "        193, 194, 197, 199, 200, 202, 203, 204, 205, 207, 208, 210, 214, 215,\n",
      "        216, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 240, 242, 243, 244, 245, 246, 249, 250,\n",
      "        251, 252, 254, 255])\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([257, 258, 261, 263, 264, 266, 268, 269, 270, 274, 275, 276, 280, 281,\n",
      "        283, 285, 287, 290, 291, 293, 295, 297, 298, 301, 302, 304, 306, 307,\n",
      "        308, 311, 312, 313, 318, 320, 321, 322, 323, 324, 328, 329, 334, 338,\n",
      "        339, 340, 342, 345, 346, 349, 351, 353, 354, 359, 360, 362, 363, 368,\n",
      "        370, 372, 374, 376, 382])\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413, 415,\n",
      "        416, 417, 419, 420, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450,\n",
      "        451, 452, 453, 455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 494, 495, 496, 497,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511])\n",
      "\t\t-reshaping (view)\n",
      "Finished execution of layer 68\n",
      "Max diff:\n",
      "tensor([0.7589])\n",
      "\n",
      "tensor([[9.4529e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2945e-07, 6.8219e-08,\n",
      "         4.6566e-10, 0.0000e+00, 0.0000e+00, 3.5507e-08, 6.2500e-09, 1.3773e-08,\n",
      "         2.8871e-08, 4.8988e-07, 0.0000e+00, 0.0000e+00, 2.8289e-08, 0.0000e+00,\n",
      "         8.0955e-07, 4.9244e-08, 7.6834e-09, 2.3749e-08, 0.0000e+00, 0.0000e+00,\n",
      "         5.5908e-08, 7.7300e-08, 5.1339e-08, 3.5448e-07, 1.1153e-07, 2.6776e-08,\n",
      "         0.0000e+00, 3.0501e-08, 4.1793e-08, 0.0000e+00, 3.4634e-07, 1.3970e-08,\n",
      "         8.1491e-09, 0.0000e+00, 0.0000e+00, 1.3411e-07, 0.0000e+00, 0.0000e+00,\n",
      "         2.8913e-06, 1.2536e-08, 2.5146e-08, 9.1968e-09, 0.0000e+00, 8.3563e-07,\n",
      "         3.4925e-08, 3.8766e-08, 2.3050e-08, 2.5029e-08, 1.8480e-06, 0.0000e+00,\n",
      "         4.1910e-08, 0.0000e+00, 2.2561e-07, 0.0000e+00, 0.0000e+00, 4.6275e-08,\n",
      "         3.3528e-08, 0.0000e+00, 1.5090e-06, 1.0594e-08, 0.0000e+00, 1.1016e-08,\n",
      "         3.9086e-08, 2.3210e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8440e-08,\n",
      "         4.6683e-08, 1.1059e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8673e-07,\n",
      "         7.5670e-09, 3.5594e-08, 0.0000e+00, 2.3050e-08, 8.8476e-09, 2.0163e-07,\n",
      "         5.6825e-08, 7.3767e-07, 0.0000e+00, 6.2485e-05, 6.0478e-08, 2.4214e-08,\n",
      "         4.3880e-07, 0.0000e+00, 0.0000e+00, 2.8405e-08, 0.0000e+00, 6.0466e-07,\n",
      "         0.0000e+00, 0.0000e+00, 1.0245e-08, 1.9139e-07, 4.0545e-09, 1.6240e-08,\n",
      "         1.6298e-08, 2.8955e-06, 1.2951e-06, 8.1700e-07, 0.0000e+00, 4.5635e-08,\n",
      "         2.4278e-06, 0.0000e+00, 1.0724e-06, 0.0000e+00, 1.5162e-06, 2.6601e-08,\n",
      "         0.0000e+00, 1.8191e-06, 1.6065e-08, 3.2247e-08, 1.3178e-07, 6.4957e-07,\n",
      "         1.9325e-08, 6.5425e-08, 1.8138e-07, 2.9104e-09, 4.7439e-08, 4.1795e-06,\n",
      "         1.7253e-07, 0.0000e+00, 2.0445e-03, 3.1862e-03, 8.0457e-05, 2.5778e-02,\n",
      "         8.7171e-03, 1.5544e-01, 7.3269e-01, 4.8732e-03, 1.5291e-01, 5.0865e-02,\n",
      "         2.1381e-02, 4.5409e-02, 1.7354e-02, 4.3908e-02, 5.6613e-03, 0.0000e+00,\n",
      "         1.2654e-01, 0.0000e+00, 2.3544e-01, 8.9299e-02, 0.0000e+00, 4.7200e-01,\n",
      "         0.0000e+00, 0.0000e+00, 2.6757e-02, 5.4972e-01, 0.0000e+00, 1.8674e-03,\n",
      "         1.3742e-01, 1.5831e-01, 0.0000e+00, 7.6802e-02, 0.0000e+00, 1.9167e-01,\n",
      "         6.6905e-02, 4.3260e-01, 3.0364e-01, 0.0000e+00, 2.5519e-02, 1.3514e-01,\n",
      "         2.3166e-02, 1.9861e-01, 1.9024e-01, 3.9121e-02, 2.9196e-01, 3.0276e-02,\n",
      "         2.1242e-01, 3.8313e-02, 5.0628e-03, 0.0000e+00, 1.0446e-01, 0.0000e+00,\n",
      "         2.3813e-02, 3.0917e-02, 4.9294e-02, 0.0000e+00, 1.4863e-01, 1.5676e-01,\n",
      "         0.0000e+00, 0.0000e+00, 5.0980e-02, 6.3718e-02, 6.7202e-02, 2.3118e-01,\n",
      "         7.4047e-02, 5.6539e-01, 2.7735e-02, 0.0000e+00, 0.0000e+00, 9.1836e-03,\n",
      "         0.0000e+00, 8.8581e-02, 3.2512e-03, 0.0000e+00, 1.3139e-01, 1.8068e-02,\n",
      "         5.4305e-02, 6.1703e-03, 0.0000e+00, 1.3242e-01, 1.2948e-02, 0.0000e+00,\n",
      "         6.7005e-03, 0.0000e+00, 1.0894e-02, 0.0000e+00, 1.1342e-01, 2.6192e-01,\n",
      "         4.8171e-01, 0.0000e+00, 0.0000e+00, 3.1084e-01, 7.5894e-01, 1.5640e-01,\n",
      "         2.7117e-01, 4.9071e-02, 5.2071e-02, 2.4395e-02, 5.5454e-02, 2.1363e-02,\n",
      "         2.4286e-02, 5.8636e-02, 4.5472e-02, 1.0655e-01, 2.5659e-04, 6.3125e-04,\n",
      "         2.5509e-01, 8.6468e-02, 4.2281e-01, 1.3121e-01, 5.9590e-02, 0.0000e+00,\n",
      "         5.2465e-01, 6.2620e-03, 6.0658e-02, 3.0363e-01, 6.8208e-02, 2.7579e-01,\n",
      "         8.6179e-02, 0.0000e+00, 0.0000e+00, 5.4644e-03, 2.5206e-02, 3.5290e-01,\n",
      "         1.1951e-02, 0.0000e+00, 1.1985e-01, 3.5081e-02, 0.0000e+00, 1.7455e-03,\n",
      "         1.5214e-02, 0.0000e+00, 0.0000e+00, 2.9769e-02, 0.0000e+00, 1.9901e-02,\n",
      "         3.1132e-03, 0.0000e+00, 3.3989e-03, 0.0000e+00, 3.0848e-03, 1.1718e-01,\n",
      "         2.3895e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1452e-03, 4.0387e-03,\n",
      "         1.2116e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0544e-03, 6.0638e-03,\n",
      "         0.0000e+00, 8.6958e-04, 0.0000e+00, 3.2218e-03, 0.0000e+00, 2.0918e-06,\n",
      "         0.0000e+00, 3.1121e-03, 1.4766e-03, 6.2862e-04, 0.0000e+00, 6.7316e-03,\n",
      "         1.3828e-03, 5.4343e-04, 0.0000e+00, 3.0035e-03, 1.3254e-03, 0.0000e+00,\n",
      "         4.7553e-03, 1.7338e-03, 3.4239e-02, 0.0000e+00, 2.6965e-03, 0.0000e+00,\n",
      "         1.7428e-04, 3.1510e-04, 1.3118e-04, 0.0000e+00, 0.0000e+00, 5.1100e-04,\n",
      "         2.3142e-03, 5.2538e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.9048e-03, 0.0000e+00, 2.1258e-03, 1.4929e-02, 7.7234e-03, 2.2190e-02,\n",
      "         3.9441e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5463e-03, 2.7795e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8777e-03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.6885e-02, 2.8788e-02, 5.2088e-03, 0.0000e+00,\n",
      "         9.6786e-03, 5.9142e-04, 0.0000e+00, 1.7196e-04, 1.0928e-04, 0.0000e+00,\n",
      "         0.0000e+00, 2.7025e-03, 0.0000e+00, 4.9424e-04, 0.0000e+00, 2.5481e-03,\n",
      "         9.2125e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1188e-03,\n",
      "         4.4066e-03, 0.0000e+00, 5.0795e-03, 1.3926e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.8403e-03, 0.0000e+00, 1.7131e-03, 0.0000e+00,\n",
      "         6.2632e-04, 0.0000e+00, 3.8628e-04, 0.0000e+00, 8.3676e-06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5020e-04, 0.0000e+00,\n",
      "         3.2031e-02, 4.0057e-02, 7.9486e-04, 6.7721e-02, 4.6055e-02, 5.6138e-03,\n",
      "         0.0000e+00, 2.7279e-03, 4.4678e-04, 3.8935e-03, 1.8962e-03, 9.2008e-03,\n",
      "         1.3023e-02, 2.1937e-02, 3.1401e-02, 1.8860e-02, 2.0517e-04, 3.9168e-03,\n",
      "         1.6825e-02, 2.0694e-02, 2.7220e-04, 3.9050e-05, 3.4272e-03, 2.9261e-02,\n",
      "         1.1288e-02, 1.3338e-03, 0.0000e+00, 1.1705e-02, 1.1498e-02, 5.4899e-03,\n",
      "         0.0000e+00, 2.7093e-02, 2.8946e-03, 1.9473e-02, 0.0000e+00, 2.7374e-03,\n",
      "         1.9973e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.5701e-03, 0.0000e+00,\n",
      "         9.4724e-04, 6.4692e-03, 1.3243e-02, 1.4908e-02, 3.3283e-03, 6.4677e-03,\n",
      "         2.2629e-03, 7.2430e-02, 1.1361e-03, 1.0570e-01, 1.2126e-02, 1.4744e-05,\n",
      "         7.0564e-04, 3.2637e-02, 1.0288e-02, 2.2630e-03, 7.9074e-04, 1.0860e-01,\n",
      "         2.6912e-02, 7.5001e-04, 7.7402e-03, 5.7887e-03, 0.0000e+00, 3.0738e-02,\n",
      "         4.0391e-02, 2.5093e-02, 1.0624e-02, 4.4865e-02, 0.0000e+00, 4.7658e-02,\n",
      "         0.0000e+00, 6.9128e-02, 2.2560e-03, 2.9278e-03, 0.0000e+00, 3.9092e-03,\n",
      "         1.5071e-02, 1.3470e-02, 1.6475e-02, 1.2940e-02, 4.2439e-03, 4.0381e-02,\n",
      "         2.0978e-02, 8.1073e-03, 1.5807e-02, 6.8592e-02, 2.4506e-02, 2.2402e-02,\n",
      "         1.0931e-01, 8.8074e-03, 3.3732e-02, 1.3509e-04, 4.2047e-02, 3.1326e-02,\n",
      "         2.8455e-03, 9.4687e-03, 1.6287e-04, 3.2695e-02, 9.6339e-03, 6.1751e-02,\n",
      "         9.7687e-03, 3.9590e-03, 3.4344e-04, 6.9500e-03, 8.7342e-03, 0.0000e+00,\n",
      "         1.8970e-02, 0.0000e+00, 2.1554e-03, 1.1413e-02, 2.8852e-03, 4.1494e-02,\n",
      "         0.0000e+00, 2.5607e-03, 3.4085e-03, 1.0272e-02, 2.5509e-02, 7.0904e-04,\n",
      "         2.3485e-02, 1.9278e-03, 2.2837e-02, 4.4686e-05, 0.0000e+00, 1.0034e-02,\n",
      "         4.1752e-03, 1.1524e-03]])\n",
      "tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 144, 146, 147, 149, 152, 153, 155, 156, 157, 159,\n",
      "        161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "        176, 178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192, 193, 194,\n",
      "        197, 199, 200, 202, 203, 204, 205, 207, 208, 210, 212, 214, 215, 216,\n",
      "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 249,\n",
      "        250, 251, 252, 254, 255, 257, 258, 261, 263, 264, 266, 268, 269, 270,\n",
      "        274, 275, 276, 280, 281, 283, 285, 287, 289, 290, 291, 293, 294, 295,\n",
      "        297, 298, 300, 301, 302, 304, 306, 307, 308, 311, 312, 313, 318, 320,\n",
      "        321, 322, 323, 324, 328, 329, 334, 338, 339, 340, 342, 343, 345, 346,\n",
      "        349, 351, 353, 354, 359, 360, 362, 363, 368, 370, 372, 374, 376, 382,\n",
      "        384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413,\n",
      "        415, 416, 417, 419, 420, 424, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        449, 450, 451, 452, 453, 455, 457, 458, 459, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
      "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 494, 495,\n",
      "        496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 141, 142, 144, 146, 147, 149, 152, 153, 155, 156, 157, 159, 161,\n",
      "        162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "        178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192, 193, 194, 197,\n",
      "        199, 200, 202, 203, 204, 205, 207, 208, 210, 212, 214, 215, 216, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 249, 250,\n",
      "        251, 254, 255, 257, 258, 261, 263, 264, 266, 268, 269, 270, 274, 275,\n",
      "        276, 280, 281, 283, 285, 287, 289, 290, 291, 293, 294, 295, 297, 300,\n",
      "        301, 302, 304, 306, 307, 308, 311, 312, 313, 318, 320, 321, 323, 324,\n",
      "        328, 329, 334, 338, 339, 340, 342, 343, 345, 346, 349, 351, 353, 354,\n",
      "        359, 360, 362, 363, 368, 370, 372, 374, 376, 382, 384, 385, 386, 387,\n",
      "        388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403,\n",
      "        404, 405, 406, 407, 408, 409, 411, 412, 413, 415, 416, 417, 419, 420,\n",
      "        424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438,\n",
      "        439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450, 451, 452, 453,\n",
      "        455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "        485, 486, 487, 488, 489, 490, 492, 494, 495, 496, 497, 499, 500, 501,\n",
      "        502, 503, 504, 505, 506, 507, 509, 510, 511])  (len = 359)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 69: linear\n",
      "\tExecuting on machine 0\n",
      "\t\t received input channels tensor([  0,   4,   5,   6,   9,  10,  11,  12,  13,  16,  18,  19,  20,  21,\n",
      "         24,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,  39,  42,  43,\n",
      "         44,  45,  47,  48,  49,  50,  51,  52,  54,  56,  59,  60,  62,  63,\n",
      "         65,  66,  67,  71,  72,  73,  77,  78,  79,  81,  82,  83,  84,  85,\n",
      "         87,  88,  89,  90,  93,  95,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126])\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\t\t sending C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t received input channels tensor([128, 130, 131, 133, 134, 136, 137, 138, 140, 141, 142, 144, 147, 149,\n",
      "        152, 153, 156, 157, 159, 161, 163, 164, 166, 167, 168, 169, 171, 172,\n",
      "        173, 174, 176, 178, 180, 181, 182, 184, 185, 188, 189, 190, 191, 192,\n",
      "        193, 194, 197, 199, 200, 202, 203, 204, 205, 207, 208, 210, 214, 215,\n",
      "        216, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 240, 242, 243, 244, 245, 246, 249, 250,\n",
      "        251, 252, 254, 255])\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\t\t sending C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\tExecuting on machine 2\n",
      "\t\t received input channels tensor([257, 258, 261, 263, 264, 266, 268, 269, 270, 274, 275, 276, 280, 281,\n",
      "        283, 285, 287, 290, 291, 293, 295, 297, 298, 301, 302, 304, 306, 307,\n",
      "        308, 311, 312, 313, 318, 320, 321, 322, 323, 324, 328, 329, 334, 338,\n",
      "        339, 340, 342, 345, 346, 349, 351, 353, 354, 359, 360, 362, 363, 368,\n",
      "        370, 372, 374, 376, 382])\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\t\t sending C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\tExecuting on machine 3\n",
      "\t\t received input channels tensor([384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413, 415,\n",
      "        416, 417, 419, 420, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450,\n",
      "        451, 452, 453, 455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 494, 495, 496, 497,\n",
      "        499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511])\n",
      "\t\t Output tensor shape : torch.Size([1, 10])\n",
      "\t\t sending C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "Finished execution of layer 69\n",
      "Max diff:\n",
      "tensor([0.8416])\n",
      "\n",
      "tensor([[0.6786, 0.0315, 0.3742, 0.2042, 0.5419, 0.4796, 0.8416, 0.5883, 0.1707,\n",
      "         0.4467]])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "failing Cout = tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])  (len = 10)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Prep Inout for Mock Run version 2 (fx)'''\n",
    "\n",
    "# TODO: reduce size of communicated tensors to only what is necessary \n",
    "# TODO: also check bias for nonzero\n",
    "# TODO: come up with more general scheme to handle residual layers\n",
    "\n",
    "# channel_id == INPUTS\n",
    "# filter_id  == OUTPUTS\n",
    "\n",
    "# setup input \n",
    "N_batch = 1\n",
    "input_tensor = torch.rand(N_batch, 3, 32, 32, device=torch.device(configs['device'])) # 1k images, 3 channels, 32x32 image (cifar100) \n",
    "\n",
    "# broadcast input_tensor to different machines\n",
    "# TODO: find a better datastructure for this\n",
    "#input = np.empty((num_machines, num_machines), dtype=torch.Tensor)\n",
    "input = [None]*num_machines\n",
    "input = [input[:] for i in range(num_machines)]\n",
    "for imach in range(num_machines):\n",
    "    input[imach][imach] = input_tensor\n",
    "\n",
    "residual_block_start, residual_connection_start, residual_block_end = get_residual_block_indexes(model)\n",
    "\n",
    "# put models into eval mode and on device\n",
    "model.eval()\n",
    "model.to(configs['device'])\n",
    "\n",
    "# set index to execute vertical splitting up to \n",
    "exec_to_layer = 69\n",
    "\n",
    "# get list of intermediate outputs \n",
    "get_horz_out = {}\n",
    "for aname in layer_names_fx:\n",
    "    get_horz_out[aname] = aname\n",
    "\n",
    "# make extractor model and get output\n",
    "extractor_model = create_feature_extractor(model,return_nodes = get_horz_out)\n",
    "with torch.no_grad():\n",
    "    extractor_model.eval()\n",
    "    horz_output = extractor_model(input_tensor)\n",
    "\n",
    "'''\n",
    "    mock run through inference using split models \n",
    "'''\n",
    "\n",
    "# make inference \n",
    "with torch.no_grad():\n",
    "    residual_input = {} # use this to keep track of inputs stored in machine memory for residule layers\n",
    "\n",
    "    # iterate through layers 1 module at a time \n",
    "    for imodule in range(exec_to_layer+1):#range(num_total_modules): # 16 <=> layer_1 block \n",
    "\n",
    "        # initialize output for ilayer\n",
    "        #output = np.empty((num_machines, num_machines), dtype=torch.Tensor) # square list indexed as: output[destination/RX machine][origin/TX machine]\n",
    "        # TODO: find a better datastructure for this \n",
    "        output = [None]*num_machines\n",
    "        output = [output[:] for i in range(num_machines)]\n",
    "\n",
    "        print(f'Executing module {imodule}: {layer_names_fx[imodule]}')\n",
    "\n",
    "        # iterate through each machine (done in parallel later)\n",
    "        for imach in range(num_machines):\n",
    "            print(f'\\tExecuting on machine {imach}')\n",
    "\n",
    "            # collect communication inputs if necessary \n",
    "            if not imodule == 0 and ('conv' in layer_names_fx[imodule-1] or 'linear' in layer_names_fx[imodule-1]):\n",
    "                curr_input = combine_inputs(input, num_machines, imach)\n",
    "            else:\n",
    "                curr_input = input[imach][imach]\n",
    "\n",
    "            # skip this machine+module if there is no input to compute \n",
    "            if not torch.is_tensor(curr_input):\n",
    "                print('\\t\\t-No input sent to this machine. Skipping module')\n",
    "                continue\n",
    "            \n",
    "            # debug\n",
    "            print(f'\\t\\t received input channels {get_nonzero_channels(curr_input)}')\n",
    "\n",
    "            # non-comms operations \n",
    "            if 'relu' in layer_names_fx[imodule]:\n",
    "                # just relu no comm necessary \n",
    "                print('\\t\\t-Applying ReLU')\n",
    "                output[imach][imach] = F.relu(curr_input)\n",
    "                continue\n",
    "\n",
    "            elif 'add' in layer_names_fx[imodule]:\n",
    "                # residual layer. No comm necessary \n",
    "                if str(imach) in residual_input:\n",
    "                    print('\\t\\t-adding residual')\n",
    "                    if 'block_out' in residual_input[str(imach)]:\n",
    "                        curr_input += residual_input[str(imach)]['block_out']\n",
    "                    elif 'block_in' in residual_input[str(imach)]:\n",
    "                        curr_input += residual_input[str(imach)]['block_in']\n",
    "                        print('\\t\\t-assuming shortcut had no layers')\n",
    "                else:\n",
    "                    print(f'\\t\\t-assuming this machine did not rx any input at the beginning of this block. No residual found')\n",
    "                output[imach][imach] = curr_input\n",
    "\n",
    "                # erase stored \n",
    "                residual_input[str(imach)] = {}\n",
    "                continue\n",
    "            \n",
    "            elif 'avg_pool2d' in layer_names_fx[imodule]:\n",
    "                print('\\t\\t-average pooling')\n",
    "                output[imach][imach] = F.avg_pool2d(curr_input, 4)\n",
    "                continue\n",
    "            \n",
    "            elif 'size' in layer_names_fx[imodule]:\n",
    "                print('\\t\\t-skipping')\n",
    "                output[imach][imach] = curr_input\n",
    "                continue\n",
    "            \n",
    "            elif 'view' in layer_names_fx[imodule]:\n",
    "                print('\\t\\t-reshaping (view)')\n",
    "                output[imach][imach] = curr_input.view(curr_input.size(0), -1)\n",
    "                continue\n",
    "            elif 'x' == layer_names_fx[imodule]:\n",
    "                # do nothing if model input\n",
    "                print('\\t\\t-model input layer.. skipping')\n",
    "                output[imach][imach] = curr_input\n",
    "                continue\n",
    "                        \n",
    "            # swap out io for residual connection\n",
    "            if imodule in residual_block_start:\n",
    "                # save input for later \n",
    "                residual_input[str(imach)] = {}\n",
    "                residual_input[str(imach)]['block_in'] = curr_input\n",
    "                print('\\t\\t-Saving input for later...')\n",
    "            elif imodule in residual_connection_start:\n",
    "                # swap tensors\n",
    "                residual_input[str(imach)]['block_out'] = curr_input\n",
    "                curr_input = residual_input[str(imach)]['block_in'] \n",
    "                print('\\t\\t-Saving current input. Swapping for input saved from start of block')\n",
    "\n",
    "            # get the current module\n",
    "            # TODO: is this very bad for latency? Only load module if you have to \n",
    "            curr_layer = get_current_module(model, imodule)\n",
    "\n",
    "            # update communication I/O for this layer  \n",
    "            # TODO: revist this implementation\n",
    "            split_param_name = layer_names_fx[imodule] + '.weight'\n",
    "            if split_param_name in split_module_names:\n",
    "                # skip if machine doesnt expect input\n",
    "                if len(configs['partition'][split_param_name]['channel_id'][imach]) == 0:\n",
    "                        print(f'\\t\\t-WARNING: No input assigned to this machine (but it was sent input?). Skipping...')\n",
    "                        continue\n",
    "\n",
    "                # TODO: reconsider implementation \n",
    "                # What input channels does this machine compute?\n",
    "                input_channels = torch.tensor(configs['partition'][split_param_name]['channel_id'][imach],\n",
    "                        device=torch.device(configs['device']))\n",
    "                N_in = len(input_channels) # TODO: is this used?\n",
    "\n",
    "                # Where to send output (map of output channels to different machines)\n",
    "                output_channel_map = configs['partition'][split_param_name]['filter_id']\n",
    "            elif type(curr_layer) == nn.Linear and imodule == total_layers_fx-1:\n",
    "                # if final layer output all goes to machine 0 \n",
    "                # TODO: find better way to handle this. Also will we encounter Linear layers not at the end of the model\n",
    "                N_Cin = curr_layer.in_features\n",
    "                Cin_per_machine = N_Cin/num_machines\n",
    "                if Cin_per_machine % 1 > 0:\n",
    "                        print('ERROR: UNEXPECTED NUMBER OF I/O FOR LINEAR MODULE {imodule}')\n",
    "                Cin_per_machine = int(Cin_per_machine)\n",
    "                input_channels = np.arange(Cin_per_machine) + imach*Cin_per_machine\n",
    "                N_Cout = curr_layer.out_features \n",
    "                output_channel_map = [None]*num_machines\n",
    "                for i in range(num_machines):\n",
    "                        if i == 0:\n",
    "                                output_channel_map[i] = np.arange(N_Cout) \n",
    "                        else:\n",
    "                                output_channel_map[i] = np.array([])\n",
    "                input_channels = torch.tensor(input_channels, device=torch.device(configs['device']))\n",
    "            else:\n",
    "                # for batch normal, and functional passes through the code\n",
    "                # TODO: address the following assumptions:\n",
    "                #       - assume all BN layers have C_in divisable by num_machines\n",
    "                #       - assume C_in are evenly split in sequential order WARNING THIS WILL BREAK WHEN WE START TO DO ASSIGN WEIGHTS TO DIFF MACHINES\n",
    "                N_Cin = curr_layer.num_features\n",
    "                Cin_per_machine = N_Cin/num_machines\n",
    "                if Cin_per_machine % 1 > 0:\n",
    "                        print('ERROR: UNEXPECTED NUMBER OF I/O FOR BATCH NORMAL MODULE {imodule}')\n",
    "                Cin_per_machine = int(Cin_per_machine)\n",
    "                input_channels = np.arange(Cin_per_machine) + imach*Cin_per_machine\n",
    "                output_channel_map = [None]*num_machines\n",
    "                for i in range(num_machines):\n",
    "                        if i == imach:\n",
    "                                output_channel_map[i] = input_channels\n",
    "                        else:\n",
    "                                output_channel_map[i] = np.array([])\n",
    "                input_channels = torch.tensor(input_channels, device=torch.device(configs['device']))\n",
    "\n",
    "\n",
    "            # make vertically split layer \n",
    "            if type(curr_layer) == nn.Conv2d:\n",
    "                split_layer = split_conv_layer(curr_layer, input_channels)\n",
    "            elif type(curr_layer) == nn.BatchNorm2d:\n",
    "                split_layer = split_bn_layer(curr_layer, input_channels)\n",
    "            elif type(curr_layer) == nn.Linear:\n",
    "                split_layer = split_linear_layer(curr_layer, input_channels)\n",
    "            else:\n",
    "                print(f'\\t\\t-Skipping module {type(curr_layer).__name__}')\n",
    "                continue\n",
    "                        \n",
    "            # eval split\n",
    "            split_layer.eval()\n",
    "            out_tensor = split_layer(curr_input.index_select(1, input_channels))\n",
    "            if type(curr_layer) == nn.BatchNorm2d:\n",
    "                tmp_out_tensor = torch.zeros(curr_input.shape)\n",
    "                tmp_out_tensor[:,input_channels.numpy(),:,:] = out_tensor\n",
    "                out_tensor = tmp_out_tensor\n",
    "\n",
    "            print(f'\\t\\t Output tensor shape : {out_tensor.shape}')\n",
    "\n",
    "            # debug\n",
    "            nonzero_out_tensor = torch.unique(torch.nonzero(out_tensor, as_tuple=True)[1])\n",
    "\n",
    "            # look at which C_out need to be computed and sent\n",
    "            #nonzero_Cout = torch.unique(torch.nonzero(split_layer.weight, as_tuple=True)[0]) # find nonzero dimensions in output channels\n",
    "            nonzero_Cout = get_nonzero_channels(out_tensor)\n",
    "\n",
    "            # prep communications by populating output\n",
    "            out_channel_array = torch.arange(out_tensor.shape[1])\n",
    "            for rx_mach in range(num_machines):\n",
    "                # only add to output if communication is necessary \n",
    "\n",
    "                # Get output channels for current rx machine? TODO: consider removing, this just maps C_out's to machine\n",
    "                output_channels = torch.tensor(output_channel_map[rx_mach],\n",
    "                        device=torch.device(configs['device']))\n",
    "\n",
    "                # TODO: is there a faster way to do this? Consider putting larger array 1st... just not sure which one that'd be\n",
    "                nonzero_out_channels = nonzero_Cout[torch.isin(nonzero_Cout, output_channels)]\n",
    "                if nonzero_out_channels.nelement() > 0:\n",
    "                        communication_mask = torch.isin(out_channel_array, nonzero_out_channels)\n",
    "\n",
    "                        # TODO: this is inefficient, redo. Probbably need to send a tensor and some info what output channels are being sent\n",
    "                        tmp_out = torch.zeros(out_tensor.shape) \n",
    "                        if imodule == total_layers_fx-1:\n",
    "                                tmp_out[:,communication_mask] = out_tensor[:,communication_mask]\n",
    "                        else:\n",
    "                                tmp_out[:,communication_mask,:,:] = out_tensor[:,communication_mask,:,:]\n",
    "                        output[rx_mach][imach] = tmp_out\n",
    "\n",
    "                        # debug\n",
    "                        print(f'\\t\\t sending C_out {nonzero_out_channels} to machine {rx_mach}')\n",
    "\n",
    "        # send to next layer  \n",
    "        input = output\n",
    "        print(f'Finished execution of layer {imodule}')\n",
    "\n",
    "        # check output at end of each layer to see if fit matches \n",
    "        tmp_output = input \n",
    "        need_to_init  = True\n",
    "        for rx_mach in range(num_machines):\n",
    "                for tx_mach in range(num_machines):\n",
    "                        if not tmp_output[rx_mach][tx_mach] == None:\n",
    "                                if need_to_init:\n",
    "                                        vert_output = tmp_output[rx_mach][tx_mach]\n",
    "                                        need_to_init = False\n",
    "                                else:\n",
    "                                        # TODO: += causes assignment issues, switched to x = x+y which might be more more inefficent memory wise ... \n",
    "                                        vert_output = vert_output + tmp_output[rx_mach][tx_mach] \n",
    "                                        #nz_channels = get_nonzero_channels(vert_output)\n",
    "                                        #print(f'({rx_mach},{tx_mach}) {nz_channels}')\n",
    "        \n",
    "        truth_output = horz_output[layer_names_fx[imodule]]\n",
    "        if torch.is_tensor(truth_output):\n",
    "            compare_outputs(vert_output, truth_output)\n",
    "        else:\n",
    "            print(f'Horizontal output is {type(truth_output)}. Skipping comparison')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Conv1 layer test -- should we expect some difference, or exactly 0 in the output when we split the model?\n",
    "'''\n",
    "\n",
    "# DIFFERENCE SHOULD BE 0 NOT 1E-7\n",
    "\n",
    "N_in = 1\n",
    "split_1 = nn.Conv2d(N_in,\n",
    "            model.conv1.weight.shape[0], # TODO does this need to be an int? (currently tensor)\n",
    "            kernel_size= model.conv1.kernel_size,\n",
    "            stride=model.conv1.stride,\n",
    "            padding=model.conv1.padding, \n",
    "            bias=False) # TODO: add bias during input collecting step on next layer \n",
    "split_1.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([0])))  \n",
    "out_split1 = split_1(input_tensor.index_select(1, torch.tensor([0])))\n",
    "\n",
    "split_2 = split_1\n",
    "split_2.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([1])))  \n",
    "out_split2 = split_2(input_tensor.index_select(1, torch.tensor([1])))\n",
    "\n",
    "split_3 = split_1\n",
    "split_3.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([2])))  \n",
    "out_split3 = split_3(input_tensor.index_select(1, torch.tensor([2])))\n",
    "\n",
    "split_out = torch.add(torch.add(out_split1, out_split2), out_split3)\n",
    "full_out = model.conv1(input_tensor)\n",
    "\n",
    "diff_output = torch.abs(full_out - split_out)\n",
    "max_diff = torch.max(diff_output)\n",
    "max_diff.sci_mode = True\n",
    "print(max_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
