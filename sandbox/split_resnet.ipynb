{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Load RESNET model and split it\\n        1. layer by layer\\n        2. [TODO] vertically \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Load RESNET model and split it\n",
    "        1. layer by layer\n",
    "        2. [TODO] vertically \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.core.engine import MoP\n",
    "from source.core import run_partition\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "from source.utils.split_network import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "from source.core.split_manager import SplitManager\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "from source.utils import testers\n",
    "from source.core import engine\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from torchsummary import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  \n",
      "model :  resnet18\n",
      "data_code :  cifar10\n",
      "num_classes :  10\n",
      "model_file :  test.pt\n",
      "epochs :  0\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  1\n",
      "admm :  True\n",
      "admm_epochs :  300\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.005\n",
      "retrain_ep :  50\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.001\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  1\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  False\n",
      "comm_outsize :  False\n",
      "lambda_comm :  0\n",
      "lambda_comp :  0\n",
      "distill_model :  \n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n"
     ]
    }
   ],
   "source": [
    "# setup config\n",
    "dataset='cifar10'\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "\n",
    "configs = run_p.main()\n",
    "\n",
    "configs[\"device\"] = \"cpu\"\n",
    "configs['load_model'] = \"cifar10-resnet18-kernel-npv0-pr0.75-lcm0.001.pt\"\n",
    "configs[\"num_partition\"] = '4' #'resnet18-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into full model\n",
    "state_dict = torch.load(io.get_model_path(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time per data is 32.542229ms.\n",
      "conv1.weight 1024\n",
      "layer1.0.conv1.weight 1024\n",
      "layer1.0.conv2.weight 1024\n",
      "layer1.1.conv1.weight 1024\n",
      "layer1.1.conv2.weight 1024\n",
      "layer2.0.conv1.weight 256\n",
      "layer2.0.conv2.weight 256\n",
      "layer2.0.shortcut.0.weight 256\n",
      "layer2.1.conv1.weight 256\n",
      "layer2.1.conv2.weight 256\n",
      "layer3.0.conv1.weight 64\n",
      "layer3.0.conv2.weight 64\n",
      "layer3.0.shortcut.0.weight 64\n",
      "layer3.1.conv1.weight 64\n",
      "layer3.1.conv2.weight 64\n",
      "layer4.0.conv1.weight 16\n",
      "layer4.0.conv2.weight 16\n",
      "layer4.0.shortcut.0.weight 16\n",
      "layer4.1.conv1.weight 16\n",
      "layer4.1.conv2.weight 16\n",
      "['x', 'conv1', 'bn1', 'relu', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avg_pool2d', 'size', 'view', 'linear']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    add partitions and communications to configs\n",
    "'''\n",
    "\n",
    "# gets random test input (with correct size)\n",
    "input_var = engine.get_input_from_code(configs)\n",
    "#print(input_var)\n",
    "\n",
    "# Config partitions and prune_ratio\n",
    "configs = engine.partition_generator(configs, model)\n",
    "            \n",
    "# Compute output size of each layer\n",
    "configs['partition'] = engine.featuremap_summary(model, configs['partition'], input_var)\n",
    "\n",
    "# split model general parameters\n",
    "\n",
    "# make copies of model per machine\n",
    "num_machines = max(configs['partition']['bn_partition']) # TODO: double check this makes sense\n",
    "model_machines = [model]*num_machines\n",
    "\n",
    "layer_names_fx =  get_graph_node_names(model)[1]\n",
    "total_layers_fx = len(layer_names_fx)\n",
    "\n",
    "split_module_names = list(configs['partition'].keys())\n",
    "\n",
    "print(layer_names_fx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    IO helpers\n",
    "'''\n",
    "\n",
    "def prep_data(tensor, node, layer):\n",
    "    '''\n",
    "        Prepare input tensors to model \n",
    "    '''\n",
    "    return {\n",
    "        'node' : node,\n",
    "        'layer' : layer,\n",
    "        'tensor' : tensor, \n",
    "        'Cin' : list(get_nonzero_channels(tensor)),\n",
    "        'is_empty' : False\n",
    "    }\n",
    "\n",
    "def compare_outputs_wrapper(horz_output, comm_layer, split_model_output, limit = 0.1):\n",
    "    '''\n",
    "        Checks if output from split model is correct \n",
    "\n",
    "        return 0 if check fails and 1 if passes\n",
    "    '''\n",
    "    \n",
    "    if comm_layer == 0:\n",
    "        print(f'Input layer. Skipping comparison')\n",
    "        return 1\n",
    "    else:\n",
    "        # if reaches the end use the full model output \n",
    "        if comm_layer == len(horz_output):\n",
    "            comm_layer_name = 'x'\n",
    "        else:\n",
    "            comm_layer_name = layer_names_fx[comm_layer]\n",
    "    \n",
    "        truth_output = horz_output[comm_layer_name]\n",
    "        if torch.is_tensor(truth_output):\n",
    "            \n",
    "            max_diff, max_by_Cout = compare_outputs(split_model_output, truth_output)\n",
    "            if max_diff > 0.1:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1 \n",
    "        else:\n",
    "            print(f'Horizontal output is {type(truth_output)}. Skipping comparison')\n",
    "            return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 0\n",
      "\t\tNo comms for 0 layer 2 yet. Skipping...\n",
      "\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([0, 1, 2])\n",
      "\t\t EXEC SPLIT: #1-conv1; Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #2-bn1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([0, 1, 2])\n",
      "\t\t EXEC SPLIT: #1-conv1; Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #2-bn1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([0, 1, 2])\n",
      "\t\t EXEC SPLIT: #1-conv1; Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #2-bn1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for conv1:\n",
      "Max diff:\n",
      "tensor([1.1102e-16], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1102e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([30, 31])\n",
      "\n",
      "failing Cout = tensor([30, 31])  (len = 2)\n",
      "passing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 46)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t EXEC SPLIT: #2-bn1; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([15])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 11 12 13 15 40 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t Prepping to send C_out tensor([40]) to machine 2\n",
      "\t\t Prepping to send C_out tensor([63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #2-bn1; Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from bn1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from relu C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_out=[ 1  3 10 12 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 40]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t Prepping to send C_out tensor([ 1,  3, 10, 12]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([40]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natet\\AppData\\Local\\Temp\\ipykernel_31072\\1610696366.py:116: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  comm_layer = int(comm_layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t EXEC SPLIT: #2-bn1; Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from bn1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from relu C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_out=[ 0  3  6 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 53]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t Prepping to send C_out tensor([0, 3, 6]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([53]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #2-bn1; Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from bn1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from relu C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 55, 56, 57, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_out=[ 3  4 15 32 34 45 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([ 3,  4, 15]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([32, 34, 45, 47]) to machine 2\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer1.0.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer1.0.conv1:\n",
      "Max diff:\n",
      "tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 2.2204e-16, 0.0000e+00, 5.2042e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00,\n",
      "         4.1633e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 5.3291e-15,\n",
      "         2.6645e-15, 8.8818e-15, 2.6645e-15, 2.6645e-15, 2.2204e-15, 3.5527e-15,\n",
      "         2.2204e-15, 3.5527e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15, 3.5527e-15,\n",
      "         1.3323e-15, 1.0547e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16, 3.3307e-16,\n",
      "         2.6645e-15, 8.8818e-16, 2.7756e-16, 4.4409e-16, 3.5527e-15, 3.3307e-16,\n",
      "         3.3307e-16, 6.6613e-16, 2.2204e-16, 1.3323e-15, 4.4409e-16, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([ 1,  3, 10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\n",
      "failing Cout = tensor([ 1,  3, 10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])  (len = 36)\n",
      "passing Cout = tensor([ 0,  2,  4,  5,  6,  7,  8,  9, 11, 13, 15, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 27)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15])\n",
      "\t\t EXEC SPLIT: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.0.bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.0.relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([0, 1])\n",
      "\t\t EXEC SPLIT: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 27 57 59]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t Prepping to send C_out tensor([27]) to machine 1\n",
      "\t\t Prepping to send C_out tensor([57, 59]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.0.bn1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.0.relu C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_out=[ 6 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 42 45]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t Prepping to send C_out tensor([6]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([42, 45]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t EXEC SPLIT: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.0.bn1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.0.relu C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 36, 40, 45])\n",
      "\t\t EXEC SPLIT: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_out=[ 4  9 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 54 56]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t Prepping to send C_out tensor([4, 9]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([54, 56]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.0.bn1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.0.relu C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 51, 52, 53, 54, 55, 59, 61, 63])\n",
      "\t\t EXEC SPLIT: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_out=[ 4  5 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([4, 5]) to machine 0\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer1.0.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer1.0.conv2:\n",
      "Max diff:\n",
      "tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.7347e-18, 1.3878e-17, 3.4694e-18, 2.7756e-17, 7.1054e-15, 4.1633e-17,\n",
      "         6.9389e-18, 1.3878e-17, 1.3878e-17, 5.5511e-17, 1.1102e-16, 2.0817e-17,\n",
      "         3.4694e-18, 2.7756e-17, 1.3878e-17, 3.4694e-18, 5.3291e-15, 1.4294e-15,\n",
      "         3.1086e-15, 8.8818e-15, 7.1054e-15, 8.8818e-15, 2.6645e-15, 5.3291e-15,\n",
      "         5.3291e-15, 7.1054e-15, 7.1054e-15, 4.4409e-15, 2.2204e-15, 5.3291e-15,\n",
      "         3.5527e-15, 3.5527e-15, 1.6653e-15, 8.8818e-16, 1.1102e-15, 1.7764e-15,\n",
      "         1.7764e-15, 1.3323e-15, 2.6645e-15, 1.5266e-16, 8.8818e-16, 1.2212e-15,\n",
      "         1.3323e-15, 1.5543e-15, 6.6613e-16, 1.5543e-15, 1.3323e-15, 1.7764e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7764e-15, 0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54, 56])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54, 56])  (len = 50)\n",
      "passing Cout = tensor([48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63])  (len = 14)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t EXEC SPLIT: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.0.bn2 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.0.add C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.0.relu_1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 4,  7,  9, 11])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t Prepping to send C_out tensor([63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.0.bn2 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.0.add C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.0.relu_1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_out=[ 2  6  8 12 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 38 47 49]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t Prepping to send C_out tensor([ 2,  6,  8, 12, 15]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([38, 47]) to machine 2\n",
      "\t\t Prepping to send C_out tensor([49]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t EXEC SPLIT: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.0.bn2 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.0.add C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.0.relu_1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 36, 38, 39, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_out=[ 1 10 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 62]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t Prepping to send C_out tensor([ 1, 10]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([30]) to machine 1\n",
      "\t\t Prepping to send C_out tensor([62]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.0.bn2 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.0.add C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.0.relu_1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 52, 54, 55, 56, 57, 59, 60, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_out=[ 1  5 12 13 36 44 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([ 1,  5, 12, 13]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([36, 44]) to machine 2\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer1.1.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer1.1.conv1:\n",
      "Max diff:\n",
      "tensor([1.7764e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[8.3267e-17, 2.6645e-15, 1.3323e-15, 4.4409e-16, 1.7764e-15, 6.6613e-16,\n",
      "         8.8818e-16, 6.6613e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 1.3323e-15,\n",
      "         3.5527e-15, 8.8818e-16, 4.4409e-16, 2.6645e-15, 7.1054e-15, 1.4211e-14,\n",
      "         8.8818e-15, 1.4211e-14, 1.0658e-14, 1.0658e-14, 1.7764e-14, 8.8818e-15,\n",
      "         8.8818e-15, 8.8818e-15, 1.0658e-14, 1.4211e-14, 8.8818e-15, 1.0658e-14,\n",
      "         1.0658e-14, 1.4211e-14, 8.8818e-16, 6.6613e-16, 1.7764e-15, 1.6653e-16,\n",
      "         1.6653e-16, 1.6653e-16, 1.3461e-15, 8.8818e-16, 1.7764e-15, 5.5511e-17,\n",
      "         3.3307e-16, 1.3323e-15, 8.3267e-17, 3.8858e-16, 1.6653e-16, 2.6645e-15,\n",
      "         5.5511e-17, 1.1102e-16, 4.4409e-16, 2.2204e-16, 1.1102e-16, 5.5511e-16,\n",
      "         2.2204e-16, 1.1102e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17, 8.8818e-16,\n",
      "         2.2204e-16, 8.8818e-16, 4.4409e-16, 1.1102e-16]], dtype=torch.float64)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t EXEC SPLIT: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #13-layer1.1.relu; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.1.bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.1.relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t EXEC SPLIT: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_out=[]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #13-layer1.1.relu; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.1.bn1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.1.relu C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_out=[ 4  7  9 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 45]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t Prepping to send C_out tensor([ 4,  7,  9, 14]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([45]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t EXEC SPLIT: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #13-layer1.1.relu; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.1.bn1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.1.relu C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([38, 40, 43, 45, 47])\n",
      "\t\t EXEC SPLIT: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 52]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t Prepping to send C_out tensor([52]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #13-layer1.1.relu; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.1.bn1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.1.relu C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([50, 51, 53, 56, 59, 61, 62])\n",
      "\t\t EXEC SPLIT: #14-layer1.1.conv2; Shape=[1, 64, 32, 32]; C_out=[ 2 40 43 46 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([2]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([40, 43, 46]) to machine 2\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer1.1.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer1.1.conv2:\n",
      "Max diff:\n",
      "tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 2.1684e-18, 0.0000e+00, 3.3307e-16, 0.0000e+00,\n",
      "         0.0000e+00, 4.8572e-17, 0.0000e+00, 3.1225e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.4593e-17, 0.0000e+00, 5.3291e-15, 3.1086e-15,\n",
      "         3.5527e-15, 5.3291e-15, 4.4409e-15, 5.3291e-15, 7.1054e-15, 2.2204e-15,\n",
      "         5.3291e-15, 3.9968e-15, 4.4409e-15, 8.8818e-15, 4.4409e-15, 5.3291e-15,\n",
      "         3.5527e-15, 7.1054e-15, 2.2204e-16, 1.8128e-16, 1.6653e-16, 1.6653e-16,\n",
      "         2.4980e-16, 1.6653e-16, 3.3307e-16, 1.1102e-16, 4.4409e-16, 5.8981e-17,\n",
      "         2.2204e-16, 6.6613e-16, 8.3267e-17, 5.5511e-16, 1.6653e-16, 1.1102e-16,\n",
      "         4.4409e-16, 6.2450e-17, 1.1102e-16, 1.1102e-16, 3.3307e-16, 1.1102e-16,\n",
      "         2.7756e-17, 2.2204e-16, 2.7756e-16, 1.1102e-16, 2.2204e-16, 6.9389e-17,\n",
      "         8.3267e-17, 1.6653e-16, 1.6653e-16, 5.5511e-17]], dtype=torch.float64)\n",
      "tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 2,  4,  7,  9, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 53)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 2,  4,  7,  9, 14])\n",
      "\t\t EXEC SPLIT: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #16-layer1.1.add; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.1.bn2 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #17-layer1.1.relu_1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.1.add C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #18-layer2.0.conv1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\t\tChecking output from layer1.1.relu_1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 4,  7,  9, 11])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #18-layer2.0.conv1; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #16-layer1.1.add; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.1.bn2 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #17-layer1.1.relu_1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.1.add C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #18-layer2.0.conv1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer1.1.relu_1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #18-layer2.0.conv1; Shape=[1, 128, 16, 16]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t EXEC SPLIT: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #16-layer1.1.add; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.1.bn2 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #17-layer1.1.relu_1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.1.add C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #18-layer2.0.conv1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "\t\tChecking output from layer1.1.relu_1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 36, 42, 43, 44, 46, 47])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #18-layer2.0.conv1; Shape=[1, 128, 16, 16]; C_out=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #15-layer1.1.bn2; Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #16-layer1.1.add; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.1.bn2 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #17-layer1.1.relu_1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.1.add C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #18-layer2.0.conv1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer1.1.relu_1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([48, 49, 52, 54, 55, 56, 57, 59, 60, 62])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #18-layer2.0.conv1; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer2.0.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer2.0.conv1:\n",
      "Max diff:\n",
      "tensor([2.1316e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[8.8818e-16, 2.6645e-15, 2.7756e-16, 3.5527e-15, 4.4409e-16, 1.7764e-15,\n",
      "         4.4409e-16, 1.3878e-16, 1.7764e-15, 8.8818e-16, 2.2204e-16, 8.8818e-16,\n",
      "         2.7756e-16, 2.2204e-16, 8.3267e-17, 4.1633e-17, 3.5527e-15, 3.0531e-16,\n",
      "         1.6653e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 1.7764e-15, 1.6653e-16,\n",
      "         3.5527e-15, 1.6653e-16, 1.1102e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16,\n",
      "         8.3267e-17, 2.2204e-16, 5.3291e-15, 3.5527e-15, 5.2180e-15, 1.0658e-14,\n",
      "         8.4377e-15, 5.3291e-15, 5.3291e-15, 8.8818e-15, 6.2172e-15, 1.1546e-14,\n",
      "         7.7716e-15, 1.0214e-14, 1.7764e-14, 6.2172e-15, 7.1054e-15, 1.0658e-14,\n",
      "         8.8818e-15, 2.1316e-14, 7.1054e-15, 7.9936e-15, 5.3291e-15, 1.0658e-14,\n",
      "         1.3323e-14, 7.7716e-15, 8.4377e-15, 1.7764e-14, 1.0658e-14, 6.2172e-15,\n",
      "         5.7732e-15, 1.0658e-14, 5.9952e-15, 5.3291e-15, 8.3267e-17, 2.2204e-16,\n",
      "         1.1102e-16, 8.8818e-16, 2.2204e-16, 1.1102e-16, 1.1102e-16, 1.1102e-16,\n",
      "         2.2204e-16, 2.7756e-17, 8.8818e-16, 1.6653e-16, 1.6653e-16, 5.5511e-17,\n",
      "         4.1633e-16, 4.4409e-16, 8.8818e-16, 1.1102e-16, 6.6613e-16, 2.2204e-16,\n",
      "         4.4409e-16, 8.8818e-16, 2.4286e-17, 2.0817e-17, 3.1225e-17, 8.8818e-16,\n",
      "         1.3878e-17, 4.4409e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 1.3323e-15,\n",
      "         5.5511e-16, 5.8287e-16, 4.4409e-16, 8.8818e-16, 2.2204e-16, 4.4409e-16,\n",
      "         2.7756e-17, 6.6613e-16, 2.2204e-16, 4.4409e-16, 1.6653e-16, 4.4409e-16,\n",
      "         6.6613e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 2.7756e-17, 8.8818e-16,\n",
      "         2.7756e-16, 1.1102e-16, 2.2204e-16, 1.3323e-15, 4.4409e-16, 4.4409e-16,\n",
      "         6.6613e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #20-layer2.0.relu; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.0.bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.0.relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  5,  8, 16, 17, 18, 22, 24, 28])\n",
      "\t\t EXEC SPLIT: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #20-layer2.0.relu; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.0.bn1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.0.relu C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52,\n",
      "        53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_out=[10 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54\n",
      " 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([10]) to machine 0\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t EXEC SPLIT: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_out=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #20-layer2.0.relu; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.0.bn1 C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.0.relu C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([78, 79, 89, 91, 93])\n",
      "\t\t EXEC SPLIT: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_out=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #19-layer2.0.bn1; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #20-layer2.0.relu; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.0.bn1 C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.0.relu C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97, 101, 104, 105, 107, 108, 109, 110, 114, 116, 120, 121, 122,\n",
      "        123, 126, 127])\n",
      "\t\t EXEC SPLIT: #21-layer2.0.conv2; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer2.0.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer2.0.conv2:\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.2204e-16, 2.2204e-16, 3.3307e-16, 8.8818e-16, 8.3267e-17, 6.6613e-16,\n",
      "         8.3267e-17, 1.6653e-16, 1.6653e-16, 1.3878e-16, 2.7756e-16, 4.4409e-16,\n",
      "         1.6653e-16, 2.2204e-16, 2.2204e-16, 1.9429e-16, 2.2204e-16, 3.3307e-16,\n",
      "         3.3307e-16, 1.1102e-16, 1.7764e-15, 1.2490e-16, 4.1633e-17, 8.8818e-16,\n",
      "         2.2204e-16, 1.3878e-16, 4.4409e-16, 3.3307e-16, 1.3878e-16, 3.3307e-16,\n",
      "         2.2204e-16, 1.3323e-15, 8.8818e-15, 1.0658e-14, 7.5495e-15, 7.1054e-15,\n",
      "         6.6613e-15, 1.0658e-14, 6.2172e-15, 1.2434e-14, 1.2434e-14, 7.1054e-15,\n",
      "         8.4377e-15, 8.8818e-15, 8.8818e-15, 7.1054e-15, 7.1054e-15, 1.4211e-14,\n",
      "         8.8818e-15, 6.2172e-15, 6.6613e-15, 1.0658e-14, 8.8818e-15, 7.1054e-15,\n",
      "         8.8818e-15, 7.9936e-15, 9.3259e-15, 1.0658e-14, 1.0658e-14, 7.1054e-15,\n",
      "         1.2434e-14, 1.0658e-14, 7.1054e-15, 8.8818e-15, 5.5511e-17, 2.7756e-17,\n",
      "         4.4409e-16, 4.4409e-16, 5.5511e-17, 8.8818e-16, 2.2204e-16, 1.1102e-16,\n",
      "         4.1633e-17, 2.7756e-17, 5.5511e-17, 1.1102e-16, 5.5511e-17, 4.4409e-16,\n",
      "         5.5511e-17, 2.2204e-16, 4.1633e-17, 2.2204e-16, 5.5511e-17, 2.2204e-16,\n",
      "         2.2204e-16, 1.3323e-15, 1.6653e-16, 1.1102e-16, 8.8818e-16, 6.6613e-16,\n",
      "         4.4409e-16, 6.6613e-16, 4.1633e-17, 1.6480e-17, 4.4409e-16, 8.3267e-17,\n",
      "         5.5511e-16, 1.7764e-15, 1.3323e-15, 1.1102e-15, 1.7764e-15, 2.7756e-16,\n",
      "         2.2204e-16, 1.2212e-15, 1.1102e-15, 2.7756e-16, 2.7756e-16, 8.8818e-16,\n",
      "         1.3323e-15, 1.3323e-15, 1.0547e-15, 4.4409e-16, 5.5511e-16, 2.6645e-15,\n",
      "         3.5527e-15, 8.8818e-16, 3.5527e-15, 8.8818e-16, 3.3307e-16, 3.5527e-15,\n",
      "         1.5543e-15, 4.4409e-16, 4.4409e-15, 1.7764e-15, 8.8818e-16, 4.4409e-16,\n",
      "         3.5527e-15, 1.3323e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.0.bn2 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  38 121]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t Prepping to send C_out tensor([38]) to machine 1\n",
      "\t\t Prepping to send C_out tensor([121]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.0.bn2 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_out=[  0   2   3   5   7  10  19  24  32  33  34  35  36  37  38  39  40  41\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  65  66  68  70  73  78  80  92  93 104 115 121]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([ 0,  2,  3,  5,  7, 10, 19, 24]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([65, 66, 68, 70, 73, 78, 80, 92, 93]) to machine 2\n",
      "\t\t Prepping to send C_out tensor([104, 115, 121]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t EXEC SPLIT: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_out=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.0.bn2 C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_out=[ 14  28  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
      "  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95 101 102\n",
      " 121 122]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t Prepping to send C_out tensor([14, 28]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([101, 102, 121, 122]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #22-layer2.0.bn2; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.0.bn2 C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #23-layer2.0.shortcut.0; Shape=[1, 128, 16, 16]; C_out=[  4   5  10  21  23  30  33  60  65  68  86  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t Prepping to send C_out tensor([ 4,  5, 10, 21, 23, 30]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([33, 60]) to machine 1\n",
      "\t\t Prepping to send C_out tensor([65, 68, 86]) to machine 2\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer2.0.shortcut.0-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer2.0.shortcut.0:\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.2204e-16, 1.6653e-16, 2.2204e-16, 2.2204e-16, 2.7756e-17, 1.6653e-16,\n",
      "         1.7347e-18, 3.8164e-17, 4.1633e-17, 2.0817e-17, 1.6653e-16, 8.3267e-17,\n",
      "         3.3307e-16, 1.6653e-16, 1.6653e-16, 3.3307e-16, 2.2204e-16, 1.6653e-16,\n",
      "         2.2204e-16, 8.3267e-17, 8.8818e-16, 8.3267e-17, 1.7347e-18, 1.6653e-16,\n",
      "         4.1633e-17, 1.6653e-16, 1.6653e-16, 1.6653e-16, 8.3267e-17, 1.6653e-16,\n",
      "         2.2204e-16, 2.2204e-16, 1.3323e-15, 3.5527e-15, 1.7764e-15, 1.3323e-15,\n",
      "         1.3323e-15, 1.7764e-15, 5.3291e-15, 1.9984e-15, 1.3323e-15, 1.7764e-15,\n",
      "         2.6645e-15, 2.2204e-15, 1.2768e-15, 2.2204e-15, 2.5535e-15, 2.6645e-15,\n",
      "         1.8874e-15, 2.2204e-15, 2.6645e-15, 2.6645e-15, 1.9984e-15, 1.7764e-15,\n",
      "         3.5527e-15, 1.1657e-15, 3.1086e-15, 2.6645e-15, 2.5535e-15, 1.7764e-15,\n",
      "         2.6645e-15, 2.2204e-15, 1.7764e-15, 2.6645e-15, 2.0817e-17, 2.0817e-17,\n",
      "         1.1102e-16, 1.6653e-16, 1.1102e-16, 1.1102e-16, 1.2490e-16, 2.7756e-17,\n",
      "         6.9389e-18, 2.7756e-17, 6.9389e-18, 6.9389e-18, 1.2143e-17, 2.2204e-16,\n",
      "         8.6736e-18, 5.5511e-17, 1.0408e-17, 3.4694e-17, 1.3878e-17, 5.5511e-17,\n",
      "         5.5511e-17, 1.1102e-16, 2.7756e-17, 2.0817e-17, 1.1102e-16, 1.1102e-16,\n",
      "         1.1102e-16, 1.1102e-16, 5.5511e-17, 6.9389e-18, 5.5511e-17, 1.7347e-17,\n",
      "         1.3878e-17, 5.5511e-17, 1.2490e-16, 1.1102e-16, 1.6653e-16, 1.7347e-17,\n",
      "         4.1633e-17, 1.3878e-16, 8.8818e-16, 1.3878e-17, 1.3878e-17, 1.1102e-16,\n",
      "         5.5511e-17, 1.1102e-16, 1.1102e-16, 1.3878e-17, 2.7756e-17, 2.2204e-16,\n",
      "         1.6653e-16, 1.3323e-15, 1.1102e-16, 1.1102e-16, 2.7756e-17, 1.1102e-16,\n",
      "         1.9429e-16, 2.7756e-17, 1.1102e-16, 1.1102e-16, 1.1102e-16, 2.7756e-17,\n",
      "         2.2204e-16, 9.7145e-17]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #25-layer2.0.add; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.0.shortcut.1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #26-layer2.0.relu_1; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.0.add C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.0.relu_1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 6,  7,  8, 12, 15, 18, 21])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #25-layer2.0.add; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.0.shortcut.1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #26-layer2.0.relu_1; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.0.add C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.0.relu_1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "        51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63 80]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([80]) to machine 2\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t EXEC SPLIT: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_out=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #25-layer2.0.add; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.0.shortcut.1 C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #26-layer2.0.relu_1; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.0.add C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.0.relu_1 C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([67, 69, 85, 88, 89, 91])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_out=[ 2 14 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85\n",
      " 86 87 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t Prepping to send C_out tensor([ 2, 14]) to machine 0\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #24-layer2.0.shortcut.1; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #25-layer2.0.add; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.0.shortcut.1 C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #26-layer2.0.relu_1; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.0.add C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.0.relu_1 C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 97,  98,  99, 103, 104, 107, 108, 109, 110, 113, 114, 115, 116, 117,\n",
      "        119, 120, 123, 124, 126, 127])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #27-layer2.1.conv1; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer2.1.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer2.1.conv1:\n",
      "Max diff:\n",
      "tensor([3.5527e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[1.7347e-17, 6.0715e-18, 2.0817e-17, 1.0408e-17, 5.2042e-18, 9.5410e-18,\n",
      "         2.0817e-17, 1.3878e-17, 3.4694e-18, 3.2526e-18, 8.6736e-18, 1.0408e-17,\n",
      "         1.0408e-17, 6.0715e-18, 2.2204e-16, 5.2042e-18, 6.9389e-18, 5.2042e-18,\n",
      "         2.0817e-17, 8.6736e-18, 2.0817e-17, 1.0408e-17, 1.0408e-17, 1.3878e-17,\n",
      "         6.0715e-18, 8.6736e-18, 1.0408e-17, 5.6379e-18, 1.0408e-17, 1.3878e-17,\n",
      "         5.2042e-18, 1.2143e-17, 1.9540e-14, 1.5987e-14, 1.7764e-14, 2.4869e-14,\n",
      "         1.5987e-14, 1.5987e-14, 1.7764e-14, 3.5527e-14, 1.5987e-14, 1.7764e-14,\n",
      "         2.1316e-14, 1.7764e-14, 1.4211e-14, 1.2434e-14, 1.7764e-14, 1.5987e-14,\n",
      "         2.4869e-14, 2.8422e-14, 2.1316e-14, 1.3323e-14, 1.7764e-14, 2.1316e-14,\n",
      "         2.1316e-14, 1.9540e-14, 1.8652e-14, 2.1316e-14, 2.8422e-14, 2.8422e-14,\n",
      "         1.7764e-14, 2.1316e-14, 2.1316e-14, 2.8422e-14, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 1.7764e-15, 4.4409e-16, 2.2204e-15, 4.1633e-17,\n",
      "         6.6613e-16, 2.2204e-16, 4.4409e-16, 4.4409e-16, 1.1102e-16, 4.4409e-16,\n",
      "         3.3307e-16, 1.6653e-16, 1.1102e-16, 8.8818e-16, 3.3307e-16, 1.6653e-16,\n",
      "         2.2204e-16, 6.6613e-16, 2.2204e-16, 1.3323e-15, 2.2204e-16, 2.2204e-16,\n",
      "         1.4211e-14, 2.6645e-15, 5.3291e-15, 1.4211e-14, 2.6645e-15, 7.1054e-15,\n",
      "         2.2204e-15, 2.2204e-15, 1.1102e-15, 3.5527e-15, 6.6613e-16, 2.2204e-15,\n",
      "         1.7764e-15, 1.7764e-15, 3.5527e-15, 7.1054e-15, 2.8866e-15, 8.8818e-15,\n",
      "         8.8818e-16, 1.7764e-15, 1.4211e-14, 1.7764e-14, 7.1054e-15, 4.4409e-15,\n",
      "         2.6645e-15, 8.8818e-15, 5.3291e-15, 1.4211e-14, 3.5527e-15, 1.2434e-14,\n",
      "         1.0658e-14, 7.1054e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #29-layer2.1.relu; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.1.bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.1.relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "        20, 21, 22, 25, 26, 27, 28, 30, 31])\n",
      "\t\t EXEC SPLIT: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #29-layer2.1.relu; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.1.bn1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.1.relu C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52,\n",
      "        54, 55, 56, 57, 60, 61, 62])\n",
      "\t\t EXEC SPLIT: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_out=[ 4 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54\n",
      " 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([4]) to machine 0\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t EXEC SPLIT: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_out=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #29-layer2.1.relu; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.1.bn1 C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.1.relu C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t EXEC SPLIT: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_out=[]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #28-layer2.1.bn1; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #29-layer2.1.relu; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.1.bn1 C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.1.relu C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  98, 105, 111, 112, 122, 124, 125, 127])\n",
      "\t\t EXEC SPLIT: #30-layer2.1.conv2; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer2.1.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer2.1.conv2:\n",
      "Max diff:\n",
      "tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[8.6736e-18, 6.7221e-18, 4.1633e-17, 4.1633e-17, 5.5511e-17, 6.9389e-18,\n",
      "         4.7705e-18, 1.2143e-17, 4.8572e-17, 4.1633e-17, 1.3010e-17, 4.1633e-17,\n",
      "         4.8572e-17, 2.9273e-18, 3.4694e-17, 2.9490e-17, 1.2143e-17, 4.7705e-18,\n",
      "         2.0817e-17, 4.5103e-17, 4.4409e-16, 4.8572e-17, 8.6736e-18, 5.5511e-17,\n",
      "         4.8572e-17, 3.2526e-18, 2.4286e-17, 1.0408e-17, 1.5613e-17, 6.9389e-17,\n",
      "         5.5511e-17, 8.3267e-17, 9.7700e-15, 5.3291e-15, 7.5495e-15, 5.7732e-15,\n",
      "         6.2172e-15, 5.3291e-15, 4.4409e-15, 1.0658e-14, 7.1054e-15, 3.9968e-15,\n",
      "         4.4409e-15, 5.3291e-15, 4.4409e-15, 3.5527e-15, 6.2172e-15, 4.4409e-15,\n",
      "         5.3291e-15, 4.4409e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15, 4.4409e-15,\n",
      "         3.9968e-15, 6.4393e-15, 3.9968e-15, 5.3291e-15, 4.5519e-15, 6.2172e-15,\n",
      "         7.9936e-15, 7.1054e-15, 7.5495e-15, 5.3291e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7764e-15, 9.9920e-16, 8.8818e-16, 3.8858e-16, 8.8818e-16, 8.8818e-16,\n",
      "         4.4409e-16, 1.3323e-15, 6.6613e-16, 1.3323e-15, 5.5511e-17, 1.7764e-15,\n",
      "         3.4694e-16, 6.6613e-16, 8.8818e-16, 1.1102e-16, 1.3323e-15, 1.3323e-15,\n",
      "         1.3323e-15, 4.7184e-16, 4.4409e-16, 6.6613e-16, 3.3307e-16, 1.7764e-15,\n",
      "         8.8818e-16, 1.7764e-15, 1.7764e-15, 8.8818e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 8.8818e-16]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])  (len = 96)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t EXEC SPLIT: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #32-layer2.1.add; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.1.bn2 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #33-layer2.1.relu_1; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.1.add C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #34-layer3.0.conv1; Shape=[1, 128, 16, 16]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "\t\tChecking output from layer2.1.relu_1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 7,  8, 10, 11, 12, 15, 18, 21, 23, 26])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #34-layer3.0.conv1; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #32-layer2.1.add; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.1.bn2 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #33-layer2.1.relu_1; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.1.add C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #34-layer3.0.conv1; Shape=[1, 128, 16, 16]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer2.1.relu_1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #34-layer3.0.conv1; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t EXEC SPLIT: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_out=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #32-layer2.1.add; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.1.bn2 C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #33-layer2.1.relu_1; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.1.add C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #34-layer3.0.conv1; Shape=[1, 128, 16, 16]; C_in=[64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]\n",
      "\t\tChecking output from layer2.1.relu_1 C_in [64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 94 95]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([67, 69, 85, 88, 89, 91])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #34-layer3.0.conv1; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #31-layer2.1.bn2; Shape=[1, 128, 16, 16]; C_out=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #32-layer2.1.add; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.1.bn2 C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #33-layer2.1.relu_1; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.1.add C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #34-layer3.0.conv1; Shape=[1, 128, 16, 16]; C_in=[ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer2.1.relu_1 C_in [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 96,  97,  98,  99, 101, 103, 104, 105, 107, 108, 109, 110, 112, 113,\n",
      "        114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #34-layer3.0.conv1; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer3.0.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer3.0.conv1:\n",
      "Max diff:\n",
      "tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.7756e-17, 2.0817e-17, 9.3241e-18, 6.9389e-18, 1.3878e-17, 4.1633e-17,\n",
      "         1.3878e-17, 1.3878e-17, 1.3878e-17, 6.9389e-18, 1.3878e-17, 2.7756e-17,\n",
      "         2.0817e-17, 2.7756e-17, 1.0408e-17, 8.6736e-18, 2.0817e-17, 1.7347e-17,\n",
      "         2.7756e-17, 8.2399e-18, 2.7756e-17, 1.3878e-17, 2.7756e-17, 1.0408e-17,\n",
      "         8.6736e-18, 6.9389e-18, 1.2143e-17, 1.5613e-17, 1.4745e-17, 6.9389e-18,\n",
      "         2.0817e-17, 1.0408e-17, 8.6736e-18, 2.7756e-17, 1.3878e-17, 8.6736e-18,\n",
      "         1.0408e-17, 5.2042e-18, 2.0817e-17, 1.0408e-17, 1.7347e-17, 2.0817e-17,\n",
      "         1.2143e-17, 1.3878e-17, 1.0408e-17, 1.7347e-17, 1.2143e-17, 2.7756e-17,\n",
      "         6.9389e-18, 1.7347e-17, 4.1633e-17, 1.0408e-17, 1.3878e-17, 1.3878e-17,\n",
      "         2.7756e-17, 6.9389e-18, 2.0817e-17, 1.2143e-17, 1.3878e-17, 1.3878e-17,\n",
      "         2.0817e-17, 6.0715e-18, 1.0408e-17, 2.7756e-17, 1.5987e-14, 1.7764e-15,\n",
      "         1.0658e-14, 2.8422e-14, 1.3323e-14, 1.0658e-14, 2.3870e-14, 2.3093e-14,\n",
      "         1.4211e-14, 2.1316e-14, 1.5987e-14, 1.2434e-14, 1.4211e-14, 1.0658e-14,\n",
      "         1.2434e-14, 1.0658e-14, 1.4211e-14, 1.3323e-14, 1.0658e-14, 2.1316e-14,\n",
      "         1.4211e-14, 1.4211e-14, 1.4211e-14, 7.1054e-15, 1.3323e-14, 1.2434e-14,\n",
      "         1.4211e-14, 1.2434e-14, 1.7764e-15, 1.4211e-14, 1.7764e-14, 1.2434e-14,\n",
      "         1.0658e-14, 8.8818e-15, 1.7764e-14, 1.4211e-14, 1.0658e-14, 2.1316e-14,\n",
      "         8.8818e-15, 1.5987e-14, 1.7764e-14, 1.4211e-14, 1.5987e-14, 1.3323e-14,\n",
      "         8.8818e-15, 1.0658e-14, 1.7764e-14, 1.2434e-14, 1.2434e-14, 2.1316e-14,\n",
      "         1.0658e-14, 1.4211e-14, 1.1546e-14, 1.7764e-14, 2.1316e-14, 1.7764e-14,\n",
      "         1.7764e-14, 1.2434e-14, 1.4211e-14, 1.7764e-14, 1.5987e-14, 2.1316e-14,\n",
      "         1.8652e-14, 1.0658e-14, 4.1633e-17, 1.7764e-15, 5.5511e-17, 2.2204e-16,\n",
      "         5.5511e-17, 2.2204e-16, 6.6613e-16, 8.8818e-16, 2.2204e-16, 2.2204e-16,\n",
      "         2.2204e-16, 2.2204e-16, 8.8818e-16, 8.8818e-16, 1.1102e-16, 2.6645e-15,\n",
      "         1.7764e-15, 8.8818e-16, 8.3267e-17, 1.1102e-16, 8.8818e-16, 4.4409e-16,\n",
      "         8.8818e-16, 1.7764e-15, 8.3267e-17, 6.6613e-16, 1.1102e-16, 1.6653e-16,\n",
      "         5.5511e-17, 1.1102e-16, 5.5511e-17, 1.1102e-16, 2.7756e-17, 2.2204e-16,\n",
      "         1.1102e-16, 2.2204e-16, 2.6645e-15, 8.3267e-17, 6.6613e-16, 1.1102e-16,\n",
      "         1.7764e-15, 1.1102e-16, 8.8818e-16, 8.8818e-16, 4.1633e-17, 1.1102e-16,\n",
      "         5.5511e-17, 1.7764e-15, 4.4409e-16, 1.1102e-16, 2.7756e-17, 3.3307e-16,\n",
      "         1.1102e-16, 1.7764e-15, 2.2204e-16, 5.5511e-17, 1.1102e-16, 6.6613e-16,\n",
      "         1.7764e-15, 8.8818e-16, 1.7764e-15, 8.3267e-17, 2.2204e-16, 2.2204e-16,\n",
      "         1.4211e-14, 7.1054e-15, 8.8818e-15, 2.6645e-15, 6.6613e-16, 1.4211e-14,\n",
      "         4.4409e-15, 1.0658e-14, 3.5527e-15, 2.1316e-14, 8.8818e-15, 1.7764e-14,\n",
      "         3.9968e-15, 4.4409e-16, 8.8818e-16, 1.0658e-14, 7.1054e-15, 7.1054e-15,\n",
      "         1.2434e-14, 3.5527e-15, 1.5987e-14, 4.4409e-15, 1.0658e-14, 2.6645e-15,\n",
      "         5.3291e-15, 1.4211e-14, 1.3323e-15, 1.0658e-14, 7.1054e-15, 1.7764e-14,\n",
      "         6.2172e-15, 1.7764e-14, 8.8818e-16, 1.7764e-15, 6.6613e-15, 1.0658e-14,\n",
      "         1.0658e-14, 8.8818e-16, 1.3323e-15, 5.3291e-15, 7.9936e-15, 7.1054e-15,\n",
      "         1.4211e-14, 7.1054e-15, 1.0658e-14, 3.5527e-15, 5.3291e-15, 1.0658e-14,\n",
      "         8.8818e-16, 5.3291e-15, 2.6645e-15, 7.1054e-15, 5.3291e-15, 2.6645e-15,\n",
      "         5.3291e-15, 1.3323e-15, 1.4211e-14, 5.3291e-15, 4.4409e-15, 1.7764e-14,\n",
      "         5.7732e-15, 8.8818e-15, 7.1054e-15, 7.5495e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #36-layer3.0.relu; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.0.bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.0.relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 1,  3,  5,  6,  8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24,\n",
      "        25, 26, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 47, 49, 50, 52,\n",
      "        53, 54, 56, 57, 59, 60, 61])\n",
      "\t\t EXEC SPLIT: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #36-layer3.0.relu; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.0.bn1 C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.0.relu C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  66,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         81,  82,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,  98,  99,\n",
      "        101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115,\n",
      "        116, 120, 121, 123, 124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t EXEC SPLIT: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #36-layer3.0.relu; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.0.bn1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.0.relu C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([141, 144, 150, 168])\n",
      "\t\t EXEC SPLIT: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t EXEC SPLIT: #35-layer3.0.bn1; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #36-layer3.0.relu; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.0.bn1 C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.0.relu C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([193, 208, 213, 220, 226, 231, 232, 235, 236, 241, 249, 252, 254, 255])\n",
      "\t\t EXEC SPLIT: #37-layer3.0.conv2; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer3.0.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer3.0.conv2:\n",
      "Max diff:\n",
      "tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[6.9389e-18, 1.7347e-18, 2.6021e-18, 1.3878e-17, 1.3878e-17, 1.3878e-17,\n",
      "         6.9389e-18, 1.7347e-18, 1.7347e-18, 1.7347e-18, 3.4694e-18, 1.7347e-18,\n",
      "         3.4694e-18, 2.1684e-18, 3.4694e-18, 4.3368e-19, 1.3010e-18, 3.4694e-18,\n",
      "         1.7347e-18, 1.3010e-18, 3.4694e-18, 3.4694e-18, 1.3878e-17, 3.4694e-18,\n",
      "         1.7347e-18, 1.3878e-17, 1.3878e-17, 3.0358e-18, 1.7347e-18, 1.7347e-18,\n",
      "         6.9389e-18, 3.4694e-18, 6.9389e-18, 2.1684e-18, 2.1684e-18, 2.7756e-17,\n",
      "         6.9389e-18, 1.3878e-17, 3.4694e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18,\n",
      "         3.4694e-18, 1.3878e-17, 1.3878e-17, 1.3878e-17, 3.4694e-18, 6.9389e-18,\n",
      "         1.7347e-18, 1.7347e-18, 1.7347e-18, 3.0358e-18, 6.9389e-18, 2.6021e-18,\n",
      "         1.3010e-18, 2.7756e-17, 6.9389e-18, 2.1684e-18, 6.9389e-18, 6.9389e-18,\n",
      "         6.9389e-18, 4.3368e-18, 3.4694e-18, 1.0842e-18, 7.9936e-15, 9.3259e-15,\n",
      "         7.9936e-15, 6.2172e-15, 1.4211e-14, 1.0658e-14, 1.0658e-14, 9.7700e-15,\n",
      "         8.8818e-15, 8.9928e-15, 1.0658e-14, 6.6613e-15, 8.8818e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.2434e-14, 7.3275e-15, 8.8818e-15, 1.0658e-14, 1.4211e-14,\n",
      "         8.8818e-15, 9.7700e-15, 1.0658e-14, 6.2172e-15, 6.2172e-15, 8.4377e-15,\n",
      "         8.8818e-15, 1.1546e-14, 9.3259e-15, 1.1546e-14, 6.8834e-15, 1.0658e-14,\n",
      "         7.1054e-15, 1.0658e-14, 7.1054e-15, 8.8818e-15, 9.3259e-15, 8.8818e-15,\n",
      "         1.0658e-14, 8.8818e-15, 7.1054e-15, 8.8818e-15, 8.8818e-15, 7.1054e-15,\n",
      "         1.2434e-14, 8.8818e-15, 7.9936e-15, 7.1054e-15, 8.8818e-15, 7.9936e-15,\n",
      "         7.1054e-15, 1.0658e-14, 1.4211e-14, 7.1054e-15, 1.2434e-14, 8.8818e-15,\n",
      "         8.6597e-15, 7.9936e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 9.7700e-15,\n",
      "         7.1054e-15, 1.0658e-14, 4.4409e-16, 3.1225e-16, 8.8818e-16, 2.7756e-17,\n",
      "         3.8858e-16, 4.4409e-16, 2.2204e-16, 8.8818e-16, 5.5511e-17, 1.1102e-16,\n",
      "         4.4409e-16, 1.1102e-16, 5.5511e-17, 2.2204e-16, 2.7756e-17, 2.2204e-16,\n",
      "         4.4409e-16, 3.6082e-16, 4.4409e-16, 3.8858e-16, 1.3878e-17, 3.3307e-16,\n",
      "         4.4409e-16, 4.4409e-16, 3.3307e-16, 4.4409e-16, 4.4409e-16, 1.1102e-16,\n",
      "         8.8818e-16, 5.5511e-17, 6.6613e-16, 6.9389e-18, 4.4409e-16, 8.8818e-16,\n",
      "         4.4409e-16, 4.4409e-16, 6.6613e-16, 1.3878e-17, 3.3307e-16, 8.8818e-16,\n",
      "         2.2204e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 6.6613e-16, 5.5511e-17,\n",
      "         8.8818e-16, 5.5511e-17, 4.4409e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17,\n",
      "         4.4409e-16, 2.7756e-17, 2.7756e-17, 6.6613e-16, 2.7756e-16, 3.3307e-16,\n",
      "         2.7756e-17, 4.4409e-16, 5.5511e-17, 4.4409e-16, 1.1102e-16, 3.3307e-16,\n",
      "         3.3307e-16, 6.6613e-16, 2.6645e-15, 2.2204e-15, 5.3291e-15, 4.4409e-15,\n",
      "         2.6645e-15, 2.2204e-15, 2.6645e-15, 3.5527e-15, 2.6645e-15, 4.4409e-15,\n",
      "         3.3307e-16, 1.7764e-15, 1.5543e-15, 2.6645e-15, 3.3307e-16, 2.2204e-15,\n",
      "         2.6645e-15, 2.6645e-15, 2.2204e-15, 3.3307e-15, 4.4409e-16, 3.5527e-15,\n",
      "         2.6645e-15, 2.6645e-15, 3.5527e-15, 1.3323e-15, 4.4409e-15, 3.5527e-15,\n",
      "         2.2204e-15, 4.4409e-15, 1.3323e-15, 2.7756e-16, 2.6645e-15, 2.4425e-15,\n",
      "         3.3307e-16, 2.6645e-15, 3.5527e-15, 2.4425e-15, 2.6645e-15, 2.9976e-15,\n",
      "         1.3323e-15, 3.3307e-16, 2.6645e-15, 2.2204e-15, 3.5527e-15, 2.2204e-16,\n",
      "         2.6645e-15, 3.5527e-15, 1.7764e-15, 4.4409e-16, 1.7764e-15, 3.1086e-15,\n",
      "         2.9976e-15, 1.1102e-15, 1.8874e-15, 2.6645e-15, 3.3307e-16, 1.1102e-16,\n",
      "         5.5511e-16, 2.1094e-15, 1.7764e-15, 1.8874e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.0.bn2 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63 182 208 234 243 247 252]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t Prepping to send C_out tensor([182]) to machine 2\n",
      "\t\t Prepping to send C_out tensor([208, 234, 243, 247, 252]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.0.bn2 C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_out=[  4   7   8  10  12  13  18  22  24  28  32  40  44  52  57  61  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 199 243 251]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t Prepping to send C_out tensor([ 4,  7,  8, 10, 12, 13, 18, 22, 24, 28, 32, 40, 44, 52, 57, 61]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([199, 243, 251]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t EXEC SPLIT: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.0.bn2 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_out=[ 35  37 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t Prepping to send C_out tensor([35, 37]) to machine 0\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t EXEC SPLIT: #38-layer3.0.bn2; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.0.bn2 C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #39-layer3.0.shortcut.0; Shape=[1, 256, 8, 8]; C_out=[  1   3  14  15  20  22  28  29  30  34  38  54  58  61  63  77  86 111\n",
      " 155 186 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
      " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
      " 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
      " 244 245 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t Prepping to send C_out tensor([ 1,  3, 14, 15, 20, 22, 28, 29, 30, 34, 38, 54, 58, 61, 63]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([ 77,  86, 111]) to machine 1\n",
      "\t\t Prepping to send C_out tensor([155, 186]) to machine 2\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer3.0.shortcut.0-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer3.0.shortcut.0:\n",
      "Max diff:\n",
      "tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[4.8789e-18, 2.6021e-18, 5.2042e-18, 2.6021e-18, 6.9389e-18, 5.2042e-18,\n",
      "         3.4694e-18, 2.9816e-18, 2.1684e-18, 2.7105e-18, 1.3010e-18, 1.3010e-18,\n",
      "         1.9082e-17, 4.3368e-18, 2.6021e-18, 1.3010e-18, 2.6021e-18, 3.4694e-18,\n",
      "         1.7347e-18, 2.1684e-18, 1.7347e-18, 1.5179e-18, 7.3726e-18, 2.1684e-18,\n",
      "         2.3852e-18, 6.0715e-18, 2.6021e-18, 1.7347e-18, 1.7347e-18, 2.6021e-18,\n",
      "         2.6021e-18, 2.6021e-18, 1.7347e-17, 3.4694e-18, 4.0251e-18, 6.9389e-18,\n",
      "         3.4694e-18, 2.6021e-18, 3.1442e-18, 3.4694e-18, 2.6021e-18, 2.6021e-18,\n",
      "         5.2042e-18, 3.4694e-18, 6.0715e-18, 2.6021e-18, 5.2042e-18, 4.3368e-19,\n",
      "         1.7347e-18, 3.4694e-18, 1.7347e-18, 2.1684e-18, 6.9389e-18, 2.6021e-18,\n",
      "         2.6021e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18, 2.6021e-18, 2.6021e-18,\n",
      "         1.9516e-18, 6.0715e-18, 6.9389e-18, 8.6736e-19, 4.4409e-15, 2.7200e-15,\n",
      "         4.2188e-15, 1.6792e-15, 3.8858e-15, 1.7764e-15, 3.4417e-15, 2.2204e-15,\n",
      "         2.5813e-15, 5.0515e-15, 2.6645e-15, 2.6645e-15, 2.6645e-15, 3.6637e-15,\n",
      "         3.9968e-15, 3.1086e-15, 1.7764e-15, 6.2172e-15, 2.6645e-15, 3.9968e-15,\n",
      "         2.4425e-15, 3.5527e-15, 2.6645e-15, 1.8874e-15, 1.7798e-15, 2.8866e-15,\n",
      "         5.3291e-15, 7.1054e-15, 3.5527e-15, 5.3291e-15, 2.6645e-15, 5.3291e-15,\n",
      "         2.6645e-15, 3.5527e-15, 7.1054e-15, 2.4425e-15, 2.9976e-15, 3.9968e-15,\n",
      "         3.5527e-15, 3.5527e-15, 2.4425e-15, 1.5543e-15, 4.8850e-15, 5.3291e-15,\n",
      "         3.5527e-15, 1.8874e-15, 3.5527e-15, 2.6645e-15, 2.8866e-15, 5.7732e-15,\n",
      "         4.4409e-15, 3.7748e-15, 2.4425e-15, 3.5527e-15, 4.8850e-15, 3.5527e-15,\n",
      "         4.4409e-15, 2.4425e-15, 3.5527e-15, 3.1086e-15, 4.6629e-15, 2.8311e-15,\n",
      "         2.6645e-15, 2.7756e-15, 3.3307e-16, 3.3307e-16, 5.5511e-17, 2.7756e-17,\n",
      "         4.4409e-16, 8.3267e-17, 5.5511e-17, 6.6613e-16, 1.7347e-17, 1.1102e-16,\n",
      "         2.7756e-17, 5.5511e-17, 2.7756e-17, 3.3307e-16, 1.3878e-17, 4.4409e-16,\n",
      "         4.4409e-16, 5.5511e-17, 3.3307e-16, 6.6613e-16, 1.3878e-17, 8.3267e-17,\n",
      "         2.2204e-16, 2.2204e-16, 4.4409e-16, 1.7347e-17, 1.1102e-16, 5.5511e-17,\n",
      "         2.2204e-16, 5.5511e-17, 1.3878e-17, 1.0408e-17, 2.2204e-16, 6.6613e-16,\n",
      "         6.6613e-16, 5.5511e-17, 4.4409e-16, 1.7347e-17, 1.6653e-16, 8.8818e-16,\n",
      "         1.1102e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16, 5.5511e-17,\n",
      "         3.3307e-16, 2.7756e-17, 1.6653e-16, 3.3307e-16, 6.6613e-16, 2.7756e-17,\n",
      "         4.1633e-17, 6.9389e-18, 3.4694e-17, 4.4409e-16, 2.2204e-16, 6.6613e-16,\n",
      "         2.0817e-17, 2.7756e-17, 2.0817e-17, 2.2204e-16, 5.5511e-17, 1.1102e-16,\n",
      "         1.6653e-16, 4.4409e-16, 1.3323e-15, 1.3323e-15, 1.7764e-15, 4.4409e-16,\n",
      "         1.3323e-15, 3.5527e-15, 1.7764e-15, 8.8818e-16, 8.8818e-16, 1.9429e-16,\n",
      "         3.3307e-16, 3.8858e-16, 4.4409e-16, 2.6645e-15, 1.6653e-16, 1.3323e-15,\n",
      "         1.3323e-15, 1.1102e-15, 1.2212e-15, 3.3307e-16, 3.3307e-16, 2.2204e-16,\n",
      "         1.7764e-15, 4.4409e-16, 9.9920e-16, 1.3323e-15, 8.8818e-16, 4.4409e-16,\n",
      "         4.4409e-16, 1.7764e-15, 1.3323e-15, 4.1633e-17, 1.7764e-15, 8.8818e-16,\n",
      "         1.3878e-16, 6.6613e-16, 1.7764e-15, 4.4409e-16, 8.8818e-16, 6.6613e-16,\n",
      "         2.2204e-16, 1.6653e-16, 7.7716e-16, 1.3323e-15, 1.6653e-16, 7.1124e-17,\n",
      "         6.6613e-16, 1.7764e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16, 3.3307e-16,\n",
      "         3.5527e-15, 3.3307e-16, 1.7764e-15, 1.7764e-15, 3.3307e-16, 1.6653e-16,\n",
      "         1.1102e-16, 2.4980e-16, 1.1102e-15, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #41-layer3.0.add; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.0.shortcut.1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #42-layer3.0.relu_1; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.0.add C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.0.relu_1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 5, 20, 21, 22, 23, 25, 26, 35, 36, 37, 39, 41, 42, 48, 52, 55, 56, 58,\n",
      "        59, 62])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #41-layer3.0.add; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.0.shortcut.1 C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #42-layer3.0.relu_1; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.0.add C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.0.relu_1 C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  66,  67,  68,  70,  72,  73,  74,  75,  76,  77,  78,  80,  81,\n",
      "         82,  84,  85,  87,  88,  89,  90,  92,  93,  94,  95,  96,  97,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t EXEC SPLIT: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #41-layer3.0.add; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.0.shortcut.1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #42-layer3.0.relu_1; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.0.add C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.0.relu_1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([130, 132, 133, 134, 141, 143, 144, 145, 149, 150, 152, 153, 158, 160,\n",
      "        163, 164, 166, 171, 177, 180, 183, 184, 185, 187, 189])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t EXEC SPLIT: #40-layer3.0.shortcut.1; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #41-layer3.0.add; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.0.shortcut.1 C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #42-layer3.0.relu_1; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.0.add C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.0.relu_1 C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([194, 195, 197, 199, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213,\n",
      "        215, 216, 217, 218, 220, 221, 222, 224, 227, 229, 230, 231, 233, 237,\n",
      "        240, 244, 245, 246, 248, 253, 254])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #43-layer3.1.conv1; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer3.1.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer3.1.conv1:\n",
      "Max diff:\n",
      "tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[3.4694e-18, 6.9389e-18, 6.9389e-18, 3.4694e-18, 6.9389e-18, 1.3010e-18,\n",
      "         3.4694e-18, 8.6736e-19, 1.3878e-17, 8.6736e-19, 6.9389e-18, 3.4694e-18,\n",
      "         6.9389e-18, 8.6736e-19, 1.7347e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 8.6736e-19, 8.6736e-19, 3.4694e-18, 4.3368e-19,\n",
      "         6.9389e-18, 3.4694e-18, 1.7347e-18, 3.4694e-18, 1.7347e-18, 3.4694e-18,\n",
      "         1.7347e-18, 1.7347e-18, 3.4694e-18, 1.0842e-18, 1.3878e-17, 8.6736e-19,\n",
      "         6.9389e-18, 6.5052e-19, 3.4694e-18, 3.4694e-18, 6.9389e-18, 6.9389e-18,\n",
      "         6.9389e-18, 6.9389e-18, 1.7347e-18, 6.9389e-18, 1.7347e-18, 3.4694e-18,\n",
      "         8.6736e-19, 4.3368e-19, 6.9389e-18, 1.3878e-17, 3.4694e-18, 3.4694e-18,\n",
      "         1.3878e-17, 6.9389e-18, 6.9389e-18, 6.9389e-18, 6.9389e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 6.9389e-18, 3.4694e-18, 1.7764e-14, 1.4211e-14,\n",
      "         1.4211e-14, 9.7700e-15, 1.4211e-14, 2.1316e-14, 1.2434e-14, 1.4211e-14,\n",
      "         1.7764e-14, 1.4211e-14, 2.1316e-14, 1.4211e-14, 1.4211e-14, 1.4211e-14,\n",
      "         2.8422e-14, 1.4211e-14, 1.4211e-14, 2.4869e-14, 2.1316e-14, 1.4211e-14,\n",
      "         2.1316e-14, 1.0658e-14, 1.4211e-14, 2.3093e-14, 1.9540e-14, 1.9540e-14,\n",
      "         1.4211e-14, 1.0658e-14, 2.8422e-14, 1.3323e-14, 1.4211e-14, 1.1546e-14,\n",
      "         1.6875e-14, 1.7764e-14, 1.1546e-14, 1.7764e-14, 1.7764e-14, 1.7764e-14,\n",
      "         2.1316e-14, 1.0658e-14, 1.4211e-14, 9.7700e-15, 1.4211e-14, 9.7700e-15,\n",
      "         1.2434e-14, 1.4211e-14, 1.5987e-14, 1.6875e-14, 5.3291e-15, 2.1316e-14,\n",
      "         1.5987e-14, 1.4211e-14, 1.2434e-14, 1.0658e-14, 1.5987e-14, 1.4211e-14,\n",
      "         2.1316e-14, 2.1316e-14, 2.1316e-14, 1.4211e-14, 1.4211e-14, 8.8818e-15,\n",
      "         2.1316e-14, 2.1316e-14, 1.1102e-16, 2.2204e-16, 4.4409e-16, 1.3323e-15,\n",
      "         2.2204e-16, 1.1102e-16, 8.8818e-16, 1.1102e-16, 1.3323e-15, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 1.1102e-16, 2.2204e-16, 1.7764e-15, 1.3323e-15,\n",
      "         1.3323e-15, 8.8818e-16, 8.8818e-16, 2.2204e-16, 1.7764e-15, 5.5511e-17,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 5.5511e-17, 1.7764e-15, 1.1102e-16,\n",
      "         5.5511e-17, 5.5511e-17, 1.1102e-15, 8.8818e-16, 8.3267e-17, 8.8818e-16,\n",
      "         1.1102e-16, 8.8818e-16, 1.1102e-16, 8.8818e-16, 1.3323e-15, 4.4409e-16,\n",
      "         5.5511e-17, 1.1102e-16, 2.2204e-16, 1.1102e-16, 5.5511e-17, 4.4409e-16,\n",
      "         5.5511e-17, 8.8818e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16, 5.5511e-17,\n",
      "         1.2768e-15, 1.3323e-15, 1.1102e-16, 8.8818e-16, 8.8818e-16, 2.2204e-16,\n",
      "         6.6613e-16, 8.8818e-16, 5.5511e-17, 3.3307e-16, 1.1102e-16, 1.1102e-16,\n",
      "         8.8818e-16, 3.5527e-15, 1.3323e-15, 1.3323e-15, 4.4409e-16, 3.5527e-15,\n",
      "         7.1054e-15, 4.4409e-16, 4.4409e-16, 4.4409e-16, 7.1054e-15, 3.5527e-15,\n",
      "         2.6645e-15, 5.3291e-15, 5.3291e-15, 2.2204e-16, 4.4409e-16, 4.4409e-16,\n",
      "         2.2204e-16, 7.1054e-15, 1.7764e-15, 2.6645e-15, 7.1054e-15, 7.1054e-15,\n",
      "         8.8818e-16, 4.4409e-16, 3.5527e-15, 8.8818e-16, 5.3291e-15, 1.1102e-16,\n",
      "         5.3291e-15, 3.1086e-15, 2.9976e-15, 3.5527e-15, 2.6645e-15, 1.7764e-15,\n",
      "         4.4409e-15, 3.5527e-15, 4.4409e-16, 7.1054e-15, 2.2204e-16, 2.6645e-15,\n",
      "         3.9968e-15, 3.5527e-15, 3.5527e-15, 8.8818e-16, 4.4409e-16, 3.5527e-15,\n",
      "         5.3291e-15, 8.8818e-16, 6.6613e-16, 4.4409e-16, 3.1086e-15, 2.6645e-15,\n",
      "         1.7764e-15, 8.8818e-16, 1.7764e-15, 1.3323e-15, 1.7764e-15, 3.5527e-15,\n",
      "         3.5527e-15, 5.3291e-15, 3.3307e-16, 1.3323e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #45-layer3.1.relu; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.1.bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.1.relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 11, 12, 14, 15, 16, 20, 21, 22, 24, 25,\n",
      "        26, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 48, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 63])\n",
      "\t\t EXEC SPLIT: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #45-layer3.1.relu; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.1.bn1 C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.1.relu C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  72,  73,  74,  75,  76,  77,  81,  83,  86,\n",
      "         87,  88,  90,  93,  95,  96,  97,  98,  99, 101, 102, 103, 105, 107,\n",
      "        108, 109, 110, 111, 114, 115, 116, 117, 118, 119, 124, 125])\n",
      "\t\t EXEC SPLIT: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t EXEC SPLIT: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #45-layer3.1.relu; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.1.bn1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.1.relu C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([131, 142, 143, 144, 145, 154, 158, 159, 161, 163, 165, 166, 180, 181])\n",
      "\t\t EXEC SPLIT: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t EXEC SPLIT: #44-layer3.1.bn1; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #45-layer3.1.relu; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.1.bn1 C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.1.relu C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([198, 203, 206, 213, 223, 224, 228, 229, 233, 234, 244, 253])\n",
      "\t\t EXEC SPLIT: #46-layer3.1.conv2; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer3.1.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer3.1.conv2:\n",
      "Max diff:\n",
      "tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[3.2526e-19, 0.0000e+00, 8.6736e-19, 6.9389e-18, 3.4694e-18, 3.4694e-18,\n",
      "         1.7347e-18, 1.7347e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18, 3.4694e-18,\n",
      "         1.3878e-17, 0.0000e+00, 4.3368e-19, 1.7347e-18, 1.3878e-17, 3.4694e-18,\n",
      "         6.9389e-18, 3.4694e-18, 4.3368e-19, 1.7347e-18, 3.4694e-18, 1.7347e-18,\n",
      "         6.9389e-18, 6.9389e-18, 1.7347e-18, 3.4694e-18, 8.6736e-19, 3.4694e-18,\n",
      "         1.7347e-18, 3.4694e-18, 4.3368e-19, 1.7347e-18, 3.4694e-18, 6.9389e-18,\n",
      "         3.4694e-18, 8.6736e-19, 1.7347e-18, 3.4694e-18, 1.7347e-18, 1.7347e-18,\n",
      "         1.7347e-18, 3.4694e-18, 3.4694e-18, 0.0000e+00, 3.4694e-18, 3.4694e-18,\n",
      "         1.7347e-18, 4.3368e-19, 8.6736e-19, 6.9389e-18, 1.7347e-18, 3.4694e-18,\n",
      "         3.4694e-18, 6.9389e-18, 3.4694e-18, 0.0000e+00, 3.4694e-18, 3.4694e-18,\n",
      "         3.4694e-18, 3.4694e-18, 1.7347e-18, 1.7347e-18, 5.3291e-15, 7.1054e-15,\n",
      "         6.2172e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15,\n",
      "         7.9936e-15, 1.0658e-14, 5.3291e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15,\n",
      "         7.1054e-15, 5.7732e-15, 5.3291e-15, 5.3291e-15, 7.1054e-15, 5.3291e-15,\n",
      "         7.1054e-15, 4.4409e-15, 5.3291e-15, 8.8818e-15, 1.0658e-14, 7.1054e-15,\n",
      "         6.2172e-15, 7.1054e-15, 7.1054e-15, 6.2172e-15, 9.5479e-15, 4.4409e-15,\n",
      "         6.2172e-15, 5.3291e-15, 7.5495e-15, 7.1054e-15, 4.8850e-15, 5.3291e-15,\n",
      "         5.3291e-15, 5.3291e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15, 7.9936e-15,\n",
      "         6.2172e-15, 4.4409e-15, 8.8818e-15, 7.9936e-15, 5.3291e-15, 5.3291e-15,\n",
      "         3.9968e-15, 8.8818e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15, 6.2172e-15,\n",
      "         5.3291e-15, 6.2172e-15, 4.4409e-15, 7.1054e-15, 7.1054e-15, 4.8850e-15,\n",
      "         6.2172e-15, 7.1054e-15, 4.4409e-16, 2.2595e-16, 6.6613e-16, 4.1633e-17,\n",
      "         2.4980e-16, 1.1102e-16, 1.3878e-16, 2.2204e-16, 4.1633e-17, 1.1102e-16,\n",
      "         1.3878e-16, 2.7756e-17, 4.1633e-17, 4.4409e-16, 4.1633e-17, 8.3267e-17,\n",
      "         1.6653e-16, 4.4409e-16, 3.3307e-16, 5.5511e-16, 5.5511e-17, 3.8858e-16,\n",
      "         2.2204e-16, 3.3307e-16, 1.9429e-16, 6.6613e-16, 6.9389e-17, 5.5511e-17,\n",
      "         3.3307e-16, 2.7756e-17, 3.3307e-16, 2.0817e-17, 2.7756e-16, 1.1102e-16,\n",
      "         3.3307e-16, 4.4409e-16, 4.4409e-16, 2.7756e-17, 4.4409e-16, 1.6653e-16,\n",
      "         1.1102e-16, 9.7145e-17, 2.2204e-16, 4.4409e-16, 2.2204e-16, 1.1102e-16,\n",
      "         3.3307e-16, 2.7756e-17, 4.4409e-16, 1.1102e-16, 3.3307e-16, 2.7756e-17,\n",
      "         1.9429e-16, 6.9389e-17, 1.3878e-17, 4.4409e-16, 4.4409e-16, 2.2204e-16,\n",
      "         4.1633e-17, 3.3307e-16, 1.1102e-16, 5.5511e-16, 6.9389e-17, 3.3307e-16,\n",
      "         1.1102e-16, 1.1102e-15, 4.4409e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16,\n",
      "         8.8818e-16, 6.6613e-16, 6.6613e-16, 9.9920e-16, 8.8818e-16, 7.7716e-16,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 6.6613e-16, 1.1102e-16, 7.7716e-16,\n",
      "         6.6613e-16, 5.5511e-16, 6.6613e-16, 8.8818e-16, 1.6653e-16, 9.9920e-16,\n",
      "         4.4409e-16, 8.8818e-16, 8.8818e-16, 6.3838e-16, 1.1102e-15, 1.3323e-15,\n",
      "         4.9960e-16, 8.8818e-16, 6.6613e-16, 4.7184e-16, 4.4409e-16, 6.6613e-16,\n",
      "         4.4409e-16, 1.2768e-15, 8.8818e-16, 8.8818e-16, 8.8818e-16, 6.6613e-16,\n",
      "         8.8818e-16, 1.1102e-16, 8.8818e-16, 8.8818e-16, 9.9920e-16, 7.7716e-16,\n",
      "         8.8818e-16, 5.5511e-16, 3.8858e-16, 6.6613e-16, 8.8818e-16, 7.7716e-16,\n",
      "         8.8818e-16, 5.5511e-16, 5.5511e-16, 6.6613e-16, 1.6653e-16, 6.9389e-17,\n",
      "         8.8818e-16, 2.4980e-16, 6.6613e-16, 1.1102e-15]], dtype=torch.float64)\n",
      "tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
      "         60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "         88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
      "        158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
      "         60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "         88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
      "        158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 252)\n",
      "passing Cout = tensor([ 1, 13, 45, 57])  (len = 4)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t EXEC SPLIT: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #48-layer3.1.add; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.1.bn2 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #49-layer3.1.relu_1; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.1.add C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #50-layer4.0.conv1; Shape=[1, 256, 8, 8]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "\t\tChecking output from layer3.1.relu_1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 16, 17, 18, 19,\n",
      "        20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38,\n",
      "        39, 40, 41, 42, 43, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
      "        60, 61, 62])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #50-layer4.0.conv1; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t EXEC SPLIT: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_out=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #48-layer3.1.add; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.1.bn2 C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #49-layer3.1.relu_1; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.1.add C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #50-layer4.0.conv1; Shape=[1, 256, 8, 8]; C_in=[ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]\n",
      "\t\tChecking output from layer3.1.relu_1 C_in [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([ 64,  65,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
      "         94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 125,\n",
      "        126, 127])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #50-layer4.0.conv1; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t EXEC SPLIT: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #48-layer3.1.add; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.1.bn2 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #49-layer3.1.relu_1; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.1.add C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #50-layer4.0.conv1; Shape=[1, 256, 8, 8]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "\t\tChecking output from layer3.1.relu_1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([130, 132, 134, 135, 141, 143, 144, 145, 146, 147, 149, 152, 153, 156,\n",
      "        158, 160, 163, 164, 166, 171, 177, 180, 183, 184, 185, 187, 189, 191])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #50-layer4.0.conv1; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t EXEC SPLIT: #47-layer3.1.bn2; Shape=[1, 256, 8, 8]; C_out=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #48-layer3.1.add; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.1.bn2 C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #49-layer3.1.relu_1; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.1.add C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #50-layer4.0.conv1; Shape=[1, 256, 8, 8]; C_in=[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]\n",
      "\t\tChecking output from layer3.1.relu_1 C_in [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209,\n",
      "        210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 227, 229, 230, 231, 233, 234, 236, 237, 238, 239, 240, 244, 245,\n",
      "        246, 248, 252, 253, 254])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #50-layer4.0.conv1; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer4.0.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer4.0.conv1:\n",
      "Max diff:\n",
      "tensor([1.7764e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.7756e-17, 0.0000e+00, 0.0000e+00, 2.7756e-17, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 1.7347e-18, 3.4694e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 5.5511e-17, 0.0000e+00, 1.3878e-17, 0.0000e+00,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7756e-17, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 2.7756e-17, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 2.7756e-17, 0.0000e+00, 5.5511e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 1.3878e-17, 1.3878e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 0.0000e+00, 0.0000e+00, 2.7756e-17, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.4211e-14, 1.4211e-14, 1.4211e-14, 7.1054e-15,\n",
      "         1.4211e-14, 7.1054e-15, 1.4211e-14, 8.8818e-15, 1.3323e-14, 7.1054e-15,\n",
      "         8.8818e-15, 8.8818e-15, 7.1054e-15, 1.4211e-14, 7.9936e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.0658e-14, 8.8818e-15, 9.7700e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.7764e-14, 1.0658e-14, 8.8818e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15,\n",
      "         1.0658e-14, 1.0658e-14, 9.7700e-15, 7.1054e-15, 1.0658e-14, 1.4211e-14,\n",
      "         1.4211e-14, 1.2434e-14, 1.0658e-14, 7.1054e-15, 6.6613e-15, 7.1054e-15,\n",
      "         1.4211e-14, 7.1054e-15, 1.4211e-14, 1.4211e-14, 7.1054e-15, 1.0658e-14,\n",
      "         7.1054e-15, 1.0658e-14, 8.8818e-15, 1.4211e-14, 1.0658e-14, 1.0658e-14,\n",
      "         1.0658e-14, 7.5495e-15, 7.9936e-15, 1.0658e-14, 1.5987e-14, 5.3291e-15,\n",
      "         1.0658e-14, 1.0658e-14, 1.0658e-14, 8.8818e-15, 1.0658e-14, 1.5987e-14,\n",
      "         7.5495e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15, 8.8818e-15, 7.1054e-15,\n",
      "         7.9936e-15, 7.9936e-15, 1.0658e-14, 7.1054e-15, 1.0658e-14, 8.8818e-15,\n",
      "         7.1054e-15, 3.5527e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 1.0658e-14,\n",
      "         8.8818e-15, 6.2172e-15, 8.8818e-15, 1.4211e-14, 8.8818e-15, 1.0658e-14,\n",
      "         1.4211e-14, 7.1054e-15, 8.8818e-15, 6.2172e-15, 5.7732e-15, 1.4211e-14,\n",
      "         5.3291e-15, 1.2434e-14, 7.1054e-15, 6.2172e-15, 1.5987e-14, 7.1054e-15,\n",
      "         7.9936e-15, 7.1054e-15, 7.5495e-15, 7.1054e-15, 7.1054e-15, 8.8818e-15,\n",
      "         1.0214e-14, 1.3323e-14, 1.0658e-14, 7.1054e-15, 1.0658e-14, 7.1054e-15,\n",
      "         7.1054e-15, 1.0658e-14, 1.0658e-14, 7.1054e-15, 7.1054e-15, 1.0658e-14,\n",
      "         5.3291e-15, 8.8818e-15, 7.9936e-15, 5.3291e-15, 7.1054e-15, 8.8818e-15,\n",
      "         7.1054e-15, 1.4211e-14, 1.5987e-14, 8.8818e-15, 1.1102e-16, 2.2204e-16,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 5.5511e-17, 1.1102e-16, 1.7764e-15,\n",
      "         4.4409e-16, 8.8818e-16, 3.3307e-16, 8.8818e-16, 1.3323e-15, 4.4409e-16,\n",
      "         2.2204e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 1.1102e-16,\n",
      "         8.8818e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16,\n",
      "         6.6613e-16, 8.8818e-16, 4.4409e-16, 9.4369e-16, 2.2204e-16, 4.4409e-16,\n",
      "         6.6613e-16, 2.2204e-16, 6.6613e-16, 4.4409e-16, 8.8818e-16, 5.5511e-16,\n",
      "         8.8818e-16, 2.2204e-16, 5.5511e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16,\n",
      "         8.8818e-16, 1.1102e-16, 4.4409e-16, 8.8818e-16, 1.1102e-16, 8.8818e-16,\n",
      "         4.9960e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16, 1.3323e-15, 6.6613e-16,\n",
      "         2.2204e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16,\n",
      "         5.5511e-17, 4.4409e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         2.2204e-16, 8.8818e-16, 4.4409e-16, 1.3323e-15, 8.8818e-16, 1.7764e-15,\n",
      "         5.5511e-17, 5.5511e-17, 4.4409e-16, 8.8818e-16, 2.2204e-16, 2.2204e-16,\n",
      "         8.8818e-16, 1.1102e-16, 5.5511e-17, 2.2204e-16, 8.8818e-16, 1.1102e-16,\n",
      "         6.6613e-16, 6.6613e-16, 2.2204e-16, 4.4409e-16, 2.2204e-16, 8.8818e-16,\n",
      "         2.2204e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16, 5.5511e-16, 1.1102e-16,\n",
      "         8.8818e-16, 3.8858e-16, 1.7764e-15, 4.4409e-16, 8.8818e-16, 2.2204e-16,\n",
      "         1.7764e-15, 1.1102e-16, 6.6613e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 1.7764e-15, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16,\n",
      "         4.4409e-16, 2.2204e-16, 4.4409e-16, 2.2204e-16, 6.6613e-16, 4.4409e-16,\n",
      "         1.7764e-15, 7.1054e-15, 2.2204e-16, 1.7764e-15, 1.7764e-15, 2.6645e-15,\n",
      "         1.3323e-15, 3.5527e-15, 1.7764e-15, 4.4409e-16, 2.4425e-15, 5.3291e-15,\n",
      "         3.5527e-15, 7.1054e-15, 2.6645e-15, 3.1086e-15, 2.6645e-15, 2.2204e-15,\n",
      "         2.6645e-15, 8.8818e-16, 2.6645e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15,\n",
      "         2.6645e-15, 2.2204e-15, 2.6645e-15, 2.6645e-15, 3.5527e-15, 2.6645e-15,\n",
      "         3.5527e-15, 1.7764e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15,\n",
      "         3.5527e-15, 1.7764e-15, 8.8818e-16, 4.4409e-16, 2.6645e-15, 5.3291e-15,\n",
      "         1.7764e-15, 2.6645e-15, 3.5527e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15,\n",
      "         3.5527e-15, 4.4409e-16, 1.7764e-15, 8.8818e-16, 3.5527e-15, 2.6645e-15,\n",
      "         3.1086e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15, 2.2204e-15,\n",
      "         1.7764e-15, 1.7764e-15, 8.8818e-16, 2.6645e-15, 3.5527e-15, 1.7764e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.7764e-15, 3.5527e-15, 8.8818e-16, 3.5527e-15,\n",
      "         2.6645e-15, 3.5527e-15, 1.7764e-15, 1.7764e-15, 3.3307e-15, 3.5527e-15,\n",
      "         1.7764e-15, 1.7764e-15, 2.6645e-15, 1.3323e-15, 7.1054e-15, 3.5527e-15,\n",
      "         2.6645e-15, 2.6645e-15, 4.4409e-16, 3.5527e-15, 1.7764e-15, 8.8818e-16,\n",
      "         3.5527e-15, 5.3291e-15, 4.4409e-16, 1.7764e-15, 1.7764e-15, 7.1054e-15,\n",
      "         4.4409e-16, 5.3291e-15, 1.7764e-15, 6.6613e-16, 3.5527e-15, 2.4425e-15,\n",
      "         3.1086e-15, 2.6645e-15, 2.6645e-15, 3.5527e-15, 2.2204e-16, 3.5527e-15,\n",
      "         1.7764e-15, 2.6645e-15, 3.5527e-15, 2.6645e-15, 3.7748e-15, 1.7764e-15,\n",
      "         3.5527e-15, 5.3291e-15, 3.1086e-15, 8.8818e-16, 3.5527e-15, 2.6645e-15,\n",
      "         3.5527e-15, 8.8818e-16, 3.5527e-15, 2.2204e-15, 3.5527e-15, 2.6645e-15,\n",
      "         3.5527e-15, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  0,   3,   4,   7,   8,  22,  25,  28,  31,  32,  34,  36,  44,  45,\n",
      "         49,  51,  53,  60,  62,  64,  78,  82,  85,  87,  88,  94,  95, 109,\n",
      "        112, 113, 120, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
      "        153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "        181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
      "        265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
      "        279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292,\n",
      "        293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
      "        307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
      "        321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334,\n",
      "        335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
      "        349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
      "        363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
      "        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
      "        405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
      "        419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "        433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
      "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460,\n",
      "        461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
      "        475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488,\n",
      "        489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
      "        503, 504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   3,   4,   7,   8,  22,  25,  28,  31,  32,  34,  36,  44,  45,\n",
      "         49,  51,  53,  60,  62,  64,  78,  82,  85,  87,  88,  94,  95, 109,\n",
      "        112, 113, 120, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
      "        153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "        181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
      "        265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
      "        279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292,\n",
      "        293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
      "        307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
      "        321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334,\n",
      "        335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
      "        349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
      "        363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
      "        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
      "        405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
      "        419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "        433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
      "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460,\n",
      "        461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
      "        475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488,\n",
      "        489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
      "        503, 504, 505, 506, 507, 508, 509, 510, 511])  (len = 415)\n",
      "passing Cout = tensor([  1,   2,   5,   6,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,\n",
      "         19,  20,  21,  23,  24,  26,  27,  29,  30,  33,  35,  37,  38,  39,\n",
      "         40,  41,  42,  43,  46,  47,  48,  50,  52,  54,  55,  56,  57,  58,\n",
      "         59,  61,  63,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
      "         76,  77,  79,  80,  81,  83,  84,  86,  89,  90,  91,  92,  93,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111,\n",
      "        114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127])  (len = 97)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t EXEC SPLIT: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #52-layer4.0.relu; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.0.bn1 C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.0.relu C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  23,  25,  28,  29,  31,  33,  34,  37,\n",
      "         38,  39,  41,  43,  44,  47,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  68,  69,  70,  72,  73,\n",
      "         77,  78,  79,  80,  81,  82,  83,  87,  88,  90,  91,  92,  99, 100,\n",
      "        101, 102, 103, 104, 105, 107, 108, 111, 112, 113, 115, 116, 117, 119,\n",
      "        120, 121, 124, 125, 126])\n",
      "\t\t EXEC SPLIT: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t EXEC SPLIT: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #52-layer4.0.relu; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.0.bn1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.0.relu C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 131, 132, 134, 135, 136, 137, 138, 142, 145, 146, 147, 152, 153,\n",
      "        157, 158, 162, 163, 165, 166, 167, 168, 169, 171, 172, 174, 175, 177,\n",
      "        178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 191, 192, 194, 195,\n",
      "        196, 197, 198, 199, 200, 203, 204, 206, 209, 210, 211, 212, 214, 218,\n",
      "        219, 220, 222, 223, 224, 225, 226, 227, 228, 230, 232, 233, 234, 235,\n",
      "        236, 242, 247, 248, 250, 251, 252, 254, 255])\n",
      "\t\t EXEC SPLIT: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t EXEC SPLIT: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #52-layer4.0.relu; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.0.bn1 C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.0.relu C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([260, 263, 264, 265, 266, 268, 271, 272, 273, 276, 277, 280, 287, 290,\n",
      "        292, 293, 294, 296, 297, 299, 300, 305, 306, 307, 308, 311, 313, 316,\n",
      "        320, 322, 323, 327, 333, 336, 342, 343, 345, 351, 352, 354, 355, 356,\n",
      "        358, 362, 364, 365, 367, 369, 370, 374, 382, 383])\n",
      "\t\t EXEC SPLIT: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t EXEC SPLIT: #51-layer4.0.bn1; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #52-layer4.0.relu; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.0.bn1 C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.0.relu C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([388, 394, 396, 398, 400, 401, 402, 410, 424, 426, 427, 430, 431, 432,\n",
      "        436, 438, 447, 448, 449, 450, 451, 453, 458, 465, 472, 477, 482, 486,\n",
      "        488, 495, 496, 497, 499, 500, 502, 503, 507, 508])\n",
      "\t\t EXEC SPLIT: #53-layer4.0.conv2; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer4.0.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer4.0.conv2:\n",
      "Max diff:\n",
      "tensor([2.1316e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00, 1.3878e-17, 0.0000e+00,\n",
      "         5.4210e-20, 0.0000e+00, 2.1684e-19, 1.7347e-18, 8.6736e-19, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 2.1684e-19, 6.9389e-18, 6.9389e-18, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 1.7347e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 6.9389e-18, 1.7347e-18, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 2.1684e-19, 8.6736e-19, 0.0000e+00, 8.6736e-19, 3.4694e-18,\n",
      "         0.0000e+00, 4.3368e-19, 3.4694e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18,\n",
      "         3.4694e-18, 1.3878e-17, 0.0000e+00, 1.7347e-18, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00,\n",
      "         3.4694e-18, 2.1684e-19, 6.9389e-18, 4.3368e-19, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 0.0000e+00, 6.9389e-18, 0.0000e+00, 6.9389e-18,\n",
      "         3.4694e-18, 0.0000e+00, 3.4694e-18, 8.6736e-19, 4.3368e-19, 3.4694e-18,\n",
      "         1.7347e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18, 8.6736e-19, 6.9389e-18,\n",
      "         8.6736e-19, 0.0000e+00, 0.0000e+00, 4.3368e-19, 3.4694e-18, 4.3368e-19,\n",
      "         6.9389e-18, 1.7347e-18, 8.6736e-19, 0.0000e+00, 6.9389e-18, 0.0000e+00,\n",
      "         8.6736e-19, 0.0000e+00, 1.7347e-18, 0.0000e+00, 8.6736e-19, 2.7756e-17,\n",
      "         0.0000e+00, 6.9389e-18, 8.6736e-19, 0.0000e+00, 0.0000e+00, 4.3368e-19,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         6.9389e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00,\n",
      "         0.0000e+00, 3.4694e-18, 0.0000e+00, 6.9389e-18, 8.6736e-19, 6.9389e-18,\n",
      "         1.3878e-17, 2.1684e-19, 1.4211e-14, 6.2172e-15, 1.0658e-14, 1.4211e-14,\n",
      "         7.1054e-15, 7.5495e-15, 1.0658e-14, 7.1054e-15, 6.6613e-15, 8.8818e-15,\n",
      "         1.4211e-14, 1.0658e-14, 8.8818e-15, 8.8818e-15, 7.1054e-15, 1.0658e-14,\n",
      "         7.1054e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.7764e-14, 8.8818e-15, 8.8818e-15, 1.4211e-14, 7.1054e-15,\n",
      "         1.0658e-14, 1.7764e-14, 1.0658e-14, 8.8818e-15, 1.4211e-14, 1.6875e-14,\n",
      "         1.5987e-14, 1.0658e-14, 8.8818e-15, 1.4211e-14, 1.0658e-14, 7.5495e-15,\n",
      "         1.0658e-14, 8.8818e-15, 8.8818e-15, 1.0658e-14, 1.5099e-14, 8.8818e-15,\n",
      "         7.1054e-15, 6.2172e-15, 1.0658e-14, 6.2172e-15, 5.3291e-15, 1.4211e-14,\n",
      "         8.8818e-15, 7.1054e-15, 2.1316e-14, 7.1054e-15, 1.4211e-14, 1.0658e-14,\n",
      "         7.1054e-15, 1.4211e-14, 7.1054e-15, 9.7700e-15, 1.0658e-14, 1.4211e-14,\n",
      "         7.1054e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.0658e-14, 7.1054e-15, 7.1054e-15, 1.0658e-14, 1.2434e-14, 1.0658e-14,\n",
      "         1.4211e-14, 7.1054e-15, 1.4211e-14, 1.4211e-14, 1.0658e-14, 1.5099e-14,\n",
      "         2.1316e-14, 7.9936e-15, 7.1054e-15, 1.4211e-14, 5.3291e-15, 7.1054e-15,\n",
      "         3.5527e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15, 8.8818e-15, 1.4211e-14,\n",
      "         1.4211e-14, 8.4377e-15, 7.1054e-15, 1.0658e-14, 9.3259e-15, 1.0658e-14,\n",
      "         1.0658e-14, 1.4211e-14, 1.4211e-14, 7.1054e-15, 7.1054e-15, 1.0658e-14,\n",
      "         1.0658e-14, 7.1054e-15, 8.8818e-15, 1.4211e-14, 1.0658e-14, 1.0658e-14,\n",
      "         1.4211e-14, 3.5527e-15, 8.8818e-15, 1.4211e-14, 1.0658e-14, 7.1054e-15,\n",
      "         1.2434e-14, 8.8818e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 1.2434e-14,\n",
      "         1.4211e-14, 5.3291e-15, 1.0658e-14, 7.5495e-15, 5.5511e-17, 1.7764e-15,\n",
      "         4.4409e-16, 2.7756e-17, 5.5511e-17, 4.4409e-16, 4.4409e-16, 3.3307e-16,\n",
      "         1.1102e-16, 6.6613e-16, 4.4409e-16, 5.5511e-17, 2.2204e-16, 4.4409e-16,\n",
      "         6.6613e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 1.7764e-15, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 8.8818e-16, 3.6082e-16,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 1.7764e-15, 4.4409e-16, 5.5511e-17,\n",
      "         5.5511e-17, 4.1633e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16,\n",
      "         6.6613e-16, 4.4409e-16, 2.2204e-16, 8.8818e-16, 2.2204e-16, 8.8818e-16,\n",
      "         3.3307e-16, 1.1102e-16, 1.7764e-15, 4.4409e-16, 8.8818e-16, 2.7756e-17,\n",
      "         4.4409e-16, 1.1102e-16, 2.2204e-16, 1.1102e-16, 8.8818e-16, 8.8818e-16,\n",
      "         8.8818e-16, 4.4409e-16, 5.5511e-17, 4.4409e-16, 4.4409e-16, 1.1102e-16,\n",
      "         6.6613e-16, 5.5511e-17, 4.4409e-16, 4.4409e-16, 8.8818e-16, 3.3307e-16,\n",
      "         4.4409e-16, 1.1102e-16, 2.7756e-17, 1.3323e-15, 4.4409e-16, 3.3307e-16,\n",
      "         5.5511e-17, 4.4409e-16, 8.8818e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         2.2204e-16, 4.4409e-16, 7.7716e-16, 6.6613e-16, 4.4409e-16, 8.8818e-16,\n",
      "         8.8818e-16, 8.8818e-16, 5.5511e-17, 4.4409e-16, 1.3878e-17, 1.1102e-16,\n",
      "         1.1102e-16, 8.8818e-16, 1.3323e-15, 2.2204e-16, 8.3267e-17, 8.8818e-16,\n",
      "         4.4409e-16, 1.1102e-16, 8.8818e-16, 4.4409e-16, 5.5511e-17, 8.8818e-16,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 5.5511e-16, 5.5511e-17, 5.5511e-17,\n",
      "         8.8818e-16, 1.1102e-16, 4.4409e-16, 2.2204e-16, 8.8818e-16, 2.7756e-17,\n",
      "         8.8818e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 5.5511e-17, 1.1102e-16,\n",
      "         8.8818e-16, 8.8818e-16, 5.5511e-17, 4.4409e-16, 6.6613e-16, 1.1102e-16,\n",
      "         8.8818e-16, 9.9920e-16, 8.8818e-16, 6.6613e-16, 1.1102e-15, 1.7764e-15,\n",
      "         2.6645e-15, 1.3323e-15, 2.2204e-16, 1.7764e-15, 1.7764e-15, 8.8818e-16,\n",
      "         1.7764e-15, 8.8818e-16, 8.8818e-16, 8.8818e-16, 8.8818e-16, 1.3323e-15,\n",
      "         8.8818e-16, 1.3323e-15, 2.6645e-15, 1.3323e-15, 1.7764e-15, 1.7764e-15,\n",
      "         1.7764e-15, 8.8818e-16, 1.3323e-15, 1.7764e-15, 1.1102e-15, 8.8818e-16,\n",
      "         8.8818e-16, 1.3323e-15, 8.8818e-16, 8.8818e-16, 1.3323e-15, 8.8818e-16,\n",
      "         8.8818e-16, 1.7764e-15, 8.8818e-16, 1.7764e-15, 8.8818e-16, 1.4433e-15,\n",
      "         8.8818e-16, 1.3323e-15, 1.7764e-15, 1.3323e-15, 6.6613e-16, 7.7716e-16,\n",
      "         8.8818e-16, 9.4369e-16, 8.8818e-16, 1.4433e-15, 4.9960e-16, 8.8818e-16,\n",
      "         1.7764e-15, 1.5543e-15, 8.8818e-16, 1.7764e-15, 3.5527e-15, 8.8818e-16,\n",
      "         8.8818e-16, 3.5527e-15, 1.1102e-15, 1.7764e-15, 6.6613e-16, 6.9389e-16,\n",
      "         1.1102e-15, 8.8818e-16, 1.1102e-15, 8.8818e-16, 1.3323e-15, 1.3323e-15,\n",
      "         7.7716e-16, 8.8818e-16, 1.3323e-15, 1.7764e-15, 1.7764e-15, 1.1102e-15,\n",
      "         9.4369e-16, 1.3323e-15, 8.8818e-16, 1.3323e-15, 1.7764e-15, 8.8818e-16,\n",
      "         8.8818e-16, 1.1102e-15, 1.1102e-15, 9.4369e-16, 1.3323e-15, 8.8818e-16,\n",
      "         1.3323e-15, 8.8818e-16, 8.8818e-16, 5.5511e-17, 8.8818e-16, 1.7764e-15,\n",
      "         8.8818e-16, 1.3323e-15, 8.8818e-16, 1.1102e-15, 1.7764e-15, 7.7716e-16,\n",
      "         1.3323e-15, 8.8818e-16, 1.7764e-15, 8.8818e-16, 1.2212e-15, 1.2212e-15,\n",
      "         1.3323e-15, 1.3323e-15, 8.8818e-16, 8.8818e-16, 1.7764e-15, 6.6613e-16,\n",
      "         1.7764e-15, 8.8818e-16, 5.5511e-16, 2.6645e-15, 1.1102e-15, 1.1102e-15,\n",
      "         8.8818e-16, 1.7764e-15, 8.8818e-16, 1.7764e-15, 1.3323e-15, 6.6613e-16,\n",
      "         1.7764e-15, 1.7764e-15]], dtype=torch.float64)\n",
      "tensor([  2,   4,   6,   8,   9,  10,  11,  14,  15,  16,  18,  20,  23,  25,\n",
      "         26,  30,  31,  32,  33,  36,  37,  38,  40,  41,  43,  44,  47,  48,\n",
      "         49,  51,  53,  55,  58,  60,  61,  62,  63,  64,  67,  69,  71,  72,\n",
      "         74,  75,  76,  77,  78,  81,  82,  83,  84,  87,  88,  89,  90,  91,\n",
      "         92,  94,  96,  98, 100, 101, 103, 104, 107, 112, 114, 118, 121, 123,\n",
      "        124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "        138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "        152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
      "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
      "        264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
      "        278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "        292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "        306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319,\n",
      "        320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "        334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347,\n",
      "        348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
      "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
      "        376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
      "        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
      "        418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
      "        432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "        446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
      "        460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "        474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487,\n",
      "        488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
      "        502, 503, 504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  2,   4,   6,   8,   9,  10,  11,  14,  15,  16,  18,  20,  23,  25,\n",
      "         26,  30,  31,  32,  33,  36,  37,  38,  40,  41,  43,  44,  47,  48,\n",
      "         49,  51,  53,  55,  58,  60,  61,  62,  63,  64,  67,  69,  71,  72,\n",
      "         74,  75,  76,  77,  78,  81,  82,  83,  84,  87,  88,  89,  90,  91,\n",
      "         92,  94,  96,  98, 100, 101, 103, 104, 107, 112, 114, 118, 121, 123,\n",
      "        124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "        138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "        152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
      "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
      "        264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
      "        278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "        292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "        306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319,\n",
      "        320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "        334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347,\n",
      "        348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
      "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
      "        376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
      "        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
      "        418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
      "        432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "        446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
      "        460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "        474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487,\n",
      "        488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
      "        502, 503, 504, 505, 506, 507, 508, 509, 510, 511])  (len = 458)\n",
      "passing Cout = tensor([  0,   1,   3,   5,   7,  12,  13,  17,  19,  21,  22,  24,  27,  28,\n",
      "         29,  34,  35,  39,  42,  45,  46,  50,  52,  54,  56,  57,  59,  65,\n",
      "         66,  68,  70,  73,  79,  80,  85,  86,  93,  95,  97,  99, 102, 105,\n",
      "        106, 108, 109, 110, 111, 113, 115, 116, 117, 119, 120, 122])  (len = 54)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t EXEC SPLIT: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.0.bn2 C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 344 355]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t Prepping to send C_out tensor([344, 355]) to machine 2\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t EXEC SPLIT: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.0.bn2 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_out=[ 60  61  76  89  96 117 125 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173\n",
      " 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191\n",
      " 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255 262 300 313 342 353 369 399 403\n",
      " 417 419 450 459 484 510]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t Prepping to send C_out tensor([ 60,  61,  76,  89,  96, 117, 125, 127]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([262, 300, 313, 342, 353, 369]) to machine 2\n",
      "\t\t Prepping to send C_out tensor([399, 403, 417, 419, 450, 459, 484, 510]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t EXEC SPLIT: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.0.bn2 C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_out=[ 58  67  87 100 127 141 149 150 152 165 238 239 240 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278\n",
      " 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296\n",
      " 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314\n",
      " 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332\n",
      " 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350\n",
      " 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368\n",
      " 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t Prepping to send C_out tensor([ 58,  67,  87, 100, 127]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([141, 149, 150, 152, 165, 238, 239, 240]) to machine 1\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t EXEC SPLIT: #54-layer4.0.bn2; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.0.bn2 C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t EXEC SPLIT: #55-layer4.0.shortcut.0; Shape=[1, 512, 4, 4]; C_out=[  4  39  53  61  70  81  86  96 118 123 124 129 130 134 137 138 140 141\n",
      " 147 153 154 160 171 174 177 178 181 188 189 204 206 207 211 212 213 214\n",
      " 215 216 221 224 229 232 236 240 244 246 251 252 254 255 262 269 275 280\n",
      " 310 313 314 322 354 369 378 384 385 386 387 388 389 390 391 392 393 394\n",
      " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
      " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
      " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
      " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
      " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
      " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
      " 503 504 505 506 507 508 509 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t Prepping to send C_out tensor([  4,  39,  53,  61,  70,  81,  86,  96, 118, 123, 124]) to machine 0\n",
      "\t\t Prepping to send C_out tensor([129, 130, 134, 137, 138, 140, 141, 147, 153, 154, 160, 171, 174, 177,\n",
      "        178, 181, 188, 189, 204, 206, 207, 211, 212, 213, 214, 215, 216, 221,\n",
      "        224, 229, 232, 236, 240, 244, 246, 251, 252, 254, 255]) to machine 1\n",
      "\t\t Prepping to send C_out tensor([262, 269, 275, 280, 310, 313, 314, 322, 354, 369, 378]) to machine 2\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer4.0.shortcut.0-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer4.0.shortcut.0:\n",
      "Max diff:\n",
      "tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 1.7347e-18, 1.7347e-18, 6.9389e-18, 6.9389e-18, 0.0000e+00,\n",
      "         8.6736e-19, 0.0000e+00, 0.0000e+00, 3.4694e-18, 4.3368e-19, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 8.6736e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 1.3878e-17, 3.4694e-18, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.3368e-19, 8.6736e-19, 6.9389e-18, 4.3368e-19, 0.0000e+00,\n",
      "         0.0000e+00, 8.6736e-19, 0.0000e+00, 6.9389e-18, 0.0000e+00, 3.4694e-18,\n",
      "         0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 8.6736e-19,\n",
      "         0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00, 1.7347e-18, 6.9389e-18,\n",
      "         0.0000e+00, 1.7347e-18, 0.0000e+00, 8.6736e-19, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9389e-18, 3.4694e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3368e-19, 4.3368e-19, 6.9389e-18,\n",
      "         3.4694e-18, 8.6736e-19, 0.0000e+00, 3.4694e-18, 8.6736e-19, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 3.4694e-18, 0.0000e+00, 1.7347e-18,\n",
      "         0.0000e+00, 0.0000e+00, 8.6736e-19, 6.9389e-18, 0.0000e+00, 3.4694e-18,\n",
      "         8.6736e-19, 0.0000e+00, 6.5052e-19, 0.0000e+00, 1.7347e-18, 6.9389e-18,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-18, 3.4694e-18, 0.0000e+00, 3.4694e-18, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-18, 4.1633e-17, 3.4694e-18, 1.7347e-18,\n",
      "         0.0000e+00, 1.7347e-18, 0.0000e+00, 1.3878e-17, 0.0000e+00, 6.9389e-18,\n",
      "         0.0000e+00, 8.6736e-19, 1.7764e-15, 2.2204e-15, 1.5543e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.7764e-15, 2.2204e-15, 1.6862e-15, 8.8818e-16, 2.6645e-15,\n",
      "         3.1086e-15, 2.2204e-15, 1.8041e-15, 2.6645e-15, 2.8866e-15, 2.6645e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.1086e-15, 2.2204e-15, 2.6645e-15, 1.5543e-15,\n",
      "         1.7764e-15, 4.4409e-15, 2.6645e-15, 2.6645e-15, 2.6645e-15, 2.2204e-15,\n",
      "         3.1086e-15, 3.5527e-15, 1.7764e-15, 2.6645e-15, 2.4425e-15, 1.7764e-15,\n",
      "         3.1086e-15, 1.3323e-15, 1.9984e-15, 2.6645e-15, 2.2204e-15, 2.2204e-15,\n",
      "         1.7764e-15, 2.6645e-15, 4.4409e-15, 3.5527e-15, 2.8866e-15, 3.1086e-15,\n",
      "         1.6653e-15, 2.2204e-15, 1.7764e-15, 3.1086e-15, 2.6645e-15, 5.3291e-15,\n",
      "         1.7764e-15, 2.6645e-15, 4.4409e-15, 3.3862e-15, 2.6645e-15, 2.8866e-15,\n",
      "         3.5527e-15, 4.4409e-15, 2.7756e-15, 1.3323e-15, 2.2204e-15, 2.6645e-15,\n",
      "         1.7764e-15, 2.2204e-15, 1.7764e-15, 1.7764e-15, 2.6645e-15, 4.8850e-15,\n",
      "         3.1086e-15, 1.7764e-15, 2.2204e-15, 3.9968e-15, 1.9984e-15, 2.5535e-15,\n",
      "         4.4409e-15, 3.5527e-15, 3.1086e-15, 1.7764e-15, 2.2204e-15, 3.1086e-15,\n",
      "         3.5527e-15, 4.4409e-15, 2.6645e-15, 1.7764e-15, 1.4433e-15, 2.4425e-15,\n",
      "         6.6613e-16, 3.1086e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15, 2.6645e-15,\n",
      "         3.1086e-15, 2.6645e-15, 1.7764e-15, 1.3323e-15, 2.6645e-15, 2.6645e-15,\n",
      "         2.5535e-15, 2.6645e-15, 1.8319e-15, 3.5527e-15, 3.5527e-15, 2.7756e-15,\n",
      "         3.9968e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15, 2.2204e-15,\n",
      "         3.5527e-15, 2.6645e-15, 1.9984e-15, 1.7764e-15, 1.3600e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.7764e-15, 2.6645e-15, 2.6645e-15, 2.3315e-15, 1.7764e-15,\n",
      "         3.1086e-15, 3.5527e-15, 1.7764e-15, 3.6499e-15, 2.0817e-17, 3.3307e-16,\n",
      "         5.5511e-17, 1.0408e-17, 1.3878e-17, 1.6653e-16, 4.4409e-16, 6.5919e-17,\n",
      "         1.3878e-17, 8.3267e-17, 2.5674e-16, 2.7756e-17, 1.3878e-16, 8.8818e-16,\n",
      "         5.5511e-17, 4.8572e-17, 2.2204e-16, 6.9389e-17, 2.7756e-17, 1.6653e-16,\n",
      "         1.3878e-16, 1.2490e-16, 3.3307e-16, 4.1633e-17, 8.3267e-17, 1.1102e-16,\n",
      "         1.1102e-16, 4.4409e-16, 1.6653e-16, 2.2204e-16, 4.8572e-17, 1.5613e-17,\n",
      "         2.7756e-17, 1.1102e-16, 1.3878e-16, 5.5511e-17, 5.5511e-17, 1.6653e-16,\n",
      "         2.2204e-16, 1.1102e-16, 8.3267e-17, 2.0817e-16, 8.3267e-17, 9.7145e-17,\n",
      "         1.1380e-15, 5.5511e-17, 2.2204e-16, 3.3307e-16, 3.4694e-17, 1.3878e-17,\n",
      "         2.2204e-16, 4.8572e-17, 9.7145e-17, 2.0817e-17, 1.6653e-16, 2.7756e-16,\n",
      "         1.2490e-16, 6.6613e-16, 6.9389e-18, 1.6653e-16, 5.5511e-17, 5.5511e-17,\n",
      "         6.9389e-17, 2.0817e-17, 2.2204e-16, 1.2490e-16, 8.8818e-16, 9.7145e-17,\n",
      "         1.6653e-16, 2.7756e-17, 2.0817e-17, 2.2204e-16, 1.1102e-16, 1.1102e-16,\n",
      "         2.0817e-17, 1.3878e-16, 3.3307e-16, 5.5511e-17, 1.3878e-17, 1.1102e-16,\n",
      "         2.0817e-17, 9.7145e-17, 8.3267e-17, 1.3878e-16, 8.3267e-17, 4.4409e-16,\n",
      "         1.1102e-16, 1.9949e-16, 2.0817e-17, 3.3307e-16, 1.3878e-17, 1.3878e-17,\n",
      "         2.7756e-17, 1.1102e-16, 8.3267e-17, 1.1102e-16, 4.1633e-17, 2.7756e-16,\n",
      "         4.4409e-16, 5.5511e-17, 4.1633e-17, 2.7756e-16, 1.3878e-17, 5.5511e-17,\n",
      "         2.2204e-16, 2.2204e-16, 2.7756e-17, 7.6328e-17, 1.3878e-17, 1.3878e-17,\n",
      "         2.2204e-16, 8.6736e-18, 1.6653e-16, 4.4409e-16, 2.2204e-16, 1.7347e-17,\n",
      "         8.6736e-17, 1.1102e-16, 1.2143e-16, 2.2204e-16, 2.7756e-17, 5.5511e-17,\n",
      "         1.6653e-16, 2.2204e-16, 2.7756e-17, 2.2204e-16, 1.6653e-16, 2.7756e-17,\n",
      "         1.2212e-15, 4.9960e-16, 4.4409e-16, 6.6613e-16, 1.6653e-16, 1.3323e-15,\n",
      "         6.6613e-16, 5.5511e-16, 1.1102e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16,\n",
      "         4.4409e-16, 2.2204e-16, 2.0817e-16, 7.7716e-16, 6.6613e-16, 6.6613e-16,\n",
      "         4.4409e-16, 1.1102e-15, 8.8818e-16, 4.4409e-16, 1.3323e-15, 3.8858e-16,\n",
      "         4.4409e-16, 6.6613e-16, 7.7716e-16, 6.1062e-16, 2.2204e-16, 4.4409e-16,\n",
      "         1.3323e-15, 4.4409e-16, 4.4409e-16, 6.6613e-16, 8.8818e-16, 3.8511e-16,\n",
      "         6.6613e-16, 4.4409e-16, 4.4409e-16, 6.6613e-16, 7.7716e-16, 2.6645e-15,\n",
      "         6.6613e-16, 2.7756e-16, 8.8818e-16, 8.3267e-16, 3.3307e-16, 8.8818e-16,\n",
      "         8.8818e-16, 6.6613e-16, 1.7764e-15, 6.5226e-16, 3.3307e-16, 1.7764e-15,\n",
      "         2.9143e-16, 5.8287e-16, 7.7716e-16, 4.4409e-16, 4.4409e-16, 3.8858e-16,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 2.7756e-16, 6.6613e-16, 8.8818e-16,\n",
      "         1.3323e-15, 3.0531e-16, 2.2204e-16, 4.4409e-16, 6.6613e-16, 2.7756e-16,\n",
      "         8.8818e-16, 4.4409e-16, 1.8735e-16, 8.8818e-16, 2.2204e-16, 6.6613e-16,\n",
      "         2.2204e-16, 3.8858e-16, 1.3323e-15, 2.7756e-16, 8.8818e-16, 1.6653e-16,\n",
      "         4.4409e-16, 8.8818e-16, 1.8041e-16, 5.5511e-16, 4.4409e-16, 6.6613e-16,\n",
      "         6.6613e-16, 8.8818e-16, 8.8818e-16, 5.5511e-17, 2.2204e-16, 8.8818e-16,\n",
      "         8.8818e-16, 8.0491e-16, 8.8818e-16, 8.8818e-16, 5.5511e-16, 8.8818e-16,\n",
      "         6.6613e-16, 5.5511e-16, 5.5511e-16, 4.4409e-16, 8.8818e-16, 3.3307e-16,\n",
      "         6.6613e-16, 3.7470e-16, 8.8818e-16, 6.6613e-16, 1.7694e-16, 3.3307e-16,\n",
      "         8.8818e-16, 6.6613e-16, 5.5511e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16,\n",
      "         6.6613e-16, 4.9960e-16, 4.4409e-16, 4.4409e-16, 5.5511e-16, 4.4409e-16,\n",
      "         1.7764e-15, 4.9960e-16]], dtype=torch.float64)\n",
      "tensor([  1,   2,   3,   4,   6,   9,  10,  11,  14,  20,  21,  22,  23,  27,\n",
      "         33,  37,  38,  39,  40,  43,  45,  47,  50,  53,  55,  58,  59,  61,\n",
      "         63,  67,  68,  70,  75,  76,  77,  78,  79,  81,  82,  86,  87,  89,\n",
      "         92,  93,  95,  96,  98, 100, 101, 105, 108, 109, 111, 116, 117, 118,\n",
      "        119, 121, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
      "        263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
      "        277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
      "        291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "        305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
      "        319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
      "        333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "        347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
      "        361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "        375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388,\n",
      "        389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
      "        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430,\n",
      "        431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n",
      "        445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "        459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "        473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "        487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500,\n",
      "        501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   4,   6,   9,  10,  11,  14,  20,  21,  22,  23,  27,\n",
      "         33,  37,  38,  39,  40,  43,  45,  47,  50,  53,  55,  58,  59,  61,\n",
      "         63,  67,  68,  70,  75,  76,  77,  78,  79,  81,  82,  86,  87,  89,\n",
      "         92,  93,  95,  96,  98, 100, 101, 105, 108, 109, 111, 116, 117, 118,\n",
      "        119, 121, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
      "        263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
      "        277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
      "        291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "        305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
      "        319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
      "        333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "        347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
      "        361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "        375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388,\n",
      "        389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
      "        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430,\n",
      "        431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n",
      "        445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "        459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "        473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "        487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500,\n",
      "        501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511])  (len = 445)\n",
      "passing Cout = tensor([  0,   5,   7,   8,  12,  13,  15,  16,  17,  18,  19,  24,  25,  26,\n",
      "         28,  29,  30,  31,  32,  34,  35,  36,  41,  42,  44,  46,  48,  49,\n",
      "         51,  52,  54,  56,  57,  60,  62,  64,  65,  66,  69,  71,  72,  73,\n",
      "         74,  80,  83,  84,  85,  88,  90,  91,  94,  97,  99, 102, 103, 104,\n",
      "        106, 107, 110, 112, 113, 114, 115, 120, 122, 124, 126])  (len = 67)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t EXEC SPLIT: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #57-layer4.0.add; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.0.shortcut.1 C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #58-layer4.0.relu_1; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.0.add C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.0.relu_1 C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  1,  17,  18,  42,  47,  69,  72,  87, 104, 108, 119])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t EXEC SPLIT: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #57-layer4.0.add; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.0.shortcut.1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #58-layer4.0.relu_1; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.0.add C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.0.relu_1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([129, 131, 133, 134, 136, 140, 141, 144, 149, 151, 152, 153, 155, 159,\n",
      "        161, 163, 164, 167, 169, 172, 173, 174, 176, 177, 178, 183, 188, 189,\n",
      "        191, 194, 199, 203, 211, 212, 218, 219, 221, 222, 223, 225, 226, 227,\n",
      "        228, 229, 231, 235, 236, 242, 243, 244, 246, 247, 248, 249, 251, 253,\n",
      "        254, 255])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t EXEC SPLIT: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #57-layer4.0.add; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.0.shortcut.1 C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #58-layer4.0.relu_1; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.0.add C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.0.relu_1 C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([258, 261, 263, 266, 268, 270, 272, 274, 275, 276, 280, 281, 290, 291,\n",
      "        293, 295, 297, 300, 302, 308, 310, 311, 312, 313, 318, 321, 323, 324,\n",
      "        329, 331, 338, 340, 342, 343, 345, 350, 353, 354, 360, 362, 363, 374,\n",
      "        375, 382])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t EXEC SPLIT: #56-layer4.0.shortcut.1; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #57-layer4.0.add; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.0.shortcut.1 C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-adding residual\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #58-layer4.0.relu_1; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.0.add C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.0.relu_1 C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 391, 395, 397, 398, 399, 403, 407, 411, 412,\n",
      "        413, 414, 416, 417, 419, 420, 424, 429, 432, 433, 435, 436, 439, 440,\n",
      "        443, 444, 446, 447, 449, 451, 452, 453, 454, 455, 457, 458, 462, 465,\n",
      "        466, 467, 468, 469, 470, 471, 472, 473, 474, 478, 479, 483, 485, 487,\n",
      "        489, 490, 491, 494, 496, 497, 499, 500, 501, 502, 503, 504, 506, 509])\n",
      "\t\t-Saving input for later...\n",
      "\t\t EXEC SPLIT: #59-layer4.1.conv1; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer4.1.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer4.1.conv1:\n",
      "Max diff:\n",
      "tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      "tensor([[2.1684e-19, 2.7105e-20, 1.0842e-19, 1.0842e-19, 1.0842e-19, 0.0000e+00,\n",
      "         5.4210e-20, 2.1684e-19, 2.1684e-19, 5.4210e-20, 5.4210e-20, 0.0000e+00,\n",
      "         1.3553e-20, 1.3553e-20, 1.0842e-19, 5.4210e-20, 2.7105e-20, 0.0000e+00,\n",
      "         0.0000e+00, 6.7763e-21, 1.0842e-19, 0.0000e+00, 5.4210e-20, 5.4210e-20,\n",
      "         2.1684e-19, 0.0000e+00, 2.1684e-19, 5.4210e-20, 0.0000e+00, 4.3368e-19,\n",
      "         1.0842e-19, 2.1684e-19, 1.3553e-20, 2.1684e-19, 2.1684e-19, 2.1684e-19,\n",
      "         2.1684e-19, 4.3368e-19, 0.0000e+00, 0.0000e+00, 2.7105e-20, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.3368e-19, 6.7763e-21, 2.7105e-20, 1.0842e-19,\n",
      "         2.1684e-19, 2.7105e-20, 2.1684e-19, 2.1684e-19, 0.0000e+00, 2.1684e-19,\n",
      "         1.0164e-20, 1.3553e-20, 5.4210e-20, 1.3553e-20, 2.1684e-19, 1.3553e-20,\n",
      "         2.1684e-19, 1.3553e-20, 0.0000e+00, 6.7763e-21, 2.1684e-19, 2.1684e-19,\n",
      "         2.7105e-20, 2.1684e-19, 1.0842e-19, 1.3553e-20, 2.7105e-20, 2.1684e-19,\n",
      "         1.3553e-20, 2.1684e-19, 1.0842e-19, 1.3553e-20, 1.3553e-20, 4.3368e-19,\n",
      "         2.1684e-19, 0.0000e+00, 1.3553e-20, 1.3553e-20, 2.1684e-19, 1.0842e-19,\n",
      "         2.1684e-19, 1.0842e-19, 1.0842e-19, 1.0842e-19, 5.4210e-20, 5.4210e-20,\n",
      "         2.7105e-20, 1.0842e-19, 2.7105e-20, 2.1684e-19, 5.4210e-20, 0.0000e+00,\n",
      "         1.0842e-19, 5.4210e-20, 6.7763e-21, 0.0000e+00, 1.3553e-20, 2.1684e-19,\n",
      "         1.3553e-20, 4.3368e-19, 4.3368e-19, 0.0000e+00, 1.3553e-20, 0.0000e+00,\n",
      "         4.3368e-19, 1.3553e-20, 2.1684e-19, 2.1684e-19, 1.0842e-19, 1.0842e-19,\n",
      "         1.0842e-19, 0.0000e+00, 0.0000e+00, 2.0329e-20, 2.1684e-19, 2.1684e-19,\n",
      "         4.3368e-19, 1.0842e-19, 2.7105e-20, 2.7105e-20, 2.1684e-19, 2.7105e-20,\n",
      "         4.3368e-19, 1.0842e-19, 5.3291e-15, 3.5527e-15, 4.4409e-15, 7.1054e-15,\n",
      "         7.3275e-15, 4.4409e-15, 4.4409e-15, 7.1054e-15, 8.8818e-15, 5.3291e-15,\n",
      "         3.5527e-15, 6.2172e-15, 5.3291e-15, 2.2204e-16, 3.5527e-15, 3.9968e-15,\n",
      "         6.2172e-15, 6.6613e-15, 7.1054e-15, 5.0515e-15, 7.1054e-15, 7.1054e-15,\n",
      "         3.9968e-15, 7.1054e-15, 3.5527e-15, 3.1086e-15, 2.2204e-16, 3.5527e-15,\n",
      "         8.8818e-15, 5.3291e-15, 5.3291e-15, 1.7764e-15, 4.4409e-15, 5.3291e-15,\n",
      "         3.5527e-15, 4.4409e-16, 3.5527e-15, 3.5527e-15, 8.8818e-15, 5.3291e-15,\n",
      "         3.5527e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15,\n",
      "         7.1054e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15, 4.4409e-15,\n",
      "         5.3291e-15, 7.1054e-15, 5.7732e-15, 4.4409e-15, 4.4409e-15, 6.2172e-15,\n",
      "         5.3291e-15, 5.3291e-15, 7.1054e-15, 5.3291e-15, 3.5527e-15, 6.2172e-15,\n",
      "         4.4409e-15, 7.1054e-15, 5.3291e-15, 4.3299e-15, 5.3291e-15, 8.8818e-15,\n",
      "         5.3291e-15, 4.8850e-15, 4.4409e-15, 5.3291e-15, 4.2188e-15, 3.5527e-15,\n",
      "         5.3291e-15, 7.1054e-15, 7.1054e-15, 4.4409e-16, 4.4409e-16, 5.3291e-15,\n",
      "         6.2172e-15, 5.3291e-15, 8.8818e-16, 3.5527e-15, 7.1054e-15, 5.3291e-15,\n",
      "         7.1054e-15, 7.1054e-15, 6.2172e-15, 4.6629e-15, 7.1054e-15, 3.5527e-15,\n",
      "         5.3291e-15, 7.1054e-15, 7.5495e-15, 5.7732e-15, 5.3291e-15, 4.8850e-15,\n",
      "         5.3291e-15, 5.3291e-15, 5.3291e-15, 3.5527e-15, 3.5527e-15, 7.9936e-15,\n",
      "         2.6645e-15, 7.1054e-15, 2.2204e-16, 5.7732e-15, 4.4409e-15, 5.3291e-15,\n",
      "         5.3291e-15, 4.4409e-15, 2.6645e-15, 6.2172e-15, 3.1086e-15, 8.8818e-15,\n",
      "         6.2172e-15, 7.1054e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15, 7.1054e-15,\n",
      "         4.4409e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15, 6.6613e-16, 8.8818e-16,\n",
      "         4.4409e-16, 5.5511e-17, 5.5511e-17, 8.8818e-16, 2.7756e-17, 8.8818e-16,\n",
      "         8.8818e-16, 3.3307e-16, 5.5511e-17, 1.3878e-17, 2.2204e-16, 1.1102e-16,\n",
      "         4.4409e-16, 8.8818e-16, 5.5511e-17, 2.2204e-16, 5.5511e-17, 2.7756e-17,\n",
      "         1.1102e-16, 5.5511e-17, 4.4409e-16, 8.8818e-16, 4.4409e-16, 1.1102e-16,\n",
      "         5.5511e-17, 1.1102e-16, 5.5511e-17, 8.8818e-16, 5.5511e-17, 8.8818e-16,\n",
      "         8.8818e-16, 2.2204e-16, 5.5511e-17, 4.4409e-16, 5.5511e-17, 2.2204e-16,\n",
      "         1.1102e-16, 1.1102e-16, 5.5511e-17, 2.7756e-17, 2.2204e-16, 4.4409e-16,\n",
      "         5.5511e-17, 2.7756e-17, 5.5511e-17, 8.8818e-16, 6.1062e-16, 1.1102e-16,\n",
      "         2.2204e-16, 5.5511e-17, 4.4409e-16, 5.5511e-17, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 2.0817e-17, 1.1102e-16, 2.7756e-17, 8.8818e-16,\n",
      "         5.5511e-17, 5.5511e-17, 4.4409e-16, 5.5511e-17, 2.7756e-17, 4.4409e-16,\n",
      "         1.1102e-16, 1.3323e-15, 4.4409e-16, 5.5511e-17, 1.1102e-16, 4.4409e-16,\n",
      "         2.7756e-17, 4.4409e-16, 4.4409e-16, 5.5511e-17, 8.8818e-16, 1.1102e-16,\n",
      "         1.7764e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 2.0817e-17,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 8.8818e-16,\n",
      "         6.6613e-16, 4.4409e-16, 2.2204e-16, 2.7756e-17, 5.5511e-17, 8.8818e-16,\n",
      "         5.5511e-17, 8.3267e-17, 2.7756e-17, 5.5511e-17, 2.7756e-17, 2.7756e-17,\n",
      "         2.2204e-16, 4.4409e-16, 8.8818e-16, 1.1102e-16, 2.2204e-16, 8.8818e-16,\n",
      "         2.2204e-16, 1.1102e-16, 2.7756e-17, 5.5511e-17, 5.5511e-17, 8.8818e-16,\n",
      "         4.4409e-16, 4.4409e-16, 8.8818e-16, 1.1102e-16, 4.4409e-16, 2.2204e-16,\n",
      "         5.5511e-17, 5.5511e-17, 4.4409e-16, 5.5511e-17, 6.6613e-16, 4.4409e-16,\n",
      "         2.2204e-16, 1.7764e-15, 1.7764e-15, 1.1102e-15, 4.4409e-16, 1.3323e-15,\n",
      "         4.4409e-16, 1.1102e-16, 2.2204e-16, 3.3307e-16, 1.3323e-15, 1.1102e-16,\n",
      "         2.2204e-16, 8.8818e-16, 1.3323e-15, 6.6613e-16, 1.7764e-15, 1.3323e-15,\n",
      "         8.8818e-16, 1.1102e-16, 1.7764e-15, 1.3323e-15, 4.4409e-16, 1.7764e-15,\n",
      "         1.7764e-15, 1.1102e-15, 1.7764e-15, 1.7764e-15, 1.1102e-16, 3.5527e-15,\n",
      "         8.8818e-16, 8.8818e-16, 2.6645e-15, 1.7764e-15, 2.2204e-16, 8.8818e-16,\n",
      "         1.1102e-15, 3.3307e-16, 1.1102e-16, 1.7764e-15, 2.2204e-16, 1.7764e-15,\n",
      "         2.2204e-16, 1.1102e-16, 8.8818e-16, 2.2204e-15, 2.2204e-16, 1.1102e-16,\n",
      "         8.8818e-16, 1.7764e-15, 5.5511e-17, 8.8818e-16, 7.7716e-16, 1.3323e-15,\n",
      "         8.8818e-16, 1.7764e-15, 1.7764e-15, 1.7764e-15, 1.7764e-15, 1.1102e-16,\n",
      "         2.6645e-15, 2.2204e-16, 3.5527e-15, 1.1102e-15, 2.2204e-16, 1.7764e-15,\n",
      "         1.7764e-15, 1.1102e-16, 8.8818e-16, 1.3323e-15, 8.8818e-16, 1.6653e-15,\n",
      "         2.2204e-16, 1.3323e-15, 1.1102e-16, 1.7764e-15, 1.1102e-16, 8.8818e-16,\n",
      "         1.4988e-15, 8.8818e-16, 1.1102e-16, 1.1102e-16, 1.1102e-16, 1.7764e-15,\n",
      "         1.7764e-15, 1.7764e-15, 2.2204e-16, 8.8818e-16, 1.3323e-15, 4.4409e-16,\n",
      "         1.7764e-15, 1.1102e-16, 8.8818e-16, 8.8818e-16, 1.1102e-16, 1.3323e-15,\n",
      "         1.5543e-15, 1.7764e-15, 2.2204e-16, 1.3323e-15, 1.7764e-15, 4.4409e-16,\n",
      "         2.2204e-16, 1.7764e-15, 8.8818e-16, 2.2204e-16, 4.4409e-16, 1.7764e-15,\n",
      "         1.7764e-15, 8.8818e-16, 8.8818e-16, 4.4409e-16, 1.6653e-16, 8.8818e-16,\n",
      "         2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 1.7764e-15,\n",
      "         1.1102e-16, 1.7764e-15, 1.7764e-15, 1.6653e-16, 2.6645e-15, 8.8818e-16,\n",
      "         8.8818e-16, 1.3323e-15]], dtype=torch.float64)\n",
      "tensor([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  12,  13,  14,  15,\n",
      "         16,  19,  20,  22,  23,  24,  26,  27,  29,  30,  31,  32,  33,  34,\n",
      "         35,  36,  37,  40,  44,  45,  46,  47,  48,  49,  50,  51,  53,  54,\n",
      "         55,  56,  57,  58,  59,  60,  61,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  96,  97,  98, 100,\n",
      "        101, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
      "        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "        175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,\n",
      "        189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
      "        203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
      "        217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
      "        231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
      "        245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258,\n",
      "        259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
      "        287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
      "        301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314,\n",
      "        315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
      "        329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
      "        343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "        357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
      "        385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412,\n",
      "        413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
      "        427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440,\n",
      "        441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
      "        469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
      "        483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496,\n",
      "        497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
      "        511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  12,  13,  14,  15,\n",
      "         16,  19,  20,  22,  23,  24,  26,  27,  29,  30,  31,  32,  33,  34,\n",
      "         35,  36,  37,  40,  44,  45,  46,  47,  48,  49,  50,  51,  53,  54,\n",
      "         55,  56,  57,  58,  59,  60,  61,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  96,  97,  98, 100,\n",
      "        101, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
      "        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "        175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,\n",
      "        189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
      "        203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
      "        217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
      "        231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
      "        245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258,\n",
      "        259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
      "        287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
      "        301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314,\n",
      "        315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
      "        329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
      "        343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "        357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
      "        385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "        399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412,\n",
      "        413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
      "        427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440,\n",
      "        441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
      "        469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
      "        483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496,\n",
      "        497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
      "        511])  (len = 491)\n",
      "passing Cout = tensor([  5,  11,  17,  18,  21,  25,  28,  38,  39,  41,  42,  43,  52,  62,\n",
      "         79,  95,  99, 105, 107, 115, 116])  (len = 21)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t EXEC SPLIT: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #61-layer4.1.relu; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.1.bn1 C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.1.relu C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   4,   5,   6,   8,   9,  11,  17,  20,  21,  23,  25,  26,  28,\n",
      "         29,  33,  34,  35,  37,  41,  43,  47,  48,  50,  58,  64,  65,  68,\n",
      "         70,  74,  77,  82,  84,  86,  87,  88,  90,  91,  93,  95,  96,  99,\n",
      "        103, 104, 105, 107, 108, 111, 114, 115, 119, 120, 121])\n",
      "\t\t EXEC SPLIT: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t EXEC SPLIT: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #61-layer4.1.relu; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.1.bn1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.1.relu C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([130, 131, 132, 134, 136, 137, 139, 145, 147, 150, 153, 155, 161, 162,\n",
      "        164, 166, 167, 170, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183,\n",
      "        184, 186, 187, 189, 190, 191, 192, 193, 194, 195, 199, 201, 202, 209,\n",
      "        210, 218, 219, 223, 224, 227, 231, 233, 234, 235, 237, 238, 239, 240,\n",
      "        241, 243, 246, 247, 249, 254])\n",
      "\t\t EXEC SPLIT: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t EXEC SPLIT: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #61-layer4.1.relu; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.1.bn1 C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.1.relu C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 265, 271, 280, 285, 293, 304, 311, 312, 320, 323, 325,\n",
      "        337, 339, 342, 343, 346, 377, 382, 383])\n",
      "\t\t EXEC SPLIT: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t EXEC SPLIT: #60-layer4.1.bn1; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #61-layer4.1.relu; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.1.bn1 C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.1.relu C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([398, 400, 401, 402, 408, 414, 442, 447, 453, 455, 457, 461, 462, 472,\n",
      "        479, 480, 494, 497, 511])\n",
      "\t\t EXEC SPLIT: #62-layer4.1.conv2; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer4.1.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer4.1.conv2:\n",
      "Max diff:\n",
      "tensor([1.5099e-14], dtype=torch.float64)\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-15, 7.1054e-15, 7.1054e-15, 6.2172e-15,\n",
      "         6.9944e-15, 1.1102e-14, 2.8866e-15, 7.1054e-15, 4.4409e-15, 2.6645e-15,\n",
      "         3.5527e-15, 3.5527e-15, 2.6090e-15, 3.9968e-15, 5.3291e-15, 6.2172e-15,\n",
      "         6.2172e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15,\n",
      "         1.7764e-15, 3.5527e-15, 7.1054e-15, 1.4211e-14, 7.1054e-15, 7.1054e-15,\n",
      "         3.9968e-15, 5.7732e-15, 7.1054e-15, 7.9936e-15, 8.8818e-15, 3.1086e-15,\n",
      "         3.5527e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15, 5.3291e-15, 5.3291e-15,\n",
      "         5.3291e-15, 6.6613e-15, 3.9968e-15, 8.8818e-15, 7.9936e-15, 7.1054e-15,\n",
      "         3.9968e-15, 2.8866e-15, 4.4409e-15, 1.1546e-14, 3.5527e-15, 3.5527e-15,\n",
      "         6.2172e-15, 6.2172e-15, 1.5099e-14, 8.8818e-15, 7.1054e-15, 4.4409e-15,\n",
      "         2.6645e-15, 1.0658e-14, 3.5527e-15, 7.1054e-15, 4.4409e-15, 1.0658e-14,\n",
      "         5.3291e-15, 4.4409e-15, 8.8818e-15, 1.0658e-14, 8.8818e-15, 5.3291e-15,\n",
      "         7.1054e-15, 7.1054e-15, 4.8850e-15, 5.7732e-15, 5.7732e-15, 3.5527e-15,\n",
      "         3.5527e-15, 4.4409e-15, 5.3291e-15, 1.1546e-14, 3.8858e-15, 8.8818e-15,\n",
      "         3.6637e-15, 8.8818e-15, 2.6645e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15,\n",
      "         2.2204e-15, 8.8818e-15, 4.2188e-15, 5.3291e-15, 2.6645e-15, 7.1054e-15,\n",
      "         2.6645e-15, 7.1054e-15, 8.8818e-15, 9.7700e-15, 5.3291e-15, 4.4409e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.8858e-15, 4.4409e-15, 3.1086e-15, 7.1054e-15,\n",
      "         6.6613e-15, 5.3291e-15, 4.4409e-15, 1.0658e-14, 4.4409e-15, 8.8818e-15,\n",
      "         7.1054e-15, 3.9968e-15, 7.1054e-15, 4.4409e-15, 8.6597e-15, 3.1086e-15,\n",
      "         5.3291e-15, 4.4409e-15, 7.1054e-15, 4.4409e-15, 4.4409e-15, 3.9968e-15,\n",
      "         8.8818e-15, 5.3291e-15, 4.4409e-15, 5.3291e-15, 2.2204e-16, 4.4409e-16,\n",
      "         2.2204e-16, 5.5511e-17, 5.5511e-17, 2.7756e-16, 2.2204e-16, 1.3878e-16,\n",
      "         2.2204e-16, 1.1102e-16, 2.2204e-16, 1.3878e-17, 4.4409e-16, 2.2204e-16,\n",
      "         2.2204e-16, 2.7756e-16, 4.4409e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         2.2204e-16, 4.4409e-16, 2.2204e-16, 2.7756e-17, 2.2204e-16, 1.1102e-16,\n",
      "         4.4409e-16, 4.4409e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16,\n",
      "         1.1102e-16, 2.2204e-16, 2.7756e-16, 1.1102e-16, 2.2204e-16, 2.2204e-16,\n",
      "         4.4409e-16, 4.4409e-16, 1.1102e-16, 1.1102e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 2.7756e-17,\n",
      "         2.2204e-16, 4.4409e-16, 1.1102e-16, 5.5511e-17, 4.4409e-16, 2.2204e-16,\n",
      "         4.4409e-16, 4.4409e-16, 2.7756e-17, 1.1102e-16, 2.2204e-16, 5.5511e-17,\n",
      "         4.4409e-16, 2.7756e-17, 2.2204e-16, 8.8818e-16, 5.5511e-16, 2.2204e-16,\n",
      "         2.2204e-16, 5.5511e-17, 4.4409e-16, 4.4409e-16, 3.3307e-16, 2.3592e-16,\n",
      "         2.7756e-17, 4.4409e-16, 4.4409e-16, 2.2204e-16, 2.2204e-16, 5.5511e-17,\n",
      "         3.3307e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 1.1102e-16, 4.4409e-16,\n",
      "         2.2204e-16, 8.8818e-16, 2.7756e-17, 1.4572e-16, 6.9389e-18, 4.4409e-16,\n",
      "         5.5511e-17, 2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         2.2204e-16, 5.5511e-17, 8.8818e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16, 5.5511e-17, 2.2204e-16,\n",
      "         4.4409e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 4.4409e-16, 2.7756e-17,\n",
      "         2.2204e-16, 3.3307e-16, 1.1102e-16, 2.2204e-16, 4.4409e-16, 5.5511e-17,\n",
      "         2.2204e-16, 2.2204e-16, 5.5511e-17, 2.2204e-16, 1.6653e-16, 5.5511e-17,\n",
      "         3.8858e-16, 3.7470e-16, 3.3307e-16, 3.3307e-16, 4.4409e-16, 8.8818e-16,\n",
      "         8.8818e-16, 5.5511e-16, 5.5511e-17, 4.4409e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.9960e-16, 4.4409e-16, 3.3307e-16, 8.8818e-16,\n",
      "         4.4409e-16, 6.6613e-16, 4.4409e-16, 3.3307e-16, 3.3307e-16, 4.4409e-16,\n",
      "         5.5511e-16, 4.4409e-16, 6.6613e-16, 3.3307e-16, 6.6613e-16, 6.6613e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 4.4409e-16, 3.3307e-16, 3.3307e-16, 8.8818e-16,\n",
      "         4.4409e-16, 2.2204e-16, 1.1102e-15, 4.4409e-16, 4.4409e-16, 4.4409e-16,\n",
      "         8.8818e-16, 5.5511e-16, 4.9960e-16, 3.6082e-16, 3.8858e-16, 8.8818e-16,\n",
      "         8.8818e-16, 2.2204e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16,\n",
      "         2.2204e-16, 8.8818e-16, 4.4409e-16, 7.7716e-16, 5.5511e-16, 8.8818e-16,\n",
      "         4.4409e-16, 7.2164e-16, 8.8818e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         6.6613e-16, 4.1633e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 3.3307e-16,\n",
      "         4.4409e-16, 5.5511e-16, 3.6082e-16, 4.4409e-16, 4.4409e-16, 2.4980e-16,\n",
      "         4.4409e-16, 6.6613e-16, 4.4409e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16,\n",
      "         6.6613e-16, 8.8818e-16, 4.4409e-16, 1.1102e-16, 7.7716e-16, 6.6613e-16,\n",
      "         2.2204e-16, 6.6613e-16, 4.4409e-16, 2.7756e-16, 8.8818e-16, 8.8818e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 4.4409e-16, 6.6613e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 6.6613e-16, 7.7716e-16, 5.5511e-16, 2.2204e-16,\n",
      "         1.1102e-15, 7.7716e-16, 8.8818e-16, 4.4409e-16, 4.4409e-16, 3.8858e-16,\n",
      "         4.4409e-16, 7.7716e-16]], dtype=torch.float64)\n",
      "tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
      "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
      "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
      "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
      "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "        394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
      "        408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "        422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
      "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
      "        450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "        464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
      "        478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
      "        492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
      "        506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
      "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
      "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
      "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
      "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "        394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
      "        408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "        422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
      "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
      "        450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "        464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
      "        478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
      "        492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
      "        506, 507, 508, 509, 510, 511])  (len = 384)\n",
      "passing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t EXEC SPLIT: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_out=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #64-layer4.1.add; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.1.bn2 C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #65-layer4.1.relu_1; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.1.add C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #66-avg_pool2d; Shape=[1, 512, 4, 4]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from layer4.1.relu_1 C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t-average pooling\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #67-size; Shape=[1, 512, 1, 1]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from avg_pool2d C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t-skipping\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #68-view; Shape=[1, 512, 1, 1]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tSkipping check for output size (no tensor found for ref.) \n",
      "\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t-reshaping (view)\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #69-linear; Shape=[1, 512]; C_in=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]\n",
      "\t\tChecking output from view C_in [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([], dtype=torch.int64)\n",
      "\t\t EXEC SPLIT: #69-linear; Shape=[1, 10]; C_out=[]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #70-FINAL_MODEL_OUTPUT; Shape=[1, 10]; C_in=[0 1 2 3 4 5 6 7 8 9]\n",
      "\tExecuting on machine 1\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t EXEC SPLIT: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_out=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #64-layer4.1.add; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.1.bn2 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #65-layer4.1.relu_1; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.1.add C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #66-avg_pool2d; Shape=[1, 512, 4, 4]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from layer4.1.relu_1 C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144,\n",
      "        145, 146, 149, 150, 151, 156, 157, 159, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181,\n",
      "        183, 184, 185, 186, 188, 189, 191, 193, 195, 196, 197, 199, 200, 201,\n",
      "        202, 203, 204, 207, 208, 210, 212, 214, 215, 216, 217, 218, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253,\n",
      "        254, 255])\n",
      "\t\t-average pooling\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #67-size; Shape=[1, 512, 1, 1]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from avg_pool2d C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144,\n",
      "        145, 146, 149, 150, 151, 156, 157, 159, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181,\n",
      "        183, 184, 185, 186, 188, 189, 191, 193, 195, 196, 197, 199, 200, 201,\n",
      "        202, 203, 204, 207, 208, 210, 212, 214, 215, 216, 217, 218, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253,\n",
      "        254, 255])\n",
      "\t\t-skipping\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #68-view; Shape=[1, 512, 1, 1]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tSkipping check for output size (no tensor found for ref.) \n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144,\n",
      "        145, 146, 149, 150, 151, 156, 157, 159, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181,\n",
      "        183, 184, 185, 186, 188, 189, 191, 193, 195, 196, 197, 199, 200, 201,\n",
      "        202, 203, 204, 207, 208, 210, 212, 214, 215, 216, 217, 218, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253,\n",
      "        254, 255])\n",
      "\t\t-reshaping (view)\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #69-linear; Shape=[1, 512]; C_in=[128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]\n",
      "\t\tChecking output from view C_in [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144,\n",
      "        145, 146, 149, 150, 151, 156, 157, 159, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181,\n",
      "        183, 184, 185, 186, 188, 189, 191, 193, 195, 196, 197, 199, 200, 201,\n",
      "        202, 203, 204, 207, 208, 210, 212, 214, 215, 216, 217, 218, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236,\n",
      "        238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253,\n",
      "        254, 255])\n",
      "\t\t EXEC SPLIT: #69-linear; Shape=[1, 10]; C_out=[0 1 2 3 4 5 6 7 8 9]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #70-FINAL_MODEL_OUTPUT; Shape=[1, 10]; C_in=[]\n",
      "\t\t Prepping to send C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\tExecuting on machine 2\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t EXEC SPLIT: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_out=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #64-layer4.1.add; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.1.bn2 C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #65-layer4.1.relu_1; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.1.add C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #66-avg_pool2d; Shape=[1, 512, 4, 4]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from layer4.1.relu_1 C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([257, 258, 261, 263, 266, 268, 270, 274, 275, 280, 281, 285, 290, 291,\n",
      "        293, 295, 297, 301, 302, 308, 310, 311, 312, 313, 318, 321, 323, 324,\n",
      "        326, 329, 334, 338, 339, 340, 342, 351, 353, 354, 356, 359, 363, 370,\n",
      "        374, 382])\n",
      "\t\t-average pooling\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #67-size; Shape=[1, 512, 1, 1]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from avg_pool2d C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([257, 258, 261, 263, 266, 268, 270, 274, 275, 280, 281, 285, 290, 291,\n",
      "        293, 295, 297, 301, 302, 308, 310, 311, 312, 313, 318, 321, 323, 324,\n",
      "        326, 329, 334, 338, 339, 340, 342, 351, 353, 354, 356, 359, 363, 370,\n",
      "        374, 382])\n",
      "\t\t-skipping\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #68-view; Shape=[1, 512, 1, 1]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tSkipping check for output size (no tensor found for ref.) \n",
      "\n",
      "\t\t current input channels tensor([257, 258, 261, 263, 266, 268, 270, 274, 275, 280, 281, 285, 290, 291,\n",
      "        293, 295, 297, 301, 302, 308, 310, 311, 312, 313, 318, 321, 323, 324,\n",
      "        326, 329, 334, 338, 339, 340, 342, 351, 353, 354, 356, 359, 363, 370,\n",
      "        374, 382])\n",
      "\t\t-reshaping (view)\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #69-linear; Shape=[1, 512]; C_in=[256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]\n",
      "\t\tChecking output from view C_in [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([257, 258, 261, 263, 266, 268, 270, 274, 275, 280, 281, 285, 290, 291,\n",
      "        293, 295, 297, 301, 302, 308, 310, 311, 312, 313, 318, 321, 323, 324,\n",
      "        326, 329, 334, 338, 339, 340, 342, 351, 353, 354, 356, 359, 363, 370,\n",
      "        374, 382])\n",
      "\t\t EXEC SPLIT: #69-linear; Shape=[1, 10]; C_out=[0 1 2 3 4 5 6 7 8 9]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #70-FINAL_MODEL_OUTPUT; Shape=[1, 10]; C_in=[]\n",
      "\t\t Prepping to send C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\tExecuting on machine 3\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t EXEC SPLIT: #63-layer4.1.bn2; Shape=[1, 512, 4, 4]; C_out=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #64-layer4.1.add; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.1.bn2 C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #65-layer4.1.relu_1; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.1.add C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511])\n",
      "\t\t-Applying ReLU\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #66-avg_pool2d; Shape=[1, 512, 4, 4]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from layer4.1.relu_1 C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 391, 393, 395, 396, 397, 398, 399, 402, 403,\n",
      "        404, 407, 408, 411, 412, 413, 416, 417, 419, 424, 426, 427, 428, 429,\n",
      "        430, 431, 432, 433, 434, 435, 436, 439, 440, 443, 444, 446, 447, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        467, 468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 487,\n",
      "        488, 489, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 509, 510, 511])\n",
      "\t\t-average pooling\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #67-size; Shape=[1, 512, 1, 1]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from avg_pool2d C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 391, 393, 395, 396, 397, 398, 399, 402, 403,\n",
      "        404, 407, 408, 411, 412, 413, 416, 417, 419, 424, 426, 427, 428, 429,\n",
      "        430, 431, 432, 433, 434, 435, 436, 439, 440, 443, 444, 446, 447, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        467, 468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 487,\n",
      "        488, 489, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 509, 510, 511])\n",
      "\t\t-skipping\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #68-view; Shape=[1, 512, 1, 1]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tSkipping check for output size (no tensor found for ref.) \n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 391, 393, 395, 396, 397, 398, 399, 402, 403,\n",
      "        404, 407, 408, 411, 412, 413, 416, 417, 419, 424, 426, 427, 428, 429,\n",
      "        430, 431, 432, 433, 434, 435, 436, 439, 440, 443, 444, 446, 447, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        467, 468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 487,\n",
      "        488, 489, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 509, 510, 511])\n",
      "\t\t-reshaping (view)\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #69-linear; Shape=[1, 512]; C_in=[384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]\n",
      "\t\tChecking output from view C_in [384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
      " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
      " 510 511]: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t current input channels tensor([384, 385, 386, 387, 388, 391, 393, 395, 396, 397, 398, 399, 402, 403,\n",
      "        404, 407, 408, 411, 412, 413, 416, 417, 419, 424, 426, 427, 428, 429,\n",
      "        430, 431, 432, 433, 434, 435, 436, 439, 440, 443, 444, 446, 447, 449,\n",
      "        450, 451, 452, 453, 454, 455, 457, 458, 461, 462, 463, 464, 465, 466,\n",
      "        467, 468, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 485, 487,\n",
      "        488, 489, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 509, 510, 511])\n",
      "\t\t EXEC SPLIT: #69-linear; Shape=[1, 10]; C_out=[0 1 2 3 4 5 6 7 8 9]\n",
      "\t\t INITIALIZING CURRENT TENSOR FOR: #70-FINAL_MODEL_OUTPUT; Shape=[1, 10]; C_in=[]\n",
      "\t\t Prepping to send C_out tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) to machine 0\n",
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR linear-----------------------------------\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n",
      "\t\t current input channels tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "FINISHED MODEL EXECUTION\n",
      "\t\t FINAL TENSOR FOR: #71-FINAL_MODEL_OUTPUT; Shape=[1, 10]\n",
      "\t\t SPLIT OUTPUT: tensor([[-1.0856, -0.9201,  7.7138,  3.5600,  0.2154,  0.9633, -2.1835, -3.7813,\n",
      "          0.7813, -2.8512]], dtype=torch.float64)\n",
      "\t\t FULL OUTPUT: tensor([[-1.0856, -0.9201,  7.7138,  3.5600,  0.2154,  0.9633, -2.1835, -3.7813,\n",
      "          0.7813, -2.8512]], dtype=torch.float64)\n",
      "\tMachine 1 has finished calculations. Skipping...\n",
      "\n",
      "\tMachine 2 has finished calculations. Skipping...\n",
      "\n",
      "\tMachine 3 has finished calculations. Skipping...\n",
      "\n",
      "\n",
      "\n",
      "############################# FINAL EXECUTION TIME 5.792242050170898 [seconds] #############################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Prep Inout for Mock Run version 2 (fx)'''\n",
    "\n",
    "# TODO: reduce size of communicated tensors to only what is necessary \n",
    "# TODO: also check bias for nonzero\n",
    "# TODO: implement broadcast vs multi-cast? switch e.g. a single machine broadcasts outputs because weights that reach across layers are executed on the rx machine only \n",
    "# TODO: handle arbitrary kernel to machine assignment \n",
    "\n",
    "# channel_id == INPUTS\n",
    "# filter_id  == OUTPUTS\n",
    "\n",
    "configs_copy = configs # keep the origonal config \n",
    "\n",
    "# setup input \n",
    "N_batch = 1\n",
    "torch.manual_seed(0)\n",
    "input_tensor = torch.rand(N_batch, 3, 32, 32, dtype=torch.float64, device=torch.device(configs_copy['device'])) # 1k images, 3 channels, 32x32 image (cifar100) \n",
    "model = model.type(torch.float64)\n",
    "\n",
    "# add logic for final layer TODO: add this in automatically somewhere\n",
    "final_node= 0\n",
    "linear_map = SplitManager.get_io_for_linear(configs_copy, layer_names_fx, num_machines, 0, 10)\n",
    "configs_copy['partition']['linear.weight'] = linear_map\n",
    "configs_copy['partition']['FINAL_MODEL_OUTPUT.weight'] = { 'channel_id' : [np.array([])]*num_machines }\n",
    "configs_copy['partition']['FINAL_MODEL_OUTPUT.weight']['channel_id'][0] = np.arange(model.linear.out_features) # send all outputs to machine 0 \n",
    "\n",
    "# make SplitManagers for split model execution \n",
    "debug = True\n",
    "configs_copy['dtype'] = 'float64'\n",
    "split_managers = [SplitManager]*num_machines\n",
    "for i in range(num_machines):\n",
    "    split_managers[i] = SplitManager(configs_copy, i, num_machines, input_tensor, debug=True)\n",
    "\n",
    "# emulates queue that server collects inputs with. \n",
    "# Each network node has it's own list of inputs it looks at when collecting inputs \n",
    "# input :\n",
    "#   [rx node (str)] : (list) list of data dicts \n",
    "input = {}\n",
    "for imach in range(num_machines):\n",
    "    in_data = prep_data(input_tensor, -1, 0)\n",
    "    input[str(imach)] = [in_data]\n",
    "\n",
    "# put models into eval mode and on device\n",
    "model.eval()\n",
    "model.to(configs['device'])\n",
    "\n",
    "# get true output at each layer\n",
    "# WARNING: bn layers are initialized differently between model in this notebook and model in split manager. The moving mean and variance fields do not match HOWEVER the weights and biases are the same\n",
    "#horz_output, layer_output_size_LUT = get_output_at_each_layer(model, input_tensor) \n",
    "horz_output, layer_output_size_LUT = get_output_at_each_layer(split_managers[0].model, input_tensor)\n",
    "\n",
    "'''\n",
    "    mock run through inference using split models \n",
    "'''\n",
    "\n",
    "# timing\n",
    "split_execution_start_time = time.time()\n",
    "layer_completion_time_stamp = {}\n",
    "layer_execution_duration = {}\n",
    "\n",
    "# make inference \n",
    "with torch.no_grad():\n",
    "\n",
    "    # iterate through layers 1 module at a time \n",
    "    while True:#range(num_total_modules): # 16 <=> layer_1 block \n",
    "\n",
    "        # Write outputs to one big queue with everyone's data in it \n",
    "        output = {}\n",
    "\n",
    "        # iterate through each machine (done in parallel later)\n",
    "        for imach in range(num_machines):\n",
    "            \n",
    "            if split_managers[imach].is_done():\n",
    "                print(f'\\tMachine {split_managers[imach].machine} has finished calculations. Skipping...\\n')\n",
    "                continue\n",
    "            else:\n",
    "                print(f'\\tExecuting on machine {imach}')\n",
    "            \n",
    "            # collect communication inputs if necessary \n",
    "            # 1. collect inputs for this machine and it's current layer\n",
    "            # 2. add them to the current_tensor \n",
    "            if str(imach) in input:\n",
    "                success = split_managers[imach].process_input(input[str(imach)]) # update local tensor with inputs\n",
    "                if success == -1:\n",
    "                    print(f'\\t\\tNo comms for {imach} layer {split_managers[imach].current_layer} yet. Skipping...\\n')\n",
    "                    continue\n",
    "            \n",
    "            # execute split layers\n",
    "            output_tensor = split_managers[imach].execute_layers_until_comms()\n",
    "\n",
    "            # prep output\n",
    "            processed_output = split_managers[imach].prep_output(output_tensor) # prepare communication\n",
    "            \n",
    "            # Send output! (Append output data to proper rx machine queue)\n",
    "            for a_output in processed_output:\n",
    "                rx_mach = a_output['node_to']\n",
    "                if str(rx_mach) in output:\n",
    "                    output[str(rx_mach)].append(a_output)\n",
    "                else:\n",
    "                    output[str(rx_mach)] = [a_output]\n",
    "\n",
    "        # are machines finished executing model?\n",
    "        if all([amanager.is_done() for amanager in split_managers]):\n",
    "            # final execution time\n",
    "            tot_split_execution_time = time.time() - split_execution_start_time\n",
    "            print(f'\\n\\n############################# FINAL EXECUTION TIME {tot_split_execution_time} [seconds] #############################\\n\\n')\n",
    "            break\n",
    "\n",
    "        # check output after each communication/convolutional layer \n",
    "        all_output = [el for alist in list(output.values()) for el in alist]\n",
    "        comm_layers = np.array([adict['layer'] for adict in all_output])\n",
    "        comm_layer = np.unique(comm_layers)\n",
    "        if len(comm_layer) > 1:\n",
    "            print('ERROR: MORE THAN ONE COMM LAYER IN OUTPUT')\n",
    "            break\n",
    "        else:\n",
    "            comm_layer = int(comm_layer)\n",
    "        comm_layer_name = layer_names_fx[comm_layer]\n",
    "        \n",
    "        print(f'\\n\\n---------------------------FINISHED COMMS FOR {comm_layer_name}-----------------------------------\\n\\n')\n",
    "\n",
    "        if not comm_layer_name == 'linear':\n",
    "            # collect communicated output\n",
    "            split_model_output = SplitManager.combine_all_dict_inputs(\n",
    "                split_managers[0].get_input_size(comm_layer), \n",
    "                all_output, # TODO: assumes you can sum all outputs from the same layer \n",
    "                comm_layer, \n",
    "                device=split_managers[0].device,\n",
    "                dtype=split_managers[0].dtype)\n",
    "\n",
    "            # add current tensors stored in machines \n",
    "            for i in range(num_machines):\n",
    "                if split_managers[i].current_layer-1 == comm_layer:\n",
    "                    split_model_output = split_model_output + split_managers[i].current_tensor\n",
    "\n",
    "            # compare split vs full (truth) \n",
    "            print(f'\\nChecking split model output for {comm_layer_name}:')\n",
    "            compare_outputs_wrapper(horz_output, comm_layer, split_model_output)\n",
    "            print('\\n\\n')\n",
    "\n",
    "        # send to next layer  \n",
    "        input = output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
