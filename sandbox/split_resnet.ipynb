{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Load RESNET model and split it\\n        1. layer by layer\\n        2. [TODO] vertically \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Load RESNET model and split it\n",
    "        1. layer by layer\n",
    "        2. [TODO] vertically \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.core.engine import MoP\n",
    "from source.core import run_partition\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "from source.utils.split_network import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "from source.core.split_manager import SplitManager\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "from source.utils import testers\n",
    "from source.core import engine\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from torchsummary import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  \n",
      "model :  resnet18\n",
      "data_code :  cifar10\n",
      "num_classes :  10\n",
      "model_file :  test.pt\n",
      "epochs :  0\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  1\n",
      "admm :  True\n",
      "admm_epochs :  300\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.005\n",
      "retrain_ep :  50\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.001\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  1\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  False\n",
      "comm_outsize :  False\n",
      "lambda_comm :  0\n",
      "lambda_comp :  0\n",
      "distill_model :  \n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n"
     ]
    }
   ],
   "source": [
    "# setup config\n",
    "dataset='cifar10'\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "\n",
    "configs = run_partition.main()\n",
    "\n",
    "configs[\"device\"] = \"cpu\"\n",
    "configs['load_model'] = \"cifar10-resnet18-kernel-npv2-pr0.75-lcm0.001.pt\"\n",
    "configs[\"num_partition\"] = '4' #'resnet18-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into full model\n",
    "state_dict = torch.load(io.get_model_path(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time per data is 32.539129ms.\n",
      "conv1.weight 1024\n",
      "layer1.0.conv1.weight 1024\n",
      "layer1.0.conv2.weight 1024\n",
      "layer1.1.conv1.weight 1024\n",
      "layer1.1.conv2.weight 1024\n",
      "layer2.0.conv1.weight 256\n",
      "layer2.0.conv2.weight 256\n",
      "layer2.0.shortcut.0.weight 256\n",
      "layer2.1.conv1.weight 256\n",
      "layer2.1.conv2.weight 256\n",
      "layer3.0.conv1.weight 64\n",
      "layer3.0.conv2.weight 64\n",
      "layer3.0.shortcut.0.weight 64\n",
      "layer3.1.conv1.weight 64\n",
      "layer3.1.conv2.weight 64\n",
      "layer4.0.conv1.weight 16\n",
      "layer4.0.conv2.weight 16\n",
      "layer4.0.shortcut.0.weight 16\n",
      "layer4.1.conv1.weight 16\n",
      "layer4.1.conv2.weight 16\n",
      "['x', 'conv1', 'bn1', 'relu', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avg_pool2d', 'size', 'view', 'linear']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    add partitions and communications to configs\n",
    "'''\n",
    "\n",
    "# gets random test input (with correct size)\n",
    "input_var = engine.get_input_from_code(configs)\n",
    "#print(input_var)\n",
    "\n",
    "# Config partitions and prune_ratio\n",
    "configs = engine.partition_generator(configs, model)\n",
    "            \n",
    "# Compute collected_data_queues size of each layer\n",
    "configs['partition'] = engine.featuremap_summary(model, configs['partition'], input_var)\n",
    "\n",
    "# split model general parameters\n",
    "\n",
    "# make copies of model per machine\n",
    "num_machines = max(configs['partition']['bn_partition']) # TODO: double check this makes sense\n",
    "model_machines = [model]*num_machines\n",
    "\n",
    "layer_names_fx =  get_graph_node_names(model)[1]\n",
    "total_layers_fx = len(layer_names_fx)\n",
    "\n",
    "split_module_names = list(configs['partition'].keys())\n",
    "\n",
    "print(layer_names_fx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    IO helpers\n",
    "'''\n",
    "\n",
    "def prep_data(tensor, node, layer):\n",
    "    '''\n",
    "        Prepare input tensors to model \n",
    "    '''\n",
    "    return {\n",
    "        'node' : node,\n",
    "        'layer' : layer,\n",
    "        'tensor' : tensor, \n",
    "        'Cin' : list(get_nonzero_channels(tensor)),\n",
    "        'is_empty' : False\n",
    "    }\n",
    "\n",
    "def compare_outputs_wrapper(horz_output, comm_layer, split_model_output, limit = 0.1):\n",
    "    '''\n",
    "        Checks if output from split model is correct \n",
    "\n",
    "        return 0 if check fails and 1 if passes\n",
    "    '''\n",
    "    \n",
    "    if comm_layer == 0:\n",
    "        print(f'Input layer. Skipping comparison')\n",
    "        return 1\n",
    "    else:\n",
    "        # if reaches the end use the full model output \n",
    "        if comm_layer == len(horz_output):\n",
    "            comm_layer_name = 'x'\n",
    "        else:\n",
    "            comm_layer_name = layer_names_fx[comm_layer]\n",
    "    \n",
    "        truth_output = horz_output[comm_layer_name]\n",
    "        if torch.is_tensor(truth_output):\n",
    "            \n",
    "            max_diff, max_by_Cout = compare_outputs(split_model_output, truth_output)\n",
    "            if max_diff > 0.1:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1 \n",
    "        else:\n",
    "            print(f'Horizontal output is {type(truth_output)}. Skipping comparison')\n",
    "            return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:41 - INFO - Too few inputs for layer=2\n",
      "2024-09-15 20:31:41 - DEBUG - \t\t Collected inputs from nodes: []\n",
      "2024-09-15 20:31:41 - DEBUG - \t\t Need inputs from nodes: [2. 3.]\n",
      "2024-09-15 20:31:41 - DEBUG - Current input channels tensor([0, 1, 2])\n",
      "2024-09-15 20:31:41 - DEBUG - EXECUTED: #1-conv1\n",
      "2024-09-15 20:31:41 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 31 56 62]\n",
      "2024-09-15 20:31:41 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #2-bn1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:41 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 0\n",
      "\tExecuting on machine 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:41 - DEBUG - Machine=1, Layer to execute = 2:bn1.\n",
      "2024-09-15 20:31:41 - DEBUG - Prepping to send C_out tensor([56, 62]) to machine 3\n",
      "2024-09-15 20:31:41 - DEBUG - Current input channels tensor([0, 1, 2])\n",
      "2024-09-15 20:31:41 - DEBUG - EXECUTED: #1-conv1\n",
      "2024-09-15 20:31:41 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0 12 38 42 54 57]\n",
      "2024-09-15 20:31:41 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #2-bn1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:41 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:41 - DEBUG - Machine=2, Layer to execute = 2:bn1.\n",
      "2024-09-15 20:31:41 - DEBUG - Prepping to send C_out tensor([ 0, 12]) to machine 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:42 - DEBUG - Machine=2, Layer to execute = 2:bn1.\n",
      "2024-09-15 20:31:42 - DEBUG - Prepping to send C_out tensor([54, 57]) to machine 3\n",
      "2024-09-15 20:31:42 - DEBUG - Current input channels tensor([0, 1, 2])\n",
      "2024-09-15 20:31:42 - DEBUG - EXECUTED: #1-conv1\n",
      "2024-09-15 20:31:42 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 4  8 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 31 36 42 45 46 47 54\n",
      " 57]\n",
      "2024-09-15 20:31:42 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #2-bn1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:42 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:42 - DEBUG - Machine=3, Layer to execute = 2:bn1.\n",
      "2024-09-15 20:31:42 - DEBUG - Prepping to send C_out tensor([ 4,  8, 14]) to machine 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:42 - DEBUG - Machine=3, Layer to execute = 2:bn1.\n",
      "2024-09-15 20:31:42 - DEBUG - Prepping to send C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31]) to machine 1\n",
      "2024-09-15 20:31:42 - DEBUG - Machine=3, Layer to execute = 2:bn1.\n",
      "2024-09-15 20:31:42 - DEBUG - Prepping to send C_out tensor([36, 42, 45, 46, 47]) to machine 2\n",
      "2024-09-15 20:31:42 - DEBUG - Current input channels tensor([ 0,  4,  8, 12, 14])\n",
      "2024-09-15 20:31:42 - DEBUG - EXECUTED: #2-bn1\n",
      "2024-09-15 20:31:42 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:42 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:42 - DEBUG - Checking output from bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "2024-09-15 20:31:42 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:42 - DEBUG - Current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "2024-09-15 20:31:42 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:42 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:42 - DEBUG - Checking output from relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "2024-09-15 20:31:42 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:42 - DEBUG - Current input channels tensor([4])\n",
      "2024-09-15 20:31:42 - INFO - Saving input for later...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for conv1:\n",
      "Max diff:\n",
      " tensor([4.4409e-16], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 2.6368e-16,\n",
      "         4.4409e-16, 2.2204e-16, 3.3307e-16, 4.4409e-16, 2.4980e-16, 3.3307e-16,\n",
      "         1.7521e-16, 4.4409e-16, 4.4409e-16, 2.2204e-16, 3.3307e-16, 4.4409e-16,\n",
      "         0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-16, 0.0000e+00, 0.0000e+00, 3.7470e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0842e-19, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 42, 54, 57,\n",
      "        62])\n",
      "\n",
      "failing Cout = tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 42, 54, 57,\n",
      "        62])  (len = 19)\n",
      "passing Cout = tensor([ 0,  4,  8, 12, 14, 36, 38, 45, 46, 47, 56])  (len = 11)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:42 - DEBUG - EXECUTED: #4-layer1.0.conv1\n",
      "2024-09-15 20:31:42 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 1  3  5 12 14 18 20 24 27 28 33 35 41 44 48 57 58 59 60 63]\n",
      "2024-09-15 20:31:42 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:42 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:42 - DEBUG - Machine=0, Layer to execute = 5:layer1.0.bn1.\n",
      "2024-09-15 20:31:42 - DEBUG - Prepping to send C_out tensor([18, 20, 24, 27, 28]) to machine 1\n",
      "2024-09-15 20:31:42 - DEBUG - Machine=0, Layer to execute = 5:layer1.0.bn1.\n",
      "2024-09-15 20:31:42 - DEBUG - Prepping to send C_out tensor([33, 35, 41, 44]) to machine 2\n",
      "2024-09-15 20:31:42 - DEBUG - Machine=0, Layer to execute = 5:layer1.0.bn1.\n",
      "2024-09-15 20:31:42 - DEBUG - Prepping to send C_out tensor([48, 57, 58, 59, 60, 63]) to machine 3\n",
      "2024-09-15 20:31:42 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31])\n",
      "2024-09-15 20:31:42 - DEBUG - EXECUTED: #2-bn1\n",
      "2024-09-15 20:31:42 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:42 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:42 - DEBUG - Checking output from bn1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "2024-09-15 20:31:42 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:42 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "2024-09-15 20:31:42 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:42 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:42 - DEBUG - Checking output from relu C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "2024-09-15 20:31:42 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:42 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31])\n",
      "2024-09-15 20:31:42 - INFO - Saving input for later...\n",
      "2024-09-15 20:31:42 - DEBUG - EXECUTED: #4-layer1.0.conv1\n",
      "2024-09-15 20:31:42 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:42 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:42 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:43 - DEBUG - Machine=1, Layer to execute = 5:layer1.0.bn1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:43 - DEBUG - Prepping to send C_out tensor([ 0,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "2024-09-15 20:31:43 - DEBUG - Machine=1, Layer to execute = 5:layer1.0.bn1.\n",
      "2024-09-15 20:31:43 - DEBUG - Prepping to send C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "2024-09-15 20:31:43 - DEBUG - Machine=1, Layer to execute = 5:layer1.0.bn1.\n",
      "2024-09-15 20:31:43 - DEBUG - Prepping to send C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "2024-09-15 20:31:43 - DEBUG - Current input channels tensor([36, 38, 42, 45, 46, 47])\n",
      "2024-09-15 20:31:43 - DEBUG - EXECUTED: #2-bn1\n",
      "2024-09-15 20:31:43 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:43 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:43 - DEBUG - Checking output from bn1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "2024-09-15 20:31:43 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:43 - DEBUG - Current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "2024-09-15 20:31:43 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:43 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:43 - DEBUG - Checking output from relu C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "2024-09-15 20:31:43 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:43 - DEBUG - Current input channels tensor([], dtype=torch.int64)\n",
      "2024-09-15 20:31:43 - INFO - Saving input for later...\n",
      "2024-09-15 20:31:43 - DEBUG - EXECUTED: #4-layer1.0.conv1\n",
      "2024-09-15 20:31:43 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[]\n",
      "2024-09-15 20:31:43 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:43 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:43 - DEBUG - Current input channels tensor([54, 56, 57, 62])\n",
      "2024-09-15 20:31:43 - DEBUG - EXECUTED: #2-bn1\n",
      "2024-09-15 20:31:43 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:43 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #3-relu; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:43 - DEBUG - Checking output from bn1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "2024-09-15 20:31:43 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:43 - DEBUG - Current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "2024-09-15 20:31:43 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:43 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #4-layer1.0.conv1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:43 - DEBUG - Checking output from relu C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "2024-09-15 20:31:43 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:43 - DEBUG - Current input channels tensor([54, 57])\n",
      "2024-09-15 20:31:43 - INFO - Saving input for later...\n",
      "2024-09-15 20:31:43 - DEBUG - EXECUTED: #4-layer1.0.conv1\n",
      "2024-09-15 20:31:43 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  1  4  5 10 11 13 14 16 19 21 25 30 32 33 36 38 39 41 42 44 45 46 47\n",
      " 51]\n",
      "2024-09-15 20:31:43 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #5-layer1.0.bn1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:43 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:43 - DEBUG - Machine=3, Layer to execute = 5:layer1.0.bn1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:43 - DEBUG - Prepping to send C_out tensor([ 0,  1,  4,  5, 10, 11, 13, 14]) to machine 0\n",
      "2024-09-15 20:31:43 - DEBUG - Machine=3, Layer to execute = 5:layer1.0.bn1.\n",
      "2024-09-15 20:31:43 - DEBUG - Prepping to send C_out tensor([16, 19, 21, 25, 30]) to machine 1\n",
      "2024-09-15 20:31:43 - DEBUG - Machine=3, Layer to execute = 5:layer1.0.bn1.\n",
      "2024-09-15 20:31:43 - DEBUG - Prepping to send C_out tensor([32, 33, 36, 38, 39, 41, 42, 44, 45, 46, 47]) to machine 2\n",
      "2024-09-15 20:31:44 - DEBUG - Current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "2024-09-15 20:31:44 - DEBUG - EXECUTED: #5-layer1.0.bn1\n",
      "2024-09-15 20:31:44 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:44 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:44 - DEBUG - Checking output from layer1.0.bn1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "2024-09-15 20:31:44 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:44 - DEBUG - Current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "2024-09-15 20:31:44 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:44 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:44 - DEBUG - Checking output from layer1.0.relu C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "2024-09-15 20:31:44 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:44 - DEBUG - Current input channels tensor([], dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer1.0.conv1-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer1.0.conv1:\n",
      "Max diff:\n",
      " tensor([2.6645e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.3368e-19, 1.5247e-19, 4.3368e-19, 3.2526e-19, 8.1315e-20, 4.3368e-19,\n",
      "         6.5052e-19, 4.3368e-19, 6.5052e-19, 4.3368e-19, 6.5052e-19, 4.3368e-19,\n",
      "         4.3368e-19, 1.0842e-19, 4.3368e-19, 1.8974e-19, 1.1102e-15, 1.7764e-15,\n",
      "         1.1102e-15, 2.6645e-15, 1.1102e-15, 1.3323e-15, 1.3323e-15, 1.5543e-15,\n",
      "         1.3323e-15, 1.1102e-15, 1.1102e-15, 6.6613e-16, 6.6613e-16, 9.9920e-16,\n",
      "         1.7764e-15, 6.6613e-16, 4.3368e-19, 1.8974e-19, 3.2526e-19, 5.4210e-19,\n",
      "         6.5052e-19, 3.2526e-19, 8.6736e-19, 3.2526e-19, 3.2526e-19, 6.5052e-19,\n",
      "         4.3368e-19, 4.3368e-19, 5.4210e-19, 3.2526e-19, 3.2526e-19, 2.1684e-19,\n",
      "         2.7105e-19, 4.3368e-19, 1.6263e-19, 1.3878e-17, 3.2526e-19, 3.2526e-19,\n",
      "         2.1684e-19, 1.3553e-19, 1.0842e-19, 4.3368e-19, 2.1684e-19, 4.3368e-19,\n",
      "         1.3553e-19, 5.4210e-19, 5.4210e-20, 2.1684e-19]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:44 - DEBUG - EXECUTED: #7-layer1.0.conv2\n",
      "2024-09-15 20:31:44 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[]\n",
      "2024-09-15 20:31:44 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:44 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:44 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "2024-09-15 20:31:44 - DEBUG - EXECUTED: #5-layer1.0.bn1\n",
      "2024-09-15 20:31:44 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:44 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:44 - DEBUG - Checking output from layer1.0.bn1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "2024-09-15 20:31:44 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:44 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "2024-09-15 20:31:44 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:44 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:44 - DEBUG - Checking output from layer1.0.relu C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "2024-09-15 20:31:44 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:44 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:44 - DEBUG - EXECUTED: #7-layer1.0.conv2\n",
      "2024-09-15 20:31:44 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:44 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:44 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:44 - DEBUG - Machine=1, Layer to execute = 8:layer1.0.bn2.\n",
      "2024-09-15 20:31:44 - DEBUG - Prepping to send C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "2024-09-15 20:31:45 - DEBUG - Machine=1, Layer to execute = 8:layer1.0.bn2.\n",
      "2024-09-15 20:31:45 - DEBUG - Prepping to send C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "2024-09-15 20:31:45 - DEBUG - Machine=1, Layer to execute = 8:layer1.0.bn2.\n",
      "2024-09-15 20:31:45 - DEBUG - Prepping to send C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "2024-09-15 20:31:45 - DEBUG - Current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "2024-09-15 20:31:45 - DEBUG - EXECUTED: #5-layer1.0.bn1\n",
      "2024-09-15 20:31:45 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:45 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:45 - DEBUG - Checking output from layer1.0.bn1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "2024-09-15 20:31:45 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:45 - DEBUG - Current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "2024-09-15 20:31:45 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:45 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:45 - DEBUG - Checking output from layer1.0.relu C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "2024-09-15 20:31:45 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:45 - DEBUG - Current input channels tensor([], dtype=torch.int64)\n",
      "2024-09-15 20:31:45 - DEBUG - EXECUTED: #7-layer1.0.conv2\n",
      "2024-09-15 20:31:45 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[]\n",
      "2024-09-15 20:31:45 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:45 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:45 - DEBUG - Current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "2024-09-15 20:31:45 - DEBUG - EXECUTED: #5-layer1.0.bn1\n",
      "2024-09-15 20:31:45 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:45 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #6-layer1.0.relu; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:45 - DEBUG - Checking output from layer1.0.bn1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "2024-09-15 20:31:45 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:45 - DEBUG - Current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "2024-09-15 20:31:45 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:45 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #7-layer1.0.conv2; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:45 - DEBUG - Checking output from layer1.0.relu C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "2024-09-15 20:31:45 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:45 - DEBUG - Current input channels tensor([], dtype=torch.int64)\n",
      "2024-09-15 20:31:45 - DEBUG - EXECUTED: #7-layer1.0.conv2\n",
      "2024-09-15 20:31:45 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[]\n",
      "2024-09-15 20:31:45 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #8-layer1.0.bn2; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:45 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "2024-09-15 20:31:46 - DEBUG - EXECUTED: #8-layer1.0.bn2\n",
      "2024-09-15 20:31:46 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.bn2 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "2024-09-15 20:31:46 - INFO - Adding residual\n",
      "2024-09-15 20:31:46 - INFO - Assuming shortcut had no layers\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.add C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "2024-09-15 20:31:46 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.relu_1 C_in [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([], dtype=torch.int64)\n",
      "2024-09-15 20:31:46 - INFO - Saving input for later...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------FINISHED COMMS FOR layer1.0.conv2-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Checking split model output for layer1.0.conv2:\n",
      "Max diff:\n",
      " tensor([2.6645e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.5052e-19, 1.0842e-18, 9.7578e-19, 8.6736e-19, 8.8818e-16, 1.1520e-19,\n",
      "         3.2526e-19, 4.8789e-19, 5.5511e-17, 1.0842e-18, 2.7756e-16, 7.5894e-19,\n",
      "         3.2526e-19, 5.6921e-19, 1.6653e-16, 6.5052e-19, 9.9920e-16, 1.1102e-15,\n",
      "         2.2204e-15, 1.9984e-15, 1.7764e-15, 1.3323e-15, 8.8818e-16, 8.8818e-16,\n",
      "         1.3323e-15, 2.2204e-15, 2.6645e-15, 1.7764e-15, 4.4409e-16, 1.1102e-15,\n",
      "         0.0000e+00, 9.4369e-16, 4.1633e-17, 4.6079e-19, 4.3368e-19, 8.6736e-19,\n",
      "         7.2164e-16, 9.7578e-19, 5.4210e-19, 3.2526e-19, 9.7578e-19, 6.5052e-19,\n",
      "         2.7756e-17, 8.6736e-18, 8.6736e-19, 7.5894e-19, 2.7756e-17, 2.7756e-17,\n",
      "         5.4210e-19, 3.7947e-19, 8.6736e-19, 6.5052e-19, 1.7347e-17, 4.3368e-19,\n",
      "         5.5511e-16, 7.5894e-19, 1.3010e-18, 8.8818e-16, 8.6736e-19, 5.9631e-19,\n",
      "         6.5052e-19, 8.6736e-19, 8.1315e-19, 9.2157e-19]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 63)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "\n",
      "\n",
      "\tExecuting on machine 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:46 - DEBUG - EXECUTED: #11-layer1.1.conv1\n",
      "2024-09-15 20:31:46 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[]\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "2024-09-15 20:31:46 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31])\n",
      "2024-09-15 20:31:46 - DEBUG - EXECUTED: #8-layer1.0.bn2\n",
      "2024-09-15 20:31:46 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.bn2 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "2024-09-15 20:31:46 - INFO - Adding residual\n",
      "2024-09-15 20:31:46 - INFO - Assuming shortcut had no layers\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.add C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "2024-09-15 20:31:46 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.relu_1 C_in [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31])\n",
      "2024-09-15 20:31:46 - INFO - Saving input for later...\n",
      "2024-09-15 20:31:46 - DEBUG - EXECUTED: #11-layer1.1.conv1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:46 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "2024-09-15 20:31:46 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:46 - DEBUG - Machine=1, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:46 - DEBUG - Prepping to send C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "2024-09-15 20:31:46 - DEBUG - Machine=1, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:46 - DEBUG - Prepping to send C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "2024-09-15 20:31:46 - DEBUG - Machine=1, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:46 - DEBUG - Prepping to send C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "2024-09-15 20:31:46 - DEBUG - EXECUTED: #8-layer1.0.bn2\n",
      "2024-09-15 20:31:46 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.bn2 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "2024-09-15 20:31:46 - INFO - Adding residual\n",
      "2024-09-15 20:31:46 - INFO - Assuming shortcut had no layers\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.add C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "2024-09-15 20:31:46 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:46 - DEBUG - Current input channels tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])\n",
      "2024-09-15 20:31:46 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:46 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:46 - DEBUG - Checking output from layer1.0.relu_1 C_in [32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]: \n",
      "2024-09-15 20:31:47 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:47 - DEBUG - Current input channels tensor([36])\n",
      "2024-09-15 20:31:47 - INFO - Saving input for later...\n",
      "2024-09-15 20:31:47 - DEBUG - EXECUTED: #11-layer1.1.conv1\n",
      "2024-09-15 20:31:47 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 0  2  4  5 10 13 19 20 21 22 24 30 39 42 44 45 49 61 62]\n",
      "2024-09-15 20:31:47 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "2024-09-15 20:31:47 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:47 - DEBUG - Machine=2, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:47 - DEBUG - Prepping to send C_out tensor([ 0,  2,  4,  5, 10, 13]) to machine 0\n",
      "2024-09-15 20:31:47 - DEBUG - Machine=2, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:47 - DEBUG - Prepping to send C_out tensor([19, 20, 21, 22, 24, 30]) to machine 1\n",
      "2024-09-15 20:31:47 - DEBUG - Machine=2, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:47 - DEBUG - Prepping to send C_out tensor([49, 61, 62]) to machine 3\n",
      "2024-09-15 20:31:47 - DEBUG - Current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "2024-09-15 20:31:47 - DEBUG - EXECUTED: #8-layer1.0.bn2\n",
      "2024-09-15 20:31:47 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:47 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #9-layer1.0.add; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:47 - DEBUG - Checking output from layer1.0.bn2 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "2024-09-15 20:31:47 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:47 - DEBUG - Current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "2024-09-15 20:31:47 - INFO - Adding residual\n",
      "2024-09-15 20:31:47 - INFO - Assuming shortcut had no layers\n",
      "2024-09-15 20:31:47 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #10-layer1.0.relu_1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:47 - DEBUG - Checking output from layer1.0.add C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "2024-09-15 20:31:47 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:47 - DEBUG - Current input channels tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "2024-09-15 20:31:47 - INFO - Applying ReLU\n",
      "2024-09-15 20:31:47 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #11-layer1.1.conv1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:47 - DEBUG - Checking output from layer1.0.relu_1 C_in [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]: \n",
      "2024-09-15 20:31:47 - DEBUG - \n",
      "\n",
      "\n",
      "2024-09-15 20:31:47 - DEBUG - Current input channels tensor([54, 57])\n",
      "2024-09-15 20:31:47 - INFO - Saving input for later...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting on machine 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:31:47 - DEBUG - EXECUTED: #11-layer1.1.conv1\n",
      "2024-09-15 20:31:47 - DEBUG - SPLIT OUTPUT: Shape=[1, 64, 32, 32]; C_out=[ 1  2  3  4  5  6 10 11 22 23 24 30 35 39 41 42 54 56 61]\n",
      "2024-09-15 20:31:47 - DEBUG - INITIALIZING CURRENT TENSOR FOR: #12-layer1.1.bn1; Shape=[1, 64, 32, 32]; C_in=[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "2024-09-15 20:31:47 - DEBUG - \t\tOutput tensor shape : torch.Size([1, 64, 32, 32])\n",
      "2024-09-15 20:31:47 - DEBUG - Machine=3, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:47 - DEBUG - Prepping to send C_out tensor([ 1,  2,  3,  4,  5,  6, 10, 11]) to machine 0\n",
      "2024-09-15 20:31:47 - DEBUG - Machine=3, Layer to execute = 12:layer1.1.bn1.\n",
      "2024-09-15 20:31:47 - DEBUG - Prepping to send C_out tensor([22, 23, 24, 30]) to machine 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# always send output unless on final layer\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m split_managers[imach]\u001b[38;5;241m.\u001b[39mcurrent_layer \u001b[38;5;241m==\u001b[39m split_managers[imach]\u001b[38;5;241m.\u001b[39mtotal_layers_fx:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# prep output\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     processed_output \u001b[38;5;241m=\u001b[39m \u001b[43msplit_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimach\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_tensor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# prepare communication\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# Send output! (Append output data to proper rx machine queue)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a_output \u001b[38;5;129;01min\u001b[39;00m processed_output:\n",
      "File \u001b[1;32mc:\\Users\\natet\\Desktop\\graduate school\\thesis\\CaP\\source\\core\\split_manager.py:443\u001b[0m, in \u001b[0;36mSplitManager.prep_output\u001b[1;34m(self, out_tensor)\u001b[0m\n\u001b[0;32m    439\u001b[0m all_output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rx_mach \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_machines): \u001b[38;5;66;03m# TODO: change implementation to only consider parent nodes\u001b[39;00m\n\u001b[0;32m    441\u001b[0m     \n\u001b[0;32m    442\u001b[0m     \u001b[38;5;66;03m# only send message if rx_mach expects communication from this machine\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmachine \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_comms_for_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrx_mach\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_layer\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# init output dict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\natet\\Desktop\\graduate school\\thesis\\CaP\\source\\core\\split_manager.py:353\u001b[0m, in \u001b[0;36mSplitManager.expected_comms_for_layer\u001b[1;34m(self, network_node, layer)\u001b[0m\n\u001b[0;32m    351\u001b[0m output_channels_for_machine \u001b[38;5;241m=\u001b[39m cout_map[network_node]\n\u001b[0;32m    352\u001b[0m curr_layer \u001b[38;5;241m=\u001b[39m split_network\u001b[38;5;241m.\u001b[39mget_current_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, conv_layer)\n\u001b[1;32m--> 353\u001b[0m corresponding_input_channels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_channels_for_machine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m tx_nodes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_machines):\n",
      "File \u001b[1;32mc:\\Users\\natet\\anaconda3\\envs\\cap_nb\\lib\\site-packages\\torch\\_jit_internal.py:485\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\natet\\anaconda3\\envs\\cap_nb\\lib\\site-packages\\torch\\_jit_internal.py:485\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\natet\\anaconda3\\envs\\cap_nb\\lib\\site-packages\\torch\\functional.py:877\u001b[0m, in \u001b[0;36m_return_output\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[1;32m--> 877\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\natet\\anaconda3\\envs\\cap_nb\\lib\\site-packages\\torch\\functional.py:791\u001b[0m, in \u001b[0;36m_unique_impl\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    783\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    785\u001b[0m         dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[0;32m    789\u001b[0m     )\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 791\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' Prep Inout for Mock Run version 2 (fx)'''\n",
    "\n",
    "# TODO: reduce size of communicated tensors to only what is necessary \n",
    "# TODO: also check bias for nonzero\n",
    "# TODO: implement broadcast vs multi-cast? switch e.g. a single machine broadcasts outputs because weights that reach across layers are executed on the rx machine only \n",
    "# TODO: handle arbitrary kernel to machine assignment \n",
    "\n",
    "# channel_id == INPUTS\n",
    "# filter_id  == OUTPUTS\n",
    "\n",
    "configs_copy = configs # keep the origonal config \n",
    "\n",
    "# setup input \n",
    "N_batch = 1\n",
    "torch.manual_seed(0)\n",
    "input_tensor = torch.rand(N_batch, 3, 32, 32, dtype=torch.float64, device=torch.device(configs_copy['device'])) # 1k images, 3 channels, 32x32 image (cifar100) \n",
    "model = model.type(torch.float64)\n",
    "\n",
    "# add some extra logic to handle final splitting of layer \n",
    "final_node = 0\n",
    "\n",
    "# make SplitManagers for split model execution \n",
    "debug = True\n",
    "configs_copy['dtype'] = 'float64'\n",
    "split_managers = [SplitManager]*num_machines\n",
    "for i in range(num_machines):\n",
    "    split_managers[i] = SplitManager(configs_copy, i, num_machines, input_tensor, final_node, debug=True)\n",
    "\n",
    "# emulates queue that server collects inputs with. \n",
    "# Each network node has it's own list of inputs it looks at when collecting inputs \n",
    "# input :\n",
    "#   [rx node (str)] : (list) list of data dicts \n",
    "# Write outputs to one big queue with everyone's data in it \n",
    "collected_data_queues = {}\n",
    "for i in range(num_machines):\n",
    "    in_data = prep_data(input_tensor, -1, 0)\n",
    "    if split_managers[i].current_layer == 1:\n",
    "        collected_data_queues[str(i)] =  [in_data]\n",
    "    else:\n",
    "        collected_data_queues[str(i)] = []\n",
    "\n",
    "# put models into eval mode and on device\n",
    "model.eval()\n",
    "model.to(configs['device'])\n",
    "\n",
    "# get true output at each layer\n",
    "# WARNING: bn layers are initialized differently between model in this notebook and model in split manager. The moving mean and variance fields do not match HOWEVER the weights and biases are the same\n",
    "#horz_output, layer_output_size_LUT = get_output_at_each_layer(model, input_tensor) \n",
    "horz_output, layer_output_size_LUT = get_output_at_each_layer(split_managers[0].model, input_tensor)\n",
    "\n",
    "'''\n",
    "    mock run through inference using split models \n",
    "'''\n",
    "\n",
    "# timing\n",
    "split_execution_start_time = time.time()\n",
    "layer_completion_time_stamp = {}\n",
    "layer_execution_duration = {}\n",
    "\n",
    "# make inference \n",
    "with torch.no_grad():\n",
    "\n",
    "    # iterate through layers 1 module at a time \n",
    "    while True:#range(num_total_modules): # 16 <=> layer_1 block \n",
    "\n",
    "        # iterate through each machine (done in parallel later)\n",
    "        for imach in range(num_machines):\n",
    "\n",
    "            if split_managers[imach].is_done():\n",
    "                print(f'\\tMachine {split_managers[imach].machine} has finished calculations. Skipping...\\n')\n",
    "                continue\n",
    "            else:\n",
    "                print(f'\\tExecuting on machine {imach}')\n",
    "            \n",
    "            # collect communication inputs if necessary \n",
    "            # 1. collect inputs for this machine and it's current layer\n",
    "            # 2. add them to the current_tensor \n",
    "            enough_input = split_managers[imach].process_input(collected_data_queues[str(imach)]) # update local tensor with inputs\n",
    "            if enough_input:\n",
    "                \n",
    "                # execute split layers\n",
    "                output_tensor = split_managers[imach].execute_layers_until_comms()\n",
    "\n",
    "                # always send output unless on final layer\n",
    "                if not split_managers[imach].current_layer == split_managers[imach].total_layers_fx:\n",
    "                    # prep output\n",
    "                    processed_output = split_managers[imach].prep_output(output_tensor) # prepare communication\n",
    "                    \n",
    "                    # Send output! (Append output data to proper rx machine queue)\n",
    "                    for a_output in processed_output:\n",
    "                        rx_mach = a_output['node_to']\n",
    "                        collected_data_queues[str(rx_mach)].append(a_output)\n",
    "\n",
    "        # are machines finished executing model?\n",
    "        if all([amanager.is_done() for amanager in split_managers]):\n",
    "            # final execution time\n",
    "            tot_split_execution_time = time.time() - split_execution_start_time\n",
    "            print(f'\\n\\n############################# FINAL EXECUTION TIME {tot_split_execution_time} [seconds] #############################\\n\\n')\n",
    "            break\n",
    "\n",
    "        # collect all output in one array \n",
    "        all_output = [el for alist in list(collected_data_queues.values()) for el in alist]\n",
    "\n",
    "        # find lowest communication layer that machines are waiting on \n",
    "        comm_layer = -1\n",
    "        for node in range(num_machines):\n",
    "            node_comm_layer = split_managers[node].current_layer -1\n",
    "            if comm_layer == -1:\n",
    "                comm_layer = node_comm_layer\n",
    "            elif node_comm_layer < comm_layer:\n",
    "                comm_layer = node_comm_layer\n",
    "        comm_layer_name = layer_names_fx[comm_layer]\n",
    "        \n",
    "        print(f'\\n\\n---------------------------FINISHED COMMS FOR {comm_layer_name}-----------------------------------\\n\\n')\n",
    "\n",
    "        if not comm_layer_name == 'linear':\n",
    "            # collect communicated output\n",
    "            split_model_output = SplitManager.combine_all_dict_inputs(\n",
    "                split_managers[0].get_input_size(comm_layer), \n",
    "                all_output, # TODO: assumes you can sum all outputs from the same layer \n",
    "                comm_layer, \n",
    "                device=split_managers[0].device,\n",
    "                dtype=split_managers[0].dtype)\n",
    "\n",
    "            # add current tensors stored in machines \n",
    "            for i in range(num_machines):\n",
    "                if split_managers[i].current_layer-1 == comm_layer:\n",
    "                    split_model_output = split_model_output + split_managers[i].current_tensor\n",
    "\n",
    "            # compare split vs full (truth) \n",
    "            print(f'\\nChecking split model output for {comm_layer_name}:')\n",
    "            compare_outputs_wrapper(horz_output, comm_layer, split_model_output)\n",
    "            print('\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication for layer1.0.bn1 layer:\n",
      "\tNode=0, rx:[1. 2. 3.]\n",
      "\tNode=1, rx:[0.]\n",
      "\tNode=2, rx:[0. 1. 3.]\n",
      "\tNode=3, rx:[0. 2.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer = 5\n",
    "machine = 1\n",
    "\n",
    "print(f'Communication for {split_managers[machine].get_layer_name(layer)} layer:')\n",
    "for i in range(num_machines):\n",
    "    tx_nodes = split_managers[i].expected_comms_for_layer(i, layer)\n",
    "    print(f'\\tNode={i}, rx:{tx_nodes}')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fucntion 70, field 70\n",
      "fucntion 69, field 69\n",
      "fucntion 69, field 69\n",
      "fucntion 69, field 69\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_machines):\n",
    "    ending_layer = split_managers[i].get_machine_ending_layer()\n",
    "    field_ending = split_managers[i].final_layer\n",
    "    print(f'fucntion {ending_layer}, field {ending_layer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_managers[0].final_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
