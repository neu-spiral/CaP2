{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Load model and split it\\n        1. layer by layer\\n        2. [TODO] vertically \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Load model and split it\n",
    "        1. layer by layer\n",
    "        2. [TODO] vertically \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.core.engine import MoP\n",
    "import source.core.run_partition as run_p\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "from source.utils.split_network import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "from source.core.split_manager_old import SplitManager\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "from source.utils import testers\n",
    "from source.core import engine\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model\n",
    "\n",
    "# model = 'resnet18'\n",
    "# dataset = 'cifar10'\n",
    "\n",
    "# model = 'wrn28_10'\n",
    "dataset = 'cifar100'\n",
    "\n",
    "# model = 'EscFusion'\n",
    "# dataset = 'esc'\n",
    "\n",
    "# model = 'InfoFusionThree'\n",
    "# dataset = 'flash'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# yaml_version = 'v0'\n",
    "# num_partitions = 4\n",
    "# prune_ratio = 0.75\n",
    "\n",
    "# yaml_version = 'v1'\n",
    "# yaml_version = 'v2'\n",
    "# yaml_version = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda:0\n",
      "model :  resnet101\n",
      "data_code :  cifar100\n",
      "num_classes :  100\n",
      "epochs :  300\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  0.5\n",
      "admm :  True\n",
      "admm_epochs :  300\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.001\n",
      "retrain_ep :  100\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.01\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  4\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  True\n",
      "comm_outsize :  True\n",
      "lambda_comm :  0.0001\n",
      "lambda_comp :  0\n",
      "create_partition :  False\n",
      "load_dense_model :  True\n",
      "load_pruned_model :  False\n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n",
      "load_pruned_model_file :  cifar100-resnet101-kernel-np4-pr0.5-lcm0.0001.pt\n",
      "partition_path :  config/resnet101-np4.yaml\n",
      "load_dense_model_file :  cifar100-resnet101.pt\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "configs = run_p.main()\n",
    "\n",
    "load_model = f\"{configs['data_code']}-{configs['model']}-{configs['sparsity_type']}-np{configs['num_partition']}-pr{configs['prune_ratio']}-lcm{configs['lambda_comm']}.pt\"\n",
    "\n",
    "# configs = {}\n",
    "# configs[\"num_classes\"] = num_classes\n",
    "# configs[\"data_code\"] = dataset\n",
    "# configs[\"layer_type\"] = layer_type\n",
    "# configs[\"bn_type\"] = bn_type\n",
    "# configs[\"model\"] = model\n",
    "# configs[\"prune_ratio\"] = prune_ratio\n",
    "# configs[\"seed\"] = 1234\n",
    "# configs[\"model_file\"] = load_model\n",
    "\n",
    "# if model == 'resnet18':\n",
    "#     dataset='cifar10'\n",
    "#     load_model = f\"cifar10-resnet18-kernel-np{num_partitions}-pr{prune_ratio}-lcm0.001.pt\"\n",
    "#     num_classes = 10\n",
    "#     layer_type = 'regular'\n",
    "#     bn_type = 'masked'\n",
    "#     model = 'resnet18'\n",
    "# elif model == 'EscFusion':\n",
    "#     dataset='esc'\n",
    "#     load_model = f\"esc-escnet-kernel-np{num_partitions}-pr{prune_ratio}-lcm0.001.pt\"\n",
    "#     num_classes = 2\n",
    "#     layer_type = 'regular'\n",
    "#     bn_type = 'regular'\n",
    "#     model = 'EscFusion'\n",
    "# elif model == 'InfoFusionThree':\n",
    "#     dataset='flash'\n",
    "#     load_model = f\"flash-flashnet-kernel-np{num_partitions}-pr{prune_ratio}-lcm0.001.pt\"\n",
    "# elif model == 'wrn28_10':\n",
    "#     dataset='cifar100'\n",
    "#     load_model = f\"cifar100-wrn28-kernel-np{num_partitions}-pr{prune_ratio}-lcm0.001.pt\"\n",
    "#     num_classes = 100\n",
    "#     layer_type = 'regular'\n",
    "#     bn_type = 'masked'\n",
    "#     model = 'wrn28_10'\n",
    "    \n",
    "\n",
    "configs[\"device\"] = \"cpu\"\n",
    "configs['load_model'] = load_model\n",
    "\n",
    "# if yaml_version == 'v0':\n",
    "#     configs['num_partition'] = num_partitions\n",
    "# else:\n",
    "#     if model == 'resnet18':\n",
    "#         configs[\"num_partition\"] = f'config/resnet18-{yaml_version}.yaml'\n",
    "#     elif model == 'EscFusion':\n",
    "#         configs[\"num_partition\"] = f'config/escnet-{yaml_version}.yaml'\n",
    "#     elif model == 'InfoFusionThree':\n",
    "#         configs[\"num_partition\"] = f'config/flashnet.yaml'\n",
    "#     elif model == 'wrn28_10':\n",
    "#         configs[\"num_partition\"] = f'config/wrn28-{yaml_version}.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (19): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (20): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (21): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (22): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (out): Linear(in_features=512, out_features=100, bias=True)\n",
      ")\n",
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.shortcut.0.weight\n",
      "layer2.0.shortcut.1.weight\n",
      "layer2.0.shortcut.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.shortcut.0.weight\n",
      "layer3.0.shortcut.1.weight\n",
      "layer3.0.shortcut.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.6.conv1.weight\n",
      "layer3.6.conv2.weight\n",
      "layer3.6.bn1.weight\n",
      "layer3.6.bn1.bias\n",
      "layer3.6.bn2.weight\n",
      "layer3.6.bn2.bias\n",
      "layer3.7.conv1.weight\n",
      "layer3.7.conv2.weight\n",
      "layer3.7.bn1.weight\n",
      "layer3.7.bn1.bias\n",
      "layer3.7.bn2.weight\n",
      "layer3.7.bn2.bias\n",
      "layer3.8.conv1.weight\n",
      "layer3.8.conv2.weight\n",
      "layer3.8.bn1.weight\n",
      "layer3.8.bn1.bias\n",
      "layer3.8.bn2.weight\n",
      "layer3.8.bn2.bias\n",
      "layer3.9.conv1.weight\n",
      "layer3.9.conv2.weight\n",
      "layer3.9.bn1.weight\n",
      "layer3.9.bn1.bias\n",
      "layer3.9.bn2.weight\n",
      "layer3.9.bn2.bias\n",
      "layer3.10.conv1.weight\n",
      "layer3.10.conv2.weight\n",
      "layer3.10.bn1.weight\n",
      "layer3.10.bn1.bias\n",
      "layer3.10.bn2.weight\n",
      "layer3.10.bn2.bias\n",
      "layer3.11.conv1.weight\n",
      "layer3.11.conv2.weight\n",
      "layer3.11.bn1.weight\n",
      "layer3.11.bn1.bias\n",
      "layer3.11.bn2.weight\n",
      "layer3.11.bn2.bias\n",
      "layer3.12.conv1.weight\n",
      "layer3.12.conv2.weight\n",
      "layer3.12.bn1.weight\n",
      "layer3.12.bn1.bias\n",
      "layer3.12.bn2.weight\n",
      "layer3.12.bn2.bias\n",
      "layer3.13.conv1.weight\n",
      "layer3.13.conv2.weight\n",
      "layer3.13.bn1.weight\n",
      "layer3.13.bn1.bias\n",
      "layer3.13.bn2.weight\n",
      "layer3.13.bn2.bias\n",
      "layer3.14.conv1.weight\n",
      "layer3.14.conv2.weight\n",
      "layer3.14.bn1.weight\n",
      "layer3.14.bn1.bias\n",
      "layer3.14.bn2.weight\n",
      "layer3.14.bn2.bias\n",
      "layer3.15.conv1.weight\n",
      "layer3.15.conv2.weight\n",
      "layer3.15.bn1.weight\n",
      "layer3.15.bn1.bias\n",
      "layer3.15.bn2.weight\n",
      "layer3.15.bn2.bias\n",
      "layer3.16.conv1.weight\n",
      "layer3.16.conv2.weight\n",
      "layer3.16.bn1.weight\n",
      "layer3.16.bn1.bias\n",
      "layer3.16.bn2.weight\n",
      "layer3.16.bn2.bias\n",
      "layer3.17.conv1.weight\n",
      "layer3.17.conv2.weight\n",
      "layer3.17.bn1.weight\n",
      "layer3.17.bn1.bias\n",
      "layer3.17.bn2.weight\n",
      "layer3.17.bn2.bias\n",
      "layer3.18.conv1.weight\n",
      "layer3.18.conv2.weight\n",
      "layer3.18.bn1.weight\n",
      "layer3.18.bn1.bias\n",
      "layer3.18.bn2.weight\n",
      "layer3.18.bn2.bias\n",
      "layer3.19.conv1.weight\n",
      "layer3.19.conv2.weight\n",
      "layer3.19.bn1.weight\n",
      "layer3.19.bn1.bias\n",
      "layer3.19.bn2.weight\n",
      "layer3.19.bn2.bias\n",
      "layer3.20.conv1.weight\n",
      "layer3.20.conv2.weight\n",
      "layer3.20.bn1.weight\n",
      "layer3.20.bn1.bias\n",
      "layer3.20.bn2.weight\n",
      "layer3.20.bn2.bias\n",
      "layer3.21.conv1.weight\n",
      "layer3.21.conv2.weight\n",
      "layer3.21.bn1.weight\n",
      "layer3.21.bn1.bias\n",
      "layer3.21.bn2.weight\n",
      "layer3.21.bn2.bias\n",
      "layer3.22.conv1.weight\n",
      "layer3.22.conv2.weight\n",
      "layer3.22.bn1.weight\n",
      "layer3.22.bn1.bias\n",
      "layer3.22.bn2.weight\n",
      "layer3.22.bn2.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.shortcut.0.weight\n",
      "layer4.0.shortcut.1.weight\n",
      "layer4.0.shortcut.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into full model\n",
    "state_dict = torch.load(io.get_model_path_split(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name)\n",
    "#     print(param.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_partition: {'conv1.weight': 4, 'inputs': 4, 'layer1.0.conv1.weight': 4, 'layer1.0.conv2.weight': 4, 'layer1.1.conv1.weight': 4, 'layer1.1.conv2.weight': 4, 'layer1.2.conv1.weight': 4, 'layer1.2.conv2.weight': 4, 'layer2.0.conv1.weight': 4, 'layer2.0.conv2.weight': 4, 'layer2.0.shortcut.0.weight': 4, 'layer2.1.conv1.weight': 4, 'layer2.1.conv2.weight': 4, 'layer2.2.conv1.weight': 4, 'layer2.2.conv2.weight': 4, 'layer2.3.conv1.weight': 4, 'layer2.3.conv2.weight': 4, 'layer3.0.conv1.weight': 4, 'layer3.0.conv2.weight': 4, 'layer3.0.shortcut.0.weight': 4, 'layer3.1.conv1.weight': 4, 'layer3.1.conv2.weight': 4, 'layer3.10.conv1.weight': 4, 'layer3.10.conv2.weight': 4, 'layer3.11.conv1.weight': 4, 'layer3.11.conv2.weight': 4, 'layer3.12.conv1.weight': 4, 'layer3.12.conv2.weight': 4, 'layer3.13.conv1.weight': 4, 'layer3.13.conv2.weight': 4, 'layer3.14.conv1.weight': 4, 'layer3.14.conv2.weight': 4, 'layer3.15.conv1.weight': 4, 'layer3.15.conv2.weight': 4, 'layer3.16.conv1.weight': 4, 'layer3.16.conv2.weight': 4, 'layer3.17.conv1.weight': 4, 'layer3.17.conv2.weight': 4, 'layer3.18.conv1.weight': 4, 'layer3.18.conv2.weight': 4, 'layer3.19.conv1.weight': 4, 'layer3.19.conv2.weight': 4, 'layer3.2.conv1.weight': 4, 'layer3.2.conv2.weight': 4, 'layer3.20.conv1.weight': 4, 'layer3.20.conv2.weight': 4, 'layer3.21.conv1.weight': 4, 'layer3.21.conv2.weight': 4, 'layer3.22.conv1.weight': 4, 'layer3.22.conv2.weight': 4, 'layer3.3.conv1.weight': 4, 'layer3.3.conv2.weight': 4, 'layer3.4.conv1.weight': 4, 'layer3.4.conv2.weight': 4, 'layer3.5.conv1.weight': 4, 'layer3.5.conv2.weight': 4, 'layer3.6.conv1.weight': 4, 'layer3.6.conv2.weight': 4, 'layer3.7.conv1.weight': 4, 'layer3.7.conv2.weight': 4, 'layer3.8.conv1.weight': 4, 'layer3.8.conv2.weight': 4, 'layer3.9.conv1.weight': 4, 'layer3.9.conv2.weight': 4, 'layer4.0.conv1.weight': 4, 'layer4.0.conv2.weight': 4, 'layer4.0.shortcut.0.weight': 4, 'layer4.1.conv1.weight': 4, 'layer4.1.conv2.weight': 4, 'layer4.2.conv1.weight': 4, 'layer4.2.conv2.weight': 4}\n",
      "ratio_partition: {'conv1.weight': [1, 1, 1, 1], 'inputs': [1, 1, 1, 1], 'layer1.0.conv1.weight': [1, 1, 1, 1], 'layer1.0.conv2.weight': [1, 1, 1, 1], 'layer1.1.conv1.weight': [1, 1, 1, 1], 'layer1.1.conv2.weight': [1, 1, 1, 1], 'layer1.2.conv1.weight': [1, 1, 1, 1], 'layer1.2.conv2.weight': [1, 1, 1, 1], 'layer2.0.conv1.weight': [1, 1, 1, 1], 'layer2.0.conv2.weight': [1, 1, 1, 1], 'layer2.0.shortcut.0.weight': [1, 1, 1, 1], 'layer2.1.conv1.weight': [1, 1, 1, 1], 'layer2.1.conv2.weight': [1, 1, 1, 1], 'layer2.2.conv1.weight': [1, 1, 1, 1], 'layer2.2.conv2.weight': [1, 1, 1, 1], 'layer2.3.conv1.weight': [1, 1, 1, 1], 'layer2.3.conv2.weight': [1, 1, 1, 1], 'layer3.0.conv1.weight': [1, 1, 1, 1], 'layer3.0.conv2.weight': [1, 1, 1, 1], 'layer3.0.shortcut.0.weight': [1, 1, 1, 1], 'layer3.1.conv1.weight': [1, 1, 1, 1], 'layer3.1.conv2.weight': [1, 1, 1, 1], 'layer3.10.conv1.weight': [1, 1, 1, 1], 'layer3.10.conv2.weight': [1, 1, 1, 1], 'layer3.11.conv1.weight': [1, 1, 1, 1], 'layer3.11.conv2.weight': [1, 1, 1, 1], 'layer3.12.conv1.weight': [1, 1, 1, 1], 'layer3.12.conv2.weight': [1, 1, 1, 1], 'layer3.13.conv1.weight': [1, 1, 1, 1], 'layer3.13.conv2.weight': [1, 1, 1, 1], 'layer3.14.conv1.weight': [1, 1, 1, 1], 'layer3.14.conv2.weight': [1, 1, 1, 1], 'layer3.15.conv1.weight': [1, 1, 1, 1], 'layer3.15.conv2.weight': [1, 1, 1, 1], 'layer3.16.conv1.weight': [1, 1, 1, 1], 'layer3.16.conv2.weight': [1, 1, 1, 1], 'layer3.17.conv1.weight': [1, 1, 1, 1], 'layer3.17.conv2.weight': [1, 1, 1, 1], 'layer3.18.conv1.weight': [1, 1, 1, 1], 'layer3.18.conv2.weight': [1, 1, 1, 1], 'layer3.19.conv1.weight': [1, 1, 1, 1], 'layer3.19.conv2.weight': [1, 1, 1, 1], 'layer3.2.conv1.weight': [1, 1, 1, 1], 'layer3.2.conv2.weight': [1, 1, 1, 1], 'layer3.20.conv1.weight': [1, 1, 1, 1], 'layer3.20.conv2.weight': [1, 1, 1, 1], 'layer3.21.conv1.weight': [1, 1, 1, 1], 'layer3.21.conv2.weight': [1, 1, 1, 1], 'layer3.22.conv1.weight': [1, 1, 1, 1], 'layer3.22.conv2.weight': [1, 1, 1, 1], 'layer3.3.conv1.weight': [1, 1, 1, 1], 'layer3.3.conv2.weight': [1, 1, 1, 1], 'layer3.4.conv1.weight': [1, 1, 1, 1], 'layer3.4.conv2.weight': [1, 1, 1, 1], 'layer3.5.conv1.weight': [1, 1, 1, 1], 'layer3.5.conv2.weight': [1, 1, 1, 1], 'layer3.6.conv1.weight': [1, 1, 1, 1], 'layer3.6.conv2.weight': [1, 1, 1, 1], 'layer3.7.conv1.weight': [1, 1, 1, 1], 'layer3.7.conv2.weight': [1, 1, 1, 1], 'layer3.8.conv1.weight': [1, 1, 1, 1], 'layer3.8.conv2.weight': [1, 1, 1, 1], 'layer3.9.conv1.weight': [1, 1, 1, 1], 'layer3.9.conv2.weight': [1, 1, 1, 1], 'layer4.0.conv1.weight': [1, 1, 1, 1], 'layer4.0.conv2.weight': [1, 1, 1, 1], 'layer4.0.shortcut.0.weight': [1, 1, 1, 1], 'layer4.1.conv1.weight': [1, 1, 1, 1], 'layer4.1.conv2.weight': [1, 1, 1, 1], 'layer4.2.conv1.weight': [1, 1, 1, 1], 'layer4.2.conv2.weight': [1, 1, 1, 1]}\n",
      "map_partition: {'conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'inputs': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer1.0.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer1.0.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer1.1.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer1.1.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer1.2.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer1.2.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.0.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.0.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.0.shortcut.0.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.1.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.1.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.2.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.2.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.3.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer2.3.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.0.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.0.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.0.shortcut.0.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.1.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.1.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.10.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.10.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.11.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.11.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.12.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.12.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.13.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.13.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.14.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.14.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.15.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.15.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.16.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.16.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.17.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.17.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.18.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.18.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.19.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.19.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.2.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.2.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.20.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.20.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.21.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.21.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.22.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.22.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.3.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.3.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.4.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.4.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.5.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.5.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.6.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.6.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.7.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.7.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.8.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.8.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.9.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer3.9.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer4.0.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer4.0.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer4.0.shortcut.0.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer4.1.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer4.1.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer4.2.conv1.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]], 'layer4.2.conv2.weight': [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]]}\n",
      "bn_partition: [4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Inference time per data is 65.165281ms.\n",
      "conv1.weight 1024\n",
      "layer1.0.conv1.weight 1024\n",
      "layer1.0.conv2.weight 1024\n",
      "layer1.1.conv1.weight 1024\n",
      "layer1.1.conv2.weight 1024\n",
      "layer1.2.conv1.weight 1024\n",
      "layer1.2.conv2.weight 1024\n",
      "layer2.0.conv1.weight 256\n",
      "layer2.0.conv2.weight 256\n",
      "layer2.0.shortcut.0.weight 256\n",
      "layer2.1.conv1.weight 256\n",
      "layer2.1.conv2.weight 256\n",
      "layer2.2.conv1.weight 256\n",
      "layer2.2.conv2.weight 256\n",
      "layer2.3.conv1.weight 256\n",
      "layer2.3.conv2.weight 256\n",
      "layer3.0.conv1.weight 64\n",
      "layer3.0.conv2.weight 64\n",
      "layer3.0.shortcut.0.weight 64\n",
      "layer3.1.conv1.weight 64\n",
      "layer3.1.conv2.weight 64\n",
      "layer3.2.conv1.weight 64\n",
      "layer3.2.conv2.weight 64\n",
      "layer3.3.conv1.weight 64\n",
      "layer3.3.conv2.weight 64\n",
      "layer3.4.conv1.weight 64\n",
      "layer3.4.conv2.weight 64\n",
      "layer3.5.conv1.weight 64\n",
      "layer3.5.conv2.weight 64\n",
      "layer3.6.conv1.weight 64\n",
      "layer3.6.conv2.weight 64\n",
      "layer3.7.conv1.weight 64\n",
      "layer3.7.conv2.weight 64\n",
      "layer3.8.conv1.weight 64\n",
      "layer3.8.conv2.weight 64\n",
      "layer3.9.conv1.weight 64\n",
      "layer3.9.conv2.weight 64\n",
      "layer3.10.conv1.weight 64\n",
      "layer3.10.conv2.weight 64\n",
      "layer3.11.conv1.weight 64\n",
      "layer3.11.conv2.weight 64\n",
      "layer3.12.conv1.weight 64\n",
      "layer3.12.conv2.weight 64\n",
      "layer3.13.conv1.weight 64\n",
      "layer3.13.conv2.weight 64\n",
      "layer3.14.conv1.weight 64\n",
      "layer3.14.conv2.weight 64\n",
      "layer3.15.conv1.weight 64\n",
      "layer3.15.conv2.weight 64\n",
      "layer3.16.conv1.weight 64\n",
      "layer3.16.conv2.weight 64\n",
      "layer3.17.conv1.weight 64\n",
      "layer3.17.conv2.weight 64\n",
      "layer3.18.conv1.weight 64\n",
      "layer3.18.conv2.weight 64\n",
      "layer3.19.conv1.weight 64\n",
      "layer3.19.conv2.weight 64\n",
      "layer3.20.conv1.weight 64\n",
      "layer3.20.conv2.weight 64\n",
      "layer3.21.conv1.weight 64\n",
      "layer3.21.conv2.weight 64\n",
      "layer3.22.conv1.weight 64\n",
      "layer3.22.conv2.weight 64\n",
      "layer4.0.conv1.weight 16\n",
      "layer4.0.conv2.weight 16\n",
      "layer4.0.shortcut.0.weight 16\n",
      "layer4.1.conv1.weight 16\n",
      "layer4.1.conv2.weight 16\n",
      "layer4.2.conv1.weight 16\n",
      "layer4.2.conv2.weight 16\n",
      "Total layers: 245\n",
      "['x', 'conv1', 'bn1', 'relu', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer1.2.conv1', 'layer1.2.bn1', 'layer1.2.relu', 'layer1.2.conv2', 'layer1.2.bn2', 'layer1.2.add', 'layer1.2.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer2.2.conv1', 'layer2.2.bn1', 'layer2.2.relu', 'layer2.2.conv2', 'layer2.2.bn2', 'layer2.2.add', 'layer2.2.relu_1', 'layer2.3.conv1', 'layer2.3.bn1', 'layer2.3.relu', 'layer2.3.conv2', 'layer2.3.bn2', 'layer2.3.add', 'layer2.3.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer3.2.conv1', 'layer3.2.bn1', 'layer3.2.relu', 'layer3.2.conv2', 'layer3.2.bn2', 'layer3.2.add', 'layer3.2.relu_1', 'layer3.3.conv1', 'layer3.3.bn1', 'layer3.3.relu', 'layer3.3.conv2', 'layer3.3.bn2', 'layer3.3.add', 'layer3.3.relu_1', 'layer3.4.conv1', 'layer3.4.bn1', 'layer3.4.relu', 'layer3.4.conv2', 'layer3.4.bn2', 'layer3.4.add', 'layer3.4.relu_1', 'layer3.5.conv1', 'layer3.5.bn1', 'layer3.5.relu', 'layer3.5.conv2', 'layer3.5.bn2', 'layer3.5.add', 'layer3.5.relu_1', 'layer3.6.conv1', 'layer3.6.bn1', 'layer3.6.relu', 'layer3.6.conv2', 'layer3.6.bn2', 'layer3.6.add', 'layer3.6.relu_1', 'layer3.7.conv1', 'layer3.7.bn1', 'layer3.7.relu', 'layer3.7.conv2', 'layer3.7.bn2', 'layer3.7.add', 'layer3.7.relu_1', 'layer3.8.conv1', 'layer3.8.bn1', 'layer3.8.relu', 'layer3.8.conv2', 'layer3.8.bn2', 'layer3.8.add', 'layer3.8.relu_1', 'layer3.9.conv1', 'layer3.9.bn1', 'layer3.9.relu', 'layer3.9.conv2', 'layer3.9.bn2', 'layer3.9.add', 'layer3.9.relu_1', 'layer3.10.conv1', 'layer3.10.bn1', 'layer3.10.relu', 'layer3.10.conv2', 'layer3.10.bn2', 'layer3.10.add', 'layer3.10.relu_1', 'layer3.11.conv1', 'layer3.11.bn1', 'layer3.11.relu', 'layer3.11.conv2', 'layer3.11.bn2', 'layer3.11.add', 'layer3.11.relu_1', 'layer3.12.conv1', 'layer3.12.bn1', 'layer3.12.relu', 'layer3.12.conv2', 'layer3.12.bn2', 'layer3.12.add', 'layer3.12.relu_1', 'layer3.13.conv1', 'layer3.13.bn1', 'layer3.13.relu', 'layer3.13.conv2', 'layer3.13.bn2', 'layer3.13.add', 'layer3.13.relu_1', 'layer3.14.conv1', 'layer3.14.bn1', 'layer3.14.relu', 'layer3.14.conv2', 'layer3.14.bn2', 'layer3.14.add', 'layer3.14.relu_1', 'layer3.15.conv1', 'layer3.15.bn1', 'layer3.15.relu', 'layer3.15.conv2', 'layer3.15.bn2', 'layer3.15.add', 'layer3.15.relu_1', 'layer3.16.conv1', 'layer3.16.bn1', 'layer3.16.relu', 'layer3.16.conv2', 'layer3.16.bn2', 'layer3.16.add', 'layer3.16.relu_1', 'layer3.17.conv1', 'layer3.17.bn1', 'layer3.17.relu', 'layer3.17.conv2', 'layer3.17.bn2', 'layer3.17.add', 'layer3.17.relu_1', 'layer3.18.conv1', 'layer3.18.bn1', 'layer3.18.relu', 'layer3.18.conv2', 'layer3.18.bn2', 'layer3.18.add', 'layer3.18.relu_1', 'layer3.19.conv1', 'layer3.19.bn1', 'layer3.19.relu', 'layer3.19.conv2', 'layer3.19.bn2', 'layer3.19.add', 'layer3.19.relu_1', 'layer3.20.conv1', 'layer3.20.bn1', 'layer3.20.relu', 'layer3.20.conv2', 'layer3.20.bn2', 'layer3.20.add', 'layer3.20.relu_1', 'layer3.21.conv1', 'layer3.21.bn1', 'layer3.21.relu', 'layer3.21.conv2', 'layer3.21.bn2', 'layer3.21.add', 'layer3.21.relu_1', 'layer3.22.conv1', 'layer3.22.bn1', 'layer3.22.relu', 'layer3.22.conv2', 'layer3.22.bn2', 'layer3.22.add', 'layer3.22.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'layer4.2.conv1', 'layer4.2.bn1', 'layer4.2.relu', 'layer4.2.conv2', 'layer4.2.bn2', 'layer4.2.add', 'layer4.2.relu_1', 'avg_pool', 'size', 'view', 'out']\n",
      "num_machines: 4\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    add partitions and communications to configs\n",
    "'''\n",
    "\n",
    "# gets random test input (with correct size)\n",
    "input_var = get_input_from_code(configs)\n",
    "\n",
    "# Config partitions and prune_ratio\n",
    "configs = engine.partition_generator(configs, model)\n",
    "            \n",
    "# Compute output size of each layer\n",
    "configs['partition'] = engine.featuremap_summary(model, configs['partition'], input_var)\n",
    "\n",
    "# print(configs['partition'])\n",
    "        \n",
    "# model communication costs\n",
    "configs['comm_costs'] = engine.set_communication_cost(model, configs['partition'],)\n",
    "\n",
    "# print(configs['comm_costs'])\n",
    "\n",
    "\n",
    "# split model general parameters\n",
    "\n",
    "# make copies of model per machine\n",
    "num_machines = max(configs['partition']['bn_partition']) # TODO: double check this makes sense\n",
    "model_machines = [model]*num_machines\n",
    "\n",
    "layer_names_fx =  get_graph_node_names(model)[1]\n",
    "total_layers_fx = len(layer_names_fx)\n",
    "print(f\"Total layers: {total_layers_fx}\")\n",
    "\n",
    "split_module_names = list(configs['partition'].keys())\n",
    "\n",
    "print(layer_names_fx)\n",
    "print('num_machines:', num_machines)\n",
    "\n",
    "# print(model.layer1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing module 0: x\n",
      "\tExecuting on machine 0\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 1\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 2\n",
      "\t\t-model input layer.. skipping\n",
      "\tExecuting on machine 3\n",
      "\t\t-model input layer.. skipping\n",
      "Finished execution of layer 0\n",
      "Input layer. Skipping comparison\n",
      "\n",
      "Executing module 1: conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-WARNING: No input assigned to this machine (but it was sent input?). Skipping...\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 1,  3,  4,  6, 10, 11, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([33, 37, 40, 41, 42, 43]) to machine 2\n",
      "\t\t sending C_out tensor([53, 55, 56, 59, 62, 63]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  3,  4,  6,  7, 10, 12]) to machine 0\n",
      "\t\t sending C_out tensor([16, 18, 21, 30]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([50, 57, 58, 60]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 1\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 5,  9, 12]) to machine 0\n",
      "\t\t sending C_out tensor([18, 19, 24, 25, 27]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 42, 44]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 1\n",
      "Max diff:\n",
      " tensor([8.8818e-16], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9143e-16, 2.0817e-17, 0.0000e+00,\n",
      "         8.3267e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1684e-19, 0.0000e+00,\n",
      "         1.6263e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         7.7716e-16, 2.2204e-16, 0.0000e+00, 2.7756e-16, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-16, 2.2204e-16, 0.0000e+00, 2.8363e-16, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-16, 0.0000e+00, 2.2204e-16, 6.6613e-16, 6.6613e-16, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-16, 0.0000e+00, 0.0000e+00, 2.4980e-16, 3.3307e-16,\n",
      "         4.9960e-16, 1.6653e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00, 8.8818e-16,\n",
      "         0.0000e+00, 2.2204e-16, 2.2898e-16, 8.8818e-16, 3.3307e-16, 2.2204e-16,\n",
      "         2.2204e-16, 0.0000e+00, 3.3307e-16, 4.4409e-16]], dtype=torch.float64)\n",
      " tensor([ 3,  4,  6, 10, 12, 16, 18, 19, 21, 24, 25, 27, 30, 32, 33, 34, 37, 40,\n",
      "        41, 42, 43, 44, 50, 53, 55, 56, 57, 58, 59, 60, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 3,  4,  6, 10, 12, 16, 18, 19, 21, 24, 25, 27, 30, 32, 33, 34, 37, 40,\n",
      "        41, 42, 43, 44, 50, 53, 55, 56, 57, 58, 59, 60, 62, 63])  (len = 32)\n",
      "passing Cout = tensor([ 0,  1,  5,  7,  9, 11, 14, 15, 17, 20, 22, 23, 26, 28, 29, 31, 35, 36,\n",
      "        38, 39, 45, 46, 47, 48, 49, 51, 52, 54, 61])  (len = 29)\n",
      "\n",
      "Executing module 2: bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 2\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 2\n",
      "Max diff:\n",
      " tensor([1.7764e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16, 1.3878e-17, 0.0000e+00,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4694e-18, 0.0000e+00,\n",
      "         2.7756e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         6.6613e-16, 1.1102e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-16, 4.4409e-16, 0.0000e+00, 2.7756e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 2.2204e-16, 7.2164e-16, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16, 2.2204e-16,\n",
      "         5.5511e-16, 1.1102e-16, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 1.7764e-15,\n",
      "         0.0000e+00, 2.2204e-16, 1.1102e-16, 1.7764e-15, 2.2204e-16, 2.2204e-16,\n",
      "         2.2204e-16, 0.0000e+00, 3.3307e-16, 3.3307e-16]], dtype=torch.float64)\n",
      " tensor([ 3,  4,  6, 10, 12, 16, 18, 19, 21, 24, 25, 27, 30, 32, 33, 34, 37, 40,\n",
      "        41, 42, 43, 44, 50, 53, 55, 56, 57, 58, 59, 60, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 3,  4,  6, 10, 12, 16, 18, 19, 21, 24, 25, 27, 30, 32, 33, 34, 37, 40,\n",
      "        41, 42, 43, 44, 50, 53, 55, 56, 57, 58, 59, 60, 62, 63])  (len = 32)\n",
      "passing Cout = tensor([ 0,  1,  2,  5,  7,  8,  9, 11, 13, 14, 15, 17, 20, 22, 23, 26, 28, 29,\n",
      "        31, 35, 36, 38, 39, 45, 46, 47, 48, 49, 51, 52, 54, 61])  (len = 32)\n",
      "\n",
      "Executing module 3: relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 3\n",
      "Max diff:\n",
      " tensor([1.7764e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         2.2204e-16, 1.1102e-16, 0.0000e+00, 1.6653e-16, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-16, 4.4409e-16, 0.0000e+00, 2.7756e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 2.2204e-16, 5.5511e-16, 5.5511e-16, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16, 2.2204e-16,\n",
      "         5.5511e-16, 8.3267e-17, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 2.2204e-16, 1.1102e-16, 1.7764e-15, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 3.3307e-16]], dtype=torch.float64)\n",
      " tensor([16, 18, 19, 21, 24, 25, 27, 30, 32, 33, 34, 37, 40, 41, 42, 43, 44, 50,\n",
      "        53, 55, 56, 57, 58, 62, 63])\n",
      "\n",
      "failing Cout = tensor([16, 18, 19, 21, 24, 25, 27, 30, 32, 33, 34, 37, 40, 41, 42, 43, 44, 50,\n",
      "        53, 55, 56, 57, 58, 62, 63])  (len = 25)\n",
      "passing Cout = tensor([ 0, 11, 14, 17, 20, 23, 26, 29, 31, 36, 39, 45, 46, 47, 48, 49, 51, 61])  (len = 18)\n",
      "\n",
      "Executing module 4: layer1.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 4\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([34, 35, 38, 40, 41, 42, 43, 44, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 4\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 4\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 4\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 4\n",
      "Max diff:\n",
      " tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 7.7716e-16, 1.9984e-15, 1.7764e-15, 6.6613e-16, 7.1054e-15,\n",
      "         3.5527e-15, 8.8818e-16, 4.4409e-16, 2.7756e-16, 4.4409e-16, 4.4409e-16,\n",
      "         6.6613e-16, 1.7347e-17, 8.8818e-16, 3.8858e-16, 1.7764e-15, 4.4409e-15,\n",
      "         3.5527e-15, 2.2204e-15, 3.5527e-15, 1.7764e-15, 3.5527e-15, 5.3291e-15,\n",
      "         5.3291e-15, 6.2172e-15, 2.8866e-15, 3.1086e-15, 2.6645e-15, 1.5543e-15,\n",
      "         8.8818e-16, 2.2204e-15, 2.8866e-15, 3.9968e-15, 3.9968e-15, 1.9984e-15,\n",
      "         1.9984e-15, 1.0658e-14, 6.2172e-15, 4.4409e-15, 4.4409e-15, 1.7764e-15,\n",
      "         7.1054e-15, 8.8818e-15, 3.5527e-15, 1.3323e-15, 3.5527e-15, 2.2204e-15,\n",
      "         4.4409e-15, 1.7764e-15, 7.1054e-15, 5.3291e-15, 3.5527e-15, 7.1054e-15,\n",
      "         3.5527e-15, 1.0658e-14, 3.9968e-15, 1.3323e-15, 3.5527e-15, 7.9936e-15,\n",
      "         2.2204e-15, 4.8850e-15, 3.9968e-15, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 5: layer1.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 5\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 5\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 5\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 5\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 5\n",
      "Max diff:\n",
      " tensor([4.8850e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.8818e-16, 2.2204e-16, 5.5511e-16, 3.3307e-16, 1.6653e-16, 1.5543e-15,\n",
      "         6.6613e-16, 2.7756e-16, 1.3878e-16, 8.3267e-17, 1.6653e-16, 1.5266e-16,\n",
      "         2.2204e-16, 6.9389e-18, 2.7756e-16, 9.7145e-17, 5.5511e-16, 1.1102e-15,\n",
      "         7.7716e-16, 8.8818e-16, 7.7716e-16, 5.5511e-16, 1.3323e-15, 2.2204e-15,\n",
      "         2.2204e-15, 2.6645e-15, 1.3323e-15, 1.3323e-15, 6.6613e-16, 5.5511e-16,\n",
      "         2.7756e-16, 6.6613e-16, 1.1102e-15, 9.9920e-16, 6.6613e-16, 5.5511e-16,\n",
      "         6.6613e-16, 1.7764e-15, 1.8874e-15, 1.9984e-15, 3.3307e-16, 5.5511e-16,\n",
      "         1.7764e-15, 3.5527e-15, 1.3323e-15, 4.4409e-16, 1.3323e-15, 8.8818e-16,\n",
      "         3.5527e-15, 3.3307e-16, 3.5527e-15, 7.7716e-16, 1.3323e-15, 1.3323e-15,\n",
      "         8.8818e-16, 1.9984e-15, 1.7764e-15, 4.4409e-16, 1.5543e-15, 4.8850e-15,\n",
      "         7.2164e-16, 2.2204e-15, 1.3323e-15, 1.3323e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 6: layer1.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 6\n",
      "Max diff:\n",
      " tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00,\n",
      "         7.7716e-16, 8.8818e-16, 2.7756e-16, 0.0000e+00, 6.1062e-16, 1.7764e-15,\n",
      "         2.2204e-15, 3.3307e-16, 1.3323e-15, 1.3323e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00, 5.5511e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4980e-16, 1.3323e-15, 2.7756e-16, 5.5511e-16, 8.8818e-16,\n",
      "         3.5527e-15, 3.3307e-16, 0.0000e+00, 1.5266e-16, 1.3323e-15, 0.0000e+00,\n",
      "         4.4409e-16, 0.0000e+00, 6.8695e-16, 0.0000e+00, 7.2858e-16, 0.0000e+00,\n",
      "         6.6613e-16, 0.0000e+00, 1.3323e-15, 9.7145e-17]], dtype=torch.float64)\n",
      " tensor([16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 34, 38, 39, 43, 44, 45, 46,\n",
      "        47, 48, 49, 51, 52, 54, 56, 58, 60, 62, 63])\n",
      "\n",
      "failing Cout = tensor([16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 34, 38, 39, 43, 44, 45, 46,\n",
      "        47, 48, 49, 51, 52, 54, 56, 58, 60, 62, 63])  (len = 29)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 7: layer1.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 7\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 7\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 7\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 7\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 7\n",
      "Max diff:\n",
      " tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 1.1102e-15, 6.6613e-16, 2.2204e-15, 3.8858e-16, 4.4409e-16,\n",
      "         1.3323e-15, 6.6613e-16, 8.3267e-17, 6.6613e-16, 2.2204e-16, 4.4409e-15,\n",
      "         2.6021e-18, 2.2204e-16, 2.6645e-15, 1.1102e-16, 5.3291e-15, 2.2204e-15,\n",
      "         3.5527e-15, 3.5527e-15, 2.2204e-15, 2.2204e-15, 1.7764e-15, 4.4409e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.1086e-15, 4.4409e-15, 2.2204e-15, 3.5527e-15,\n",
      "         1.7764e-15, 2.2204e-15, 2.6645e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15,\n",
      "         4.4409e-15, 4.4409e-15, 2.6645e-15, 2.6645e-15, 3.5527e-15, 8.8818e-16,\n",
      "         2.4425e-15, 2.6645e-15, 3.5527e-15, 3.1086e-15, 5.3291e-15, 4.4409e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.5527e-15, 2.2204e-15, 3.1086e-15, 1.7764e-15,\n",
      "         3.5527e-15, 3.5527e-15, 2.6645e-15, 3.1086e-15, 2.6645e-15, 3.5527e-15,\n",
      "         3.1086e-15, 4.4409e-15, 2.6645e-15, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 8: layer1.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 8\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 8\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 8\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 8\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 8\n",
      "Max diff:\n",
      " tensor([3.1086e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-15, 2.7756e-16, 1.6653e-16, 1.3323e-15, 1.6653e-16, 1.3878e-16,\n",
      "         5.5511e-16, 2.2204e-16, 2.7756e-17, 2.2204e-16, 6.9389e-17, 1.1102e-15,\n",
      "         2.7756e-17, 6.9389e-17, 1.3323e-15, 5.5511e-17, 3.1086e-15, 7.7716e-16,\n",
      "         2.2204e-15, 1.1102e-15, 1.1102e-15, 1.3323e-15, 8.8818e-16, 1.3323e-15,\n",
      "         1.1102e-15, 6.6613e-16, 9.9920e-16, 1.3323e-15, 1.3323e-15, 1.3323e-15,\n",
      "         6.6613e-16, 8.8818e-16, 5.5511e-16, 5.5511e-17, 5.5511e-17, 2.2204e-16,\n",
      "         2.2204e-15, 1.1102e-15, 2.2204e-16, 1.6653e-16, 5.5511e-16, 6.9389e-18,\n",
      "         7.2164e-16, 1.3323e-15, 6.6613e-16, 1.2212e-15, 1.9984e-15, 1.1102e-15,\n",
      "         1.7764e-15, 2.2204e-15, 1.7764e-15, 6.6613e-16, 1.3323e-15, 2.7756e-16,\n",
      "         1.1102e-15, 2.6645e-15, 1.3323e-15, 1.1102e-15, 6.6613e-16, 1.7764e-15,\n",
      "         1.5543e-15, 2.6645e-15, 2.6645e-15, 8.8818e-16]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 9: layer1.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 9\n",
      "Max diff:\n",
      " tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-15, 2.7756e-16, 1.6653e-16, 1.3323e-15, 1.6653e-16, 1.3878e-16,\n",
      "         5.5511e-16, 2.2204e-16, 2.7756e-17, 2.2204e-16, 6.9389e-17, 1.1102e-15,\n",
      "         2.7756e-17, 6.9389e-17, 1.3323e-15, 5.5511e-17, 3.5527e-15, 6.6613e-16,\n",
      "         2.2204e-15, 1.1102e-15, 1.1102e-15, 1.3323e-15, 8.8818e-16, 1.3323e-15,\n",
      "         1.1102e-15, 8.8818e-16, 9.9920e-16, 1.3323e-15, 1.3323e-15, 1.3323e-15,\n",
      "         6.6613e-16, 8.8818e-16, 5.5511e-16, 5.5511e-16, 6.1062e-16, 2.2204e-16,\n",
      "         2.2204e-15, 1.1102e-15, 2.2204e-16, 1.6653e-16, 5.5511e-16, 2.2204e-16,\n",
      "         8.8818e-16, 1.3323e-15, 1.3323e-15, 1.2212e-15, 1.9984e-15, 1.1102e-15,\n",
      "         1.7764e-15, 2.2204e-15, 1.7764e-15, 6.6613e-16, 1.3323e-15, 6.6613e-16,\n",
      "         1.1102e-15, 2.6645e-15, 1.3323e-15, 2.6645e-15, 8.8818e-16, 1.7764e-15,\n",
      "         1.5543e-15, 2.6645e-15, 3.1086e-15, 8.8818e-16]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 10: layer1.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 10\n",
      "Max diff:\n",
      " tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.6306e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.2164e-16, 0.0000e+00, 3.5527e-15, 6.6613e-16,\n",
      "         2.2204e-15, 5.5511e-16, 4.9960e-16, 8.8818e-16, 0.0000e+00, 8.8818e-16,\n",
      "         5.5511e-16, 8.8818e-16, 4.9960e-16, 8.3267e-16, 0.0000e+00, 5.5511e-16,\n",
      "         3.8858e-16, 8.8818e-16, 5.5511e-16, 5.5511e-16, 6.1062e-16, 0.0000e+00,\n",
      "         1.3323e-15, 8.8818e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16, 2.2204e-16,\n",
      "         8.8818e-16, 6.6613e-16, 1.3323e-15, 8.8818e-16, 4.6491e-16, 4.9960e-16,\n",
      "         1.4433e-15, 8.8818e-16, 1.7764e-15, 4.4409e-16, 1.3323e-15, 6.6613e-16,\n",
      "         0.0000e+00, 2.6645e-15, 5.8287e-16, 2.6645e-15, 8.8818e-16, 1.7764e-15,\n",
      "         6.6613e-16, 2.6645e-15, 3.1086e-15, 3.3307e-16]], dtype=torch.float64)\n",
      " tensor([ 7, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33,\n",
      "        34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55,\n",
      "        56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 7, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33,\n",
      "        34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55,\n",
      "        56, 57, 58, 59, 60, 61, 62, 63])  (len = 44)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 11: layer1.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 11\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 22, 23, 25, 27, 29, 31]) to machine 1\n",
      "\t\t sending C_out tensor([33, 34, 35, 37, 40, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 50, 51, 52, 53, 54, 55, 57, 59, 61, 63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 11\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 11\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 11\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 11\n",
      "Max diff:\n",
      " tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-16, 1.7764e-15, 3.5527e-15, 5.5511e-16, 2.2204e-15, 5.5511e-16,\n",
      "         7.7716e-16, 3.8858e-16, 2.8623e-17, 1.1102e-15, 5.5511e-16, 7.7716e-16,\n",
      "         3.5527e-15, 1.7764e-15, 3.3307e-16, 3.5527e-15, 1.0658e-14, 1.4211e-14,\n",
      "         7.1054e-15, 7.1054e-15, 7.1054e-15, 8.8818e-15, 7.1054e-15, 6.2172e-15,\n",
      "         4.4409e-15, 7.1054e-15, 3.5527e-15, 1.3323e-15, 1.0658e-14, 3.5527e-15,\n",
      "         7.1054e-15, 7.1054e-15, 1.7764e-15, 8.8818e-15, 3.5527e-15, 3.5527e-15,\n",
      "         2.6645e-15, 3.7748e-15, 2.2204e-15, 6.2172e-15, 3.1086e-15, 1.0658e-14,\n",
      "         3.5527e-15, 7.1054e-15, 3.1086e-15, 1.0658e-14, 2.6645e-15, 7.1054e-15,\n",
      "         5.3291e-15, 7.1054e-15, 6.2172e-15, 3.3307e-15, 7.1054e-15, 7.9936e-15,\n",
      "         7.1054e-15, 6.2172e-15, 5.3291e-15, 4.4409e-15, 5.3291e-15, 4.4409e-15,\n",
      "         7.1054e-15, 1.2434e-14, 4.4409e-15, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 12: layer1.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 12\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 12\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 12\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 12\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 12\n",
      "Max diff:\n",
      " tensor([6.2172e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.7756e-17, 4.4409e-16, 8.8818e-16, 1.3878e-16, 3.3307e-16, 1.6653e-16,\n",
      "         2.2204e-16, 5.5511e-17, 1.3878e-17, 4.4409e-16, 1.6653e-16, 2.2204e-16,\n",
      "         6.6613e-16, 4.4409e-16, 1.1102e-16, 8.8818e-16, 3.1086e-15, 2.6645e-15,\n",
      "         1.7764e-15, 2.2204e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 1.3323e-15,\n",
      "         1.3323e-15, 2.6645e-15, 8.8818e-16, 3.3307e-16, 5.3291e-15, 1.1102e-15,\n",
      "         2.2204e-15, 2.6645e-15, 1.6653e-16, 1.3323e-15, 6.6613e-16, 3.3307e-16,\n",
      "         5.5511e-16, 4.9960e-16, 6.6613e-16, 1.9984e-15, 7.7716e-16, 1.7764e-15,\n",
      "         5.5511e-16, 1.5543e-15, 1.1102e-15, 4.8850e-15, 1.3323e-15, 2.6645e-15,\n",
      "         1.5543e-15, 3.5527e-15, 3.1086e-15, 7.2164e-16, 2.6645e-15, 4.8850e-15,\n",
      "         6.2172e-15, 1.3323e-15, 4.4409e-15, 1.1102e-15, 1.7764e-15, 1.3323e-15,\n",
      "         5.3291e-15, 5.3291e-15, 8.8818e-16, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 13: layer1.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 13\n",
      "Max diff:\n",
      " tensor([4.4409e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 2.2204e-16,\n",
      "         0.0000e+00, 6.6613e-16, 1.4155e-15, 8.8818e-16, 1.3323e-15, 8.8818e-16,\n",
      "         1.0547e-15, 1.3323e-15, 0.0000e+00, 0.0000e+00, 3.1086e-15, 5.9674e-16,\n",
      "         7.7716e-16, 6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7145e-17,\n",
      "         0.0000e+00, 3.1919e-16, 0.0000e+00, 1.5543e-15, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 1.9429e-16, 1.1102e-15, 1.5543e-15, 1.3323e-15, 8.8818e-16,\n",
      "         0.0000e+00, 7.7716e-16, 2.6645e-15, 7.2164e-16, 7.7716e-16, 1.9984e-15,\n",
      "         3.5527e-15, 0.0000e+00, 4.4409e-15, 6.6613e-16, 9.9920e-16, 3.3307e-16,\n",
      "         1.5543e-15, 5.7419e-16, 5.5511e-16, 7.2164e-16]], dtype=torch.float64)\n",
      " tensor([16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 35, 37, 39, 41, 43,\n",
      "        44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 35, 37, 39, 41, 43,\n",
      "        44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 36)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 14: layer1.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 14\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 14\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 14\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 14\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 14\n",
      "Max diff:\n",
      " tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.6645e-15, 3.5527e-15, 2.6645e-15, 4.4409e-16, 2.6645e-15, 1.7764e-15,\n",
      "         2.7756e-16, 1.3323e-15, 1.6653e-16, 1.6653e-16, 2.2204e-16, 7.1054e-15,\n",
      "         6.9389e-17, 1.3323e-15, 3.5527e-15, 8.3267e-17, 1.2212e-15, 1.5543e-15,\n",
      "         3.1086e-15, 2.6645e-15, 2.6645e-15, 1.9984e-15, 4.4409e-15, 8.3267e-16,\n",
      "         3.1086e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15, 1.5543e-15, 1.7764e-15,\n",
      "         1.6653e-15, 1.3323e-15, 3.5527e-15, 1.3323e-15, 1.7764e-15, 2.6645e-15,\n",
      "         5.3291e-15, 3.5527e-15, 2.6645e-15, 2.8311e-15, 5.3291e-15, 1.3323e-15,\n",
      "         2.6645e-15, 2.2204e-15, 2.6645e-15, 2.6645e-15, 2.6645e-15, 2.2204e-15,\n",
      "         7.1054e-15, 4.4409e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 3.1086e-15,\n",
      "         5.3291e-15, 6.6613e-15, 3.5527e-15, 2.6645e-15, 4.4409e-15, 7.1054e-15,\n",
      "         3.5527e-15, 4.4409e-15, 3.9968e-15, 3.5527e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 15: layer1.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 15\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 15\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 15\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 15\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 15\n",
      "Max diff:\n",
      " tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 1.1102e-15, 1.1657e-15, 1.6653e-16, 1.3323e-15, 5.5511e-16,\n",
      "         1.1102e-16, 6.6613e-16, 8.3267e-17, 5.5511e-17, 6.9389e-17, 2.6645e-15,\n",
      "         2.7756e-17, 3.8858e-16, 1.3323e-15, 2.7756e-17, 5.8981e-17, 4.4409e-16,\n",
      "         7.7716e-16, 5.5511e-16, 6.6613e-16, 8.3267e-16, 2.6645e-15, 6.9389e-18,\n",
      "         1.9429e-16, 8.8818e-16, 1.7764e-15, 4.4409e-16, 7.7716e-16, 7.7716e-16,\n",
      "         6.1062e-16, 6.6613e-16, 2.6645e-15, 1.3878e-17, 2.2204e-16, 8.8818e-16,\n",
      "         2.6645e-15, 8.8818e-16, 8.8818e-16, 2.4980e-16, 3.1086e-15, 1.1102e-16,\n",
      "         8.8818e-16, 8.8818e-16, 1.3878e-16, 1.7764e-15, 8.8818e-16, 1.3323e-15,\n",
      "         8.8818e-15, 3.5527e-15, 1.3323e-15, 6.6613e-16, 3.5527e-15, 7.7716e-16,\n",
      "         3.5527e-15, 7.7716e-15, 1.1102e-15, 4.4409e-16, 1.3323e-15, 8.8818e-15,\n",
      "         2.6645e-15, 3.5527e-15, 2.6645e-15, 2.2204e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 16: layer1.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 16\n",
      "Max diff:\n",
      " tensor([9.9920e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 1.1102e-15, 1.1657e-15, 1.6653e-16, 1.3323e-15, 5.5511e-16,\n",
      "         1.1102e-16, 6.6613e-16, 8.3267e-17, 5.5511e-17, 6.9389e-17, 2.6645e-15,\n",
      "         2.7756e-17, 3.8858e-16, 1.3323e-15, 2.7756e-17, 3.5527e-15, 8.8818e-16,\n",
      "         1.9984e-15, 7.7716e-16, 6.6613e-16, 1.5543e-15, 2.6645e-15, 8.8818e-16,\n",
      "         4.9960e-16, 8.8818e-16, 1.7764e-15, 8.3267e-16, 7.7716e-16, 8.8818e-16,\n",
      "         6.1062e-16, 8.8818e-16, 2.6645e-15, 5.5511e-16, 6.6613e-16, 8.8818e-16,\n",
      "         3.1086e-15, 9.4369e-16, 8.8818e-16, 2.4980e-16, 3.1086e-15, 2.7756e-16,\n",
      "         9.9920e-16, 1.1102e-15, 1.3323e-15, 1.7764e-15, 1.3323e-15, 1.3323e-15,\n",
      "         8.8818e-15, 3.5527e-15, 2.6645e-15, 6.6613e-16, 3.5527e-15, 8.8818e-16,\n",
      "         3.5527e-15, 9.9920e-15, 1.1102e-15, 2.6645e-15, 2.2204e-15, 8.8818e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.5527e-15, 2.2204e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 17: layer1.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 17\n",
      "Max diff:\n",
      " tensor([9.9920e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 2.6368e-16, 1.1657e-15, 0.0000e+00, 8.3267e-16, 1.8041e-16,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4980e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 3.5527e-15, 8.8818e-16,\n",
      "         1.9984e-15, 5.5511e-16, 4.9960e-16, 1.5543e-15, 3.8858e-16, 8.8818e-16,\n",
      "         4.9960e-16, 8.8818e-16, 8.8818e-16, 8.3267e-16, 7.7716e-16, 8.8818e-16,\n",
      "         4.4409e-16, 8.8818e-16, 1.1657e-15, 5.5511e-16, 6.6613e-16, 6.9389e-16,\n",
      "         2.9490e-17, 8.8818e-16, 8.8818e-16, 1.1796e-16, 1.5543e-15, 2.7756e-16,\n",
      "         8.8818e-16, 1.1102e-15, 1.3323e-15, 1.7764e-15, 1.3323e-15, 7.7716e-16,\n",
      "         4.4409e-15, 2.6645e-15, 2.6645e-15, 3.8858e-16, 3.5527e-15, 8.8818e-16,\n",
      "         3.5527e-15, 9.9920e-15, 7.4940e-16, 2.6645e-15, 1.1102e-15, 8.8818e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.5527e-15, 1.7764e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  4,  5,  7, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
      "        26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
      "        44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
      "        62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  4,  5,  7, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
      "        26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
      "        44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
      "        62, 63])  (len = 56)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 18: layer1.2.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 18\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 18\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 18\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 18\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 18\n",
      "Max diff:\n",
      " tensor([2.4869e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.1054e-15, 1.1102e-15, 1.0658e-14, 1.3323e-15, 3.5527e-15, 7.1054e-15,\n",
      "         1.0658e-14, 5.3291e-15, 7.4385e-15, 1.1102e-15, 5.5789e-15, 1.3323e-15,\n",
      "         2.6645e-15, 5.5511e-16, 4.4409e-15, 1.7764e-15, 1.0658e-14, 1.7764e-15,\n",
      "         1.1102e-15, 1.7764e-15, 1.0658e-14, 8.8818e-15, 1.5987e-14, 5.3291e-15,\n",
      "         5.3291e-15, 3.5527e-15, 2.6645e-15, 5.3291e-15, 1.0658e-14, 1.1102e-15,\n",
      "         1.0658e-14, 1.0658e-14, 7.1054e-15, 5.3291e-15, 1.7764e-14, 7.1054e-15,\n",
      "         1.4211e-14, 1.7764e-15, 2.2204e-15, 3.5527e-15, 3.5527e-15, 1.7764e-14,\n",
      "         2.2204e-15, 3.5527e-15, 8.8818e-15, 3.5527e-15, 2.2204e-15, 4.4409e-15,\n",
      "         1.0658e-14, 1.3323e-14, 2.1316e-14, 2.1316e-14, 2.1316e-14, 1.7764e-14,\n",
      "         2.4869e-14, 1.1546e-14, 1.0658e-14, 1.4211e-14, 8.8818e-15, 1.7764e-14,\n",
      "         1.4211e-14, 1.5987e-14, 7.1054e-15, 1.7764e-14]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 19: layer1.2.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 19\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 19\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 19\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 19\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 19\n",
      "Max diff:\n",
      " tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 2.7756e-16, 1.7764e-15, 3.3307e-16, 6.6613e-16, 1.3323e-15,\n",
      "         1.9984e-15, 1.3323e-15, 1.5543e-15, 2.7756e-16, 1.7764e-15, 3.3307e-16,\n",
      "         4.4409e-16, 1.1102e-16, 1.1102e-15, 4.4409e-16, 1.9984e-15, 3.3307e-16,\n",
      "         1.3878e-16, 5.5511e-16, 2.6645e-15, 2.2204e-15, 2.6645e-15, 5.5511e-16,\n",
      "         1.7764e-15, 5.5511e-16, 6.6613e-16, 6.6613e-16, 1.3323e-15, 3.3307e-16,\n",
      "         4.4409e-15, 2.2204e-15, 1.7764e-15, 1.5543e-15, 3.9968e-15, 1.7764e-15,\n",
      "         4.4409e-15, 3.3307e-16, 5.5511e-16, 4.4409e-16, 6.6613e-16, 2.6645e-15,\n",
      "         5.5511e-16, 4.4409e-16, 8.8818e-16, 4.4409e-16, 5.5511e-16, 8.8818e-16,\n",
      "         2.6645e-15, 7.1054e-15, 6.2172e-15, 4.4409e-15, 5.3291e-15, 7.1054e-15,\n",
      "         6.2172e-15, 5.3291e-15, 3.5527e-15, 6.2172e-15, 3.5527e-15, 5.3291e-15,\n",
      "         5.3291e-15, 5.7732e-15, 5.5511e-16, 5.3291e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 20: layer1.2.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 20\n",
      "Max diff:\n",
      " tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4348e-16, 4.8572e-16, 1.0825e-15, 0.0000e+00, 1.1761e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.4980e-16, 7.7716e-16, 8.8818e-16, 0.0000e+00,\n",
      "         7.7716e-16, 1.9429e-16, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00,\n",
      "         2.8866e-15, 9.4369e-16, 0.0000e+00, 1.1102e-15, 0.0000e+00, 1.3323e-15,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3838e-16,\n",
      "         0.0000e+00, 0.0000e+00, 7.6328e-17, 0.0000e+00, 0.0000e+00, 2.4980e-16,\n",
      "         1.5682e-15, 5.3291e-15, 2.3315e-15, 1.0547e-15, 0.0000e+00, 1.6098e-15,\n",
      "         7.7716e-16, 3.5527e-15, 1.6653e-15, 1.6653e-15, 2.0539e-15, 2.9837e-15,\n",
      "         1.3323e-15, 2.2204e-15, 0.0000e+00, 2.8866e-15]], dtype=torch.float64)\n",
      " tensor([ 6,  7,  8, 10, 16, 20, 21, 22, 24, 25, 28, 30, 31, 33, 35, 36, 41, 44,\n",
      "        47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63])\n",
      "\n",
      "failing Cout = tensor([ 6,  7,  8, 10, 16, 20, 21, 22, 24, 25, 28, 30, 31, 33, 35, 36, 41, 44,\n",
      "        47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63])  (len = 33)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 21: layer1.2.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 21\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 34, 37, 38, 40, 41, 42, 43, 44, 46]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 63]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 21\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 21\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 21\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\t\t sending C_out tensor([16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 21\n",
      "Max diff:\n",
      " tensor([5.3291e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 9.4369e-16, 1.8874e-15, 1.8874e-15, 1.7764e-15, 2.2204e-15,\n",
      "         1.6653e-16, 3.1086e-15, 2.8866e-15, 3.3307e-16, 8.3267e-17, 1.3323e-15,\n",
      "         1.9429e-16, 6.6613e-16, 2.6645e-15, 3.5527e-15, 1.1102e-15, 8.8818e-16,\n",
      "         1.1102e-15, 1.1102e-15, 1.1102e-15, 1.1102e-15, 9.9920e-16, 7.7716e-16,\n",
      "         1.1102e-15, 1.7764e-15, 1.1102e-15, 1.5543e-15, 1.8319e-15, 7.7716e-16,\n",
      "         1.2212e-15, 1.1380e-15, 2.6645e-15, 1.7764e-15, 1.7764e-15, 1.3323e-15,\n",
      "         1.7764e-15, 1.7764e-15, 1.7764e-15, 3.5527e-15, 1.4433e-15, 3.5527e-15,\n",
      "         1.3323e-15, 3.5527e-15, 1.3323e-15, 2.6645e-15, 1.7764e-15, 1.3323e-15,\n",
      "         3.5527e-15, 3.1086e-15, 2.6645e-15, 3.5527e-15, 5.3291e-15, 2.1094e-15,\n",
      "         3.5527e-15, 3.1086e-15, 2.2204e-15, 2.2204e-15, 4.7184e-15, 5.3291e-15,\n",
      "         1.8874e-15, 2.6645e-15, 3.5527e-15, 2.7756e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 22: layer1.2.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 22\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 22\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 22\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 22\n",
      "\t\t Output tensor shape : torch.Size([1, 64, 32, 32])\n",
      "\t\t sending C_out tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 3\n",
      "Finished execution of layer 22\n",
      "Max diff:\n",
      " tensor([3.6082e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-16, 8.3267e-17, 1.2212e-15, 1.5543e-15, 4.4409e-16, 8.8818e-16,\n",
      "         5.5511e-17, 1.1102e-15, 1.3323e-15, 8.3267e-17, 2.7756e-17, 6.6613e-16,\n",
      "         5.5511e-17, 1.6653e-16, 1.1102e-15, 1.7764e-15, 9.7145e-17, 3.3307e-16,\n",
      "         1.3878e-16, 2.7756e-16, 1.6653e-16, 2.7756e-16, 3.6082e-16, 1.3878e-17,\n",
      "         1.9429e-16, 8.8818e-16, 4.4409e-16, 3.8858e-16, 5.5511e-16, 2.4980e-16,\n",
      "         4.5797e-16, 4.9960e-16, 1.2212e-15, 8.3267e-17, 1.3878e-16, 3.3307e-16,\n",
      "         6.6613e-16, 3.3307e-16, 4.4409e-16, 1.7764e-15, 6.1062e-16, 1.1102e-15,\n",
      "         1.1102e-16, 1.3323e-15, 8.3267e-17, 8.8818e-16, 8.8818e-16, 6.6613e-16,\n",
      "         1.9984e-15, 1.1102e-15, 1.1657e-15, 1.1102e-15, 3.1086e-15, 9.7145e-17,\n",
      "         1.1102e-15, 8.8818e-16, 7.2164e-16, 1.9429e-16, 3.6082e-15, 3.5527e-15,\n",
      "         6.6613e-16, 2.2204e-15, 1.9984e-15, 1.3878e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 23: layer1.2.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 23\n",
      "Max diff:\n",
      " tensor([1.0214e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 2.9143e-16, 1.4433e-15, 1.5543e-15, 8.8818e-16, 8.8818e-16,\n",
      "         5.5511e-17, 1.1102e-15, 1.3323e-15, 8.3267e-17, 2.7756e-17, 6.6613e-16,\n",
      "         5.5511e-17, 1.6653e-16, 1.1102e-15, 1.7764e-15, 3.5527e-15, 8.8818e-16,\n",
      "         2.2204e-15, 6.6613e-16, 4.9960e-16, 1.5543e-15, 3.7470e-16, 8.8818e-16,\n",
      "         5.2736e-16, 1.1102e-15, 8.8818e-16, 7.7716e-16, 8.8818e-16, 9.9920e-16,\n",
      "         8.0491e-16, 1.0547e-15, 1.7764e-15, 5.5511e-16, 6.6613e-16, 7.2164e-16,\n",
      "         6.6613e-16, 8.8818e-16, 8.8818e-16, 1.7764e-15, 1.7764e-15, 1.1102e-15,\n",
      "         8.8818e-16, 1.3323e-15, 8.8818e-16, 1.7764e-15, 1.9984e-15, 1.0270e-15,\n",
      "         5.3291e-15, 3.5527e-15, 2.6645e-15, 1.1102e-15, 5.3291e-15, 9.9920e-16,\n",
      "         3.5527e-15, 1.0214e-14, 8.8818e-16, 2.6645e-15, 3.6082e-15, 9.7700e-15,\n",
      "         2.6645e-15, 4.4409e-15, 4.4409e-15, 2.8866e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])  (len = 64)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 24: layer1.2.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 24\n",
      "Max diff:\n",
      " tensor([1.0214e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 2.4980e-16, 1.4433e-15, 1.0408e-15, 6.6613e-16, 4.1633e-16,\n",
      "         0.0000e+00, 5.1348e-16, 9.9920e-16, 0.0000e+00, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 4.4409e-16, 3.5527e-15, 8.8818e-16,\n",
      "         2.2204e-15, 6.6613e-16, 4.9960e-16, 1.5543e-15, 3.0531e-16, 8.8818e-16,\n",
      "         5.2736e-16, 1.1102e-15, 8.8818e-16, 6.1062e-16, 8.8818e-16, 9.9920e-16,\n",
      "         8.0491e-16, 1.0547e-15, 1.7764e-15, 5.5511e-16, 6.6613e-16, 4.9960e-16,\n",
      "         6.6613e-16, 8.8818e-16, 8.8818e-16, 1.0408e-15, 1.7764e-15, 4.4409e-16,\n",
      "         8.8818e-16, 1.3323e-15, 8.8818e-16, 1.7764e-15, 1.9984e-15, 9.9920e-16,\n",
      "         5.3291e-15, 3.5527e-15, 2.6645e-15, 7.1471e-16, 5.3291e-15, 9.9920e-16,\n",
      "         3.5527e-15, 1.0214e-14, 8.8818e-16, 2.6645e-15, 2.1094e-15, 9.7700e-15,\n",
      "         2.6645e-15, 4.4409e-15, 4.4409e-15, 2.8866e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "        23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
      "        41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
      "        59, 60, 61, 62, 63])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "        23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
      "        41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
      "        59, 60, 61, 62, 63])  (len = 59)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 25: layer2.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 25\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82,\n",
      "        83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 25\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 25\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 25\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 25\n",
      "Max diff:\n",
      " tensor([2.4869e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.9429e-16, 1.6653e-16, 8.8818e-16, 3.3307e-16, 8.8818e-16, 1.6653e-16,\n",
      "         5.1070e-15, 6.6613e-16, 4.4409e-16, 2.2204e-16, 1.7764e-15, 3.3307e-16,\n",
      "         1.1102e-15, 4.4409e-16, 5.5511e-16, 1.7764e-15, 4.4409e-16, 6.2172e-15,\n",
      "         5.5511e-16, 9.7145e-17, 2.7756e-16, 7.7716e-16, 8.8818e-16, 4.4409e-15,\n",
      "         7.9936e-15, 7.9936e-15, 1.1102e-15, 5.3291e-15, 6.6613e-16, 7.1054e-15,\n",
      "         5.5511e-16, 1.1102e-16, 1.7764e-14, 8.8818e-15, 6.2172e-15, 2.6645e-15,\n",
      "         8.8818e-16, 8.8818e-15, 2.6645e-15, 7.1054e-15, 2.6645e-15, 1.7764e-15,\n",
      "         5.3291e-15, 5.3291e-15, 3.3307e-16, 7.1054e-15, 6.2172e-15, 3.1086e-15,\n",
      "         5.5511e-16, 1.3323e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15, 5.3291e-15,\n",
      "         1.3323e-15, 6.2172e-15, 1.4211e-14, 5.3291e-15, 8.8818e-15, 4.4409e-15,\n",
      "         1.0658e-14, 8.8818e-16, 7.1054e-15, 3.5527e-15, 5.3291e-15, 6.6613e-16,\n",
      "         6.6613e-16, 6.2172e-15, 7.9936e-15, 1.0658e-14, 6.2172e-15, 2.2204e-15,\n",
      "         2.2204e-15, 6.6613e-15, 7.1054e-15, 5.3291e-15, 6.2172e-15, 7.1054e-15,\n",
      "         7.1054e-15, 3.5527e-15, 7.1054e-15, 1.7764e-14, 2.6645e-15, 4.6629e-15,\n",
      "         9.7700e-15, 3.1086e-15, 8.8818e-15, 3.5527e-15, 5.3291e-15, 1.2434e-14,\n",
      "         7.1054e-15, 4.4409e-15, 4.9960e-15, 5.3291e-15, 9.7700e-15, 1.0658e-14,\n",
      "         7.1054e-15, 6.2172e-15, 7.9936e-15, 1.2434e-14, 7.1054e-15, 8.8818e-15,\n",
      "         2.2204e-15, 8.8818e-15, 6.2172e-15, 5.7732e-15, 8.8818e-15, 8.8818e-15,\n",
      "         1.0658e-14, 7.1054e-15, 1.0658e-14, 8.8818e-15, 8.8818e-15, 2.4869e-14,\n",
      "         1.0658e-14, 1.4655e-14, 1.0658e-14, 8.8818e-15, 1.0658e-14, 7.1054e-15,\n",
      "         1.0658e-14, 7.1054e-15, 1.0658e-14, 5.3291e-15, 8.8818e-15, 1.0658e-14,\n",
      "         7.1054e-15, 2.1316e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 26: layer2.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 26\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 26\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 26\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 26\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 26\n",
      "Max diff:\n",
      " tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.5511e-17, 5.5511e-17, 2.2204e-16, 1.1102e-16, 2.2204e-16, 5.5511e-17,\n",
      "         2.1094e-15, 1.6653e-16, 8.3267e-17, 5.5511e-17, 4.4409e-16, 1.1102e-16,\n",
      "         3.3307e-16, 1.1102e-16, 1.1102e-16, 4.4409e-16, 1.1102e-16, 1.9984e-15,\n",
      "         1.6653e-16, 2.7756e-17, 8.3267e-17, 1.1102e-16, 1.6653e-16, 2.4425e-15,\n",
      "         3.5527e-15, 2.6645e-15, 2.7756e-16, 6.6613e-16, 1.1102e-16, 2.6645e-15,\n",
      "         1.1102e-16, 2.7756e-17, 1.0658e-14, 4.4409e-15, 1.1102e-15, 8.8818e-16,\n",
      "         2.7756e-16, 3.5527e-15, 6.6613e-16, 4.4409e-15, 4.4409e-16, 6.6613e-16,\n",
      "         2.2204e-15, 1.7764e-15, 1.1102e-16, 2.2204e-15, 2.2204e-15, 8.8818e-16,\n",
      "         1.1102e-16, 4.4409e-16, 1.7764e-15, 3.5527e-15, 1.7764e-15, 1.7764e-15,\n",
      "         4.4409e-16, 2.2204e-15, 4.4409e-15, 4.4409e-15, 4.4409e-15, 1.5543e-15,\n",
      "         5.3291e-15, 2.2204e-16, 1.5543e-15, 1.7764e-15, 1.3323e-15, 1.1102e-16,\n",
      "         1.6653e-16, 1.7764e-15, 3.5527e-15, 2.2204e-15, 5.3291e-15, 3.3307e-16,\n",
      "         6.6613e-16, 1.7764e-15, 2.6645e-15, 8.8818e-16, 1.5543e-15, 4.4409e-15,\n",
      "         5.5511e-16, 6.6613e-16, 1.7764e-15, 1.2434e-14, 4.4409e-16, 1.2212e-15,\n",
      "         3.9968e-15, 7.7716e-16, 2.2204e-15, 1.1102e-15, 1.7764e-15, 1.3323e-15,\n",
      "         2.6645e-15, 2.2204e-15, 1.1102e-15, 1.3323e-15, 1.4433e-15, 4.4409e-15,\n",
      "         3.1086e-15, 2.7200e-15, 7.9936e-15, 9.7700e-15, 3.5527e-15, 3.1086e-15,\n",
      "         5.5511e-16, 3.1086e-15, 3.5527e-15, 2.4425e-15, 3.1086e-15, 3.5527e-15,\n",
      "         7.1054e-15, 4.4409e-15, 3.5527e-15, 3.5527e-15, 2.6645e-15, 1.0658e-14,\n",
      "         7.1054e-15, 7.3275e-15, 1.0658e-14, 2.6645e-15, 2.6645e-15, 4.4409e-15,\n",
      "         8.8818e-15, 2.6645e-15, 9.7700e-15, 2.2204e-15, 2.6645e-15, 4.4409e-15,\n",
      "         5.3291e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 27: layer2.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 27\n",
      "Max diff:\n",
      " tensor([1.0658e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.1094e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9984e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4425e-15,\n",
      "         3.5527e-15, 2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 1.0658e-14, 0.0000e+00, 1.4572e-16, 0.0000e+00,\n",
      "         0.0000e+00, 1.2768e-15, 0.0000e+00, 2.6645e-15, 3.0531e-16, 0.0000e+00,\n",
      "         2.2204e-15, 1.7764e-15, 0.0000e+00, 1.7764e-15, 8.3267e-17, 7.7716e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15, 1.0547e-15, 8.3267e-17,\n",
      "         0.0000e+00, 1.7208e-15, 2.5535e-15, 4.4409e-15, 4.4409e-15, 1.5543e-15,\n",
      "         2.6645e-15, 0.0000e+00, 6.6613e-16, 1.7764e-15, 1.3323e-15, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-16, 3.1086e-15, 0.0000e+00, 5.3291e-15, 1.3878e-16,\n",
      "         0.0000e+00, 1.3323e-15, 2.6645e-15, 1.2490e-16, 1.5543e-15, 4.4409e-15,\n",
      "         1.9429e-16, 6.6613e-16, 7.7716e-16, 1.3323e-15, 0.0000e+00, 1.2212e-15,\n",
      "         3.9968e-15, 6.1062e-16, 1.1102e-15, 6.6613e-16, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-16, 2.2204e-15, 5.8287e-16, 4.9960e-16, 6.2450e-16, 4.4409e-15,\n",
      "         3.1086e-15, 2.7200e-15, 7.9936e-15, 2.6645e-15, 3.5527e-15, 3.1086e-15,\n",
      "         0.0000e+00, 1.9984e-15, 3.5527e-15, 1.2465e-15, 3.1086e-15, 1.4433e-15,\n",
      "         7.1054e-15, 2.2551e-15, 2.1372e-15, 6.6613e-16, 1.1102e-16, 3.3307e-15,\n",
      "         7.1054e-15, 7.3275e-15, 1.0658e-14, 7.6328e-16, 4.8225e-16, 3.9968e-15,\n",
      "         8.8818e-15, 1.5543e-15, 9.7700e-15, 2.2204e-15, 5.9674e-16, 4.4409e-15,\n",
      "         0.0000e+00, 1.9429e-15]], dtype=torch.float64)\n",
      " tensor([  6,  17,  23,  24,  25,  29,  32,  34,  37,  39,  40,  42,  43,  45,\n",
      "         46,  47,  51,  52,  53,  55,  56,  57,  58,  59,  60,  62,  63,  64,\n",
      "         67,  68,  70,  71,  73,  74,  75,  76,  77,  78,  79,  80,  81,  83,\n",
      "         84,  85,  86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127])\n",
      "\n",
      "failing Cout = tensor([  6,  17,  23,  24,  25,  29,  32,  34,  37,  39,  40,  42,  43,  45,\n",
      "         46,  47,  51,  52,  53,  55,  56,  57,  58,  59,  60,  62,  63,  64,\n",
      "         67,  68,  70,  71,  73,  74,  75,  76,  77,  78,  79,  80,  81,  83,\n",
      "         84,  85,  86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127])  (len = 82)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 28: layer2.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 28\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50,\n",
      "        51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126,\n",
      "        127]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 28\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 28\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 28\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82,\n",
      "        83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 28\n",
      "Max diff:\n",
      " tensor([7.1054e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.1316e-14, 7.1054e-15, 1.7764e-15, 8.8818e-16, 3.3307e-16, 1.7764e-14,\n",
      "         6.2172e-15, 1.6653e-16, 3.5527e-15, 6.6613e-16, 2.2204e-15, 8.8818e-15,\n",
      "         1.1102e-15, 1.7764e-15, 1.0658e-14, 1.5543e-15, 1.1102e-15, 3.5527e-15,\n",
      "         8.8818e-16, 3.3307e-16, 1.7764e-15, 2.7756e-16, 1.3323e-15, 1.9984e-15,\n",
      "         1.7764e-15, 1.1102e-15, 3.3307e-16, 2.2204e-15, 6.2172e-15, 6.6613e-16,\n",
      "         8.8818e-16, 4.4409e-15, 6.2172e-15, 1.4211e-14, 5.3291e-15, 1.0658e-14,\n",
      "         2.1316e-14, 8.8818e-16, 4.9738e-14, 1.0658e-14, 8.8818e-16, 1.4211e-14,\n",
      "         1.7764e-14, 1.7764e-14, 3.5527e-15, 3.1086e-15, 1.4211e-14, 1.5987e-14,\n",
      "         2.6645e-15, 2.2204e-14, 3.5527e-15, 1.7764e-14, 1.7764e-14, 6.2172e-15,\n",
      "         1.2434e-14, 8.8818e-15, 2.8422e-14, 1.3323e-14, 1.2434e-14, 1.4211e-14,\n",
      "         1.3323e-15, 1.1102e-15, 1.3323e-15, 1.4211e-14, 7.1054e-14, 1.4211e-14,\n",
      "         2.6645e-15, 1.7764e-15, 1.1102e-15, 2.8422e-14, 1.3323e-15, 1.0658e-14,\n",
      "         2.8422e-14, 1.1546e-14, 8.8818e-15, 1.7764e-15, 8.8818e-16, 8.8818e-15,\n",
      "         5.3291e-15, 1.4211e-14, 1.7764e-14, 1.4211e-14, 2.1316e-14, 5.3291e-15,\n",
      "         8.8818e-15, 2.4869e-14, 1.9540e-14, 2.1316e-14, 8.8818e-16, 1.7764e-15,\n",
      "         1.2434e-14, 1.9540e-14, 2.1316e-14, 4.4409e-15, 1.7764e-14, 2.1316e-14,\n",
      "         2.1316e-14, 1.7764e-14, 3.5527e-15, 1.6431e-14, 2.1316e-14, 1.7764e-14,\n",
      "         2.4869e-14, 1.8652e-14, 2.1316e-14, 2.8422e-14, 2.8422e-14, 3.1974e-14,\n",
      "         2.1316e-14, 2.1316e-14, 1.2434e-14, 3.5527e-14, 1.2434e-14, 2.1316e-14,\n",
      "         1.0658e-14, 5.6843e-14, 1.9540e-14, 1.2323e-14, 2.8422e-14, 2.8422e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.6645e-14, 2.1316e-14, 3.5527e-14, 1.0658e-14,\n",
      "         2.3093e-14, 1.5099e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 29: layer2.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 29\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 29\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 29\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 29\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 29\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.0658e-14, 2.2204e-15, 6.6613e-16, 2.7756e-16, 1.1102e-16, 3.5527e-15,\n",
      "         1.9984e-15, 5.5511e-17, 1.3323e-15, 2.2204e-16, 7.7716e-16, 2.2204e-15,\n",
      "         3.3307e-16, 6.6613e-16, 3.5527e-15, 5.5511e-16, 3.3307e-16, 1.1102e-15,\n",
      "         3.3307e-16, 1.1102e-16, 6.6613e-16, 1.1102e-16, 5.5511e-16, 7.2164e-16,\n",
      "         6.6613e-16, 4.4409e-16, 1.1102e-16, 7.7716e-16, 2.2204e-15, 2.2204e-16,\n",
      "         3.3307e-16, 1.3323e-15, 1.7764e-15, 3.5527e-15, 1.3323e-15, 2.6645e-15,\n",
      "         1.0658e-14, 3.3307e-16, 2.1316e-14, 2.6645e-15, 3.3307e-16, 7.1054e-15,\n",
      "         1.2434e-14, 8.8818e-15, 1.1102e-15, 1.1102e-15, 7.1054e-15, 2.1316e-14,\n",
      "         8.8818e-16, 9.3259e-15, 1.3323e-15, 9.7700e-15, 7.1054e-15, 1.7764e-15,\n",
      "         8.8818e-15, 3.5527e-15, 4.2633e-14, 5.7732e-15, 7.1054e-15, 8.8818e-15,\n",
      "         4.4409e-16, 3.3307e-16, 4.4409e-16, 5.3291e-15, 3.5527e-14, 4.4409e-15,\n",
      "         1.1102e-15, 6.6613e-16, 4.4409e-16, 5.3291e-15, 4.4409e-16, 5.3291e-15,\n",
      "         1.4211e-14, 3.5527e-15, 2.6645e-15, 6.6613e-16, 2.7756e-16, 3.1086e-15,\n",
      "         1.5543e-15, 1.2434e-14, 1.7764e-14, 6.2172e-15, 1.0658e-14, 1.7764e-15,\n",
      "         3.5527e-15, 6.2172e-15, 3.5527e-15, 8.8818e-15, 3.3307e-16, 6.6613e-16,\n",
      "         3.5527e-15, 1.2434e-14, 9.7700e-15, 1.3323e-15, 6.2172e-15, 1.4211e-14,\n",
      "         9.7700e-15, 1.0658e-14, 1.3323e-15, 9.7700e-15, 1.4211e-14, 2.1316e-14,\n",
      "         1.2434e-14, 1.7764e-14, 1.7764e-14, 3.9080e-14, 1.7764e-14, 1.1546e-14,\n",
      "         1.7764e-14, 2.1316e-14, 9.7700e-15, 3.1974e-14, 8.8818e-15, 1.4211e-14,\n",
      "         1.4211e-14, 2.8422e-14, 1.4211e-14, 4.1633e-15, 2.8422e-14, 2.8422e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.4869e-14, 1.2434e-14, 3.5527e-14, 9.7700e-15,\n",
      "         3.0198e-14, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 30: layer2.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 30\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 30\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 30\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 30\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 30\n",
      "Max diff:\n",
      " tensor([6.2172e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.6613e-16, 5.5511e-16, 6.9389e-17, 8.3267e-17, 4.5103e-17, 5.5511e-16,\n",
      "         6.6613e-16, 5.5511e-17, 2.2204e-16, 8.3267e-17, 8.3267e-17, 6.6613e-16,\n",
      "         6.9389e-17, 5.5511e-17, 1.9429e-16, 1.3878e-16, 4.1633e-17, 1.6653e-16,\n",
      "         4.5103e-17, 3.3827e-17, 3.0683e-17, 4.5103e-17, 5.5511e-17, 3.4694e-17,\n",
      "         6.9389e-17, 1.7347e-17, 3.8923e-17, 2.0817e-17, 1.6653e-16, 5.5511e-17,\n",
      "         4.1633e-17, 2.2204e-16, 6.6613e-16, 4.4409e-16, 4.4409e-16, 1.3323e-15,\n",
      "         1.5543e-15, 1.1102e-16, 1.1657e-15, 6.6613e-16, 1.1102e-16, 3.5527e-15,\n",
      "         2.6645e-15, 2.2204e-15, 3.3307e-16, 2.7756e-16, 4.4409e-16, 1.2212e-15,\n",
      "         3.8858e-16, 1.9984e-15, 2.2204e-16, 1.7764e-15, 3.5527e-15, 3.3307e-16,\n",
      "         3.5527e-15, 1.3323e-15, 2.2204e-15, 8.8818e-16, 2.2204e-15, 1.9984e-15,\n",
      "         1.1102e-16, 8.3267e-17, 1.2143e-16, 1.1102e-15, 1.3323e-15, 6.6613e-16,\n",
      "         1.1102e-16, 1.1102e-16, 5.5511e-17, 1.3323e-15, 1.1102e-16, 1.8735e-16,\n",
      "         1.7764e-15, 9.4369e-16, 2.2204e-16, 6.9389e-17, 8.3267e-17, 2.2204e-16,\n",
      "         4.4409e-16, 1.7764e-15, 2.6645e-15, 7.7716e-16, 6.6613e-16, 3.3307e-16,\n",
      "         7.2164e-16, 1.9984e-15, 8.8818e-16, 4.4409e-16, 9.7145e-17, 1.3878e-16,\n",
      "         5.5511e-16, 1.7764e-15, 1.3323e-15, 1.1102e-16, 8.8818e-16, 1.7764e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.3307e-16, 3.5527e-15, 3.5527e-15, 2.4425e-15,\n",
      "         3.5527e-15, 5.3291e-15, 2.6645e-15, 6.2172e-15, 2.2204e-15, 1.5543e-15,\n",
      "         6.2172e-15, 1.5543e-15, 3.9968e-15, 2.6645e-15, 1.8874e-15, 2.2204e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.9968e-15, 2.6645e-15, 3.5527e-15, 2.6645e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.1086e-15, 2.2204e-15, 4.4409e-15, 9.8706e-16,\n",
      "         5.3291e-15, 3.5527e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 31: layer2.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 31\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 31\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 31\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 31\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 31\n",
      "Max diff:\n",
      " tensor([7.5495e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.1633e-17, 1.6653e-16, 2.2118e-17, 2.7756e-17, 1.3878e-17, 1.6653e-16,\n",
      "         2.4980e-16, 1.3878e-17, 8.3267e-17, 2.7756e-17, 2.7756e-17, 1.6653e-16,\n",
      "         2.7756e-17, 2.0817e-17, 5.5511e-17, 5.5511e-17, 1.3878e-17, 5.5511e-17,\n",
      "         1.3878e-17, 1.0408e-17, 1.0408e-17, 1.3878e-17, 1.7347e-17, 1.3878e-17,\n",
      "         2.0817e-17, 6.9389e-18, 1.3878e-17, 6.9389e-18, 5.5511e-17, 1.7781e-17,\n",
      "         1.3878e-17, 8.3267e-17, 2.2204e-16, 5.5511e-17, 1.1102e-16, 4.4409e-16,\n",
      "         1.3323e-15, 3.4694e-17, 6.1062e-16, 1.1102e-16, 3.8164e-17, 2.6645e-15,\n",
      "         3.5527e-15, 5.5511e-16, 1.1102e-16, 1.1102e-16, 1.3878e-17, 6.1062e-16,\n",
      "         1.2490e-16, 1.1102e-15, 5.5511e-17, 8.8818e-16, 2.6645e-15, 1.1102e-16,\n",
      "         2.6645e-15, 3.1225e-17, 1.3323e-15, 1.1102e-16, 1.7764e-15, 1.9984e-15,\n",
      "         4.1633e-17, 2.7756e-17, 4.1633e-17, 3.3307e-16, 8.8818e-16, 1.6653e-16,\n",
      "         4.1633e-17, 3.4694e-17, 1.7347e-17, 2.2204e-16, 2.7756e-17, 6.2450e-17,\n",
      "         6.6613e-16, 5.5511e-16, 8.3267e-17, 2.7756e-17, 2.7756e-17, 8.3267e-17,\n",
      "         1.1102e-16, 2.2204e-16, 1.7764e-15, 1.6653e-16, 1.2490e-16, 8.3267e-17,\n",
      "         2.0817e-16, 9.9920e-16, 3.3307e-16, 1.1102e-16, 3.4694e-17, 4.8572e-17,\n",
      "         1.6653e-16, 1.7764e-15, 5.5511e-16, 4.1633e-17, 1.6653e-16, 1.3323e-15,\n",
      "         1.7764e-15, 1.3323e-15, 1.1102e-16, 2.6645e-15, 2.2204e-15, 1.7764e-15,\n",
      "         2.2204e-15, 2.8866e-15, 2.6645e-15, 7.5495e-15, 8.3267e-16, 3.3307e-16,\n",
      "         5.3291e-15, 4.5797e-16, 1.9984e-15, 1.7764e-15, 6.6613e-16, 1.1102e-15,\n",
      "         2.6645e-15, 2.2204e-15, 2.6645e-15, 1.3323e-15, 1.5543e-15, 1.3323e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.6645e-15, 7.7716e-16, 2.2204e-15, 5.0654e-16,\n",
      "         4.4409e-15, 2.2204e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 32: layer2.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 32\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.0658e-14, 2.2204e-15, 6.6613e-16, 2.7756e-16, 1.1102e-16, 3.5527e-15,\n",
      "         2.2204e-15, 5.5511e-17, 1.3323e-15, 2.2204e-16, 6.6613e-16, 2.2204e-15,\n",
      "         3.3307e-16, 6.6613e-16, 3.5527e-15, 5.5511e-16, 3.3307e-16, 1.1102e-15,\n",
      "         3.3307e-16, 1.1102e-16, 6.6613e-16, 1.1102e-16, 5.5511e-16, 7.2164e-16,\n",
      "         6.6613e-16, 4.4409e-16, 1.1102e-16, 7.7716e-16, 2.2204e-15, 2.2204e-16,\n",
      "         3.3307e-16, 1.3323e-15, 1.7764e-15, 3.5527e-15, 1.3323e-15, 3.5527e-15,\n",
      "         1.0658e-14, 3.3307e-16, 2.1316e-14, 2.6645e-15, 3.3307e-16, 7.1054e-15,\n",
      "         1.2434e-14, 8.8818e-15, 8.8818e-16, 1.1102e-15, 7.1054e-15, 2.1316e-14,\n",
      "         1.1102e-15, 8.8818e-15, 1.3323e-15, 9.7700e-15, 8.8818e-15, 1.7764e-15,\n",
      "         1.0658e-14, 3.5527e-15, 4.2633e-14, 5.7732e-15, 7.9936e-15, 9.7700e-15,\n",
      "         4.4409e-16, 3.3307e-16, 4.4409e-16, 5.3291e-15, 3.5527e-14, 4.4409e-15,\n",
      "         1.1102e-15, 6.6613e-16, 4.4409e-16, 7.1054e-15, 4.4409e-16, 5.3291e-15,\n",
      "         1.4211e-14, 3.5527e-15, 2.6645e-15, 6.6613e-16, 3.3307e-16, 3.1086e-15,\n",
      "         1.5543e-15, 1.2434e-14, 1.7764e-14, 6.2172e-15, 1.0658e-14, 1.7764e-15,\n",
      "         3.5527e-15, 6.2172e-15, 3.5527e-15, 8.8818e-15, 3.3307e-16, 6.6613e-16,\n",
      "         3.5527e-15, 1.4211e-14, 9.7700e-15, 1.3323e-15, 6.2172e-15, 1.4211e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.3323e-15, 1.0214e-14, 1.4211e-14, 2.1316e-14,\n",
      "         1.2434e-14, 1.7764e-14, 1.7764e-14, 3.7303e-14, 1.7764e-14, 1.1546e-14,\n",
      "         2.1316e-14, 2.1316e-14, 9.7700e-15, 3.1974e-14, 8.8818e-15, 1.4211e-14,\n",
      "         1.4211e-14, 2.8422e-14, 1.4211e-14, 4.2188e-15, 2.8422e-14, 2.8422e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.3093e-14, 1.2434e-14, 4.2633e-14, 9.7700e-15,\n",
      "         3.0198e-14, 9.3259e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 33: layer2.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 33\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         8.8818e-15, 8.8818e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1316e-14,\n",
      "         0.0000e+00, 5.7176e-15, 0.0000e+00, 9.7700e-15, 4.8850e-15, 0.0000e+00,\n",
      "         1.0658e-14, 1.9984e-15, 4.2633e-14, 5.3291e-15, 7.9936e-15, 9.7700e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.2434e-14, 1.7764e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1086e-15, 1.7208e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.4211e-14, 3.6637e-15, 0.0000e+00, 0.0000e+00, 1.4211e-14,\n",
      "         4.2188e-15, 8.8818e-15, 0.0000e+00, 7.1054e-15, 9.7700e-15, 2.1316e-14,\n",
      "         5.3291e-15, 1.2434e-14, 9.7700e-15, 3.7303e-14, 0.0000e+00, 5.7732e-15,\n",
      "         2.1316e-14, 2.1316e-14, 6.5503e-15, 3.1974e-14, 8.8818e-15, 1.2434e-14,\n",
      "         1.4211e-14, 0.0000e+00, 6.2172e-15, 4.1078e-15, 2.8422e-14, 2.8422e-14,\n",
      "         7.5495e-15, 1.7764e-14, 1.9540e-14, 3.5527e-15, 3.5527e-15, 9.7700e-15,\n",
      "         3.0198e-14, 9.3259e-15]], dtype=torch.float64)\n",
      " tensor([  0,  41,  42,  43,  47,  49,  51,  52,  54,  55,  56,  57,  58,  59,\n",
      "         73,  79,  80,  85,  86,  91,  92,  95,  96,  97,  99, 100, 101, 102,\n",
      "        103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,  41,  42,  43,  47,  49,  51,  52,  54,  55,  56,  57,  58,  59,\n",
      "         73,  79,  80,  85,  86,  91,  92,  95,  96,  97,  99, 100, 101, 102,\n",
      "        103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127])  (len = 51)\n",
      "passing Cout = tensor([106])  (len = 1)\n",
      "\n",
      "Executing module 34: layer2.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 34\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 34, 36, 40, 47, 48, 54, 55, 56, 57, 58, 59]) to machine 1\n",
      "\t\t sending C_out tensor([69, 70, 71, 73, 74, 75, 76, 79, 83, 85, 86, 89, 93, 94]) to machine 2\n",
      "\t\t sending C_out tensor([ 97, 106, 111, 115, 118, 120, 121, 122, 123, 125]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 34\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,\n",
      "        84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 34\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54,\n",
      "        55, 56, 57, 59, 60, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 34\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 34\n",
      "Max diff:\n",
      " tensor([2.2737e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 3.5527e-15, 2.6645e-15, 5.3291e-15, 1.7764e-14, 3.5527e-15,\n",
      "         1.7764e-15, 8.8818e-15, 6.2172e-15, 1.7764e-14, 1.0658e-14, 1.7764e-15,\n",
      "         2.6645e-15, 4.2633e-14, 4.4409e-15, 1.0658e-14, 1.0658e-14, 7.9936e-15,\n",
      "         4.4409e-15, 3.5527e-15, 3.5527e-15, 2.6645e-15, 1.4211e-14, 4.4409e-15,\n",
      "         3.5527e-14, 2.2204e-15, 4.4409e-15, 7.1054e-15, 5.6843e-14, 3.5527e-14,\n",
      "         4.4409e-15, 8.8818e-15, 5.6843e-14, 4.2633e-14, 3.5527e-14, 8.5265e-14,\n",
      "         1.4211e-14, 4.2633e-14, 2.8422e-14, 8.5265e-14, 7.1054e-14, 1.7764e-14,\n",
      "         9.9476e-14, 8.5265e-14, 6.3949e-14, 6.2172e-15, 4.9738e-14, 3.5527e-14,\n",
      "         9.9476e-14, 6.3949e-14, 2.8422e-14, 3.5527e-14, 8.5265e-14, 2.1316e-14,\n",
      "         6.7502e-14, 8.5265e-14, 4.4409e-15, 3.5527e-14, 5.6843e-14, 2.8422e-14,\n",
      "         3.5527e-14, 8.5265e-14, 3.5527e-15, 4.6185e-14, 3.5527e-14, 3.5527e-15,\n",
      "         3.5527e-15, 5.3291e-15, 3.5527e-14, 1.4211e-13, 1.7764e-14, 2.1316e-14,\n",
      "         4.2633e-14, 1.0658e-14, 4.4409e-15, 1.4211e-14, 1.4211e-14, 4.9738e-14,\n",
      "         2.8422e-14, 1.0658e-14, 4.4409e-15, 2.8422e-14, 2.4869e-14, 1.0658e-14,\n",
      "         1.4211e-14, 4.2633e-14, 2.8422e-14, 5.3291e-15, 7.1054e-14, 3.5527e-15,\n",
      "         3.5527e-14, 4.2633e-14, 3.5527e-15, 2.1316e-14, 2.1316e-14, 5.6843e-14,\n",
      "         8.5265e-14, 8.5265e-14, 8.5265e-14, 9.9476e-14, 1.4211e-13, 7.1054e-14,\n",
      "         1.4211e-13, 9.9476e-14, 1.9895e-13, 5.6843e-14, 8.5265e-14, 1.1369e-13,\n",
      "         1.1369e-13, 8.8818e-15, 8.5265e-14, 2.2737e-13, 1.7053e-13, 1.4211e-14,\n",
      "         1.4211e-13, 2.8422e-14, 5.6843e-14, 9.9476e-14, 1.9895e-13, 7.1054e-14,\n",
      "         9.9476e-14, 3.5527e-14, 1.2790e-13, 1.7053e-13, 8.5265e-14, 8.5265e-14,\n",
      "         1.7053e-13, 9.9476e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 35: layer2.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 35\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 35\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 35\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 35\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 35\n",
      "Max diff:\n",
      " tensor([1.1369e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 1.1102e-15, 8.8818e-16, 1.7764e-15, 4.4409e-15, 1.1102e-15,\n",
      "         6.6613e-16, 3.1086e-15, 2.2204e-15, 6.2172e-15, 3.5527e-15, 5.5511e-16,\n",
      "         6.6613e-16, 1.0658e-14, 1.7764e-15, 3.5527e-15, 3.5527e-15, 2.4425e-15,\n",
      "         1.5543e-15, 1.1102e-15, 1.1102e-15, 8.8818e-16, 4.4409e-15, 1.3323e-15,\n",
      "         8.8818e-15, 5.5511e-16, 1.3323e-15, 2.6645e-15, 8.8818e-15, 1.0658e-14,\n",
      "         1.5543e-15, 2.6645e-15, 2.1316e-14, 1.4211e-14, 1.4211e-14, 1.7764e-14,\n",
      "         3.5527e-15, 8.8818e-15, 8.8818e-15, 2.1316e-14, 1.7764e-14, 4.4409e-15,\n",
      "         1.5987e-14, 1.4211e-14, 6.2172e-15, 2.2204e-15, 9.7700e-15, 8.8818e-15,\n",
      "         7.1054e-15, 1.4211e-14, 5.3291e-15, 8.8818e-15, 1.4211e-14, 5.3291e-15,\n",
      "         5.9952e-15, 1.7764e-14, 1.5543e-15, 1.0658e-14, 1.7764e-14, 5.3291e-15,\n",
      "         5.3291e-15, 2.8422e-14, 1.1102e-15, 7.9936e-15, 1.2434e-14, 8.8818e-16,\n",
      "         1.3323e-15, 1.7764e-15, 1.4211e-14, 4.2633e-14, 5.3291e-15, 5.3291e-15,\n",
      "         8.8818e-15, 2.2204e-15, 1.3323e-15, 4.4409e-15, 4.4409e-15, 7.1054e-15,\n",
      "         7.1054e-15, 2.6645e-15, 1.5543e-15, 1.0658e-14, 6.2172e-15, 3.1086e-15,\n",
      "         3.5527e-15, 1.2434e-14, 7.1054e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15,\n",
      "         1.2434e-14, 1.4211e-14, 1.3323e-15, 5.3291e-15, 7.1054e-15, 1.7764e-14,\n",
      "         2.1316e-14, 2.1316e-14, 2.4869e-14, 4.9738e-14, 6.3949e-14, 2.1316e-14,\n",
      "         7.1054e-14, 2.1316e-14, 3.5527e-14, 1.4211e-14, 2.1316e-14, 2.8422e-14,\n",
      "         2.8422e-14, 3.1086e-15, 2.8422e-14, 1.1369e-13, 2.1316e-14, 4.4409e-15,\n",
      "         5.6843e-14, 8.8818e-15, 1.2434e-14, 2.8422e-14, 8.5265e-14, 1.7764e-14,\n",
      "         5.6843e-14, 1.0658e-14, 4.9738e-14, 3.1974e-14, 2.1316e-14, 1.7764e-14,\n",
      "         3.9080e-14, 8.8818e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 36: layer2.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 36\n",
      "Max diff:\n",
      " tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-16, 2.7686e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.3584e-15, 0.0000e+00, 2.0539e-15, 0.0000e+00, 1.4502e-15, 0.0000e+00,\n",
      "         0.0000e+00, 3.1086e-15, 5.5511e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.3291e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00,\n",
      "         2.6645e-15, 0.0000e+00, 0.0000e+00, 3.9968e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.7184e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-16, 2.6645e-15, 5.3291e-15, 5.7732e-15, 1.0658e-14, 0.0000e+00,\n",
      "         7.1054e-15, 8.8818e-15, 0.0000e+00, 0.0000e+00, 1.0658e-14, 4.2188e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.0658e-14, 0.0000e+00, 2.6645e-15, 0.0000e+00,\n",
      "         9.7700e-15, 0.0000e+00, 4.4409e-15, 5.3291e-15, 8.8818e-15, 5.7732e-15,\n",
      "         1.4211e-14, 0.0000e+00, 1.4211e-14, 0.0000e+00, 4.4409e-15, 4.4409e-15,\n",
      "         0.0000e+00, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([ 34,  35,  42,  44,  46,  49,  50,  54,  58,  60,  63,  72,  96,  97,\n",
      "         98,  99, 100, 102, 103, 106, 107, 110, 112, 114, 116, 117, 118, 119,\n",
      "        120, 122, 124, 125, 127])\n",
      "\n",
      "failing Cout = tensor([ 34,  35,  42,  44,  46,  49,  50,  54,  58,  60,  63,  72,  96,  97,\n",
      "         98,  99, 100, 102, 103, 106, 107, 110, 112, 114, 116, 117, 118, 119,\n",
      "        120, 122, 124, 125, 127])  (len = 33)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 37: layer2.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 37\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 37\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 37\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2, 10, 11, 14, 15, 16, 18, 19, 23, 26, 27, 30]) to machine 0\n",
      "\t\t sending C_out tensor([37, 39, 43, 60]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 99, 105, 110, 113, 114, 117, 119, 120, 121, 123]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 37\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 37\n",
      "Max diff:\n",
      " tensor([2.1982e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.2172e-15, 1.7764e-15, 2.7756e-16, 3.5527e-15, 8.3267e-17, 4.4409e-15,\n",
      "         3.7748e-15, 2.2204e-16, 3.5527e-15, 6.6613e-16, 4.4409e-15, 7.1054e-15,\n",
      "         6.6613e-16, 1.0658e-14, 8.8818e-16, 5.3291e-15, 1.1102e-16, 4.4409e-15,\n",
      "         2.2204e-16, 1.4211e-14, 8.8818e-15, 3.3307e-16, 4.4409e-15, 5.3291e-15,\n",
      "         1.1102e-16, 2.6645e-15, 1.7764e-15, 7.9936e-15, 1.7764e-15, 1.6653e-16,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 7.2164e-16,\n",
      "         8.8818e-15, 2.8866e-15, 3.1086e-15, 5.3291e-15, 5.3291e-15, 3.9968e-15,\n",
      "         3.5527e-15, 3.1086e-15, 6.6613e-16, 4.9960e-16, 5.3291e-15, 4.4409e-15,\n",
      "         3.3307e-16, 3.3307e-15, 4.4409e-15, 4.4409e-15, 2.4425e-15, 3.5527e-15,\n",
      "         6.2172e-15, 5.3291e-15, 3.8025e-15, 3.1086e-15, 4.4409e-15, 3.1086e-15,\n",
      "         4.6074e-15, 2.1094e-15, 3.5527e-15, 5.3291e-15, 4.4409e-15, 2.6645e-15,\n",
      "         1.3323e-15, 1.7764e-15, 1.3878e-16, 4.4409e-15, 1.3878e-16, 2.2204e-15,\n",
      "         1.0658e-14, 3.1086e-15, 5.3291e-15, 1.7764e-15, 3.3307e-16, 3.5527e-15,\n",
      "         1.3323e-15, 9.7700e-15, 5.3291e-15, 2.2204e-15, 3.5527e-15, 8.8818e-16,\n",
      "         3.5527e-15, 3.5527e-15, 7.1054e-15, 2.6645e-15, 4.1633e-16, 1.1102e-16,\n",
      "         2.2204e-15, 2.6645e-15, 7.1054e-15, 3.1086e-15, 7.1054e-15, 2.6645e-15,\n",
      "         8.3822e-15, 5.7732e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 3.9968e-15,\n",
      "         1.2434e-14, 6.4393e-15, 7.1054e-15, 5.3291e-15, 1.4211e-14, 7.9936e-15,\n",
      "         7.1054e-15, 7.1054e-15, 1.4211e-14, 1.7764e-14, 1.4211e-14, 1.0658e-14,\n",
      "         7.1054e-15, 7.1054e-15, 6.4393e-15, 7.1054e-15, 1.4211e-14, 1.0658e-14,\n",
      "         9.3259e-15, 1.0658e-14, 7.1054e-15, 7.9936e-15, 2.1982e-14, 4.4409e-15,\n",
      "         1.0658e-14, 1.2434e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 38: layer2.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 38\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 38\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 38\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 38\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 38\n",
      "Max diff:\n",
      " tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-15, 3.3307e-16, 9.7145e-17, 2.2204e-16, 2.7756e-17, 4.4409e-16,\n",
      "         6.1062e-16, 8.3267e-17, 6.6613e-16, 2.2204e-16, 7.7716e-16, 2.6645e-15,\n",
      "         2.2204e-16, 2.3315e-15, 3.3307e-16, 1.1866e-15, 4.1633e-17, 6.9389e-18,\n",
      "         8.3267e-17, 7.1054e-15, 2.2204e-15, 1.1102e-16, 3.3307e-16, 2.6645e-15,\n",
      "         5.5511e-17, 6.6613e-16, 3.3307e-16, 1.1102e-15, 2.7756e-17, 5.5511e-17,\n",
      "         4.4409e-16, 8.8818e-16, 1.3323e-15, 1.3323e-15, 2.6645e-15, 3.3307e-16,\n",
      "         3.5527e-15, 8.8818e-16, 1.8041e-16, 1.7764e-15, 1.7764e-15, 7.2164e-16,\n",
      "         1.5543e-15, 1.2212e-15, 2.2204e-16, 1.3878e-16, 2.6645e-15, 2.2204e-15,\n",
      "         1.1102e-16, 2.7756e-16, 1.1102e-15, 1.0825e-15, 8.8818e-16, 1.3323e-15,\n",
      "         1.2212e-15, 2.2204e-16, 1.8180e-15, 6.1062e-16, 1.1102e-15, 6.6613e-16,\n",
      "         9.9920e-16, 3.3307e-16, 8.8818e-16, 6.6613e-16, 8.8818e-16, 6.6613e-16,\n",
      "         2.2204e-16, 3.8858e-16, 5.5511e-17, 1.1102e-15, 4.8572e-17, 1.1102e-16,\n",
      "         3.5527e-15, 1.9429e-16, 2.6645e-15, 6.1062e-16, 1.1102e-16, 1.7764e-15,\n",
      "         3.3307e-16, 2.2204e-15, 1.3323e-15, 2.3592e-16, 1.3323e-15, 8.3267e-17,\n",
      "         5.5511e-17, 2.2204e-16, 2.2204e-16, 8.8818e-16, 1.2490e-16, 4.1633e-17,\n",
      "         1.3878e-16, 1.3878e-17, 1.7764e-15, 6.6613e-16, 2.6645e-15, 6.9389e-18,\n",
      "         3.7331e-15, 3.6082e-16, 1.9984e-15, 1.7764e-15, 2.6645e-15, 1.2212e-15,\n",
      "         1.5543e-15, 2.4425e-15, 2.6645e-15, 1.1102e-15, 3.1086e-15, 1.7764e-15,\n",
      "         2.6645e-15, 1.7764e-15, 7.1054e-15, 4.8850e-15, 5.3291e-15, 4.4409e-15,\n",
      "         2.2204e-15, 3.1086e-15, 2.7756e-15, 2.6645e-15, 3.1086e-15, 8.8818e-16,\n",
      "         3.1086e-15, 4.4409e-15, 1.3323e-15, 1.3323e-15, 5.4401e-15, 3.8858e-16,\n",
      "         1.5543e-15, 3.9968e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 39: layer2.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 39\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.2204e-15, 3.3307e-16, 9.7145e-17, 2.2204e-16, 2.7756e-17, 4.4409e-16,\n",
      "         6.1062e-16, 8.3267e-17, 6.6613e-16, 2.2204e-16, 7.7716e-16, 2.6645e-15,\n",
      "         2.2204e-16, 2.3315e-15, 3.3307e-16, 1.1866e-15, 4.1633e-17, 6.9389e-18,\n",
      "         8.3267e-17, 7.1054e-15, 2.2204e-15, 1.1102e-16, 3.3307e-16, 2.6645e-15,\n",
      "         5.5511e-17, 6.6613e-16, 3.3307e-16, 1.1102e-15, 2.7756e-17, 5.5511e-17,\n",
      "         4.4409e-16, 8.8818e-16, 1.3323e-15, 1.3323e-15, 2.6645e-15, 3.3307e-16,\n",
      "         3.5527e-15, 8.8818e-16, 1.8041e-16, 1.7764e-15, 1.7764e-15, 7.1054e-15,\n",
      "         8.8818e-15, 9.3259e-15, 2.2204e-16, 1.3878e-16, 2.6645e-15, 2.1316e-14,\n",
      "         1.1102e-16, 5.7732e-15, 1.1102e-15, 9.7700e-15, 5.1903e-15, 1.3323e-15,\n",
      "         1.0658e-14, 1.9984e-15, 4.2633e-14, 6.2172e-15, 7.9936e-15, 9.7700e-15,\n",
      "         9.9920e-16, 3.3307e-16, 8.8818e-16, 6.6613e-16, 8.8818e-16, 6.6613e-16,\n",
      "         2.2204e-16, 3.8858e-16, 5.5511e-17, 1.1102e-15, 4.8572e-17, 1.1102e-16,\n",
      "         3.5527e-15, 2.6645e-15, 2.6645e-15, 6.1062e-16, 1.1102e-16, 1.7764e-15,\n",
      "         3.3307e-16, 1.2434e-14, 2.1316e-14, 2.3592e-16, 1.3323e-15, 8.3267e-17,\n",
      "         5.5511e-17, 3.1086e-15, 1.7347e-15, 8.8818e-16, 1.2490e-16, 4.1633e-17,\n",
      "         1.3878e-16, 1.4211e-14, 3.7748e-15, 6.6613e-16, 2.6645e-15, 1.4211e-14,\n",
      "         4.2188e-15, 8.8818e-15, 1.9984e-15, 7.1054e-15, 1.0658e-14, 2.1316e-14,\n",
      "         6.6613e-15, 1.2434e-14, 1.0214e-14, 3.7303e-14, 3.1086e-15, 5.7732e-15,\n",
      "         2.1316e-14, 2.1316e-14, 7.1054e-15, 3.5527e-14, 7.9936e-15, 1.2434e-14,\n",
      "         1.4211e-14, 3.1086e-15, 7.1054e-15, 3.9968e-15, 2.8422e-14, 2.8422e-14,\n",
      "         8.4377e-15, 1.7764e-14, 1.8652e-14, 4.4409e-15, 5.4401e-15, 9.7700e-15,\n",
      "         3.0198e-14, 9.3259e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 40: layer2.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 40\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.6082e-16, 0.0000e+00, 7.2858e-17, 0.0000e+00, 7.7716e-16, 7.2164e-16,\n",
      "         0.0000e+00, 1.1102e-15, 0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.1054e-15, 3.8164e-16, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 2.7756e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         7.7716e-16, 8.8818e-16, 1.3878e-16, 1.3323e-15, 1.2768e-15, 7.1054e-15,\n",
      "         8.8818e-15, 9.3259e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 2.1316e-14,\n",
      "         0.0000e+00, 5.7732e-15, 0.0000e+00, 9.7700e-15, 5.1903e-15, 3.6082e-16,\n",
      "         1.0658e-14, 1.9984e-15, 4.2633e-14, 6.2172e-15, 7.9936e-15, 9.7700e-15,\n",
      "         3.7470e-16, 1.0061e-16, 0.0000e+00, 0.0000e+00, 6.9389e-16, 2.4980e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00,\n",
      "         6.1062e-16, 2.6645e-15, 2.6645e-15, 5.1348e-16, 0.0000e+00, 7.5634e-16,\n",
      "         0.0000e+00, 1.2434e-14, 2.1316e-14, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 3.1086e-15, 1.7347e-15, 8.8818e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.4211e-14, 3.7748e-15, 4.5797e-16, 0.0000e+00, 1.4211e-14,\n",
      "         4.2188e-15, 8.8818e-15, 1.9984e-15, 7.1054e-15, 1.0658e-14, 2.1316e-14,\n",
      "         4.4409e-15, 1.2434e-14, 1.0214e-14, 3.7303e-14, 1.1102e-15, 5.7732e-15,\n",
      "         2.1316e-14, 2.1316e-14, 7.1054e-15, 3.5527e-14, 7.9936e-15, 1.2434e-14,\n",
      "         1.4211e-14, 3.1086e-15, 7.1054e-15, 3.9968e-15, 2.8422e-14, 2.8422e-14,\n",
      "         8.4377e-15, 1.7764e-14, 1.8652e-14, 4.4409e-15, 5.4401e-15, 9.7700e-15,\n",
      "         3.0198e-14, 9.3259e-15]], dtype=torch.float64)\n",
      " tensor([  0,   6,   8,  10,  11,  13,  15,  19,  20,  23,  25,  27,  31,  34,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  46,  47,  49,  51,  52,  53,\n",
      "         54,  55,  56,  57,  58,  59,  60,  61,  64,  65,  69,  72,  73,  74,\n",
      "         75,  77,  79,  80,  82,  85,  86,  87,  91,  92,  93,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   6,   8,  10,  11,  13,  15,  19,  20,  23,  25,  27,  31,  34,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  46,  47,  49,  51,  52,  53,\n",
      "         54,  55,  56,  57,  58,  59,  60,  61,  64,  65,  69,  72,  73,  74,\n",
      "         75,  77,  79,  80,  82,  85,  86,  87,  91,  92,  93,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 86)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 41: layer2.2.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 41\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 41\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 41\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 41\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 41\n",
      "Max diff:\n",
      " tensor([1.9895e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.0658e-14, 3.5527e-14, 3.1086e-15, 1.0658e-14, 1.0658e-14, 5.6843e-14,\n",
      "         1.0658e-14, 2.8422e-14, 7.1054e-15, 4.4409e-15, 3.5527e-14, 4.4409e-15,\n",
      "         1.7764e-14, 4.4409e-15, 7.1054e-15, 1.4211e-14, 1.7764e-14, 1.7764e-14,\n",
      "         3.5527e-15, 8.8818e-15, 3.5527e-15, 7.9936e-15, 1.2434e-14, 4.4409e-15,\n",
      "         2.2204e-15, 6.2172e-15, 2.6645e-15, 3.5527e-15, 4.4409e-15, 7.1054e-15,\n",
      "         3.5527e-15, 8.8818e-15, 7.1054e-15, 1.7764e-14, 4.2633e-14, 8.5265e-14,\n",
      "         3.9080e-14, 3.9080e-14, 4.2633e-14, 4.9738e-14, 3.5527e-15, 2.4869e-14,\n",
      "         1.7053e-13, 7.8160e-14, 8.5265e-14, 6.3949e-14, 5.6843e-14, 8.5265e-14,\n",
      "         7.1054e-14, 1.1369e-13, 3.5527e-14, 1.1369e-13, 3.9080e-14, 5.6843e-14,\n",
      "         1.7764e-14, 9.9476e-14, 5.6843e-14, 1.9895e-13, 5.6843e-14, 7.1054e-14,\n",
      "         1.1369e-13, 1.7764e-14, 5.6843e-14, 8.5265e-14, 1.2434e-14, 4.2633e-14,\n",
      "         1.7764e-14, 1.4211e-14, 7.1054e-15, 8.5265e-14, 2.1316e-14, 2.8422e-14,\n",
      "         3.5527e-14, 3.1974e-14, 8.8818e-15, 1.0658e-14, 2.4869e-14, 1.2434e-14,\n",
      "         1.0658e-14, 4.4409e-15, 8.8818e-15, 1.0658e-14, 1.7764e-14, 1.1369e-13,\n",
      "         4.2633e-14, 3.5527e-15, 6.3949e-14, 4.2633e-14, 5.6843e-14, 1.0658e-14,\n",
      "         2.1316e-14, 1.1369e-13, 3.5527e-15, 2.4869e-14, 5.6843e-14, 4.9738e-14,\n",
      "         1.4211e-13, 1.4211e-13, 1.9895e-13, 8.5265e-14, 9.9476e-14, 8.5265e-14,\n",
      "         1.7053e-13, 1.7053e-13, 4.9738e-14, 9.2371e-14, 8.8818e-15, 1.9895e-13,\n",
      "         2.8422e-14, 1.0658e-14, 6.0396e-14, 5.8620e-14, 8.5265e-14, 1.1369e-13,\n",
      "         9.9476e-14, 1.9895e-13, 4.0856e-14, 5.5067e-14, 7.1054e-14, 1.1369e-13,\n",
      "         1.9895e-13, 1.1369e-13, 1.9895e-13, 1.4211e-13, 1.1369e-13, 1.5632e-13,\n",
      "         1.7764e-14, 5.6843e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 42: layer2.2.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 42\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 42\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 42\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 42\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 42\n",
      "Max diff:\n",
      " tensor([1.1369e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 6.2172e-15, 1.1102e-15, 3.5527e-15, 3.5527e-15, 1.4211e-14,\n",
      "         3.1086e-15, 7.1054e-15, 2.2204e-15, 1.5543e-15, 3.5527e-15, 1.5543e-15,\n",
      "         5.3291e-15, 1.5543e-15, 1.7764e-15, 4.4409e-15, 5.3291e-15, 4.4409e-15,\n",
      "         9.9920e-16, 2.6645e-15, 8.8818e-16, 2.4425e-15, 3.5527e-15, 1.1102e-15,\n",
      "         7.7716e-16, 1.9984e-15, 8.8818e-16, 1.3323e-15, 1.3323e-15, 2.2204e-15,\n",
      "         8.8818e-16, 3.1086e-15, 1.7764e-15, 5.3291e-15, 1.0658e-14, 1.2434e-14,\n",
      "         7.9936e-15, 5.3291e-15, 8.8818e-15, 7.5495e-15, 1.3323e-15, 7.1054e-15,\n",
      "         1.2434e-14, 1.4211e-14, 1.4211e-14, 7.9936e-15, 7.9936e-15, 2.8422e-14,\n",
      "         7.1054e-15, 1.4211e-14, 5.1070e-15, 3.5527e-14, 6.6613e-15, 1.4211e-14,\n",
      "         6.2172e-15, 3.1974e-14, 1.4211e-14, 1.2434e-14, 1.2434e-14, 1.7764e-14,\n",
      "         2.8422e-14, 5.3291e-15, 5.3291e-15, 2.4869e-14, 3.9968e-15, 9.7700e-15,\n",
      "         4.4409e-15, 3.9968e-15, 1.7764e-15, 1.7764e-14, 5.3291e-15, 5.3291e-15,\n",
      "         7.1054e-15, 9.7700e-15, 2.6645e-15, 3.5527e-15, 4.8850e-15, 3.5527e-15,\n",
      "         3.5527e-15, 1.5543e-15, 1.7764e-15, 3.5527e-15, 6.2172e-15, 3.5527e-14,\n",
      "         1.2434e-14, 1.1102e-15, 1.5987e-14, 1.2434e-14, 1.2434e-14, 2.6645e-15,\n",
      "         6.2172e-15, 2.8422e-14, 1.1102e-15, 7.1054e-15, 1.4211e-14, 1.4211e-14,\n",
      "         7.1054e-14, 4.9738e-14, 7.1054e-14, 1.5987e-14, 3.3751e-14, 2.1316e-14,\n",
      "         5.6843e-14, 3.5527e-14, 1.5987e-14, 1.5099e-14, 3.5527e-15, 6.3949e-14,\n",
      "         8.8818e-15, 3.5527e-15, 1.0658e-14, 1.3767e-14, 2.8422e-14, 2.8422e-14,\n",
      "         5.6843e-14, 1.1369e-13, 1.4211e-14, 1.4433e-14, 2.3093e-14, 1.4211e-14,\n",
      "         4.2633e-14, 4.9738e-14, 5.6843e-14, 2.8422e-14, 5.6843e-14, 3.1974e-14,\n",
      "         5.3291e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 43: layer2.2.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 43\n",
      "Max diff:\n",
      " tensor([1.4433e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.3291e-15, 0.0000e+00, 5.6621e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.8850e-15, 4.4409e-16, 1.3323e-15, 5.7732e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5527e-15, 0.0000e+00, 6.2172e-15, 0.0000e+00,\n",
      "         0.0000e+00, 5.5234e-15, 0.0000e+00, 0.0000e+00, 6.2172e-15, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.1356e-15, 2.2204e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8850e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.3291e-15, 0.0000e+00, 1.3323e-14, 5.8148e-15, 3.5527e-15, 6.2172e-15,\n",
      "         7.5495e-15, 0.0000e+00, 6.4393e-15, 7.9936e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.4377e-15, 5.7732e-15, 1.7764e-15, 1.0658e-14,\n",
      "         3.1086e-15, 1.0575e-14, 1.4211e-14, 1.4433e-14, 6.6613e-15, 0.0000e+00,\n",
      "         4.4409e-16, 1.0658e-14, 1.3323e-15, 5.7732e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.9936e-15]], dtype=torch.float64)\n",
      " tensor([ 37,  39,  43,  44,  45,  46,  50,  52,  55,  58,  59,  62,  63,  76,\n",
      "         86,  96,  98,  99, 100, 101, 102, 104, 105, 110, 111, 112, 113, 114,\n",
      "        115, 116, 117, 118, 120, 121, 122, 123, 127])\n",
      "\n",
      "failing Cout = tensor([ 37,  39,  43,  44,  45,  46,  50,  52,  55,  58,  59,  62,  63,  76,\n",
      "         86,  96,  98,  99, 100, 101, 102, 104, 105, 110, 111, 112, 113, 114,\n",
      "        115, 116, 117, 118, 120, 121, 122, 123, 127])  (len = 37)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 44: layer2.2.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 44\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 44\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 44\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  3,  4,  5,  6,  7,  8, 11, 13, 14, 15, 16, 23, 24, 25, 26, 28, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 36, 37, 39, 42, 45, 46, 47, 49, 51, 54, 55, 56, 57, 60, 61, 62,\n",
      "        63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([100, 103, 104, 106, 107, 108, 114, 120, 122, 124, 125, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 44\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 44\n",
      "Max diff:\n",
      " tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.8818e-15, 5.3291e-15, 6.6613e-15, 3.5527e-15, 3.5527e-15, 7.7716e-15,\n",
      "         6.9944e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15, 4.6629e-15, 7.5495e-15,\n",
      "         3.6082e-16, 5.3291e-15, 7.1054e-15, 6.2172e-15, 4.4409e-15, 4.9405e-15,\n",
      "         2.2204e-16, 3.5527e-15, 3.9968e-15, 2.2204e-16, 4.4409e-15, 5.3291e-15,\n",
      "         4.4409e-15, 7.9936e-15, 4.4409e-15, 6.2172e-15, 3.9968e-15, 1.6653e-16,\n",
      "         5.3291e-15, 5.3291e-15, 6.2172e-15, 7.9936e-15, 7.1054e-15, 6.2172e-15,\n",
      "         7.1054e-15, 5.3291e-15, 8.4377e-15, 7.1054e-15, 6.2172e-15, 7.1054e-15,\n",
      "         8.8818e-15, 7.1054e-15, 7.9936e-15, 8.8818e-16, 7.1054e-15, 5.7732e-15,\n",
      "         6.2172e-15, 6.4393e-15, 7.1054e-15, 7.9936e-15, 6.2172e-15, 5.3291e-15,\n",
      "         1.0658e-14, 7.1054e-15, 6.2172e-15, 1.0658e-14, 5.7732e-15, 7.9936e-15,\n",
      "         7.1054e-15, 7.1054e-15, 8.8818e-15, 8.8818e-15, 4.4409e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.1086e-15, 4.4409e-15, 1.9429e-16, 5.3291e-15,\n",
      "         5.4401e-15, 2.6645e-15, 7.5495e-15, 3.5527e-15, 4.8850e-15, 5.3291e-15,\n",
      "         7.5495e-15, 3.9968e-15, 6.2172e-15, 5.1070e-15, 4.9960e-15, 1.3323e-15,\n",
      "         7.1054e-15, 3.1364e-15, 4.4409e-15, 3.9968e-15, 3.6637e-15, 6.6613e-16,\n",
      "         5.3291e-15, 3.5527e-15, 3.9968e-15, 2.1094e-15, 5.3291e-15, 4.1078e-15,\n",
      "         9.7700e-15, 6.2172e-15, 9.7700e-15, 1.1768e-14, 1.1102e-14, 7.5495e-15,\n",
      "         1.2434e-14, 7.9936e-15, 1.2434e-14, 1.0658e-14, 7.1054e-15, 8.8818e-15,\n",
      "         9.7700e-15, 6.6613e-15, 1.1324e-14, 1.4211e-14, 1.2434e-14, 6.2172e-15,\n",
      "         7.9936e-15, 8.8818e-15, 6.2172e-15, 8.8818e-15, 9.7700e-15, 7.1054e-15,\n",
      "         9.3259e-15, 6.2172e-15, 7.5495e-15, 7.5495e-15, 7.1054e-15, 7.1054e-15,\n",
      "         8.8818e-15, 1.2434e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 45: layer2.2.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 45\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 45\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 45\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 45\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 45\n",
      "Max diff:\n",
      " tensor([6.4393e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 1.9984e-15, 1.4433e-15, 6.6613e-16, 7.2164e-16, 2.6645e-15,\n",
      "         2.3870e-15, 6.6613e-16, 4.4409e-16, 1.3323e-15, 1.6653e-15, 1.5543e-15,\n",
      "         1.2490e-16, 2.6645e-15, 2.6645e-15, 1.1102e-15, 4.4409e-16, 1.9429e-15,\n",
      "         1.1102e-16, 4.6838e-16, 6.6613e-16, 8.3267e-17, 1.9984e-15, 8.8818e-16,\n",
      "         8.8818e-16, 1.3323e-15, 1.6653e-16, 1.8874e-15, 4.4409e-16, 5.5511e-17,\n",
      "         1.3323e-15, 2.2204e-15, 6.6613e-16, 3.5527e-15, 1.9984e-15, 1.1102e-15,\n",
      "         1.2212e-15, 1.3323e-15, 1.7208e-15, 3.5527e-15, 7.7716e-16, 2.6645e-15,\n",
      "         1.9984e-15, 1.6653e-16, 2.2204e-15, 3.3307e-16, 1.7764e-15, 1.6653e-15,\n",
      "         2.6645e-15, 1.7764e-15, 1.9984e-15, 2.4425e-15, 2.7756e-16, 1.1102e-15,\n",
      "         3.3307e-15, 3.5527e-15, 2.1094e-15, 4.8850e-15, 1.9984e-15, 3.9968e-15,\n",
      "         8.8818e-16, 2.6645e-15, 2.2204e-15, 2.6645e-15, 2.4980e-16, 4.4409e-16,\n",
      "         1.1102e-15, 1.3323e-15, 7.7716e-16, 1.7764e-15, 6.9389e-17, 1.5543e-15,\n",
      "         8.6042e-16, 5.1348e-16, 2.4425e-15, 1.7764e-15, 8.3267e-16, 6.6613e-16,\n",
      "         1.2212e-15, 6.9389e-17, 6.6613e-16, 4.4409e-16, 6.5919e-16, 2.2204e-16,\n",
      "         1.3323e-15, 2.7756e-17, 3.8164e-17, 1.1935e-15, 5.5511e-16, 1.6653e-16,\n",
      "         8.8818e-16, 6.9389e-18, 5.5511e-17, 4.8572e-16, 1.7764e-15, 1.3878e-17,\n",
      "         4.8850e-15, 1.3323e-15, 3.5527e-15, 4.8850e-15, 4.2188e-15, 2.2204e-15,\n",
      "         3.9968e-15, 1.6653e-15, 6.4393e-15, 3.9968e-15, 1.3323e-15, 2.7200e-15,\n",
      "         2.4425e-15, 2.6368e-16, 5.4401e-15, 2.2204e-15, 3.9968e-15, 1.3323e-15,\n",
      "         2.6645e-15, 2.5535e-15, 2.6645e-15, 3.1086e-15, 2.2204e-15, 1.3323e-15,\n",
      "         4.4409e-15, 2.2204e-15, 4.4409e-15, 1.2872e-15, 7.7716e-16, 6.9389e-16,\n",
      "         4.4409e-15, 3.5527e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 46: layer2.2.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 46\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 1.9984e-15, 1.4433e-15, 6.6613e-16, 7.2164e-16, 2.6645e-15,\n",
      "         2.3870e-15, 6.6613e-16, 4.4409e-16, 1.3323e-15, 1.7764e-15, 1.5543e-15,\n",
      "         1.2490e-16, 2.8866e-15, 2.6645e-15, 1.1935e-15, 4.4409e-16, 1.9429e-15,\n",
      "         1.1102e-16, 7.1054e-15, 6.6613e-16, 8.3267e-17, 1.9984e-15, 2.6645e-15,\n",
      "         8.8818e-16, 1.3323e-15, 1.6653e-16, 1.8874e-15, 4.4409e-16, 5.5511e-17,\n",
      "         1.3323e-15, 2.6645e-15, 6.6613e-16, 3.5527e-15, 2.6645e-15, 1.1102e-15,\n",
      "         1.2212e-15, 1.4433e-15, 1.7347e-15, 3.9968e-15, 1.1657e-15, 7.1054e-15,\n",
      "         8.8818e-15, 9.3259e-15, 2.2204e-15, 3.3307e-16, 2.6645e-15, 2.1316e-14,\n",
      "         2.6645e-15, 7.1054e-15, 1.9984e-15, 8.8818e-15, 5.0238e-15, 1.1102e-15,\n",
      "         1.0658e-14, 3.5527e-15, 4.2633e-14, 6.2172e-15, 7.9936e-15, 1.0658e-14,\n",
      "         8.8818e-16, 2.6645e-15, 2.2204e-15, 2.6645e-15, 6.9389e-16, 5.5511e-16,\n",
      "         1.1102e-15, 1.3323e-15, 7.7716e-16, 1.7764e-15, 6.9389e-17, 1.5543e-15,\n",
      "         8.8818e-16, 2.7062e-15, 2.6645e-15, 2.2204e-15, 8.3267e-16, 7.8410e-16,\n",
      "         1.2212e-15, 1.2434e-14, 2.1316e-14, 4.4409e-16, 6.5919e-16, 2.2204e-16,\n",
      "         1.3323e-15, 3.1086e-15, 1.7347e-15, 1.1102e-15, 5.5511e-16, 1.6653e-16,\n",
      "         8.8818e-16, 1.4211e-14, 3.6637e-15, 4.8572e-16, 1.7764e-15, 1.4211e-14,\n",
      "         5.3291e-15, 8.8818e-15, 3.5527e-15, 7.1054e-15, 1.1546e-14, 2.1316e-14,\n",
      "         5.3291e-15, 1.2434e-14, 1.0214e-14, 3.9080e-14, 1.8874e-15, 5.7732e-15,\n",
      "         2.1316e-14, 2.1316e-14, 8.2157e-15, 3.5527e-14, 9.7700e-15, 1.2434e-14,\n",
      "         1.4211e-14, 5.7732e-15, 8.8818e-15, 4.4409e-15, 2.8422e-14, 2.8422e-14,\n",
      "         7.9936e-15, 1.7764e-14, 1.7764e-14, 3.9968e-15, 5.5511e-15, 9.7700e-15,\n",
      "         3.0198e-14, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 47: layer2.2.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 47\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.8866e-15, 0.0000e+00, 6.6613e-16, 0.0000e+00, 3.1919e-16, 2.6645e-15,\n",
      "         2.3870e-15, 0.0000e+00, 0.0000e+00, 6.1756e-16, 1.6653e-15, 1.2351e-15,\n",
      "         0.0000e+00, 2.2204e-15, 1.3323e-15, 1.1935e-15, 0.0000e+00, 1.1241e-15,\n",
      "         0.0000e+00, 7.1054e-15, 1.2490e-16, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 6.6613e-16, 0.0000e+00, 1.2212e-15, 2.3592e-16, 0.0000e+00,\n",
      "         0.0000e+00, 2.6645e-15, 2.7756e-16, 2.3315e-15, 2.6645e-15, 0.0000e+00,\n",
      "         1.2212e-15, 4.4409e-16, 1.3323e-15, 3.9968e-15, 1.1657e-15, 7.1054e-15,\n",
      "         8.8818e-15, 9.3259e-15, 3.6082e-16, 0.0000e+00, 2.6645e-15, 2.1316e-14,\n",
      "         9.2287e-16, 7.1054e-15, 1.3878e-15, 8.8818e-15, 2.6645e-15, 0.0000e+00,\n",
      "         1.0658e-14, 0.0000e+00, 4.2633e-14, 6.2172e-15, 7.9936e-15, 1.0658e-14,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 7.9797e-17, 1.4433e-15, 0.0000e+00, 8.3267e-17,\n",
      "         8.8818e-16, 2.7062e-15, 2.6645e-15, 0.0000e+00, 3.7470e-16, 7.8410e-16,\n",
      "         0.0000e+00, 1.2434e-14, 2.1316e-14, 2.4980e-16, 5.8287e-16, 0.0000e+00,\n",
      "         0.0000e+00, 3.1086e-15, 1.7347e-15, 1.1102e-15, 2.2204e-16, 0.0000e+00,\n",
      "         4.0246e-16, 1.4211e-14, 3.6637e-15, 4.4409e-16, 3.5388e-16, 1.4211e-14,\n",
      "         3.5527e-15, 8.8818e-15, 3.3307e-15, 7.1054e-15, 1.1546e-14, 2.1316e-14,\n",
      "         5.3291e-15, 1.2434e-14, 1.0214e-14, 3.9080e-14, 1.8874e-15, 5.7732e-15,\n",
      "         2.1316e-14, 2.1316e-14, 8.2157e-15, 3.5527e-14, 9.7700e-15, 1.2434e-14,\n",
      "         1.4211e-14, 5.7732e-15, 8.8818e-15, 4.4409e-15, 2.8422e-14, 2.8422e-14,\n",
      "         7.9936e-15, 1.7764e-14, 1.7764e-14, 3.9968e-15, 5.5511e-15, 9.7700e-15,\n",
      "         3.0198e-14, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   2,   4,   5,   6,   9,  10,  11,  13,  14,  15,  17,  19,  20,\n",
      "         23,  25,  27,  28,  31,  32,  33,  34,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  46,  47,  48,  49,  50,  51,  52,  54,  56,  57,  58,\n",
      "         59,  60,  64,  65,  68,  69,  71,  72,  73,  74,  76,  77,  79,  80,\n",
      "         81,  82,  85,  86,  87,  88,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   2,   4,   5,   6,   9,  10,  11,  13,  14,  15,  17,  19,  20,\n",
      "         23,  25,  27,  28,  31,  32,  33,  34,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  46,  47,  48,  49,  50,  51,  52,  54,  56,  57,  58,\n",
      "         59,  60,  64,  65,  68,  69,  71,  72,  73,  74,  76,  77,  79,  80,\n",
      "         81,  82,  85,  86,  87,  88,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 100)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 48: layer2.3.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 48\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124,\n",
      "        125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 48\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 48\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 48\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 48\n",
      "Max diff:\n",
      " tensor([2.8422e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 5.3291e-15, 7.9936e-15, 1.0658e-14, 1.7764e-14, 1.2434e-14,\n",
      "         3.5527e-15, 3.5527e-14, 2.6645e-15, 1.0658e-14, 4.4409e-15, 4.4409e-15,\n",
      "         1.7764e-14, 4.4409e-15, 7.1054e-15, 3.5527e-14, 7.1054e-15, 5.3291e-15,\n",
      "         5.3291e-15, 4.4409e-15, 1.7764e-14, 2.8422e-14, 1.4211e-14, 5.3291e-15,\n",
      "         5.3291e-15, 3.1086e-15, 4.4409e-15, 5.3291e-15, 8.8818e-15, 8.8818e-15,\n",
      "         2.4869e-14, 4.4409e-15, 7.1054e-14, 6.3949e-14, 4.2633e-14, 8.5265e-14,\n",
      "         2.1316e-14, 3.5527e-14, 7.1054e-14, 5.6843e-14, 1.7764e-14, 1.4211e-13,\n",
      "         1.0658e-14, 7.1054e-14, 4.9738e-14, 6.3949e-14, 8.5265e-14, 4.2633e-14,\n",
      "         2.1316e-14, 1.4211e-13, 8.5265e-14, 8.5265e-14, 8.5265e-14, 8.5265e-14,\n",
      "         8.5265e-14, 4.4409e-15, 9.9476e-14, 3.5527e-14, 1.1369e-13, 7.1054e-14,\n",
      "         7.1054e-14, 4.9738e-14, 5.6843e-14, 1.0658e-14, 9.9476e-14, 4.4409e-15,\n",
      "         5.6843e-14, 2.3093e-14, 3.5527e-14, 7.1054e-15, 6.2172e-15, 5.6843e-14,\n",
      "         4.9738e-14, 8.8818e-15, 2.1316e-14, 5.6843e-14, 4.9738e-14, 3.5527e-14,\n",
      "         1.1369e-13, 3.5527e-14, 2.8422e-14, 4.2633e-14, 5.6843e-14, 7.1054e-15,\n",
      "         5.6843e-14, 7.1054e-15, 5.6843e-14, 1.4211e-13, 4.2633e-14, 2.4869e-14,\n",
      "         1.0658e-14, 1.4211e-13, 4.9738e-14, 4.9738e-14, 1.0658e-14, 2.1316e-14,\n",
      "         1.1369e-13, 1.4211e-13, 9.9476e-14, 8.5265e-14, 1.9895e-13, 8.5265e-14,\n",
      "         9.9476e-14, 1.1369e-13, 8.5265e-14, 2.8422e-13, 1.1369e-13, 1.1369e-13,\n",
      "         1.4211e-13, 1.4211e-13, 1.7053e-13, 8.5265e-14, 1.4211e-14, 1.9895e-13,\n",
      "         7.1054e-15, 1.3500e-13, 3.5527e-14, 2.4869e-14, 7.1054e-14, 7.1054e-15,\n",
      "         1.7053e-13, 8.5265e-14, 7.1054e-14, 5.3291e-14, 1.7053e-13, 1.0658e-14,\n",
      "         1.2790e-13, 1.7053e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 49: layer2.3.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 49\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 49\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 49\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 49\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 49\n",
      "Max diff:\n",
      " tensor([1.4211e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-15, 1.3323e-15, 1.5543e-15, 3.5527e-15, 3.9968e-15, 2.2204e-15,\n",
      "         7.7716e-16, 8.8818e-15, 8.8818e-16, 3.5527e-15, 1.3323e-15, 1.5543e-15,\n",
      "         4.4409e-15, 8.8818e-16, 2.2204e-15, 7.1054e-15, 1.3323e-15, 1.3323e-15,\n",
      "         1.7764e-15, 1.3323e-15, 5.3291e-15, 7.1054e-15, 3.9968e-15, 1.1102e-15,\n",
      "         1.5543e-15, 8.8818e-16, 1.1102e-15, 1.5543e-15, 2.2204e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.3323e-15, 1.4211e-14, 1.9540e-14, 8.8818e-15, 1.0658e-14,\n",
      "         6.2172e-15, 3.9968e-15, 1.7764e-14, 1.4211e-14, 5.3291e-15, 3.1974e-14,\n",
      "         3.5527e-15, 1.7764e-14, 8.8818e-15, 1.4211e-14, 4.2633e-14, 8.8818e-15,\n",
      "         5.3291e-15, 4.2633e-14, 1.4211e-14, 1.4211e-14, 2.8422e-14, 1.0658e-14,\n",
      "         2.4869e-14, 1.5543e-15, 1.4211e-14, 1.4211e-14, 2.3093e-14, 4.2188e-15,\n",
      "         1.0658e-14, 1.4211e-14, 1.2434e-14, 3.5527e-15, 2.4869e-14, 1.5543e-15,\n",
      "         1.0658e-14, 2.7756e-15, 8.8818e-15, 2.2204e-15, 1.7764e-15, 4.4409e-15,\n",
      "         1.7764e-14, 1.9984e-15, 6.2172e-15, 1.4211e-14, 1.2434e-14, 6.2172e-15,\n",
      "         1.4211e-14, 3.9968e-15, 2.6645e-15, 1.0658e-14, 1.7764e-14, 2.2204e-15,\n",
      "         2.1316e-14, 2.2204e-15, 8.8818e-15, 2.4869e-14, 5.3291e-15, 1.2434e-14,\n",
      "         3.5527e-15, 2.8422e-14, 4.4409e-15, 6.2172e-15, 2.6645e-15, 5.3291e-15,\n",
      "         2.6645e-14, 3.5527e-14, 3.1974e-14, 6.2172e-15, 8.5265e-14, 3.1974e-14,\n",
      "         4.9738e-14, 8.5265e-14, 1.4211e-14, 1.4211e-13, 4.2633e-14, 2.4869e-14,\n",
      "         1.7764e-14, 2.8422e-14, 4.9738e-14, 4.2633e-14, 4.4409e-15, 5.6843e-14,\n",
      "         2.6645e-15, 1.6875e-14, 1.0658e-14, 7.1054e-15, 7.3275e-15, 2.2204e-15,\n",
      "         6.3949e-14, 1.4211e-14, 1.4211e-14, 1.2434e-14, 3.1974e-14, 3.5527e-15,\n",
      "         2.4869e-14, 5.6843e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 50: layer2.3.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 50\n",
      "Max diff:\n",
      " tensor([1.8652e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.1088e-16, 3.7748e-15, 5.7732e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.8866e-15, 2.8866e-15, 6.2172e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.7462e-15, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         8.6597e-15, 0.0000e+00, 1.8874e-15, 2.7756e-15, 2.2204e-15, 1.3323e-15,\n",
      "         1.1102e-15, 7.1054e-15, 7.1332e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-15, 3.5527e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9984e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.5543e-15, 0.0000e+00, 1.7764e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2434e-14,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-16, 6.2172e-15, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-15, 5.7732e-15, 1.0214e-14, 2.3870e-15, 2.0539e-15, 1.8652e-14,\n",
      "         5.5511e-15, 1.7764e-14, 1.0214e-14, 0.0000e+00, 7.8271e-15, 3.5527e-15,\n",
      "         0.0000e+00, 1.9984e-15, 4.4409e-15, 1.3323e-14, 0.0000e+00, 7.3275e-15,\n",
      "         0.0000e+00, 1.6875e-14, 0.0000e+00, 0.0000e+00, 7.3275e-15, 0.0000e+00,\n",
      "         1.2434e-14, 0.0000e+00, 4.8850e-15, 1.2434e-14, 2.2760e-15, 0.0000e+00,\n",
      "         1.9984e-15, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([ 33,  37,  38,  39,  44,  45,  46,  50,  52,  54,  56,  57,  58,  59,\n",
      "         60,  61,  62,  67,  68,  77,  80,  82,  89,  92,  93,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 106, 107, 109, 110, 111, 113, 115, 118,\n",
      "        120, 122, 123, 124, 126, 127])\n",
      "\n",
      "failing Cout = tensor([ 33,  37,  38,  39,  44,  45,  46,  50,  52,  54,  56,  57,  58,  59,\n",
      "         60,  61,  62,  67,  68,  77,  80,  82,  89,  92,  93,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 106, 107, 109, 110, 111, 113, 115, 118,\n",
      "        120, 122, 123, 124, 126, 127])  (len = 48)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 51: layer2.3.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 51\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 51\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 51\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 51\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 51\n",
      "Max diff:\n",
      " tensor([3.5527e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.4211e-14, 7.9936e-15, 1.4211e-14, 5.3291e-15, 1.2434e-14, 1.7764e-14,\n",
      "         2.1316e-14, 8.8818e-15, 1.7764e-14, 7.1054e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.0658e-14, 1.3323e-14, 5.8287e-15, 1.4211e-14, 2.6645e-15, 1.4211e-14,\n",
      "         8.4377e-15, 1.4211e-14, 1.0658e-14, 4.4409e-16, 1.2434e-14, 1.4211e-14,\n",
      "         1.0658e-14, 1.4211e-14, 1.0658e-14, 1.7764e-14, 5.3291e-15, 8.8818e-16,\n",
      "         8.8818e-15, 7.1054e-15, 7.9936e-15, 6.4393e-15, 7.1054e-15, 1.0658e-14,\n",
      "         8.8818e-15, 4.4409e-15, 5.3291e-15, 7.1054e-15, 8.6597e-15, 1.2434e-14,\n",
      "         1.4211e-14, 8.8818e-15, 9.7700e-15, 5.3291e-15, 7.1054e-15, 8.8818e-15,\n",
      "         7.9936e-15, 9.7700e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15, 1.0658e-14,\n",
      "         8.8818e-15, 1.7764e-14, 4.8850e-15, 6.2172e-15, 5.3707e-15, 5.3291e-15,\n",
      "         1.4211e-14, 8.4377e-15, 7.9936e-15, 1.0658e-14, 7.1054e-15, 1.7764e-14,\n",
      "         1.4211e-14, 8.8818e-15, 1.4211e-14, 1.7764e-14, 6.6613e-16, 2.1316e-14,\n",
      "         1.4211e-14, 3.5527e-14, 1.0658e-14, 5.3291e-15, 1.4211e-14, 1.7764e-14,\n",
      "         1.0658e-14, 3.5527e-14, 1.4211e-14, 1.7764e-14, 1.7764e-14, 1.4655e-14,\n",
      "         2.8422e-14, 2.1316e-14, 1.7764e-14, 2.8422e-14, 1.0658e-14, 7.1054e-15,\n",
      "         1.7764e-14, 1.3323e-14, 2.1316e-14, 1.4211e-14, 1.0658e-14, 2.1316e-14,\n",
      "         1.1546e-14, 1.2434e-14, 2.1316e-14, 1.3267e-14, 1.5987e-14, 1.4211e-14,\n",
      "         8.8818e-15, 6.2172e-15, 1.2434e-14, 1.1546e-14, 1.7764e-14, 1.1546e-14,\n",
      "         1.0658e-14, 7.1054e-15, 1.4211e-14, 1.0658e-14, 8.8818e-15, 1.5099e-14,\n",
      "         9.5479e-15, 1.5987e-14, 9.7700e-15, 9.3259e-15, 8.8818e-15, 1.9540e-14,\n",
      "         1.9540e-14, 8.8818e-15, 1.1546e-14, 1.5987e-14, 1.1546e-14, 9.7700e-15,\n",
      "         1.0214e-14, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 52: layer2.3.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 52\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 52\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 52\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 52\n",
      "\t\t Output tensor shape : torch.Size([1, 128, 16, 16])\n",
      "\t\t sending C_out tensor([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "        124, 125, 126, 127]) to machine 3\n",
      "Finished execution of layer 52\n",
      "Max diff:\n",
      " tensor([2.1316e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 3.1086e-15, 3.5527e-15, 1.7764e-15, 2.2204e-15, 7.1054e-15,\n",
      "         8.8818e-15, 4.4409e-15, 2.2204e-15, 1.3323e-15, 3.9968e-15, 1.7764e-15,\n",
      "         1.3323e-15, 3.1086e-15, 2.1701e-15, 5.3291e-15, 7.7716e-16, 5.3291e-15,\n",
      "         2.6645e-15, 7.1054e-15, 5.3291e-15, 1.1102e-16, 7.1054e-15, 7.1054e-15,\n",
      "         3.5527e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15, 2.2204e-15, 2.7756e-16,\n",
      "         3.5527e-15, 3.1086e-15, 2.6645e-15, 1.4433e-15, 3.1086e-15, 2.6645e-15,\n",
      "         2.6645e-15, 4.4409e-16, 6.6613e-16, 2.4425e-15, 5.1070e-15, 1.9984e-15,\n",
      "         3.5527e-15, 2.2204e-15, 1.1102e-15, 1.3323e-15, 3.5527e-15, 1.3323e-15,\n",
      "         1.4433e-15, 8.8818e-16, 3.1086e-15, 1.9984e-15, 2.2204e-15, 1.7764e-15,\n",
      "         5.5511e-16, 8.8818e-15, 1.3323e-15, 1.7764e-15, 1.3878e-15, 1.7764e-15,\n",
      "         2.2204e-15, 2.2204e-15, 2.6645e-15, 5.3291e-15, 8.8818e-16, 7.1054e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.6645e-15, 7.1054e-15, 2.2204e-16, 6.2172e-15,\n",
      "         5.3291e-15, 1.2434e-14, 3.7748e-15, 2.2204e-15, 1.3323e-15, 3.5527e-15,\n",
      "         4.4409e-15, 2.1316e-14, 8.8818e-15, 8.2157e-15, 8.8818e-15, 6.8834e-15,\n",
      "         1.0658e-14, 5.3291e-15, 2.2204e-15, 1.0658e-14, 4.4409e-15, 1.7764e-15,\n",
      "         3.5527e-15, 2.4425e-15, 7.1054e-15, 5.3291e-15, 3.1086e-15, 5.3291e-15,\n",
      "         6.2172e-15, 3.9968e-15, 5.3291e-15, 3.7960e-15, 3.5527e-15, 7.9936e-15,\n",
      "         2.2204e-15, 1.7764e-15, 3.1086e-15, 3.9968e-15, 2.2204e-15, 4.7740e-15,\n",
      "         4.6629e-15, 1.0547e-15, 3.9968e-15, 2.2204e-15, 1.1102e-15, 2.8866e-15,\n",
      "         4.2188e-15, 3.5527e-15, 1.9984e-15, 3.7748e-15, 1.3323e-15, 5.3291e-15,\n",
      "         3.1086e-15, 5.3291e-15, 5.3291e-15, 1.2212e-15, 1.4433e-15, 8.8818e-16,\n",
      "         2.6645e-15, 2.4425e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 53: layer2.3.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 53\n",
      "Max diff:\n",
      " tensor([4.6185e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 3.1086e-15, 3.5527e-15, 1.7764e-15, 2.2204e-15, 7.1054e-15,\n",
      "         7.1054e-15, 4.4409e-15, 2.2204e-15, 1.3323e-15, 3.9968e-15, 1.7764e-15,\n",
      "         1.3323e-15, 3.1086e-15, 2.1701e-15, 5.3291e-15, 7.7716e-16, 5.3291e-15,\n",
      "         2.6645e-15, 7.1054e-15, 5.3291e-15, 1.1102e-16, 7.1054e-15, 7.1054e-15,\n",
      "         3.5527e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15, 2.2204e-15, 2.7756e-16,\n",
      "         3.5527e-15, 3.5527e-15, 2.6645e-15, 2.4425e-15, 3.1086e-15, 2.6645e-15,\n",
      "         2.6645e-15, 5.5511e-16, 1.5543e-15, 5.1070e-15, 5.1070e-15, 7.9936e-15,\n",
      "         8.8818e-15, 8.8818e-15, 1.1102e-15, 1.3323e-15, 3.5527e-15, 2.1316e-14,\n",
      "         1.7764e-15, 7.5495e-15, 3.1086e-15, 9.7700e-15, 2.4425e-15, 1.7764e-15,\n",
      "         1.0658e-14, 8.8818e-15, 4.6185e-14, 7.1054e-15, 7.9936e-15, 1.1768e-14,\n",
      "         2.2204e-15, 2.2204e-15, 2.6645e-15, 5.3291e-15, 9.9920e-16, 7.1054e-15,\n",
      "         1.7764e-15, 3.5527e-15, 2.6645e-15, 7.1054e-15, 2.2204e-16, 6.2172e-15,\n",
      "         5.3291e-15, 1.2434e-14, 4.4409e-15, 2.2204e-15, 1.3323e-15, 3.5527e-15,\n",
      "         4.4409e-15, 2.1316e-14, 1.8652e-14, 8.2157e-15, 8.8818e-15, 6.8834e-15,\n",
      "         1.0658e-14, 5.3291e-15, 2.2204e-15, 1.0658e-14, 4.4409e-15, 1.7764e-15,\n",
      "         3.5527e-15, 1.4211e-14, 7.1054e-15, 5.3291e-15, 3.1086e-15, 1.4211e-14,\n",
      "         6.2172e-15, 7.5495e-15, 5.3291e-15, 8.8818e-15, 1.1990e-14, 2.1316e-14,\n",
      "         5.3291e-15, 1.2434e-14, 9.3259e-15, 3.9080e-14, 3.1086e-15, 5.5511e-15,\n",
      "         2.4869e-14, 2.1316e-14, 1.0658e-14, 3.5527e-14, 9.7700e-15, 1.4211e-14,\n",
      "         1.7764e-14, 7.5495e-15, 8.8818e-15, 7.9936e-15, 2.8422e-14, 2.8422e-14,\n",
      "         8.4377e-15, 1.9540e-14, 1.9096e-14, 3.9968e-15, 5.2180e-15, 9.7700e-15,\n",
      "         3.0198e-14, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])  (len = 128)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 54: layer2.3.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 54\n",
      "Max diff:\n",
      " tensor([4.6185e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 1.7764e-15, 5.5511e-16, 0.0000e+00, 0.0000e+00, 3.2752e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9968e-15, 7.7716e-16,\n",
      "         0.0000e+00, 1.3878e-15, 2.1701e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.6645e-15, 7.1054e-15, 0.0000e+00, 0.0000e+00, 7.1054e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2042e-16, 0.0000e+00,\n",
      "         2.2204e-16, 2.6645e-15, 1.8874e-15, 1.8874e-15, 3.1086e-15, 0.0000e+00,\n",
      "         1.2212e-15, 5.5511e-16, 1.5543e-15, 5.1070e-15, 2.5535e-15, 7.9936e-15,\n",
      "         8.8818e-15, 8.8818e-15, 4.0246e-16, 0.0000e+00, 3.5527e-15, 2.1316e-14,\n",
      "         3.0531e-16, 7.5495e-15, 1.6653e-15, 9.7700e-15, 2.4425e-15, 0.0000e+00,\n",
      "         1.0658e-14, 0.0000e+00, 4.6185e-14, 7.1054e-15, 7.9936e-15, 1.1768e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-16, 0.0000e+00, 4.8850e-15, 0.0000e+00, 2.4425e-15,\n",
      "         2.2204e-15, 2.6645e-15, 3.0531e-15, 0.0000e+00, 0.0000e+00, 1.3323e-15,\n",
      "         2.0539e-15, 1.5987e-14, 1.8652e-14, 8.2157e-15, 3.9968e-15, 6.8834e-15,\n",
      "         0.0000e+00, 3.1086e-15, 1.8874e-15, 0.0000e+00, 4.3021e-16, 0.0000e+00,\n",
      "         0.0000e+00, 1.4211e-14, 4.6629e-15, 0.0000e+00, 0.0000e+00, 1.4211e-14,\n",
      "         4.4409e-15, 7.5495e-15, 6.6613e-16, 8.8818e-15, 1.1990e-14, 2.1316e-14,\n",
      "         5.3291e-15, 1.2434e-14, 9.3259e-15, 3.9080e-14, 3.1086e-15, 5.5511e-15,\n",
      "         2.4869e-14, 2.1316e-14, 1.0658e-14, 3.5527e-14, 9.7700e-15, 1.4211e-14,\n",
      "         1.7764e-14, 7.5495e-15, 8.8818e-15, 7.9936e-15, 2.8422e-14, 2.8422e-14,\n",
      "         8.4377e-15, 1.9540e-14, 1.9096e-14, 3.9968e-15, 5.2180e-15, 9.7700e-15,\n",
      "         3.0198e-14, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   5,  10,  11,  13,  14,  18,  19,  22,  28,  30,  31,\n",
      "         32,  33,  34,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,  47,\n",
      "         48,  49,  50,  51,  52,  54,  56,  57,  58,  59,  64,  67,  69,  71,\n",
      "         72,  73,  74,  77,  78,  79,  80,  81,  82,  83,  85,  86,  88,  91,\n",
      "         92,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   5,  10,  11,  13,  14,  18,  19,  22,  28,  30,  31,\n",
      "         32,  33,  34,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,  47,\n",
      "         48,  49,  50,  51,  52,  54,  56,  57,  58,  59,  64,  67,  69,  71,\n",
      "         72,  73,  74,  77,  78,  79,  80,  81,  82,  83,  85,  86,  88,  91,\n",
      "         92,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127])  (len = 90)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 55: layer3.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 55\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 55\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 55\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 55\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 55\n",
      "Max diff:\n",
      " tensor([1.8474e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 1.7764e-14, 1.3323e-15, 2.1316e-14, 1.7764e-15, 2.8422e-14,\n",
      "         1.4211e-14, 1.7764e-15, 2.8422e-14, 3.5527e-15, 2.8422e-14, 2.1316e-14,\n",
      "         1.1102e-15, 1.3323e-15, 4.4409e-15, 3.5527e-15, 4.4409e-15, 5.3291e-15,\n",
      "         1.7764e-15, 3.5527e-15, 1.7764e-15, 1.0658e-14, 2.6645e-15, 1.7764e-15,\n",
      "         3.5527e-15, 3.5527e-14, 2.2204e-15, 1.7764e-15, 5.3291e-15, 8.8818e-15,\n",
      "         2.2204e-15, 1.7764e-15, 1.7764e-15, 2.6645e-15, 3.5527e-15, 1.3323e-15,\n",
      "         1.0658e-14, 5.3291e-15, 3.5527e-15, 4.4409e-15, 2.1316e-14, 2.1316e-14,\n",
      "         2.2204e-15, 5.3291e-15, 2.2204e-15, 2.6645e-15, 1.4211e-14, 4.2633e-14,\n",
      "         1.7764e-14, 1.7764e-15, 2.1316e-14, 7.1054e-14, 2.6645e-15, 4.4409e-15,\n",
      "         3.1086e-15, 8.8818e-16, 2.8422e-14, 3.5527e-15, 8.8818e-15, 5.3291e-15,\n",
      "         2.1316e-14, 2.6645e-15, 7.1054e-15, 1.4211e-14, 4.2633e-14, 5.6843e-14,\n",
      "         5.6843e-14, 4.9738e-14, 4.2633e-14, 3.6082e-14, 2.8422e-14, 3.1974e-14,\n",
      "         5.6843e-14, 2.8422e-14, 4.2633e-14, 5.6843e-14, 4.9738e-14, 4.9738e-14,\n",
      "         4.9738e-14, 7.1054e-14, 6.3949e-14, 4.2633e-14, 5.6843e-14, 2.8422e-14,\n",
      "         2.1316e-14, 7.1054e-14, 3.5527e-14, 7.1054e-14, 3.1974e-14, 5.6843e-14,\n",
      "         4.2633e-14, 4.2633e-14, 3.9080e-14, 4.2633e-14, 3.1974e-14, 6.8390e-14,\n",
      "         3.9080e-14, 1.7764e-14, 3.1974e-14, 3.1974e-14, 4.2633e-14, 5.6843e-14,\n",
      "         1.8474e-13, 2.8422e-14, 2.8422e-14, 4.2633e-14, 9.9476e-14, 3.0198e-14,\n",
      "         1.4211e-14, 5.6843e-14, 4.0856e-14, 3.0198e-14, 5.3291e-15, 4.6185e-14,\n",
      "         4.2633e-14, 6.4837e-14, 7.8160e-14, 1.1369e-13, 5.6843e-14, 3.5527e-15,\n",
      "         7.1054e-14, 1.0658e-14, 5.6843e-14, 4.1744e-14, 7.1054e-14, 3.5527e-14,\n",
      "         5.6843e-14, 3.5527e-14, 1.4211e-13, 7.1054e-14, 8.5265e-14, 2.4869e-14,\n",
      "         5.6843e-14, 8.5265e-14, 5.6843e-14, 1.4211e-14, 5.6843e-14, 1.4211e-13,\n",
      "         1.4211e-14, 8.5265e-14, 8.5265e-14, 2.8422e-14, 5.6843e-14, 1.2790e-13,\n",
      "         8.5265e-14, 8.8818e-15, 7.1054e-14, 8.5265e-14, 1.1369e-13, 4.9738e-14,\n",
      "         1.1369e-13, 5.6843e-14, 4.2633e-14, 4.2633e-14, 8.5265e-14, 1.1369e-13,\n",
      "         2.8422e-14, 2.8422e-14, 9.9476e-14, 1.0658e-14, 7.1054e-14, 4.2633e-14,\n",
      "         8.8818e-15, 2.1316e-14, 2.8422e-14, 2.8422e-14, 1.1369e-13, 7.1054e-14,\n",
      "         3.5527e-14, 5.3291e-15, 1.1369e-13, 7.1054e-14, 1.4211e-14, 2.1316e-14,\n",
      "         1.1369e-13, 8.5265e-14, 9.9476e-14, 8.5265e-14, 7.1054e-14, 4.2633e-14,\n",
      "         3.5527e-14, 7.1054e-15, 1.0658e-14, 4.2633e-14, 2.8422e-14, 1.1369e-13,\n",
      "         8.5265e-14, 1.1369e-13, 5.3291e-15, 4.9738e-14, 1.4211e-14, 8.5265e-14,\n",
      "         7.1054e-14, 1.0658e-14, 4.9738e-14, 3.1530e-14, 4.9738e-14, 8.5265e-14,\n",
      "         4.6185e-14, 4.9738e-14, 2.1316e-14, 4.2633e-14, 7.4607e-14, 4.2633e-14,\n",
      "         5.6843e-14, 4.2633e-14, 4.9738e-14, 3.5527e-14, 4.2633e-14, 4.9738e-14,\n",
      "         5.3291e-14, 4.2633e-14, 3.5527e-14, 5.6843e-14, 6.3949e-14, 4.2633e-14,\n",
      "         4.9738e-14, 6.0396e-14, 4.9738e-14, 3.9080e-14, 5.6843e-14, 4.2633e-14,\n",
      "         4.9738e-14, 9.2371e-14, 9.9476e-14, 1.1369e-13, 6.0396e-14, 8.5265e-14,\n",
      "         4.2633e-14, 3.9080e-14, 4.9738e-14, 4.9738e-14, 8.5265e-14, 6.3949e-14,\n",
      "         4.9738e-14, 8.5265e-14, 7.1054e-14, 5.6843e-14, 1.4211e-14, 3.9080e-14,\n",
      "         1.1369e-13, 7.1054e-14, 4.9738e-14, 8.5265e-14, 5.6843e-14, 4.9738e-14,\n",
      "         6.3949e-14, 4.2633e-14, 4.7962e-14, 4.9738e-14, 6.7502e-14, 4.0856e-14,\n",
      "         4.5297e-14, 4.2633e-14, 5.6843e-14, 5.6843e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 56: layer3.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 56\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 56\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 56\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 56\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 56\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3323e-15, 3.5527e-15, 2.2204e-16, 4.4409e-15, 4.4409e-16, 7.1054e-15,\n",
      "         2.2204e-15, 3.3307e-16, 5.3291e-15, 8.8818e-16, 1.0658e-14, 4.4409e-15,\n",
      "         2.7756e-16, 2.4980e-16, 1.1102e-15, 8.8818e-16, 8.8818e-16, 6.6613e-16,\n",
      "         4.4409e-16, 6.6613e-16, 5.5511e-16, 1.7764e-15, 6.6613e-16, 3.3307e-16,\n",
      "         8.8818e-16, 3.5527e-15, 3.3307e-16, 3.3307e-16, 8.8818e-16, 2.2204e-15,\n",
      "         6.6613e-16, 2.7756e-16, 4.4409e-16, 5.5511e-16, 6.6613e-16, 3.3307e-16,\n",
      "         2.2204e-15, 1.7764e-15, 1.3323e-15, 7.7716e-16, 3.5527e-15, 3.5527e-15,\n",
      "         5.5511e-16, 1.3323e-15, 5.5511e-16, 6.6613e-16, 3.5527e-15, 1.0658e-14,\n",
      "         2.6645e-15, 2.2204e-16, 2.6645e-15, 1.0658e-14, 6.6613e-16, 1.3323e-15,\n",
      "         3.8858e-16, 2.2204e-16, 7.1054e-15, 6.6613e-16, 2.2204e-15, 1.3323e-15,\n",
      "         3.5527e-15, 8.8818e-16, 1.7764e-15, 2.6645e-15, 6.2172e-15, 1.4211e-14,\n",
      "         1.0658e-14, 5.3291e-15, 7.9936e-15, 7.2442e-15, 5.3291e-15, 4.4409e-15,\n",
      "         1.4211e-14, 6.2172e-15, 4.4409e-15, 1.0658e-14, 6.2172e-15, 1.0658e-14,\n",
      "         7.9936e-15, 7.1054e-15, 6.2172e-15, 3.5527e-15, 7.1054e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.2434e-14, 5.3291e-15, 8.8818e-15, 7.9936e-15, 7.9936e-15,\n",
      "         8.8818e-15, 3.9968e-15, 1.0658e-14, 4.4409e-15, 5.3291e-15, 7.6605e-15,\n",
      "         7.1054e-15, 4.4409e-15, 7.1054e-15, 7.9936e-15, 7.1054e-15, 2.1316e-14,\n",
      "         2.1316e-14, 5.3291e-15, 5.3291e-15, 6.2172e-15, 8.8818e-15, 5.3291e-15,\n",
      "         3.5527e-15, 8.8818e-15, 8.4377e-15, 6.6613e-15, 6.6613e-16, 1.1546e-14,\n",
      "         8.8818e-15, 7.6605e-15, 1.2434e-14, 2.8422e-14, 8.8818e-15, 1.1102e-15,\n",
      "         1.0658e-14, 2.6645e-15, 1.4211e-14, 8.9460e-15, 2.1316e-14, 2.8866e-15,\n",
      "         9.3259e-15, 9.7700e-15, 2.8422e-14, 1.4211e-14, 2.1316e-14, 4.4409e-15,\n",
      "         1.0658e-14, 1.7764e-14, 1.0658e-14, 5.3291e-15, 1.0658e-14, 4.2633e-14,\n",
      "         1.3323e-15, 3.5527e-14, 1.4211e-14, 5.3291e-15, 1.7764e-14, 2.8422e-14,\n",
      "         3.1974e-14, 2.6645e-15, 1.2434e-14, 1.4211e-14, 4.2633e-14, 1.0658e-14,\n",
      "         2.8422e-14, 1.0658e-14, 7.1054e-15, 1.0658e-14, 2.1316e-14, 3.5527e-14,\n",
      "         7.1054e-15, 8.8818e-15, 2.1316e-14, 2.6645e-15, 1.2434e-14, 7.1054e-15,\n",
      "         2.6645e-15, 3.9968e-15, 7.1054e-15, 1.0658e-14, 2.1316e-14, 1.4211e-14,\n",
      "         1.2434e-14, 1.3323e-15, 3.5527e-14, 1.4211e-14, 2.6645e-15, 2.6645e-15,\n",
      "         3.5527e-14, 2.8422e-14, 2.1316e-14, 2.1316e-14, 2.8422e-14, 5.3291e-15,\n",
      "         6.2172e-15, 1.3323e-15, 3.5527e-15, 5.3291e-15, 5.3291e-15, 2.8422e-14,\n",
      "         2.8422e-14, 2.8422e-14, 1.3323e-15, 1.2434e-14, 2.2204e-15, 1.4211e-14,\n",
      "         1.4211e-14, 3.5527e-15, 1.0658e-14, 8.2157e-15, 1.1546e-14, 1.4211e-14,\n",
      "         6.6613e-15, 7.1054e-15, 5.3291e-15, 8.8818e-15, 9.7700e-15, 6.2172e-15,\n",
      "         8.8818e-15, 5.3291e-15, 7.1054e-15, 1.0658e-14, 7.9936e-15, 1.0658e-14,\n",
      "         8.8818e-15, 7.1054e-15, 5.3291e-15, 1.4211e-14, 1.3767e-14, 7.9936e-15,\n",
      "         7.1054e-15, 1.0658e-14, 8.8818e-15, 5.3291e-15, 8.8818e-15, 8.8818e-15,\n",
      "         8.8818e-15, 1.5099e-14, 1.7764e-14, 1.7764e-14, 9.7700e-15, 1.4211e-14,\n",
      "         8.8818e-15, 7.1054e-15, 5.3291e-15, 9.7700e-15, 1.5099e-14, 1.0658e-14,\n",
      "         1.2434e-14, 8.8818e-15, 1.4211e-14, 9.7700e-15, 3.5527e-15, 7.9936e-15,\n",
      "         1.7764e-14, 1.0658e-14, 7.1054e-15, 1.4211e-14, 1.0658e-14, 6.6613e-15,\n",
      "         8.8818e-15, 7.1054e-15, 5.9952e-15, 1.0658e-14, 1.1546e-14, 7.1054e-15,\n",
      "         6.8834e-15, 1.0658e-14, 1.2434e-14, 8.8818e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 57: layer3.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 57\n",
      "Max diff:\n",
      " tensor([1.3323e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8858e-15, 0.0000e+00,\n",
      "         1.6098e-15, 0.0000e+00, 0.0000e+00, 5.7732e-15, 0.0000e+00, 4.4409e-15,\n",
      "         8.8818e-15, 6.2172e-15, 1.1380e-15, 4.4409e-15, 2.2204e-15, 3.9968e-15,\n",
      "         8.8818e-16, 0.0000e+00, 2.2760e-15, 6.9389e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.9968e-15, 0.0000e+00, 7.9936e-15, 0.0000e+00,\n",
      "         0.0000e+00, 3.9968e-15, 5.3568e-15, 4.3299e-15, 3.1086e-15, 4.2188e-15,\n",
      "         3.8858e-15, 0.0000e+00, 4.1078e-15, 7.1054e-15, 4.9960e-16, 0.0000e+00,\n",
      "         0.0000e+00, 5.3291e-15, 1.1935e-15, 4.2188e-15, 0.0000e+00, 5.3291e-15,\n",
      "         0.0000e+00, 0.0000e+00, 6.6613e-15, 5.9952e-15, 0.0000e+00, 1.1546e-14,\n",
      "         4.8850e-15, 5.3291e-15, 0.0000e+00, 0.0000e+00, 3.7748e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6629e-15, 0.0000e+00, 1.4710e-15,\n",
      "         5.1070e-15, 5.4401e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8850e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.6629e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-15, 0.0000e+00, 7.5495e-15, 8.2157e-15, 5.3291e-15, 0.0000e+00,\n",
      "         6.6613e-15, 3.7470e-15, 0.0000e+00, 5.5511e-15, 9.7700e-15, 2.2204e-16,\n",
      "         1.7833e-15, 3.1086e-15, 4.1772e-15, 0.0000e+00, 7.1054e-15, 3.5527e-15,\n",
      "         7.1054e-15, 6.6613e-15, 3.3307e-15, 0.0000e+00, 1.3323e-14, 7.9936e-15,\n",
      "         4.2188e-15, 4.6629e-15, 8.8818e-15, 4.4409e-15, 1.3323e-15, 0.0000e+00,\n",
      "         8.8818e-15, 8.4377e-15, 2.6645e-15, 0.0000e+00, 5.3291e-15, 6.6613e-15,\n",
      "         6.9666e-15, 4.4409e-15, 5.3291e-15, 8.9651e-15, 8.8818e-16, 1.0658e-14,\n",
      "         1.2212e-15, 0.0000e+00, 7.1054e-15, 9.7700e-15, 0.0000e+00, 7.9936e-15,\n",
      "         0.0000e+00, 1.0658e-14, 5.9952e-15, 0.0000e+00, 7.9936e-15, 5.3291e-15,\n",
      "         2.2204e-15, 3.4972e-15, 4.8850e-15, 5.3291e-15, 1.1546e-14, 6.8001e-15,\n",
      "         1.8874e-15, 1.0658e-14, 6.8834e-15, 4.8850e-15]], dtype=torch.float64)\n",
      " tensor([ 64,  66,  69,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  86,\n",
      "         88,  91,  92,  93,  94,  95,  96,  98,  99, 100, 103, 104, 105, 107,\n",
      "        110, 111, 113, 114, 115, 118, 123, 125, 126, 127, 149, 158, 192, 194,\n",
      "        195, 196, 198, 199, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211,\n",
      "        212, 214, 215, 216, 217, 218, 219, 220, 222, 223, 224, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 242, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([ 64,  66,  69,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  86,\n",
      "         88,  91,  92,  93,  94,  95,  96,  98,  99, 100, 103, 104, 105, 107,\n",
      "        110, 111, 113, 114, 115, 118, 123, 125, 126, 127, 149, 158, 192, 194,\n",
      "        195, 196, 198, 199, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211,\n",
      "        212, 214, 215, 216, 217, 218, 219, 220, 222, 223, 224, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 242, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 93)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 58: layer3.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 58\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 58\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 58\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  2,  3,  4,  7,  9, 10, 13, 15, 16, 17, 21, 25, 27, 31, 32, 34, 37,\n",
      "        43, 44, 45, 46, 55, 58, 59]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  68,  69,  70,  72,  75,  76,  77,  78,  80,  81,  84,  85,  87,\n",
      "         89,  90,  92,  93,  95,  96,  98, 101, 103, 111, 112, 113, 114, 116,\n",
      "        118, 119, 121, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 217, 218, 219, 222, 224, 225, 226,\n",
      "        227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 244, 246, 249, 250,\n",
      "        251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 58\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 58\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.9936e-15, 5.5511e-16, 1.5543e-15, 8.8818e-15, 2.7756e-16, 1.1102e-15,\n",
      "         3.3307e-16, 5.5511e-16, 8.8818e-15, 4.4409e-16, 6.6613e-16, 4.4409e-16,\n",
      "         2.2204e-16, 5.5511e-16, 5.5511e-16, 7.1054e-15, 5.5511e-16, 3.3307e-16,\n",
      "         4.4409e-16, 3.3307e-16, 2.2204e-16, 4.4409e-15, 5.5511e-16, 1.9429e-16,\n",
      "         1.3878e-16, 6.6613e-16, 4.4409e-16, 6.4393e-15, 3.8858e-16, 7.9936e-15,\n",
      "         3.3307e-16, 1.2879e-14, 4.4409e-16, 7.9936e-15, 5.5511e-16, 2.1094e-15,\n",
      "         7.5495e-15, 2.7756e-16, 2.7756e-16, 2.7756e-16, 1.7764e-14, 3.3307e-16,\n",
      "         6.8834e-15, 4.4409e-16, 1.3323e-14, 5.5511e-16, 2.2204e-16, 6.6613e-16,\n",
      "         2.2204e-16, 5.5511e-16, 6.2172e-15, 3.3307e-16, 5.5511e-16, 2.7756e-16,\n",
      "         4.4409e-15, 1.2434e-14, 6.2172e-15, 4.9960e-16, 1.0658e-14, 5.5511e-16,\n",
      "         1.0658e-14, 7.1054e-15, 1.9984e-15, 4.4409e-16, 1.5099e-14, 2.8422e-14,\n",
      "         1.5987e-14, 1.3767e-14, 1.5987e-14, 1.4211e-14, 1.4211e-14, 1.0658e-14,\n",
      "         1.0658e-14, 1.5987e-14, 1.5543e-14, 9.7700e-15, 1.5987e-14, 1.5099e-14,\n",
      "         1.2434e-14, 1.7764e-14, 1.2879e-14, 1.7764e-14, 1.1102e-15, 1.4988e-14,\n",
      "         1.6875e-14, 2.4869e-14, 1.7764e-14, 1.4211e-14, 1.8208e-14, 1.4211e-14,\n",
      "         8.8818e-15, 1.2046e-14, 1.3767e-14, 2.6645e-15, 1.5987e-14, 1.7764e-14,\n",
      "         2.1316e-14, 1.7764e-14, 2.8422e-14, 1.8097e-14, 1.4211e-14, 1.5987e-14,\n",
      "         1.6875e-14, 2.1316e-14, 1.7764e-14, 1.5987e-14, 1.7764e-15, 1.2879e-14,\n",
      "         1.5987e-14, 2.4869e-14, 8.8818e-15, 1.4211e-14, 1.4211e-14, 1.0658e-14,\n",
      "         1.2434e-14, 1.5987e-14, 1.2434e-14, 1.7764e-14, 9.7700e-15, 1.4211e-14,\n",
      "         1.4100e-14, 1.4211e-14, 1.5987e-14, 1.2434e-14, 1.5987e-14, 1.5987e-14,\n",
      "         1.4211e-14, 9.7700e-15, 1.2434e-14, 8.8818e-15, 7.9936e-15, 2.4869e-14,\n",
      "         7.1054e-15, 9.7700e-15, 1.9540e-14, 1.2434e-14, 1.7764e-14, 5.5511e-16,\n",
      "         6.2172e-15, 6.6613e-16, 1.5987e-14, 1.7764e-14, 1.2434e-14, 1.2434e-14,\n",
      "         1.7764e-14, 2.6645e-15, 1.4211e-14, 3.1086e-15, 8.8818e-16, 1.4211e-14,\n",
      "         1.7764e-14, 1.1102e-15, 6.2172e-15, 5.3291e-15, 3.3307e-16, 1.7764e-14,\n",
      "         2.4869e-14, 3.5527e-15, 2.2204e-15, 6.2172e-15, 1.2434e-14, 1.2879e-14,\n",
      "         1.0658e-14, 1.7764e-14, 7.9936e-15, 1.5987e-14, 2.4869e-14, 1.0658e-14,\n",
      "         1.2434e-14, 1.7764e-15, 1.7764e-14, 2.4869e-14, 1.7764e-14, 1.3156e-14,\n",
      "         2.1316e-14, 2.6645e-15, 6.2172e-15, 1.7764e-14, 1.0214e-14, 1.5987e-14,\n",
      "         2.6645e-15, 4.6629e-15, 1.3323e-15, 1.1102e-15, 2.2204e-15, 3.3307e-16,\n",
      "         1.7764e-14, 1.6875e-14, 1.5987e-14, 8.8818e-15, 2.8422e-14, 1.4211e-14,\n",
      "         2.4869e-14, 2.6645e-14, 1.6875e-14, 1.5987e-14, 1.4655e-14, 2.1316e-14,\n",
      "         1.9540e-14, 1.4211e-14, 1.5987e-14, 1.5266e-14, 2.8422e-14, 1.7764e-14,\n",
      "         1.5543e-14, 3.1974e-14, 2.1316e-14, 2.1316e-14, 1.2434e-14, 1.9540e-14,\n",
      "         1.8652e-14, 2.1316e-14, 1.2212e-14, 1.7764e-14, 1.9540e-14, 1.5987e-14,\n",
      "         2.6645e-14, 2.1316e-14, 2.1316e-14, 1.9096e-14, 1.2434e-14, 2.8422e-14,\n",
      "         1.7764e-14, 1.4655e-14, 2.1316e-14, 2.2204e-14, 1.7764e-14, 1.4211e-14,\n",
      "         1.7764e-14, 1.3323e-14, 1.3767e-14, 1.5099e-14, 1.4766e-14, 1.7764e-14,\n",
      "         1.5987e-14, 1.2434e-14, 1.7764e-14, 1.5099e-14, 1.2434e-14, 2.4869e-14,\n",
      "         1.2879e-14, 1.3323e-14, 1.2434e-14, 1.9540e-14, 1.0658e-14, 2.1316e-14,\n",
      "         2.8422e-14, 1.7764e-14, 4.4409e-15, 1.9540e-14, 2.2204e-14, 1.7764e-14,\n",
      "         2.1316e-14, 3.1974e-14, 1.4211e-14, 1.5987e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 59: layer3.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 59\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 59\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 59\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 59\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 59\n",
      "Max diff:\n",
      " tensor([2.3093e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5543e-15, 1.6653e-16, 4.4409e-16, 2.2204e-15, 1.1102e-16, 3.3307e-16,\n",
      "         1.1102e-16, 1.9429e-16, 1.9984e-15, 1.6653e-16, 2.2204e-16, 1.6653e-16,\n",
      "         8.3267e-17, 1.6653e-16, 1.9429e-16, 2.6645e-15, 1.9429e-16, 9.7145e-17,\n",
      "         1.6653e-16, 1.1102e-16, 8.3267e-17, 1.1102e-15, 1.9429e-16, 6.9389e-17,\n",
      "         5.5511e-17, 2.2204e-16, 1.6653e-16, 2.7756e-15, 1.1102e-16, 2.2204e-15,\n",
      "         1.1102e-16, 5.7732e-15, 1.6653e-16, 2.6645e-15, 1.9429e-16, 4.9960e-16,\n",
      "         2.3870e-15, 8.3267e-17, 1.1102e-16, 8.3267e-17, 4.4409e-15, 1.1102e-16,\n",
      "         2.6090e-15, 1.3878e-16, 4.2188e-15, 1.6653e-16, 8.3267e-17, 2.4980e-16,\n",
      "         8.3267e-17, 1.9429e-16, 2.2204e-15, 1.1102e-16, 1.6653e-16, 1.1102e-16,\n",
      "         8.8818e-16, 4.4409e-15, 4.4409e-16, 1.6653e-16, 3.9968e-15, 1.6653e-16,\n",
      "         1.5543e-15, 1.9984e-15, 4.4409e-16, 1.6653e-16, 6.6613e-15, 1.2434e-14,\n",
      "         8.8818e-15, 4.9960e-15, 7.9936e-15, 7.1054e-15, 4.4409e-15, 5.1070e-15,\n",
      "         3.5527e-15, 8.8818e-15, 7.5495e-15, 4.8850e-15, 9.7700e-15, 8.4377e-15,\n",
      "         4.4409e-15, 5.3291e-15, 4.8850e-15, 9.7700e-15, 4.4409e-16, 7.2893e-15,\n",
      "         7.9936e-15, 1.1546e-14, 7.1054e-15, 7.1054e-15, 6.4393e-15, 8.8818e-15,\n",
      "         2.6645e-15, 6.6648e-15, 6.2172e-15, 7.7716e-16, 7.9936e-15, 7.1054e-15,\n",
      "         1.2434e-14, 7.9936e-15, 1.4211e-14, 1.0547e-14, 7.9936e-15, 3.1086e-15,\n",
      "         6.6613e-15, 3.9968e-15, 6.2172e-15, 7.1054e-15, 6.6613e-16, 5.5511e-15,\n",
      "         4.8850e-15, 1.1546e-14, 3.1086e-15, 6.2172e-15, 6.2172e-15, 4.8850e-15,\n",
      "         5.3291e-15, 6.4393e-15, 3.5527e-15, 8.8818e-15, 5.7732e-15, 6.4393e-15,\n",
      "         4.9960e-15, 7.9936e-15, 7.9936e-15, 4.4409e-15, 7.1054e-15, 7.1054e-15,\n",
      "         7.1054e-15, 4.8850e-15, 6.2172e-15, 2.6645e-15, 2.2204e-15, 1.0658e-14,\n",
      "         2.2204e-15, 3.9968e-15, 6.2172e-15, 4.4409e-15, 7.1054e-15, 1.9429e-16,\n",
      "         1.3323e-15, 2.2204e-16, 1.2837e-15, 1.0658e-14, 6.2172e-15, 1.1102e-15,\n",
      "         7.9936e-15, 1.1102e-15, 8.8818e-15, 1.1102e-15, 2.7756e-16, 5.3291e-15,\n",
      "         6.2172e-15, 4.4409e-16, 1.3323e-15, 1.9984e-15, 1.1102e-16, 8.8818e-15,\n",
      "         7.1054e-15, 1.3323e-15, 7.7716e-16, 2.6645e-15, 4.8850e-15, 1.8319e-15,\n",
      "         7.7716e-16, 9.7700e-15, 2.4980e-16, 7.9936e-15, 1.5987e-14, 5.3291e-15,\n",
      "         6.6613e-16, 6.6613e-16, 7.1054e-15, 1.5987e-14, 7.1054e-15, 5.8287e-16,\n",
      "         8.8818e-15, 8.8818e-16, 2.2204e-15, 5.3291e-15, 2.4286e-16, 5.3291e-15,\n",
      "         1.1102e-15, 9.9920e-16, 3.3307e-16, 4.4409e-16, 8.8818e-16, 1.3878e-16,\n",
      "         1.0658e-14, 1.9984e-15, 4.7184e-16, 2.6645e-15, 1.2434e-14, 6.6613e-15,\n",
      "         1.1546e-14, 4.8850e-15, 1.0214e-14, 6.2172e-15, 6.4393e-15, 7.1054e-15,\n",
      "         6.6613e-15, 5.3291e-15, 6.2172e-15, 5.0307e-15, 1.7764e-14, 3.9968e-15,\n",
      "         5.6344e-15, 2.1316e-14, 7.1054e-15, 3.5527e-15, 4.8850e-15, 1.0658e-14,\n",
      "         6.6613e-15, 4.8850e-15, 4.1356e-15, 8.8818e-15, 7.1054e-15, 7.0777e-15,\n",
      "         1.1546e-14, 9.7700e-15, 8.8818e-15, 7.9936e-15, 5.3291e-15, 5.3291e-15,\n",
      "         6.2172e-15, 5.3291e-15, 8.8818e-15, 6.2172e-15, 8.8818e-15, 3.6637e-15,\n",
      "         1.0658e-14, 4.4409e-15, 6.2172e-15, 5.5511e-15, 5.2180e-15, 4.4409e-15,\n",
      "         3.1919e-15, 1.7764e-15, 5.7732e-15, 2.9976e-15, 4.4409e-15, 1.0658e-14,\n",
      "         5.8842e-15, 4.8850e-15, 5.3291e-15, 5.7732e-15, 3.5527e-15, 7.1054e-15,\n",
      "         8.8818e-15, 8.8818e-15, 1.5543e-15, 7.9936e-15, 7.5495e-15, 5.3291e-15,\n",
      "         7.9936e-15, 2.3093e-14, 4.4409e-15, 7.9936e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 60: layer3.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 60\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 60\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 60\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 60\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 60\n",
      "Max diff:\n",
      " tensor([3.5527e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 3.3307e-16, 6.6613e-16, 1.0658e-14, 2.2204e-16, 4.4409e-16,\n",
      "         4.4409e-16, 2.2204e-16, 8.8818e-15, 4.4409e-16, 3.3307e-16, 2.7756e-16,\n",
      "         1.6653e-16, 3.3307e-16, 2.2204e-16, 7.1054e-15, 3.3307e-16, 2.9143e-16,\n",
      "         1.7764e-15, 3.3307e-16, 1.6653e-16, 4.4409e-15, 2.2204e-16, 5.5511e-16,\n",
      "         3.3307e-16, 2.2204e-16, 3.3307e-16, 3.7748e-15, 2.2204e-16, 4.4409e-15,\n",
      "         3.0531e-16, 4.4409e-15, 3.3307e-16, 3.2752e-15, 4.4409e-16, 1.7764e-15,\n",
      "         6.2172e-15, 3.8858e-16, 1.3323e-15, 6.6613e-16, 1.7764e-14, 1.6653e-16,\n",
      "         3.9968e-15, 2.2204e-16, 2.4980e-15, 2.2204e-16, 2.2204e-16, 2.2204e-16,\n",
      "         4.4409e-16, 5.5511e-16, 1.7764e-15, 3.3307e-16, 4.4409e-16, 2.2204e-16,\n",
      "         2.6645e-15, 4.4409e-15, 3.9968e-15, 8.8818e-16, 4.4409e-15, 4.4409e-16,\n",
      "         8.8818e-15, 7.1054e-15, 1.7764e-15, 2.2204e-16, 1.0658e-14, 7.1054e-15,\n",
      "         1.5099e-14, 9.1038e-15, 1.4655e-14, 9.7700e-15, 2.1316e-14, 1.2434e-14,\n",
      "         8.8818e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15, 7.1054e-15, 7.9936e-15,\n",
      "         6.2172e-15, 1.2434e-14, 1.1546e-14, 6.2172e-15, 1.7764e-15, 1.5987e-14,\n",
      "         1.9540e-14, 6.6613e-15, 1.2879e-14, 1.6875e-14, 1.6431e-14, 1.0214e-14,\n",
      "         8.8818e-15, 7.1054e-15, 1.2434e-14, 1.1102e-15, 1.7764e-14, 1.0658e-14,\n",
      "         7.3275e-15, 9.2149e-15, 1.0658e-14, 1.2434e-14, 1.2434e-14, 1.7764e-14,\n",
      "         1.1546e-14, 1.1102e-14, 1.2434e-14, 1.1546e-14, 2.2204e-15, 1.3323e-14,\n",
      "         1.0658e-14, 2.4869e-14, 8.8818e-15, 2.6645e-14, 1.4211e-14, 1.1990e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.4211e-14, 1.5987e-14, 7.9936e-15, 9.6589e-15,\n",
      "         1.5099e-14, 8.8818e-15, 1.6875e-14, 9.7700e-15, 4.1078e-15, 2.1316e-14,\n",
      "         8.4377e-15, 3.5527e-15, 1.0658e-14, 2.2204e-15, 7.1054e-15, 1.0658e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.5987e-14, 7.1054e-15, 7.9936e-15, 1.3323e-15,\n",
      "         5.3291e-15, 4.4409e-16, 1.4211e-14, 1.4211e-14, 5.3291e-15, 1.1768e-14,\n",
      "         1.0658e-14, 3.5527e-15, 5.3291e-15, 1.7764e-15, 8.8818e-16, 1.7764e-14,\n",
      "         2.1316e-14, 8.8818e-16, 4.4409e-15, 4.4409e-15, 6.6613e-16, 7.1054e-15,\n",
      "         1.4211e-14, 3.5527e-15, 1.7764e-15, 1.2434e-14, 3.5527e-15, 1.2434e-14,\n",
      "         7.1054e-15, 1.2434e-14, 1.1435e-14, 8.8818e-15, 7.1054e-15, 1.0658e-14,\n",
      "         1.7764e-14, 1.7764e-15, 8.8818e-15, 1.0658e-14, 6.2172e-15, 1.1102e-14,\n",
      "         1.4211e-14, 1.7764e-15, 5.3291e-15, 8.8818e-15, 1.5987e-14, 2.3093e-14,\n",
      "         3.5527e-15, 1.4211e-14, 1.7764e-15, 8.8818e-16, 2.6645e-15, 4.4409e-16,\n",
      "         5.3291e-15, 1.7764e-14, 1.7764e-14, 2.6645e-15, 1.7764e-14, 5.3291e-15,\n",
      "         1.0658e-14, 2.8422e-14, 1.7764e-14, 2.8422e-14, 1.4211e-14, 1.7764e-14,\n",
      "         1.4211e-14, 1.0214e-14, 1.9096e-14, 1.0658e-14, 1.1546e-14, 1.4211e-14,\n",
      "         2.4869e-14, 2.1316e-14, 1.7764e-14, 2.8422e-14, 1.6653e-14, 1.5099e-14,\n",
      "         1.0658e-14, 1.5987e-14, 2.1316e-14, 1.0658e-14, 1.3767e-14, 2.1316e-14,\n",
      "         2.1316e-14, 1.4211e-14, 1.3989e-14, 1.5987e-14, 8.8818e-15, 1.5987e-14,\n",
      "         1.4211e-14, 1.0658e-14, 2.4869e-14, 1.4211e-14, 2.1316e-14, 1.7764e-14,\n",
      "         2.6645e-14, 2.0428e-14, 8.3267e-15, 1.4211e-14, 3.5527e-14, 4.8850e-15,\n",
      "         1.5987e-14, 8.8818e-15, 3.1974e-14, 2.1316e-14, 1.0658e-14, 1.0658e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.2434e-14, 2.8422e-14, 3.5527e-15, 1.4211e-14,\n",
      "         1.3323e-14, 1.3323e-14, 3.1086e-15, 1.0658e-14, 2.1316e-14, 1.5099e-14,\n",
      "         1.7764e-14, 1.1546e-14, 5.3291e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 61: layer3.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 61\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 61\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 61\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 61\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 61\n",
      "Max diff:\n",
      " tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.6613e-16, 1.1102e-16, 2.2204e-16, 4.8850e-15, 8.3267e-17, 1.3878e-16,\n",
      "         1.3878e-16, 5.5511e-17, 3.5527e-15, 1.3878e-16, 1.1102e-16, 8.3267e-17,\n",
      "         4.1633e-17, 9.7145e-17, 5.5511e-17, 1.7764e-15, 1.1102e-16, 9.7145e-17,\n",
      "         5.5511e-16, 1.1102e-16, 5.5511e-17, 1.3323e-15, 8.3267e-17, 1.6653e-16,\n",
      "         1.1102e-16, 6.9389e-17, 8.3267e-17, 5.8287e-16, 6.9389e-17, 1.8874e-15,\n",
      "         8.3267e-17, 1.1102e-15, 1.1102e-16, 6.3144e-16, 1.6653e-16, 4.4409e-16,\n",
      "         1.5543e-15, 1.3878e-16, 3.3307e-16, 2.2204e-16, 7.1054e-15, 4.1633e-17,\n",
      "         6.6613e-16, 5.5511e-17, 3.4694e-17, 5.5511e-17, 8.3267e-17, 8.3267e-17,\n",
      "         1.1102e-16, 1.6653e-16, 4.4409e-16, 1.1102e-16, 1.1102e-16, 6.9389e-17,\n",
      "         8.8818e-16, 5.5511e-16, 8.8818e-16, 2.7756e-16, 1.3323e-15, 8.3267e-17,\n",
      "         2.8866e-15, 2.6645e-15, 4.4409e-16, 8.3267e-17, 3.5527e-15, 1.5543e-15,\n",
      "         4.4409e-15, 2.6645e-15, 3.9968e-15, 1.8874e-15, 1.0658e-14, 3.9968e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.7764e-15, 4.9960e-16, 1.3323e-15, 1.5543e-15,\n",
      "         1.7764e-15, 4.4409e-15, 3.7748e-15, 1.2212e-15, 5.5511e-16, 7.1054e-15,\n",
      "         4.8850e-15, 1.3323e-15, 5.3291e-15, 7.1054e-15, 5.3291e-15, 3.6637e-15,\n",
      "         4.4409e-15, 8.8818e-16, 5.3291e-15, 3.8858e-16, 7.9936e-15, 4.4409e-15,\n",
      "         5.5511e-16, 1.8874e-15, 2.6645e-15, 5.7732e-15, 3.5527e-15, 6.2172e-15,\n",
      "         3.5527e-15, 1.5099e-14, 3.9968e-15, 1.8874e-15, 7.7716e-16, 5.9952e-15,\n",
      "         1.0547e-15, 6.8834e-15, 3.1086e-15, 8.4377e-15, 3.5527e-15, 3.4417e-15,\n",
      "         3.5527e-15, 2.6645e-15, 4.4409e-15, 4.4409e-15, 2.4425e-15, 2.1927e-15,\n",
      "         4.7740e-15, 2.2204e-15, 4.8850e-15, 3.3307e-15, 1.1380e-15, 3.5527e-15,\n",
      "         1.5543e-15, 1.1102e-15, 2.6645e-15, 4.4409e-16, 2.6645e-15, 3.5527e-15,\n",
      "         3.5527e-15, 5.3291e-15, 1.0658e-14, 2.2204e-15, 1.5543e-15, 4.4409e-16,\n",
      "         1.3323e-15, 1.6653e-16, 7.1054e-15, 5.3291e-15, 1.3323e-15, 4.9960e-15,\n",
      "         3.5527e-15, 8.8818e-16, 1.3323e-15, 5.5511e-16, 3.3307e-16, 4.4409e-15,\n",
      "         8.8818e-15, 3.3307e-16, 8.8818e-16, 1.3323e-15, 1.6653e-16, 1.7764e-15,\n",
      "         4.4409e-15, 8.8818e-16, 5.5511e-16, 4.4409e-15, 1.1102e-15, 5.3291e-15,\n",
      "         4.4409e-15, 2.2204e-15, 4.9960e-15, 2.6645e-15, 8.8818e-16, 5.3291e-15,\n",
      "         2.4869e-14, 6.6613e-16, 3.5527e-15, 5.3291e-15, 1.7764e-15, 5.1070e-15,\n",
      "         5.3291e-15, 3.3307e-16, 1.3323e-15, 2.6645e-15, 6.2172e-15, 1.2434e-14,\n",
      "         8.8818e-16, 2.6645e-15, 6.6613e-16, 2.2204e-16, 8.8818e-16, 1.6653e-16,\n",
      "         8.8818e-16, 1.0658e-14, 2.8422e-14, 3.2960e-17, 7.1054e-15, 1.3323e-15,\n",
      "         3.1086e-15, 1.4211e-14, 5.3291e-15, 1.4211e-14, 3.5527e-15, 1.7764e-15,\n",
      "         5.3291e-15, 1.4433e-15, 7.2164e-15, 1.3323e-15, 5.3291e-15, 7.1054e-15,\n",
      "         1.1990e-14, 7.1054e-15, 4.4409e-15, 1.2434e-14, 7.1054e-15, 3.5527e-15,\n",
      "         1.9984e-15, 2.3093e-14, 1.0658e-14, 2.6645e-15, 4.3021e-16, 5.3291e-15,\n",
      "         7.1054e-15, 4.4409e-15, 1.5543e-15, 2.6645e-15, 2.6645e-15, 2.5757e-14,\n",
      "         2.6645e-15, 2.6645e-15, 1.0658e-14, 2.6645e-15, 7.1054e-15, 5.3291e-15,\n",
      "         7.1054e-15, 9.9920e-15, 2.9143e-16, 7.1054e-15, 2.1316e-14, 2.7756e-17,\n",
      "         6.2172e-15, 3.1086e-15, 1.7764e-14, 1.0658e-14, 3.9968e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 1.7764e-15, 1.7764e-14, 7.7716e-16, 3.5527e-15,\n",
      "         5.3291e-15, 4.4409e-15, 8.8818e-16, 3.5527e-15, 1.0658e-14, 4.8295e-15,\n",
      "         7.1054e-15, 3.5527e-15, 8.3267e-17, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 62: layer3.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 62\n",
      "Max diff:\n",
      " tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 2.2204e-16, 8.8818e-16, 5.3291e-15, 1.1102e-16, 2.2204e-16,\n",
      "         1.6653e-16, 2.2204e-16, 3.5527e-15, 1.6653e-16, 2.2204e-16, 1.6653e-16,\n",
      "         1.1102e-16, 1.6653e-16, 2.2204e-16, 2.6645e-15, 2.2204e-16, 9.7145e-17,\n",
      "         5.5511e-16, 1.6653e-16, 1.1102e-16, 1.7764e-15, 1.6653e-16, 1.6653e-16,\n",
      "         1.1102e-16, 2.7756e-16, 2.2204e-16, 2.8866e-15, 1.6653e-16, 3.1086e-15,\n",
      "         1.6653e-16, 6.6613e-15, 1.1102e-16, 2.8866e-15, 2.2204e-16, 6.6613e-16,\n",
      "         2.6645e-15, 1.1102e-16, 3.3307e-16, 2.2204e-16, 7.1054e-15, 1.1102e-16,\n",
      "         2.6645e-15, 2.2204e-16, 4.2188e-15, 2.2204e-16, 1.1102e-16, 2.7756e-16,\n",
      "         1.1102e-16, 2.2204e-16, 2.2204e-15, 1.1102e-16, 2.2204e-16, 1.6653e-16,\n",
      "         1.3323e-15, 4.4409e-15, 8.8818e-16, 3.3307e-16, 4.6629e-15, 2.2204e-16,\n",
      "         2.2204e-15, 2.6645e-15, 4.4409e-16, 2.2204e-16, 7.3275e-15, 1.2434e-14,\n",
      "         8.2157e-15, 5.3291e-15, 9.7700e-15, 5.3291e-15, 1.0658e-14, 7.1054e-15,\n",
      "         3.5527e-15, 8.8818e-15, 7.9936e-15, 4.8850e-15, 1.0658e-14, 7.9936e-15,\n",
      "         5.3291e-15, 7.1054e-15, 7.5495e-15, 8.8818e-15, 4.4409e-16, 8.8818e-15,\n",
      "         8.2157e-15, 1.1546e-14, 9.7700e-15, 7.1054e-15, 8.8818e-15, 7.9936e-15,\n",
      "         5.3291e-15, 6.3977e-15, 8.8818e-15, 6.6613e-16, 8.8818e-15, 7.9936e-15,\n",
      "         1.2434e-14, 7.9936e-15, 1.4211e-14, 1.0658e-14, 8.8818e-15, 6.2172e-15,\n",
      "         6.2172e-15, 1.5987e-14, 7.1054e-15, 7.1054e-15, 8.8818e-16, 1.0214e-14,\n",
      "         4.6629e-15, 1.2434e-14, 3.7748e-15, 1.1546e-14, 7.1054e-15, 4.9960e-15,\n",
      "         5.3291e-15, 7.1054e-15, 4.4409e-15, 8.8818e-15, 7.9936e-15, 6.6613e-15,\n",
      "         7.1054e-15, 8.8818e-15, 7.9936e-15, 4.4409e-15, 6.2172e-15, 7.5495e-15,\n",
      "         7.9936e-15, 5.1070e-15, 6.2172e-15, 3.5527e-15, 2.6645e-15, 1.0658e-14,\n",
      "         5.3291e-15, 4.6629e-15, 9.7700e-15, 4.4409e-15, 7.1054e-15, 6.6613e-16,\n",
      "         1.7764e-15, 3.3307e-16, 7.1054e-15, 1.0658e-14, 7.1054e-15, 5.3291e-15,\n",
      "         7.1054e-15, 8.8818e-16, 1.0658e-14, 1.3323e-15, 4.9960e-16, 8.8818e-15,\n",
      "         8.8818e-15, 6.6613e-16, 1.7764e-15, 2.6645e-15, 2.2204e-16, 7.1054e-15,\n",
      "         8.8818e-15, 1.7764e-15, 6.6613e-16, 3.5527e-15, 4.4409e-15, 7.1054e-15,\n",
      "         4.4409e-15, 9.7700e-15, 4.9405e-15, 7.9936e-15, 1.5987e-14, 7.1054e-15,\n",
      "         2.4869e-14, 1.3323e-15, 8.8818e-15, 1.7764e-14, 7.1054e-15, 5.5511e-15,\n",
      "         7.1054e-15, 8.8818e-16, 2.6645e-15, 5.3291e-15, 6.2172e-15, 1.2434e-14,\n",
      "         1.3323e-15, 2.6645e-15, 8.8818e-16, 4.4409e-16, 8.8818e-16, 2.2204e-16,\n",
      "         1.0658e-14, 1.2434e-14, 2.8422e-14, 2.6645e-15, 1.4211e-14, 7.9936e-15,\n",
      "         9.7700e-15, 1.9540e-14, 1.1546e-14, 1.4211e-14, 7.9936e-15, 7.1054e-15,\n",
      "         7.9936e-15, 6.2172e-15, 1.0658e-14, 5.4401e-15, 1.7764e-14, 7.1054e-15,\n",
      "         1.2434e-14, 2.1316e-14, 7.9936e-15, 1.2434e-14, 1.1102e-14, 1.2434e-14,\n",
      "         6.6613e-15, 2.3093e-14, 1.0658e-14, 9.7700e-15, 7.1054e-15, 7.9936e-15,\n",
      "         1.4211e-14, 1.0658e-14, 8.8818e-15, 7.5495e-15, 6.2172e-15, 2.5313e-14,\n",
      "         6.6613e-15, 7.1054e-15, 1.5987e-14, 7.1054e-15, 1.0658e-14, 6.2172e-15,\n",
      "         1.4211e-14, 1.2434e-14, 6.4393e-15, 9.7700e-15, 1.7764e-14, 4.4409e-15,\n",
      "         7.1054e-15, 3.9968e-15, 1.7764e-14, 1.0658e-14, 6.2172e-15, 9.7700e-15,\n",
      "         7.1054e-15, 5.3291e-15, 6.2172e-15, 1.7764e-14, 3.5527e-15, 7.1054e-15,\n",
      "         1.0658e-14, 9.7700e-15, 1.7764e-15, 8.8818e-15, 1.0658e-14, 7.9936e-15,\n",
      "         1.0658e-14, 2.3093e-14, 4.4409e-15, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 63: layer3.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 63\n",
      "Max diff:\n",
      " tensor([2.4869e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5535e-15, 0.0000e+00, 3.1086e-15,\n",
      "         0.0000e+00, 4.2744e-15, 0.0000e+00, 1.1102e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         1.8874e-15, 0.0000e+00, 2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9429e-16, 0.0000e+00, 2.4425e-15, 0.0000e+00,\n",
      "         2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-15, 6.2172e-15,\n",
      "         6.2172e-15, 4.5519e-15, 2.2204e-15, 3.5527e-15, 1.0658e-14, 5.3291e-15,\n",
      "         2.6645e-15, 4.4409e-15, 0.0000e+00, 4.4409e-15, 6.6613e-15, 7.5495e-15,\n",
      "         0.0000e+00, 0.0000e+00, 7.5495e-15, 4.4409e-15, 0.0000e+00, 8.8818e-15,\n",
      "         4.8850e-15, 6.4393e-15, 5.5511e-15, 4.4409e-16, 8.8818e-15, 7.9936e-15,\n",
      "         0.0000e+00, 6.3977e-15, 6.6613e-15, 0.0000e+00, 0.0000e+00, 6.6613e-15,\n",
      "         5.7732e-15, 1.7764e-15, 0.0000e+00, 1.0658e-14, 0.0000e+00, 0.0000e+00,\n",
      "         5.3291e-15, 6.4393e-15, 9.9920e-16, 7.1054e-15, 0.0000e+00, 5.9952e-15,\n",
      "         3.2196e-15, 3.5527e-15, 3.5527e-15, 7.1054e-15, 0.0000e+00, 4.9960e-15,\n",
      "         0.0000e+00, 7.1054e-15, 4.4409e-15, 0.0000e+00, 5.7732e-15, 4.8850e-15,\n",
      "         6.6613e-15, 2.2204e-16, 7.5495e-15, 3.5527e-15, 1.9984e-15, 6.5503e-15,\n",
      "         0.0000e+00, 3.8858e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.7700e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2204e-15, 0.0000e+00, 0.0000e+00, 5.3291e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8866e-15,\n",
      "         3.5527e-15, 7.1054e-15, 2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.4869e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2172e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.1625e-15, 1.5987e-14, 0.0000e+00, 0.0000e+00, 1.9984e-15,\n",
      "         9.7700e-15, 1.9540e-14, 7.5495e-15, 0.0000e+00, 0.0000e+00, 2.4980e-15,\n",
      "         7.9936e-15, 6.2172e-15, 1.0658e-14, 4.4409e-15, 7.9936e-15, 0.0000e+00,\n",
      "         1.2434e-14, 6.2172e-15, 7.1054e-15, 1.2434e-14, 6.2172e-15, 6.6613e-15,\n",
      "         5.5511e-15, 2.3093e-14, 1.0658e-14, 9.7700e-15, 1.9984e-15, 0.0000e+00,\n",
      "         3.5527e-15, 0.0000e+00, 2.1372e-15, 4.4409e-15, 4.8850e-15, 2.3093e-14,\n",
      "         6.6613e-15, 7.1054e-15, 0.0000e+00, 7.1054e-15, 1.0658e-14, 6.2172e-15,\n",
      "         1.4211e-14, 1.1768e-14, 6.4393e-15, 9.7700e-15, 1.7764e-14, 4.4409e-15,\n",
      "         7.1054e-15, 3.9968e-15, 6.2172e-15, 1.0658e-14, 6.2172e-15, 7.1054e-15,\n",
      "         0.0000e+00, 2.2204e-16, 6.2172e-15, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         5.9952e-15, 8.4377e-15, 0.0000e+00, 7.1054e-15, 1.0658e-14, 7.9936e-15,\n",
      "         0.0000e+00, 6.2172e-15, 2.6645e-15, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([ 15,  27,  29,  31,  33,  36,  40,  42,  44,  50,  56,  58,  60,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  80,  81,\n",
      "         83,  84,  85,  86,  87,  88,  89,  91,  92,  95,  96,  97,  99, 102,\n",
      "        103, 104, 105, 107, 108, 109, 110, 111, 113, 115, 116, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 127, 134, 140, 143, 150, 161, 162, 163, 164,\n",
      "        168, 173, 178, 181, 187, 188, 191, 192, 193, 194, 197, 198, 199, 200,\n",
      "        201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216,\n",
      "        218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 239, 241, 242, 245, 246, 247, 249, 250,\n",
      "        251, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([ 15,  27,  29,  31,  33,  36,  40,  42,  44,  50,  56,  58,  60,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  80,  81,\n",
      "         83,  84,  85,  86,  87,  88,  89,  91,  92,  95,  96,  97,  99, 102,\n",
      "        103, 104, 105, 107, 108, 109, 110, 111, 113, 115, 116, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 127, 134, 140, 143, 150, 161, 162, 163, 164,\n",
      "        168, 173, 178, 181, 187, 188, 191, 192, 193, 194, 197, 198, 199, 200,\n",
      "        201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216,\n",
      "        218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 239, 241, 242, 245, 246, 247, 249, 250,\n",
      "        251, 253, 254, 255])  (len = 130)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 64: layer3.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 64\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120,\n",
      "        122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 64\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 64\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 64\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 64\n",
      "Max diff:\n",
      " tensor([3.1264e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.0658e-14, 3.5527e-15, 1.3323e-15, 2.2204e-15, 1.7764e-15, 3.1086e-15,\n",
      "         2.2204e-15, 3.5527e-15, 2.2204e-15, 2.6645e-15, 1.4211e-14, 1.0658e-14,\n",
      "         2.6645e-15, 2.6645e-15, 2.2204e-15, 1.7764e-15, 3.5527e-15, 2.2204e-15,\n",
      "         1.3323e-15, 1.3323e-15, 1.3323e-15, 3.1086e-15, 5.3291e-15, 3.5527e-15,\n",
      "         1.7764e-15, 2.2204e-15, 2.6645e-15, 2.6645e-15, 1.1102e-15, 3.5527e-15,\n",
      "         1.7764e-15, 1.1102e-15, 1.3323e-15, 4.4409e-15, 1.7764e-15, 1.1102e-15,\n",
      "         5.3291e-15, 4.4409e-15, 3.5527e-15, 3.5527e-15, 1.7764e-15, 6.2172e-15,\n",
      "         2.2204e-15, 2.6645e-15, 2.6645e-15, 1.1102e-15, 2.2204e-15, 1.7764e-15,\n",
      "         1.7764e-15, 2.2204e-15, 2.2204e-15, 2.2204e-15, 1.7764e-15, 5.3291e-15,\n",
      "         2.6645e-15, 3.5527e-15, 2.6645e-15, 2.2204e-15, 8.8818e-16, 1.7764e-14,\n",
      "         3.5527e-15, 1.7764e-15, 1.7764e-15, 4.4409e-15, 5.6843e-14, 3.5527e-14,\n",
      "         3.1086e-15, 7.1054e-15, 7.1054e-15, 4.2633e-14, 2.6645e-15, 1.7764e-14,\n",
      "         7.1054e-14, 3.5527e-15, 1.1369e-13, 2.6645e-15, 8.8818e-15, 8.8818e-15,\n",
      "         4.4409e-15, 8.5265e-14, 7.1054e-15, 1.7764e-15, 2.1316e-14, 3.5527e-15,\n",
      "         3.5527e-14, 7.1054e-15, 4.2633e-14, 1.4211e-14, 8.5265e-14, 4.2633e-14,\n",
      "         1.7764e-14, 7.1054e-14, 1.7764e-14, 5.3291e-15, 5.3291e-15, 1.4211e-14,\n",
      "         4.2633e-14, 1.1369e-13, 1.1369e-13, 2.8422e-14, 7.1054e-14, 8.5265e-14,\n",
      "         4.9738e-14, 1.2434e-14, 3.5527e-14, 4.2633e-14, 4.2633e-14, 5.3291e-15,\n",
      "         2.6645e-15, 2.1316e-14, 4.4409e-15, 1.1369e-13, 8.8818e-15, 7.1054e-15,\n",
      "         4.9738e-14, 4.2633e-14, 3.5527e-15, 8.5265e-14, 2.8422e-14, 2.1316e-14,\n",
      "         7.1054e-15, 4.2633e-14, 5.6843e-14, 1.4211e-14, 3.5527e-15, 2.1316e-14,\n",
      "         4.4409e-15, 2.2204e-15, 3.1974e-14, 7.1054e-14, 1.4211e-13, 4.2633e-14,\n",
      "         2.1316e-14, 2.8422e-14, 1.7764e-14, 1.7053e-13, 5.6843e-14, 2.1316e-14,\n",
      "         8.8818e-15, 4.2633e-14, 2.8422e-14, 4.2633e-14, 1.1369e-13, 1.4211e-13,\n",
      "         4.3521e-14, 7.1054e-14, 7.1054e-14, 1.1369e-13, 7.1054e-14, 1.0658e-14,\n",
      "         9.9476e-14, 2.8422e-14, 8.5265e-14, 1.4211e-14, 7.1054e-14, 1.0658e-14,\n",
      "         3.5527e-14, 5.3291e-14, 5.6843e-14, 2.4869e-14, 2.2737e-13, 5.6843e-14,\n",
      "         1.5632e-13, 7.1054e-14, 1.2790e-13, 4.2633e-14, 4.9738e-14, 1.7053e-13,\n",
      "         2.2204e-15, 7.1054e-14, 8.5265e-14, 1.1369e-13, 7.1054e-14, 8.8818e-15,\n",
      "         1.1369e-13, 2.8422e-14, 2.8422e-14, 8.5265e-14, 4.4409e-15, 5.6843e-14,\n",
      "         2.4869e-14, 2.1316e-14, 1.4211e-13, 3.5527e-14, 4.2633e-14, 8.5265e-14,\n",
      "         7.1054e-15, 5.6843e-14, 4.9738e-14, 1.7053e-13, 4.2633e-14, 1.4211e-14,\n",
      "         2.5580e-13, 9.9476e-14, 9.9476e-14, 5.6843e-14, 7.1054e-14, 8.5265e-14,\n",
      "         5.5067e-14, 9.9476e-14, 5.6843e-14, 8.5265e-14, 9.9476e-14, 5.6843e-14,\n",
      "         9.2371e-14, 1.9895e-13, 1.1369e-13, 2.5580e-13, 1.2790e-13, 1.4211e-13,\n",
      "         1.1369e-13, 1.4211e-13, 1.1369e-13, 1.1369e-13, 1.1369e-13, 5.3291e-14,\n",
      "         8.5265e-14, 1.4211e-13, 7.1054e-14, 9.2371e-14, 1.2790e-13, 8.5265e-14,\n",
      "         5.6843e-14, 1.1369e-13, 9.9476e-14, 7.1054e-14, 7.1054e-14, 8.5265e-14,\n",
      "         2.4869e-14, 8.5265e-14, 4.7073e-14, 5.6843e-14, 5.6843e-14, 9.9476e-14,\n",
      "         1.1369e-13, 9.9476e-14, 1.2790e-13, 7.1054e-14, 7.1054e-14, 6.3949e-14,\n",
      "         1.2790e-13, 2.2737e-13, 4.9738e-14, 3.1264e-13, 6.3949e-14, 1.5632e-13,\n",
      "         1.4211e-13, 9.2371e-14, 1.1369e-13, 1.4211e-13, 9.9476e-14, 4.2633e-14,\n",
      "         6.0396e-14, 7.1054e-14, 8.5265e-14, 1.1369e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 65: layer3.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 65\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 65\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 65\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 65\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 65\n",
      "Max diff:\n",
      " tensor([9.2371e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 1.1102e-15, 3.3307e-16, 6.6613e-16, 6.6613e-16, 9.9920e-16,\n",
      "         8.8818e-16, 1.1102e-15, 6.6613e-16, 8.8818e-16, 4.4409e-15, 3.5527e-15,\n",
      "         8.8818e-16, 8.8818e-16, 6.6613e-16, 6.6613e-16, 1.1102e-15, 7.7716e-16,\n",
      "         4.4409e-16, 4.4409e-16, 4.4409e-16, 8.8818e-16, 1.7764e-15, 1.1102e-15,\n",
      "         6.6613e-16, 6.6613e-16, 8.8818e-16, 8.8818e-16, 3.3307e-16, 1.1102e-15,\n",
      "         5.5511e-16, 4.4409e-16, 4.4409e-16, 1.5543e-15, 6.6613e-16, 3.8858e-16,\n",
      "         1.7764e-15, 1.3323e-15, 1.1102e-15, 1.1102e-15, 5.5511e-16, 1.9984e-15,\n",
      "         7.7716e-16, 8.8818e-16, 8.8818e-16, 3.3307e-16, 8.8818e-16, 5.5511e-16,\n",
      "         6.6613e-16, 6.6613e-16, 7.7716e-16, 6.6613e-16, 5.5511e-16, 1.7764e-15,\n",
      "         8.8818e-16, 1.1102e-15, 8.8818e-16, 8.8818e-16, 2.7756e-16, 5.3291e-15,\n",
      "         1.3323e-15, 6.6613e-16, 5.5511e-16, 1.3323e-15, 1.7764e-14, 1.0658e-14,\n",
      "         1.1102e-15, 2.6645e-15, 2.2204e-15, 8.8818e-15, 6.6613e-16, 5.3291e-15,\n",
      "         1.7764e-14, 1.3323e-15, 3.1974e-14, 8.8818e-16, 3.1086e-15, 2.6645e-15,\n",
      "         1.3323e-15, 1.7764e-14, 1.7764e-15, 5.5511e-16, 4.4409e-15, 1.1102e-15,\n",
      "         5.3291e-15, 2.2204e-15, 1.4211e-14, 5.3291e-15, 4.2633e-14, 1.4211e-14,\n",
      "         4.4409e-15, 2.1316e-14, 6.2172e-15, 1.7764e-15, 1.7764e-15, 4.4409e-15,\n",
      "         1.4211e-14, 3.5527e-14, 4.2633e-14, 5.7732e-15, 1.4211e-14, 2.4869e-14,\n",
      "         1.0658e-14, 5.3291e-15, 1.0658e-14, 1.4211e-14, 1.7764e-14, 1.7764e-15,\n",
      "         8.8818e-16, 7.1054e-15, 1.7764e-15, 3.1974e-14, 3.1086e-15, 2.6645e-15,\n",
      "         1.0658e-14, 1.7764e-14, 1.3323e-15, 1.5987e-14, 5.3291e-15, 7.1054e-15,\n",
      "         2.6645e-15, 7.1054e-15, 2.1316e-14, 4.4409e-15, 1.3323e-15, 7.1054e-15,\n",
      "         1.7764e-15, 6.6613e-16, 7.9936e-15, 1.4211e-14, 2.8422e-14, 1.4211e-14,\n",
      "         1.0658e-14, 1.2434e-14, 5.3291e-15, 3.1974e-14, 1.9540e-14, 7.1054e-15,\n",
      "         3.5527e-15, 1.7764e-14, 1.2434e-14, 1.4211e-14, 2.1316e-14, 7.1054e-14,\n",
      "         5.7732e-15, 2.4869e-14, 1.7764e-14, 4.2633e-14, 8.8818e-15, 4.4409e-15,\n",
      "         2.8422e-14, 8.8818e-15, 3.1974e-14, 4.4409e-15, 1.4211e-14, 3.5527e-15,\n",
      "         1.0658e-14, 1.3323e-14, 7.1054e-15, 7.1054e-15, 9.2371e-14, 2.4869e-14,\n",
      "         2.8422e-14, 2.1316e-14, 5.6843e-14, 1.4211e-14, 1.5987e-14, 8.5265e-14,\n",
      "         6.6613e-16, 2.1316e-14, 1.4211e-14, 2.4869e-14, 2.1316e-14, 3.5527e-15,\n",
      "         2.1316e-14, 6.2172e-15, 7.1054e-15, 1.7764e-14, 1.5543e-15, 1.0658e-14,\n",
      "         7.9936e-15, 7.1054e-15, 3.1974e-14, 1.0658e-14, 1.5987e-14, 1.7764e-14,\n",
      "         2.2204e-15, 1.4211e-14, 1.7764e-14, 4.9738e-14, 8.8818e-15, 4.4409e-15,\n",
      "         6.3949e-14, 4.2633e-14, 1.7764e-14, 1.7764e-14, 2.1316e-14, 1.4211e-14,\n",
      "         5.3291e-15, 2.4869e-14, 1.2434e-14, 1.3323e-14, 2.8422e-14, 1.5987e-14,\n",
      "         1.7764e-14, 3.5527e-14, 2.8422e-14, 4.9738e-14, 2.4869e-14, 2.1316e-14,\n",
      "         2.1316e-14, 1.2434e-14, 2.1316e-14, 4.2633e-14, 2.8422e-14, 7.5495e-15,\n",
      "         3.5527e-14, 2.4869e-14, 2.1316e-14, 1.0658e-14, 1.5987e-14, 1.5987e-14,\n",
      "         1.0658e-14, 2.1316e-14, 1.7764e-14, 1.7764e-14, 1.4211e-14, 2.8422e-14,\n",
      "         9.7700e-15, 1.7764e-14, 9.1038e-15, 6.2172e-15, 7.1054e-15, 4.9738e-14,\n",
      "         4.9738e-14, 1.4211e-14, 3.1974e-14, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.7764e-14, 7.8160e-14, 6.2172e-15, 8.5265e-14, 1.5987e-14, 3.5527e-14,\n",
      "         2.1316e-14, 1.5987e-14, 3.5527e-14, 2.8422e-14, 1.3323e-14, 7.1054e-15,\n",
      "         9.7700e-15, 1.7764e-14, 1.4211e-14, 2.8422e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 66: layer3.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 66\n",
      "Max diff:\n",
      " tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0801e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4211e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.7732e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8834e-15, 0.0000e+00,\n",
      "         4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.3437e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.4377e-15, 3.0254e-15, 3.7748e-15, 9.3259e-15, 1.9984e-15,\n",
      "         4.6629e-15, 0.0000e+00, 0.0000e+00, 3.3307e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6629e-15, 0.0000e+00, 7.5495e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8303e-15, 4.4409e-15, 0.0000e+00,\n",
      "         1.7764e-15, 7.3275e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4211e-14,\n",
      "         0.0000e+00, 2.4425e-15, 9.1038e-15, 0.0000e+00, 3.6637e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.7764e-15, 2.4425e-15, 0.0000e+00, 1.3323e-15, 7.9936e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00, 9.7700e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7732e-15,\n",
      "         9.7700e-15, 0.0000e+00, 4.4409e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 99, 106, 129, 144, 148, 150, 157, 175, 193, 194, 195, 196, 197, 198,\n",
      "        201, 213, 215, 219, 220, 222, 223, 227, 229, 230, 232, 235, 236, 238,\n",
      "        239, 242, 244, 251, 252, 254])\n",
      "\n",
      "failing Cout = tensor([ 99, 106, 129, 144, 148, 150, 157, 175, 193, 194, 195, 196, 197, 198,\n",
      "        201, 213, 215, 219, 220, 222, 223, 227, 229, 230, 232, 235, 236, 238,\n",
      "        239, 242, 244, 251, 252, 254])  (len = 34)\n",
      "passing Cout = tensor([237])  (len = 1)\n",
      "\n",
      "Executing module 67: layer3.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 67\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 67\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  2,  3,  5,  6,  7, 10, 12, 14, 16, 17, 19, 20, 21, 24, 25, 26, 30,\n",
      "        31, 34, 39, 40, 42, 43, 48, 53, 54, 55, 57, 58, 59, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 131, 132, 133, 136, 137, 138, 139, 142, 143, 144, 145, 146, 147,\n",
      "        148, 149, 151, 152, 153, 154, 156, 157, 160, 161, 164, 166, 167, 168,\n",
      "        170, 171, 172, 173, 175, 176, 178, 179, 180, 181, 183, 184, 185, 186,\n",
      "        187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 195, 196, 197, 198, 199, 200, 202, 204, 206, 207, 208, 210,\n",
      "        211, 215, 216, 218, 220, 222, 223, 224, 225, 226, 229, 231, 232, 234,\n",
      "        235, 237, 238, 239, 240, 242, 244, 246, 247, 248, 249, 251, 252, 253,\n",
      "        255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 67\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  2,  3,  5,  6,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22, 23, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 40, 41, 43, 44, 45,\n",
      "        46, 47, 48, 49, 50, 51, 53, 56, 57, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 67\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 67\n",
      "Max diff:\n",
      " tensor([1.5987e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 1.9429e-16, 8.8818e-16, 6.6613e-15, 4.6629e-15, 3.5527e-15,\n",
      "         1.5266e-16, 1.5266e-16, 3.4920e-15, 2.6645e-15, 1.2490e-16, 1.2490e-16,\n",
      "         3.3307e-16, 3.3307e-16, 4.9127e-15, 4.8850e-15, 1.6653e-16, 3.3307e-16,\n",
      "         1.3878e-16, 5.7732e-15, 2.7756e-16, 7.9936e-15, 3.1086e-15, 6.2172e-15,\n",
      "         4.9960e-16, 1.3878e-16, 1.1102e-16, 2.9698e-15, 1.3878e-16, 6.2172e-15,\n",
      "         2.5535e-15, 2.7756e-15, 2.4980e-15, 4.7740e-15, 4.5519e-15, 2.2204e-15,\n",
      "         3.9968e-15, 5.5511e-17, 3.1086e-15, 1.9429e-16, 4.9960e-15, 1.2490e-16,\n",
      "         4.7670e-15, 1.6653e-16, 4.2188e-15, 1.9984e-15, 4.4409e-16, 3.3307e-16,\n",
      "         5.3291e-15, 5.3291e-15, 4.6629e-15, 2.2204e-16, 3.0531e-16, 1.2490e-16,\n",
      "         6.7724e-15, 2.6645e-15, 3.3307e-15, 3.5527e-15, 1.7764e-15, 1.5543e-15,\n",
      "         3.5527e-15, 1.3323e-15, 3.9968e-15, 1.3878e-16, 1.0658e-14, 7.1054e-15,\n",
      "         5.8009e-15, 6.2172e-15, 6.5364e-15, 1.4211e-14, 7.1054e-15, 3.3307e-15,\n",
      "         5.1070e-15, 4.4409e-15, 7.1054e-15, 4.6629e-15, 7.1054e-15, 4.9405e-15,\n",
      "         2.6645e-15, 6.4393e-15, 4.4409e-15, 5.7732e-15, 3.3307e-16, 4.8850e-15,\n",
      "         7.9936e-15, 4.6629e-15, 8.8818e-15, 6.6613e-15, 4.8850e-15, 5.3291e-15,\n",
      "         2.6645e-15, 1.2434e-14, 1.0658e-14, 4.3576e-15, 5.8842e-15, 4.8850e-15,\n",
      "         3.9968e-15, 6.2172e-15, 6.2172e-15, 5.7732e-15, 7.1054e-15, 7.5495e-15,\n",
      "         4.8850e-15, 7.4385e-15, 7.5495e-15, 7.9936e-15, 8.8818e-15, 4.4409e-15,\n",
      "         7.5495e-15, 5.5511e-15, 5.7732e-15, 8.8818e-15, 3.1086e-15, 5.9952e-15,\n",
      "         7.5495e-15, 7.7854e-15, 4.9960e-15, 7.1054e-15, 7.5495e-15, 6.7724e-15,\n",
      "         7.9659e-15, 7.1054e-15, 5.7732e-15, 6.8834e-15, 6.2172e-15, 6.8834e-15,\n",
      "         6.2172e-15, 3.8858e-15, 1.0658e-14, 9.1038e-15, 5.3291e-15, 8.4377e-15,\n",
      "         8.8818e-15, 7.1054e-15, 7.1054e-15, 6.6613e-15, 6.2172e-15, 9.1038e-15,\n",
      "         7.1054e-15, 1.0658e-14, 7.9936e-15, 7.1054e-15, 1.0658e-14, 1.0658e-14,\n",
      "         1.1546e-14, 8.8818e-15, 7.1054e-15, 5.9952e-15, 1.1546e-14, 9.7700e-15,\n",
      "         5.3291e-15, 3.5527e-15, 6.2172e-15, 7.6605e-15, 8.8818e-15, 8.8818e-15,\n",
      "         9.7700e-15, 7.9936e-15, 1.0075e-14, 1.2434e-14, 7.1054e-15, 7.9936e-15,\n",
      "         7.9936e-15, 6.2172e-15, 8.4377e-15, 4.8850e-15, 7.1054e-15, 6.2172e-15,\n",
      "         9.7700e-15, 8.8818e-15, 7.3275e-15, 8.8818e-15, 8.8818e-15, 1.2434e-14,\n",
      "         6.6613e-15, 8.2157e-15, 8.8818e-15, 7.1054e-15, 7.1054e-15, 8.8818e-15,\n",
      "         7.1054e-15, 7.1054e-15, 5.3291e-15, 3.9968e-15, 1.0658e-14, 9.7700e-15,\n",
      "         7.1054e-15, 7.9936e-15, 7.5495e-15, 9.7700e-15, 6.2172e-15, 6.6613e-15,\n",
      "         7.2164e-15, 8.7708e-15, 7.9936e-15, 7.8826e-15, 7.1054e-15, 6.7724e-15,\n",
      "         9.1038e-15, 1.5987e-14, 7.1054e-15, 6.6613e-15, 1.1546e-14, 1.1546e-14,\n",
      "         1.4211e-14, 1.0658e-14, 7.9936e-15, 1.2434e-14, 8.2157e-15, 7.9936e-15,\n",
      "         9.3259e-15, 6.6613e-15, 1.0658e-14, 7.1054e-15, 1.0658e-14, 7.5495e-15,\n",
      "         1.0492e-14, 8.8818e-15, 7.9936e-15, 9.7700e-15, 9.7700e-15, 7.9936e-15,\n",
      "         8.8818e-15, 1.4211e-14, 7.1054e-15, 7.8826e-15, 1.0214e-14, 9.3259e-15,\n",
      "         7.5495e-15, 6.2172e-15, 6.5503e-15, 7.1054e-15, 1.5987e-14, 6.2172e-15,\n",
      "         8.4377e-15, 1.1546e-14, 9.7700e-15, 1.0658e-14, 7.1054e-15, 8.8818e-15,\n",
      "         7.1054e-15, 5.7176e-15, 1.2879e-14, 9.3259e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.0436e-14, 7.9936e-15, 1.2323e-14, 7.1054e-15, 7.9936e-15, 9.7700e-15,\n",
      "         8.3267e-15, 8.8818e-15, 1.0658e-14, 9.5479e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 68: layer3.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 68\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 68\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 68\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 68\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 68\n",
      "Max diff:\n",
      " tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-16, 6.9389e-17, 1.1102e-16, 2.2204e-15, 7.2164e-16, 4.4409e-16,\n",
      "         4.8572e-17, 5.2042e-17, 1.5543e-15, 5.5511e-16, 4.1633e-17, 4.1633e-17,\n",
      "         1.1102e-16, 1.3878e-16, 6.3838e-16, 9.9920e-16, 5.5511e-17, 1.2490e-16,\n",
      "         5.5511e-17, 1.9984e-15, 8.3267e-17, 3.9968e-15, 1.1102e-16, 1.3323e-15,\n",
      "         1.6653e-16, 4.1633e-17, 4.1633e-17, 8.8818e-16, 5.5511e-17, 2.3315e-15,\n",
      "         5.5511e-17, 1.1102e-15, 1.6653e-16, 1.1102e-15, 2.0262e-15, 6.1062e-16,\n",
      "         1.1102e-15, 2.0817e-17, 1.3323e-15, 8.3267e-17, 1.4710e-15, 4.8572e-17,\n",
      "         1.2004e-15, 5.5511e-17, 1.8319e-15, 1.6653e-16, 1.3878e-16, 1.1102e-16,\n",
      "         4.4409e-16, 1.7764e-15, 1.2490e-15, 8.3267e-17, 9.0206e-17, 4.8572e-17,\n",
      "         2.0539e-15, 1.6653e-16, 6.1062e-16, 1.6653e-16, 4.1633e-16, 3.3307e-16,\n",
      "         5.5511e-16, 4.4409e-16, 1.1102e-15, 4.5103e-17, 1.5543e-15, 1.3323e-15,\n",
      "         1.1935e-15, 1.3323e-15, 1.4433e-15, 2.4425e-15, 1.5543e-15, 5.5511e-16,\n",
      "         4.9960e-16, 4.9960e-16, 3.1086e-15, 1.3323e-15, 1.6653e-15, 9.4369e-16,\n",
      "         3.1225e-16, 1.5543e-15, 7.7716e-16, 1.0547e-15, 1.1102e-16, 3.6082e-16,\n",
      "         7.7716e-16, 6.9389e-16, 2.2204e-15, 2.2204e-15, 3.6082e-16, 6.6613e-16,\n",
      "         3.3307e-16, 4.4409e-15, 1.7764e-15, 1.7486e-15, 1.4155e-15, 6.8391e-16,\n",
      "         6.3838e-16, 1.9602e-16, 9.4369e-16, 1.2212e-15, 1.4433e-15, 1.1102e-15,\n",
      "         9.9920e-16, 1.1657e-15, 1.7764e-15, 1.4433e-15, 3.1086e-15, 6.6613e-16,\n",
      "         8.0491e-16, 9.4369e-16, 1.7764e-15, 1.5543e-15, 1.2490e-16, 4.4409e-16,\n",
      "         2.4425e-15, 2.3592e-15, 9.4369e-16, 1.2768e-15, 1.4433e-15, 1.7764e-15,\n",
      "         1.6931e-15, 3.1086e-15, 1.1102e-15, 2.3315e-15, 1.2212e-15, 4.1633e-16,\n",
      "         1.1102e-15, 8.3267e-16, 4.4409e-15, 2.6394e-15, 2.6645e-15, 3.7748e-15,\n",
      "         3.9968e-15, 2.6645e-15, 1.8041e-15, 3.1086e-15, 2.2204e-15, 5.1070e-15,\n",
      "         4.4409e-15, 5.3291e-15, 1.9984e-15, 8.8818e-16, 5.3291e-15, 2.8866e-15,\n",
      "         3.9968e-15, 2.6645e-15, 3.1086e-15, 1.4433e-15, 3.5527e-15, 1.7764e-15,\n",
      "         1.3323e-15, 8.8818e-16, 9.9920e-16, 2.2898e-15, 5.5511e-17, 4.2188e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.7192e-15, 3.5527e-15, 2.1094e-15, 1.2212e-15,\n",
      "         1.1102e-15, 2.2204e-15, 2.4425e-15, 6.6613e-16, 1.7764e-15, 1.7764e-15,\n",
      "         1.6792e-15, 1.7764e-15, 2.7756e-15, 3.7748e-15, 2.6645e-15, 8.8818e-15,\n",
      "         2.3315e-15, 5.5511e-15, 8.8818e-16, 3.5527e-15, 1.3323e-15, 2.6645e-15,\n",
      "         1.9984e-15, 2.2204e-15, 1.3323e-15, 1.5543e-15, 3.5527e-15, 3.5527e-15,\n",
      "         2.7756e-15, 8.8818e-16, 9.1593e-16, 4.4409e-15, 2.1094e-15, 3.1086e-15,\n",
      "         8.8818e-16, 2.0262e-15, 5.5511e-16, 2.2204e-15, 3.1086e-15, 3.7748e-15,\n",
      "         1.0825e-15, 6.6613e-15, 2.2204e-15, 1.4433e-15, 3.1086e-15, 2.8866e-15,\n",
      "         2.6645e-15, 1.9984e-15, 2.8866e-15, 2.6645e-15, 2.6645e-15, 8.8818e-16,\n",
      "         1.9984e-15, 1.4988e-15, 3.5527e-15, 2.2204e-15, 2.6645e-15, 2.4425e-15,\n",
      "         2.1094e-15, 2.8866e-15, 2.6645e-15, 2.8866e-15, 2.6645e-15, 1.9984e-15,\n",
      "         1.5543e-15, 1.3323e-15, 2.2204e-15, 2.3315e-15, 2.3315e-15, 2.2204e-15,\n",
      "         7.9971e-16, 1.9984e-15, 1.4710e-15, 1.7764e-15, 5.3291e-15, 9.9920e-16,\n",
      "         1.4433e-15, 2.8866e-15, 1.1657e-15, 4.4409e-15, 1.6098e-15, 2.6645e-15,\n",
      "         8.3267e-16, 1.2768e-15, 6.3283e-15, 8.8818e-16, 4.4409e-15, 3.1086e-15,\n",
      "         1.7070e-15, 1.2212e-15, 5.7732e-15, 1.5543e-15, 1.6653e-15, 9.9920e-16,\n",
      "         1.3323e-15, 3.1086e-15, 5.5511e-15, 2.2760e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 69: layer3.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 69\n",
      "Max diff:\n",
      " tensor([2.4869e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-16, 6.9389e-17, 1.1102e-16, 2.2204e-15, 7.2164e-16, 4.4409e-16,\n",
      "         4.8572e-17, 5.2042e-17, 1.5543e-15, 5.5511e-16, 4.1633e-17, 4.1633e-17,\n",
      "         1.1102e-16, 1.3878e-16, 6.3838e-16, 9.9920e-16, 5.5511e-17, 1.2490e-16,\n",
      "         5.5511e-17, 1.9984e-15, 8.3267e-17, 3.9968e-15, 1.1102e-16, 1.3323e-15,\n",
      "         1.6653e-16, 4.1633e-17, 4.1633e-17, 2.5535e-15, 5.5511e-17, 3.3307e-15,\n",
      "         5.5511e-17, 4.2188e-15, 1.6653e-16, 1.1102e-15, 2.0262e-15, 6.1062e-16,\n",
      "         1.3323e-15, 2.0817e-17, 1.3323e-15, 8.3267e-17, 1.4710e-15, 4.8572e-17,\n",
      "         1.4988e-15, 5.5511e-17, 3.1086e-15, 1.6653e-16, 1.3878e-16, 1.1102e-16,\n",
      "         4.4409e-16, 1.7764e-15, 1.4433e-15, 8.3267e-17, 9.0206e-17, 4.8572e-17,\n",
      "         2.0539e-15, 1.6653e-16, 6.1062e-16, 1.6653e-16, 2.3315e-15, 3.3307e-16,\n",
      "         2.2204e-15, 4.4409e-16, 1.1102e-15, 4.5103e-17, 4.4409e-15, 6.5503e-15,\n",
      "         6.2172e-15, 5.6621e-15, 1.8874e-15, 3.1086e-15, 1.0658e-14, 5.3291e-15,\n",
      "         2.5535e-15, 4.5380e-15, 3.1086e-15, 4.4409e-15, 7.5495e-15, 8.4377e-15,\n",
      "         3.1225e-16, 1.5543e-15, 7.5495e-15, 4.1633e-15, 1.1102e-16, 7.9936e-15,\n",
      "         5.3291e-15, 6.4393e-15, 5.7732e-15, 2.2204e-15, 8.8818e-15, 7.9936e-15,\n",
      "         3.3307e-16, 7.9936e-15, 7.1054e-15, 1.7486e-15, 1.4155e-15, 6.5503e-15,\n",
      "         5.5511e-15, 1.7764e-15, 9.4369e-16, 1.0658e-14, 1.4433e-15, 1.1102e-15,\n",
      "         5.7732e-15, 7.3275e-15, 1.7764e-15, 7.9936e-15, 3.1086e-15, 5.9952e-15,\n",
      "         3.1086e-15, 3.9968e-15, 4.6629e-15, 7.1054e-15, 1.2490e-16, 4.8850e-15,\n",
      "         2.4425e-15, 7.5495e-15, 4.4409e-15, 1.2768e-15, 6.2172e-15, 5.7454e-15,\n",
      "         7.3275e-15, 3.1086e-15, 7.6605e-15, 3.9968e-15, 2.2204e-15, 6.4393e-15,\n",
      "         1.1102e-15, 3.7748e-15, 4.4409e-15, 2.6394e-15, 2.6645e-15, 3.7748e-15,\n",
      "         3.9968e-15, 2.6645e-15, 1.0436e-14, 3.1086e-15, 2.2204e-15, 5.1070e-15,\n",
      "         4.4409e-15, 5.3291e-15, 1.9984e-15, 8.8818e-16, 5.3291e-15, 5.9952e-15,\n",
      "         3.9968e-15, 2.6645e-15, 3.1086e-15, 1.4433e-15, 3.5527e-15, 1.7764e-15,\n",
      "         8.8818e-15, 8.8818e-16, 9.9920e-16, 2.2898e-15, 5.5511e-17, 4.2188e-15,\n",
      "         2.6645e-15, 3.5527e-15, 3.7192e-15, 3.5527e-15, 2.1094e-15, 3.3307e-15,\n",
      "         3.5527e-15, 7.9936e-15, 3.3307e-15, 6.6613e-16, 1.7764e-15, 1.7764e-15,\n",
      "         2.4869e-14, 1.7764e-15, 2.7756e-15, 3.7748e-15, 2.6645e-15, 1.1546e-14,\n",
      "         2.3315e-15, 5.5511e-15, 8.8818e-16, 3.5527e-15, 6.2172e-15, 2.6645e-15,\n",
      "         1.9984e-15, 1.7764e-15, 1.3323e-15, 1.5543e-15, 3.5527e-15, 3.5527e-15,\n",
      "         2.7756e-15, 5.6621e-15, 1.5987e-14, 4.4409e-15, 2.1094e-15, 3.1086e-15,\n",
      "         9.8810e-15, 2.1316e-14, 7.5495e-15, 2.2204e-15, 3.1086e-15, 5.9952e-15,\n",
      "         8.2157e-15, 8.4377e-15, 8.8818e-15, 3.9968e-15, 7.1054e-15, 2.8866e-15,\n",
      "         1.1990e-14, 4.6629e-15, 7.1054e-15, 1.4211e-14, 5.7732e-15, 6.2172e-15,\n",
      "         5.7732e-15, 2.3093e-14, 1.0658e-14, 8.6597e-15, 2.6645e-15, 2.4425e-15,\n",
      "         4.4409e-15, 2.8866e-15, 3.1086e-15, 6.2172e-15, 5.5511e-15, 2.3093e-14,\n",
      "         6.1617e-15, 7.1054e-15, 2.2204e-15, 6.2172e-15, 1.0658e-14, 5.3291e-15,\n",
      "         1.4211e-14, 1.0658e-14, 6.8834e-15, 8.8818e-15, 2.1316e-14, 4.4409e-15,\n",
      "         7.1054e-15, 4.8850e-15, 6.1062e-15, 1.4211e-14, 5.7732e-15, 8.2157e-15,\n",
      "         8.3267e-16, 1.2768e-15, 7.9936e-15, 8.8818e-16, 4.4409e-15, 6.6613e-15,\n",
      "         6.2172e-15, 8.8818e-15, 5.7732e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15,\n",
      "         1.3323e-15, 6.2172e-15, 6.4393e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 70: layer3.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 70\n",
      "Max diff:\n",
      " tensor([2.4869e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 0.0000e+00, 1.9082e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6368e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.2212e-15, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5535e-15, 0.0000e+00, 3.2196e-15,\n",
      "         5.5511e-17, 3.7748e-15, 0.0000e+00, 8.8818e-16, 1.6792e-15, 0.0000e+00,\n",
      "         1.0547e-15, 0.0000e+00, 9.4369e-16, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         1.3323e-15, 0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.7716e-16, 1.4433e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0539e-15, 0.0000e+00, 1.6653e-16, 0.0000e+00, 2.3315e-15, 0.0000e+00,\n",
      "         2.2204e-15, 3.3307e-16, 0.0000e+00, 0.0000e+00, 4.4409e-15, 6.5503e-15,\n",
      "         6.2172e-15, 4.8850e-15, 1.6653e-15, 3.1086e-15, 1.0658e-14, 5.3291e-15,\n",
      "         2.5535e-15, 4.5380e-15, 9.7145e-17, 4.4409e-15, 7.5495e-15, 8.4377e-15,\n",
      "         2.2204e-16, 0.0000e+00, 7.5495e-15, 4.1633e-15, 0.0000e+00, 7.9936e-15,\n",
      "         5.3291e-15, 6.4393e-15, 5.7732e-15, 1.8041e-15, 8.8818e-15, 7.9936e-15,\n",
      "         0.0000e+00, 3.1086e-15, 7.1054e-15, 1.3323e-15, 8.8818e-16, 6.5503e-15,\n",
      "         5.5511e-15, 1.7764e-15, 8.8818e-16, 1.0658e-14, 5.8287e-16, 0.0000e+00,\n",
      "         5.7732e-15, 7.3275e-15, 1.3323e-15, 7.9936e-15, 2.8311e-15, 5.9952e-15,\n",
      "         3.1086e-15, 3.9968e-15, 4.6629e-15, 7.1054e-15, 0.0000e+00, 4.8850e-15,\n",
      "         2.4425e-15, 6.8279e-15, 4.4409e-15, 1.5959e-16, 6.2172e-15, 5.5511e-15,\n",
      "         7.3275e-15, 6.1062e-16, 4.3299e-15, 3.9968e-15, 2.2204e-15, 6.4393e-15,\n",
      "         3.6082e-16, 3.7748e-15, 0.0000e+00, 1.3323e-15, 1.1796e-15, 2.4425e-15,\n",
      "         1.1102e-15, 2.6368e-16, 1.0436e-14, 3.1086e-15, 0.0000e+00, 2.8866e-15,\n",
      "         4.4409e-15, 0.0000e+00, 1.7764e-15, 0.0000e+00, 0.0000e+00, 5.9952e-15,\n",
      "         2.3315e-15, 0.0000e+00, 4.2241e-16, 9.5757e-16, 3.5527e-15, 0.0000e+00,\n",
      "         8.8818e-15, 3.0531e-16, 7.0777e-16, 2.2898e-15, 0.0000e+00, 3.5527e-15,\n",
      "         0.0000e+00, 2.7200e-15, 2.4425e-15, 0.0000e+00, 1.6653e-15, 1.9984e-15,\n",
      "         3.5527e-15, 7.9936e-15, 3.3307e-15, 9.3675e-17, 0.0000e+00, 0.0000e+00,\n",
      "         2.4869e-14, 0.0000e+00, 2.7756e-15, 3.5527e-15, 1.3323e-15, 7.5495e-15,\n",
      "         2.2204e-15, 3.5527e-15, 0.0000e+00, 2.0539e-15, 6.2172e-15, 0.0000e+00,\n",
      "         1.9984e-15, 8.8818e-16, 8.8818e-16, 1.0894e-15, 0.0000e+00, 3.5527e-15,\n",
      "         2.6645e-15, 5.6621e-15, 1.5987e-14, 4.2188e-15, 1.4398e-16, 2.6645e-15,\n",
      "         9.8810e-15, 2.1316e-14, 7.5495e-15, 2.2204e-15, 1.6653e-15, 5.9952e-15,\n",
      "         8.2157e-15, 8.4377e-15, 8.8818e-15, 3.9968e-15, 6.4393e-15, 8.0491e-16,\n",
      "         1.1990e-14, 6.1062e-16, 7.1054e-15, 1.4211e-14, 5.7732e-15, 6.2172e-15,\n",
      "         5.7732e-15, 2.3093e-14, 1.0658e-14, 8.6597e-15, 2.6645e-15, 2.4425e-15,\n",
      "         4.4409e-15, 2.8866e-15, 3.1086e-15, 6.2172e-15, 5.5511e-15, 2.3093e-14,\n",
      "         4.9960e-15, 7.1054e-15, 2.2204e-15, 6.2172e-15, 1.0658e-14, 5.3291e-15,\n",
      "         1.4211e-14, 8.8818e-15, 6.8834e-15, 8.8818e-15, 2.1316e-14, 4.4409e-15,\n",
      "         7.1054e-15, 4.8850e-15, 6.1062e-15, 1.4211e-14, 5.7732e-15, 8.2157e-15,\n",
      "         8.3267e-16, 1.2768e-15, 7.9936e-15, 8.8818e-16, 2.2204e-15, 6.6613e-15,\n",
      "         6.2172e-15, 8.8818e-15, 2.2760e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15,\n",
      "         7.7716e-16, 6.2172e-15, 6.4393e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  3,   5,   9,  15,  19,  21,  27,  29,  30,  31,  33,  34,  36,  38,\n",
      "         40,  42,  44,  49,  50,  54,  56,  58,  60,  61,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  83,\n",
      "         84,  85,  86,  87,  88,  89,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129,\n",
      "        130, 131, 132, 133, 134, 135, 137, 138, 140, 143, 144, 146, 147, 148,\n",
      "        150, 151, 152, 153, 155, 157, 158, 160, 161, 162, 163, 164, 165, 168,\n",
      "        170, 171, 172, 173, 174, 175, 177, 178, 180, 181, 182, 183, 185, 186,\n",
      "        187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "        201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "        215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  3,   5,   9,  15,  19,  21,  27,  29,  30,  31,  33,  34,  36,  38,\n",
      "         40,  42,  44,  49,  50,  54,  56,  58,  60,  61,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  83,\n",
      "         84,  85,  86,  87,  88,  89,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129,\n",
      "        130, 131, 132, 133, 134, 135, 137, 138, 140, 143, 144, 146, 147, 148,\n",
      "        150, 151, 152, 153, 155, 157, 158, 160, 161, 162, 163, 164, 165, 168,\n",
      "        170, 171, 172, 173, 174, 175, 177, 178, 180, 181, 182, 183, 185, 186,\n",
      "        187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "        201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "        215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 195)\n",
      "passing Cout = tensor([101])  (len = 1)\n",
      "\n",
      "Executing module 71: layer3.2.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 71\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 71\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 71\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 71\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 71\n",
      "Max diff:\n",
      " tensor([2.1316e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 4.2633e-14, 2.4869e-14, 5.3291e-15, 1.3323e-15, 2.6645e-15,\n",
      "         2.2204e-15, 4.4409e-15, 2.2204e-15, 1.7764e-15, 3.1086e-15, 2.2204e-15,\n",
      "         3.5527e-15, 4.4409e-15, 3.5527e-15, 2.6645e-15, 5.3291e-15, 2.6645e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.6645e-15, 1.2434e-14, 2.6645e-15, 1.7764e-15,\n",
      "         3.5527e-15, 3.1086e-15, 1.7764e-15, 5.3291e-15, 2.2204e-15, 2.6645e-15,\n",
      "         3.1086e-15, 4.4409e-15, 5.3291e-15, 2.6645e-15, 3.5527e-15, 1.2434e-14,\n",
      "         2.6645e-15, 3.5527e-15, 2.4869e-14, 2.2204e-15, 4.4409e-15, 4.8850e-15,\n",
      "         1.0658e-14, 1.3323e-15, 6.2172e-15, 3.5527e-15, 3.1086e-15, 4.4409e-15,\n",
      "         8.8818e-15, 3.1086e-15, 7.1054e-15, 5.3291e-15, 1.7764e-15, 1.7764e-15,\n",
      "         2.2204e-15, 3.1086e-15, 2.4425e-15, 4.4409e-15, 1.3323e-15, 3.5527e-15,\n",
      "         2.2204e-15, 4.4409e-15, 1.7764e-15, 2.2204e-15, 1.7764e-14, 1.2434e-14,\n",
      "         7.1054e-14, 6.3949e-14, 1.1369e-13, 1.7764e-14, 3.5527e-14, 3.5527e-14,\n",
      "         7.1054e-14, 1.1369e-13, 4.9738e-14, 1.5987e-14, 2.8422e-14, 5.3291e-15,\n",
      "         2.4869e-14, 7.9936e-15, 5.6843e-14, 3.5527e-15, 8.8818e-15, 7.1054e-15,\n",
      "         5.6843e-14, 1.0658e-14, 2.1316e-14, 5.6843e-14, 2.6645e-15, 4.2633e-14,\n",
      "         1.4211e-14, 5.3291e-15, 6.2172e-15, 1.4211e-14, 2.1316e-14, 1.0658e-14,\n",
      "         6.2172e-15, 1.7764e-15, 1.0658e-14, 4.4409e-15, 1.5632e-13, 1.0658e-14,\n",
      "         1.0658e-14, 2.1316e-14, 1.0658e-14, 4.4409e-15, 1.1369e-13, 8.8818e-15,\n",
      "         4.2633e-14, 7.1054e-14, 3.1974e-14, 2.6645e-15, 9.9476e-14, 5.3291e-15,\n",
      "         1.1546e-14, 4.4409e-15, 3.5527e-15, 3.5527e-14, 4.2633e-14, 4.2633e-14,\n",
      "         7.1054e-14, 8.8818e-15, 5.6843e-14, 6.2172e-15, 9.9476e-14, 7.1054e-15,\n",
      "         7.1054e-15, 4.2633e-14, 7.1054e-14, 5.6843e-14, 1.5632e-13, 4.2633e-14,\n",
      "         4.2633e-14, 8.5265e-14, 6.2172e-15, 8.5265e-14, 7.1054e-14, 3.9080e-14,\n",
      "         1.4211e-13, 7.8160e-14, 4.2633e-14, 1.1369e-13, 7.1054e-14, 7.1054e-14,\n",
      "         1.4211e-13, 4.9738e-14, 4.9738e-14, 1.7764e-14, 3.5527e-14, 8.5265e-14,\n",
      "         7.1054e-14, 1.7053e-13, 2.1316e-14, 7.1054e-14, 8.5265e-14, 9.9476e-14,\n",
      "         9.9476e-14, 4.9738e-14, 5.6843e-14, 3.9080e-14, 7.1054e-14, 7.4607e-14,\n",
      "         1.2790e-13, 3.5527e-14, 1.4211e-13, 7.1054e-14, 2.4869e-14, 6.3949e-14,\n",
      "         1.4211e-13, 7.1054e-14, 5.6843e-14, 1.7053e-13, 2.4869e-14, 1.1369e-13,\n",
      "         9.9476e-14, 5.3291e-15, 1.4211e-13, 1.4211e-14, 7.1054e-14, 8.5265e-14,\n",
      "         1.4211e-13, 7.1054e-14, 8.5265e-14, 1.7764e-14, 1.5632e-13, 2.1316e-14,\n",
      "         7.1054e-14, 2.1316e-14, 8.5265e-14, 3.5527e-14, 4.2633e-14, 3.1974e-14,\n",
      "         7.1054e-14, 8.5265e-14, 1.4211e-13, 1.4211e-13, 2.8422e-14, 7.2831e-14,\n",
      "         8.5265e-14, 1.1369e-13, 7.8160e-14, 1.7053e-13, 9.9476e-14, 1.1369e-13,\n",
      "         1.7764e-14, 1.1369e-13, 4.9738e-14, 1.4211e-13, 8.5265e-14, 7.1054e-15,\n",
      "         1.4211e-13, 1.7053e-13, 5.6843e-14, 1.4211e-13, 7.1054e-14, 9.2371e-14,\n",
      "         6.3949e-14, 9.9476e-14, 7.1054e-14, 1.7053e-13, 8.1712e-14, 1.9895e-13,\n",
      "         1.9895e-13, 6.2172e-14, 9.9476e-14, 1.4211e-13, 2.8422e-14, 8.5265e-14,\n",
      "         9.9476e-14, 1.1369e-13, 1.1369e-13, 5.1514e-14, 1.7053e-13, 9.9476e-14,\n",
      "         1.1369e-13, 1.1369e-13, 6.3949e-14, 1.2790e-13, 7.1054e-14, 1.9895e-13,\n",
      "         7.8160e-14, 1.7053e-13, 7.8160e-14, 7.0166e-14, 2.1316e-13, 1.9895e-13,\n",
      "         8.5265e-14, 7.4607e-14, 8.5265e-14, 7.1054e-14, 1.2790e-13, 1.4211e-13,\n",
      "         5.6843e-14, 8.5265e-14, 1.2790e-13, 9.9476e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 72: layer3.2.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 72\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 72\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 72\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 72\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 72\n",
      "Max diff:\n",
      " tensor([1.1369e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-15, 1.2434e-14, 7.1054e-15, 1.7764e-15, 4.4409e-16, 7.7716e-16,\n",
      "         6.6613e-16, 1.5543e-15, 8.8818e-16, 5.5511e-16, 9.9920e-16, 5.5511e-16,\n",
      "         1.1102e-15, 1.3323e-15, 1.1102e-15, 8.8818e-16, 1.7764e-15, 7.7716e-16,\n",
      "         5.5511e-16, 8.8818e-16, 8.8818e-16, 3.5527e-15, 8.8818e-16, 5.5511e-16,\n",
      "         1.1102e-15, 9.9920e-16, 6.6613e-16, 1.5543e-15, 6.6613e-16, 8.8818e-16,\n",
      "         9.9920e-16, 1.3323e-15, 1.7764e-15, 8.8818e-16, 1.1102e-15, 3.1086e-15,\n",
      "         8.8818e-16, 1.3323e-15, 5.3291e-15, 6.6613e-16, 1.5543e-15, 1.5543e-15,\n",
      "         3.5527e-15, 4.4409e-16, 1.9984e-15, 1.1102e-15, 1.1102e-15, 1.5543e-15,\n",
      "         2.6645e-15, 9.9920e-16, 2.2204e-15, 1.7764e-15, 5.5511e-16, 5.5511e-16,\n",
      "         6.6613e-16, 9.9920e-16, 7.7716e-16, 1.3323e-15, 4.4409e-16, 1.1102e-15,\n",
      "         7.7716e-16, 1.3323e-15, 5.5511e-16, 6.6613e-16, 6.2172e-15, 4.4409e-15,\n",
      "         8.8818e-15, 7.9936e-15, 2.1316e-14, 5.3291e-15, 7.1054e-15, 8.8818e-15,\n",
      "         2.1316e-14, 2.8422e-14, 1.7764e-14, 6.2172e-15, 8.8818e-15, 1.7764e-15,\n",
      "         7.9936e-15, 2.6645e-15, 1.0658e-14, 1.3323e-15, 3.5527e-15, 2.2204e-15,\n",
      "         7.9936e-15, 3.9968e-15, 7.1054e-15, 1.2434e-14, 8.8818e-16, 1.2434e-14,\n",
      "         4.4409e-15, 1.7764e-15, 1.7764e-15, 4.4409e-15, 8.8818e-15, 3.5527e-15,\n",
      "         2.2204e-15, 6.6613e-16, 3.5527e-15, 1.3323e-15, 3.5527e-14, 3.5527e-15,\n",
      "         3.5527e-15, 7.1054e-15, 2.6645e-15, 1.5543e-15, 1.5987e-14, 3.1086e-15,\n",
      "         1.0658e-14, 1.4211e-14, 1.0658e-14, 8.8818e-16, 2.1316e-14, 1.7764e-15,\n",
      "         3.9968e-15, 1.5543e-15, 1.3323e-15, 7.1054e-15, 7.9936e-15, 1.4211e-14,\n",
      "         1.7764e-14, 3.1086e-15, 1.5987e-14, 2.2204e-15, 3.5527e-14, 2.2204e-15,\n",
      "         2.6645e-15, 1.5987e-14, 1.7764e-14, 1.4211e-14, 3.9080e-14, 1.5987e-14,\n",
      "         2.1316e-14, 2.8422e-14, 2.2204e-15, 3.5527e-14, 1.9540e-14, 1.4211e-14,\n",
      "         3.5527e-14, 1.5987e-14, 1.4211e-14, 2.1316e-14, 2.4869e-14, 2.1316e-14,\n",
      "         7.1054e-14, 1.9540e-14, 2.1316e-14, 8.8818e-15, 1.0658e-14, 2.4869e-14,\n",
      "         1.7764e-14, 3.5527e-14, 7.9936e-15, 1.7764e-14, 8.8818e-15, 1.4211e-14,\n",
      "         1.7764e-14, 1.2434e-14, 2.1316e-14, 1.7764e-14, 2.8422e-14, 1.3323e-14,\n",
      "         6.3949e-14, 4.4409e-15, 3.5527e-14, 2.8422e-14, 8.8818e-15, 1.2434e-14,\n",
      "         1.5987e-14, 1.5987e-14, 1.2434e-14, 7.1054e-14, 7.1054e-15, 3.9080e-14,\n",
      "         3.1974e-14, 1.7764e-15, 4.2633e-14, 5.3291e-15, 2.1316e-14, 3.1974e-14,\n",
      "         2.8422e-14, 2.8422e-14, 2.8422e-14, 4.4409e-15, 6.3949e-14, 7.9936e-15,\n",
      "         1.2434e-14, 7.9936e-15, 2.8422e-14, 1.5987e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.4211e-14, 1.7764e-14, 5.6843e-14, 4.6185e-14, 8.8818e-15, 9.7700e-15,\n",
      "         1.7764e-14, 4.6185e-14, 1.5099e-14, 4.2633e-14, 2.4869e-14, 3.1974e-14,\n",
      "         5.3291e-15, 3.5527e-14, 7.1054e-15, 4.2633e-14, 3.5527e-14, 2.2204e-15,\n",
      "         3.5527e-14, 5.6843e-14, 9.7700e-15, 2.4869e-14, 1.0658e-14, 1.5987e-14,\n",
      "         1.4211e-14, 1.1102e-14, 1.9540e-14, 2.8422e-14, 7.1054e-15, 6.3949e-14,\n",
      "         5.6843e-14, 9.5479e-15, 1.9540e-14, 4.9738e-14, 8.8818e-15, 3.5527e-14,\n",
      "         1.5987e-14, 2.3093e-14, 3.5527e-14, 6.0507e-15, 3.5527e-14, 4.2633e-14,\n",
      "         3.1974e-14, 1.7764e-14, 1.2434e-14, 2.4869e-14, 1.4211e-14, 1.1369e-13,\n",
      "         1.1546e-14, 7.1054e-14, 1.9540e-14, 7.9103e-15, 4.0856e-14, 3.5527e-14,\n",
      "         8.8818e-15, 1.1102e-14, 2.1316e-14, 7.3275e-15, 3.9080e-14, 3.1974e-14,\n",
      "         6.6613e-15, 2.1316e-14, 2.1316e-14, 3.1974e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 73: layer3.2.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 73\n",
      "Max diff:\n",
      " tensor([1.9540e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6507e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1546e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5495e-15,\n",
      "         0.0000e+00, 2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6058e-15,\n",
      "         0.0000e+00, 1.0658e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9540e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-15, 0.0000e+00, 4.5797e-16, 0.0000e+00, 3.1919e-15,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.1054e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.3291e-15, 0.0000e+00, 5.2180e-15, 0.0000e+00, 0.0000e+00, 1.0214e-14,\n",
      "         0.0000e+00, 2.9976e-15, 1.0658e-14, 0.0000e+00, 2.5535e-15, 0.0000e+00,\n",
      "         0.0000e+00, 2.6645e-15, 5.1070e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0507e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.8818e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.1086e-15, 0.0000e+00, 5.1070e-15, 5.7732e-15, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-15, 4.9960e-15, 0.0000e+00, 7.3275e-15, 2.9976e-15, 9.5236e-16,\n",
      "         6.2172e-15, 8.8818e-16, 5.7732e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 71,  84, 139, 155, 161, 163, 167, 169, 184, 193, 195, 197, 200, 206,\n",
      "        210, 212, 215, 217, 218, 220, 223, 224, 231, 236, 240, 242, 243, 246,\n",
      "        247, 249, 250, 251, 252, 253, 254])\n",
      "\n",
      "failing Cout = tensor([ 71,  84, 139, 155, 161, 163, 167, 169, 184, 193, 195, 197, 200, 206,\n",
      "        210, 212, 215, 217, 218, 220, 223, 224, 231, 236, 240, 242, 243, 246,\n",
      "        247, 249, 250, 251, 252, 253, 254])  (len = 35)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 74: layer3.2.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 74\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 74\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 3,  4,  7,  9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 28, 31, 32, 33,\n",
      "        35, 37, 39, 40, 41, 42, 45, 46, 50, 53, 54, 55, 57, 60, 61, 62]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 145, 148,\n",
      "        149, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165,\n",
      "        166, 167, 168, 171, 172, 173, 174, 175, 177, 179, 180, 182, 184, 185,\n",
      "        186, 187, 188, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 196, 197, 199, 200, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 219, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        244, 245, 246, 248, 249, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 74\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 20,\n",
      "        21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39,\n",
      "        40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 55, 56, 57, 58, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 74\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 74\n",
      "Max diff:\n",
      " tensor([1.7986e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.1070e-15, 7.1054e-15, 5.7732e-15, 1.0658e-14, 6.2172e-15, 3.5527e-15,\n",
      "         1.9429e-16, 6.0021e-16, 3.5527e-15, 7.9936e-15, 3.3307e-16, 4.1078e-15,\n",
      "         1.1102e-16, 1.9429e-16, 5.3291e-15, 4.4409e-15, 2.7756e-16, 1.6653e-16,\n",
      "         1.3878e-16, 7.1054e-15, 1.8041e-16, 7.1054e-15, 3.5805e-15, 5.3291e-15,\n",
      "         2.0817e-16, 6.2172e-15, 1.3878e-16, 1.5543e-15, 2.2204e-16, 2.8866e-15,\n",
      "         7.7716e-16, 4.9405e-15, 3.1086e-15, 5.9952e-15, 4.4409e-15, 4.4409e-15,\n",
      "         3.9968e-15, 6.0715e-18, 5.3291e-15, 3.3307e-16, 1.1990e-14, 1.3878e-16,\n",
      "         4.7740e-15, 2.7756e-16, 3.1086e-15, 8.8818e-15, 1.6653e-16, 2.2204e-16,\n",
      "         1.9082e-15, 5.3291e-15, 1.3323e-14, 2.7756e-16, 4.6629e-15, 1.6653e-16,\n",
      "         1.4988e-15, 3.9968e-15, 2.2204e-15, 3.9968e-15, 5.7732e-15, 4.4409e-15,\n",
      "         3.3307e-15, 2.4425e-15, 5.7732e-15, 3.3307e-16, 6.2172e-15, 4.9960e-15,\n",
      "         4.4409e-15, 7.9936e-15, 5.9397e-15, 5.3291e-15, 4.3299e-15, 5.3291e-15,\n",
      "         5.7732e-15, 4.4409e-15, 7.5495e-15, 4.8850e-15, 9.8810e-15, 4.6074e-15,\n",
      "         3.8580e-15, 4.4409e-15, 6.6613e-15, 6.2172e-15, 3.1086e-15, 4.2188e-15,\n",
      "         7.9936e-15, 8.5904e-15, 5.7732e-15, 8.8818e-15, 5.3291e-15, 4.4409e-15,\n",
      "         8.4377e-15, 6.8834e-15, 6.6613e-15, 6.2172e-15, 7.6605e-15, 8.8818e-15,\n",
      "         7.9936e-15, 6.2172e-15, 1.4211e-14, 4.6907e-15, 4.4409e-15, 5.3291e-15,\n",
      "         7.1054e-15, 7.5495e-15, 5.7732e-15, 8.8818e-15, 6.6613e-15, 3.7192e-15,\n",
      "         9.6589e-15, 6.6613e-15, 5.3291e-15, 4.6629e-15, 6.2172e-15, 7.1887e-15,\n",
      "         7.9936e-15, 2.6645e-15, 6.6613e-15, 6.5503e-15, 2.8588e-15, 3.9968e-15,\n",
      "         8.0491e-15, 4.8850e-15, 5.3291e-15, 9.7700e-15, 4.5519e-15, 6.8834e-15,\n",
      "         7.5495e-15, 3.9968e-15, 1.1546e-14, 9.3259e-15, 1.0658e-14, 1.5987e-14,\n",
      "         1.3323e-14, 1.3323e-14, 8.8818e-15, 1.2434e-14, 1.0658e-14, 1.3323e-14,\n",
      "         1.7764e-14, 8.8818e-15, 1.0658e-14, 7.1054e-15, 9.7700e-15, 1.1546e-14,\n",
      "         1.1990e-14, 1.0658e-14, 6.8834e-15, 1.0658e-14, 1.7764e-14, 1.0658e-14,\n",
      "         1.4211e-14, 1.2434e-14, 1.0658e-14, 1.0658e-14, 8.8818e-15, 1.6875e-14,\n",
      "         1.1546e-14, 7.1054e-15, 7.9936e-15, 7.1054e-15, 1.1102e-14, 1.1546e-14,\n",
      "         6.2172e-15, 1.4211e-14, 1.2434e-14, 1.0880e-14, 1.1102e-14, 7.1054e-15,\n",
      "         1.2434e-14, 8.4377e-15, 8.8818e-15, 8.9095e-15, 1.0214e-14, 8.8818e-15,\n",
      "         1.3101e-14, 1.1546e-14, 6.2172e-15, 4.4409e-15, 1.3323e-14, 7.9936e-15,\n",
      "         8.8818e-15, 8.8818e-15, 8.8818e-15, 1.0214e-14, 1.4211e-14, 9.3259e-15,\n",
      "         1.0436e-14, 1.7986e-14, 8.8818e-15, 1.1546e-14, 1.6875e-14, 8.8818e-15,\n",
      "         9.5479e-15, 1.0658e-14, 7.1054e-15, 6.4809e-15, 8.8818e-15, 1.7764e-14,\n",
      "         9.7700e-15, 8.8818e-15, 8.8818e-15, 1.1546e-14, 4.5519e-15, 9.7700e-15,\n",
      "         6.4393e-15, 1.6875e-14, 7.1054e-15, 8.8818e-15, 7.9936e-15, 7.2997e-15,\n",
      "         5.9952e-15, 7.9936e-15, 9.7700e-15, 1.0214e-14, 1.1546e-14, 7.9936e-15,\n",
      "         1.2434e-14, 1.0658e-14, 5.3291e-15, 8.8818e-15, 8.8818e-15, 1.4211e-14,\n",
      "         6.4393e-15, 7.1054e-15, 7.1054e-15, 8.8818e-15, 1.2434e-14, 6.6613e-15,\n",
      "         9.7700e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 7.9936e-15, 1.0658e-14,\n",
      "         6.6613e-15, 7.7716e-15, 7.0499e-15, 7.1054e-15, 7.9936e-15, 8.8818e-15,\n",
      "         7.1054e-15, 7.9936e-15, 7.1054e-15, 8.8818e-15, 6.2172e-15, 6.2172e-15,\n",
      "         1.0658e-14, 6.2172e-15, 7.7161e-15, 8.8818e-15, 1.0658e-14, 5.5511e-15,\n",
      "         6.2172e-15, 9.7700e-15, 7.1054e-15, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 75: layer3.2.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 75\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 75\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 75\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 75\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 75\n",
      "Max diff:\n",
      " tensor([9.7700e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.7716e-16, 4.4409e-16, 5.5511e-16, 3.8858e-15, 9.4369e-16, 8.2573e-16,\n",
      "         6.9389e-17, 1.5959e-16, 6.1062e-16, 3.5527e-15, 1.1102e-16, 6.6613e-16,\n",
      "         4.1633e-17, 6.9389e-17, 1.9984e-15, 8.8818e-16, 9.7145e-17, 5.5511e-17,\n",
      "         4.8572e-17, 1.9984e-15, 6.2450e-17, 3.5527e-15, 1.0547e-15, 2.5535e-15,\n",
      "         6.9389e-17, 2.2204e-15, 4.5103e-17, 2.4980e-16, 8.3267e-17, 8.8818e-16,\n",
      "         2.2204e-16, 9.9920e-16, 5.5511e-16, 1.8041e-15, 5.5511e-16, 4.4409e-16,\n",
      "         1.9984e-15, 1.7347e-18, 1.1102e-15, 1.1102e-16, 3.4417e-15, 4.8572e-17,\n",
      "         2.4425e-15, 1.1102e-16, 1.1102e-15, 3.1086e-15, 5.5511e-17, 8.3267e-17,\n",
      "         3.6082e-16, 2.6645e-15, 4.4409e-16, 9.7145e-17, 1.4988e-15, 6.2450e-17,\n",
      "         3.8858e-16, 1.5543e-15, 2.9143e-16, 8.8818e-16, 1.3323e-15, 1.3531e-15,\n",
      "         1.4433e-15, 4.4409e-16, 1.6653e-15, 1.1102e-16, 7.2164e-16, 1.4988e-15,\n",
      "         4.9960e-16, 1.5266e-15, 1.3878e-15, 1.0547e-15, 8.3267e-16, 1.1102e-15,\n",
      "         1.3323e-15, 1.1102e-15, 3.1086e-15, 4.9960e-16, 9.7838e-16, 8.8818e-16,\n",
      "         1.1102e-16, 1.7764e-15, 8.8818e-16, 9.9920e-16, 7.4940e-16, 3.5041e-16,\n",
      "         3.2196e-15, 5.9674e-16, 1.3323e-15, 2.6645e-15, 9.4542e-17, 1.3323e-15,\n",
      "         2.2204e-15, 3.1086e-15, 8.8818e-16, 8.3267e-17, 1.9498e-15, 1.8874e-15,\n",
      "         1.5439e-16, 2.2204e-15, 3.5527e-15, 1.0859e-15, 3.3307e-16, 6.6613e-16,\n",
      "         1.7764e-15, 2.2204e-15, 7.7716e-16, 1.2212e-15, 1.2212e-15, 3.0531e-16,\n",
      "         1.1102e-15, 7.7716e-16, 9.9920e-16, 4.9960e-16, 4.4409e-16, 1.3878e-16,\n",
      "         2.2204e-15, 4.4409e-16, 7.7716e-16, 6.9389e-16, 5.2736e-16, 7.2164e-16,\n",
      "         1.7208e-15, 8.8818e-16, 9.9920e-16, 3.3307e-15, 5.5511e-16, 2.8866e-15,\n",
      "         2.0539e-15, 1.5266e-16, 4.4409e-15, 3.8303e-15, 4.4409e-15, 8.8818e-15,\n",
      "         5.7732e-15, 3.1086e-15, 3.8858e-15, 6.2172e-15, 3.9968e-15, 7.5495e-15,\n",
      "         9.7700e-15, 2.2204e-15, 3.1086e-15, 4.4409e-16, 5.3291e-15, 5.3291e-15,\n",
      "         6.8834e-15, 5.3291e-15, 4.7740e-15, 2.2204e-15, 8.4377e-15, 3.5527e-15,\n",
      "         4.2188e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 4.4409e-15, 8.1046e-15,\n",
      "         4.6629e-15, 2.8866e-15, 1.5543e-15, 2.7756e-16, 5.9952e-15, 1.9984e-15,\n",
      "         8.8818e-16, 8.8818e-15, 2.8866e-15, 2.7756e-15, 7.1054e-15, 1.5543e-15,\n",
      "         4.6629e-15, 2.6645e-15, 2.6645e-15, 5.8564e-15, 4.2188e-15, 3.9968e-15,\n",
      "         5.7732e-15, 7.9936e-15, 2.2204e-15, 6.6613e-16, 1.3878e-15, 1.3323e-15,\n",
      "         3.1086e-15, 3.6637e-15, 1.7764e-15, 5.7732e-15, 1.3323e-15, 2.8866e-15,\n",
      "         6.2728e-15, 3.3862e-15, 2.6645e-15, 5.3291e-15, 6.6613e-15, 1.9984e-15,\n",
      "         9.1593e-16, 2.2204e-15, 6.1062e-16, 1.2906e-15, 1.3323e-15, 7.9936e-15,\n",
      "         2.1094e-15, 2.4425e-15, 1.3184e-15, 2.4425e-15, 9.1593e-16, 1.7764e-15,\n",
      "         1.2212e-15, 4.8850e-15, 6.6613e-16, 1.3323e-15, 1.9984e-15, 6.8001e-16,\n",
      "         1.2768e-15, 3.9968e-15, 2.1094e-15, 2.7756e-15, 3.5527e-15, 1.7764e-15,\n",
      "         1.5543e-15, 2.4425e-15, 1.5543e-15, 9.9920e-16, 1.4988e-15, 7.9936e-15,\n",
      "         8.6042e-16, 5.5511e-16, 1.5543e-15, 2.6645e-15, 2.4425e-15, 1.3323e-15,\n",
      "         9.9920e-16, 7.7716e-16, 1.9984e-15, 1.7764e-15, 1.3323e-15, 2.8866e-15,\n",
      "         1.1102e-15, 1.5543e-15, 7.3205e-16, 1.3323e-15, 8.0491e-16, 1.5543e-15,\n",
      "         4.9960e-16, 1.5543e-15, 2.2204e-15, 8.8818e-16, 1.9984e-15, 1.1102e-15,\n",
      "         2.2204e-15, 6.6613e-16, 3.1364e-15, 1.5543e-15, 1.7764e-15, 1.1102e-15,\n",
      "         7.7716e-16, 3.7748e-15, 1.7764e-15, 1.7764e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 76: layer3.2.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 76\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.7716e-16, 4.4409e-16, 5.5511e-16, 3.8858e-15, 9.4369e-16, 8.2573e-16,\n",
      "         6.9389e-17, 1.5959e-16, 6.1062e-16, 3.3307e-15, 1.1102e-16, 6.6613e-16,\n",
      "         4.1633e-17, 6.9389e-17, 1.9984e-15, 8.8818e-16, 9.7145e-17, 5.5511e-17,\n",
      "         4.8572e-17, 1.9984e-15, 6.2450e-17, 3.5527e-15, 1.0547e-15, 2.5535e-15,\n",
      "         6.9389e-17, 2.2204e-15, 4.5103e-17, 2.5535e-15, 8.3267e-17, 3.2196e-15,\n",
      "         2.6368e-16, 4.0523e-15, 5.5511e-16, 2.1094e-15, 1.7764e-15, 4.4409e-16,\n",
      "         1.9984e-15, 1.7347e-18, 1.1102e-15, 1.1102e-16, 3.4417e-15, 4.8572e-17,\n",
      "         2.4425e-15, 1.1102e-16, 3.5527e-15, 3.1086e-15, 5.5511e-17, 8.3267e-17,\n",
      "         3.6082e-16, 2.6645e-15, 1.4988e-15, 9.7145e-17, 1.4988e-15, 6.2450e-17,\n",
      "         2.0539e-15, 1.5543e-15, 2.9143e-16, 8.8818e-16, 1.7764e-15, 1.3531e-15,\n",
      "         2.8866e-15, 4.4409e-16, 1.6653e-15, 1.1102e-16, 4.4409e-15, 6.6613e-15,\n",
      "         6.3699e-15, 5.3291e-15, 1.8596e-15, 3.1086e-15, 1.2434e-14, 5.6621e-15,\n",
      "         2.7062e-15, 4.4409e-15, 3.1086e-15, 4.4409e-15, 7.5495e-15, 8.8818e-15,\n",
      "         1.9429e-16, 1.7764e-15, 7.4385e-15, 4.3854e-15, 7.4940e-16, 7.9936e-15,\n",
      "         8.4377e-15, 6.4393e-15, 5.7732e-15, 2.6645e-15, 8.8818e-15, 7.9936e-15,\n",
      "         2.2204e-15, 3.1086e-15, 7.5495e-15, 1.2768e-15, 1.9498e-15, 6.8834e-15,\n",
      "         5.5511e-15, 2.2204e-15, 3.5527e-15, 1.1546e-14, 6.6613e-16, 6.6613e-16,\n",
      "         5.3291e-15, 8.7708e-15, 1.0547e-15, 8.8818e-15, 2.5535e-15, 5.9952e-15,\n",
      "         3.5527e-15, 3.5527e-15, 4.6629e-15, 6.6613e-15, 4.4409e-16, 4.8850e-15,\n",
      "         2.9976e-15, 6.6613e-15, 4.4409e-15, 6.9389e-16, 5.9952e-15, 5.5511e-15,\n",
      "         6.7724e-15, 8.8818e-16, 4.4409e-15, 5.3291e-15, 2.6645e-15, 6.6613e-15,\n",
      "         2.0539e-15, 3.7748e-15, 4.4409e-15, 3.8303e-15, 4.4409e-15, 9.3259e-15,\n",
      "         5.7732e-15, 3.1086e-15, 1.0270e-14, 7.5495e-15, 3.9968e-15, 9.3259e-15,\n",
      "         1.1102e-14, 2.2204e-15, 3.1086e-15, 4.4409e-16, 5.3291e-15, 9.9920e-15,\n",
      "         7.5495e-15, 5.3291e-15, 4.7740e-15, 2.2204e-15, 1.2434e-14, 3.5527e-15,\n",
      "         8.8818e-15, 3.5527e-15, 3.5527e-15, 5.3291e-15, 4.4409e-15, 9.3259e-15,\n",
      "         4.6629e-15, 4.8850e-15, 2.8866e-15, 2.7756e-16, 5.9952e-15, 1.9984e-15,\n",
      "         3.5527e-15, 8.8818e-15, 3.9968e-15, 2.7756e-15, 7.1054e-15, 1.5543e-15,\n",
      "         2.8422e-14, 2.6645e-15, 4.4409e-15, 5.7732e-15, 4.2188e-15, 9.7700e-15,\n",
      "         5.7732e-15, 8.8818e-15, 2.2204e-15, 2.2760e-15, 6.3283e-15, 1.3323e-15,\n",
      "         3.1086e-15, 3.6637e-15, 1.7764e-15, 5.7732e-15, 1.3323e-15, 6.2172e-15,\n",
      "         7.9103e-15, 6.1062e-15, 1.5987e-14, 6.8834e-15, 6.6613e-15, 3.1086e-15,\n",
      "         9.8394e-15, 2.1316e-14, 7.5495e-15, 2.6645e-15, 1.5543e-15, 9.7700e-15,\n",
      "         7.9936e-15, 7.5495e-15, 8.8818e-15, 4.4409e-15, 5.7732e-15, 1.7764e-15,\n",
      "         1.1213e-14, 4.8850e-15, 7.3275e-15, 1.5987e-14, 7.1054e-15, 6.2172e-15,\n",
      "         6.4393e-15, 2.4869e-14, 1.0658e-14, 8.5487e-15, 3.7748e-15, 3.5527e-15,\n",
      "         4.6629e-15, 3.1086e-15, 3.3307e-15, 6.6613e-15, 6.2172e-15, 3.1974e-14,\n",
      "         4.6629e-15, 7.1054e-15, 2.4425e-15, 7.1054e-15, 1.0658e-14, 6.2172e-15,\n",
      "         1.4211e-14, 9.3259e-15, 7.5495e-15, 8.8818e-15, 2.1316e-14, 3.5527e-15,\n",
      "         7.1054e-15, 5.4401e-15, 5.7732e-15, 1.4211e-14, 6.2172e-15, 7.3275e-15,\n",
      "         9.9920e-16, 1.5543e-15, 7.9936e-15, 1.5543e-15, 3.1086e-15, 7.5495e-15,\n",
      "         7.1054e-15, 8.8818e-15, 3.1364e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15,\n",
      "         7.7716e-16, 4.8850e-15, 5.9952e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 77: layer3.2.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 77\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8858e-15, 4.8572e-16, 8.2573e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.5797e-16, 1.6098e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9984e-15, 6.1062e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9984e-15, 0.0000e+00, 7.2164e-16, 4.9960e-16, 2.5535e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5535e-15, 0.0000e+00, 3.2196e-15,\n",
      "         2.2898e-16, 4.0523e-15, 0.0000e+00, 2.1094e-15, 1.4433e-15, 0.0000e+00,\n",
      "         1.9984e-15, 0.0000e+00, 6.6613e-16, 0.0000e+00, 3.4417e-15, 0.0000e+00,\n",
      "         2.4425e-15, 0.0000e+00, 3.5527e-15, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0547e-15, 0.0000e+00, 2.4980e-16, 0.0000e+00,\n",
      "         1.1102e-15, 0.0000e+00, 2.9143e-16, 1.2490e-16, 1.7764e-15, 1.3531e-15,\n",
      "         2.8866e-15, 3.0531e-16, 0.0000e+00, 0.0000e+00, 4.4409e-15, 6.6613e-15,\n",
      "         6.2172e-15, 5.3291e-15, 1.6653e-15, 3.1086e-15, 1.2434e-14, 5.6621e-15,\n",
      "         2.7062e-15, 4.4409e-15, 0.0000e+00, 4.4409e-15, 7.5495e-15, 8.8818e-15,\n",
      "         0.0000e+00, 0.0000e+00, 7.4385e-15, 4.3854e-15, 6.6613e-16, 7.9936e-15,\n",
      "         8.4377e-15, 6.4393e-15, 5.7732e-15, 1.2490e-16, 8.8818e-15, 7.9936e-15,\n",
      "         9.4369e-16, 3.1086e-15, 7.5495e-15, 1.2768e-15, 1.9498e-15, 6.8834e-15,\n",
      "         5.5511e-15, 1.7764e-15, 0.0000e+00, 1.1546e-14, 6.6613e-16, 6.6613e-16,\n",
      "         5.3291e-15, 8.7708e-15, 2.6368e-16, 8.8818e-15, 1.2212e-15, 5.9952e-15,\n",
      "         3.5527e-15, 3.5527e-15, 4.6629e-15, 6.6613e-15, 3.0531e-16, 4.8850e-15,\n",
      "         2.7756e-15, 6.6613e-15, 4.4409e-15, 3.3307e-16, 5.9952e-15, 5.5511e-15,\n",
      "         6.7724e-15, 6.1062e-16, 4.4409e-15, 5.3291e-15, 2.6645e-15, 6.6613e-15,\n",
      "         3.3307e-16, 3.7748e-15, 0.0000e+00, 3.8303e-15, 9.9920e-16, 1.5543e-15,\n",
      "         4.2744e-15, 0.0000e+00, 1.0270e-14, 2.2204e-15, 2.3315e-15, 3.9968e-15,\n",
      "         1.1102e-14, 0.0000e+00, 1.8319e-15, 0.0000e+00, 0.0000e+00, 9.9920e-15,\n",
      "         7.5495e-15, 0.0000e+00, 4.7740e-15, 0.0000e+00, 1.2434e-14, 3.5527e-15,\n",
      "         8.8818e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6637e-15, 9.3259e-15,\n",
      "         2.9421e-15, 4.8850e-15, 2.8866e-15, 0.0000e+00, 4.3299e-15, 1.8874e-15,\n",
      "         3.5527e-15, 0.0000e+00, 1.5543e-15, 1.9429e-15, 7.1054e-15, 1.1657e-15,\n",
      "         2.8422e-14, 7.7716e-16, 3.4417e-15, 5.7732e-15, 1.4433e-15, 6.6613e-15,\n",
      "         5.6621e-15, 6.9944e-15, 0.0000e+00, 2.2204e-16, 5.7732e-15, 1.1102e-16,\n",
      "         2.8866e-15, 6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2172e-15,\n",
      "         5.1070e-15, 3.6082e-15, 1.5987e-14, 6.8834e-15, 0.0000e+00, 3.1086e-15,\n",
      "         9.8394e-15, 2.1316e-14, 7.5495e-15, 2.6645e-15, 8.8818e-16, 7.1054e-15,\n",
      "         7.9936e-15, 7.5495e-15, 8.8818e-15, 4.4409e-15, 5.7732e-15, 0.0000e+00,\n",
      "         9.7700e-15, 4.8850e-15, 7.3275e-15, 1.5987e-14, 6.4393e-15, 6.2172e-15,\n",
      "         6.4393e-15, 2.4869e-14, 1.0658e-14, 8.5487e-15, 1.7764e-15, 2.4425e-15,\n",
      "         4.6629e-15, 3.1086e-15, 3.3307e-15, 6.6613e-15, 6.2172e-15, 3.1974e-14,\n",
      "         4.6629e-15, 7.1054e-15, 2.4425e-15, 7.1054e-15, 1.0658e-14, 6.2172e-15,\n",
      "         1.4211e-14, 9.3259e-15, 7.5495e-15, 8.8818e-15, 2.1316e-14, 3.2196e-15,\n",
      "         7.1054e-15, 4.8850e-15, 5.7732e-15, 1.4211e-14, 6.2172e-15, 7.3275e-15,\n",
      "         9.9920e-16, 7.7716e-16, 5.9952e-15, 1.5543e-15, 2.6090e-15, 7.5495e-15,\n",
      "         7.1054e-15, 8.8818e-15, 1.1102e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15,\n",
      "         7.7716e-16, 4.8850e-15, 5.9952e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  3,   4,   5,   8,   9,  14,  15,  19,  21,  22,  23,  27,  29,  30,\n",
      "         31,  33,  34,  36,  38,  40,  42,  44,  45,  50,  52,  54,  56,  57,\n",
      "         58,  59,  60,  61,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         75,  76,  77,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 135,\n",
      "        136, 137, 138, 140, 143, 144, 146, 148, 149, 150, 154, 155, 156, 157,\n",
      "        158, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "        174, 175, 177, 178, 179, 180, 181, 185, 186, 187, 188, 189, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  3,   4,   5,   8,   9,  14,  15,  19,  21,  22,  23,  27,  29,  30,\n",
      "         31,  33,  34,  36,  38,  40,  42,  44,  45,  50,  52,  54,  56,  57,\n",
      "         58,  59,  60,  61,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         75,  76,  77,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 135,\n",
      "        136, 137, 138, 140, 143, 144, 146, 148, 149, 150, 154, 155, 156, 157,\n",
      "        158, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "        174, 175, 177, 178, 179, 180, 181, 185, 186, 187, 188, 189, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255])  (len = 202)\n",
      "passing Cout = tensor([176])  (len = 1)\n",
      "\n",
      "Executing module 78: layer3.3.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 78\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 78\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 78\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 78\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 78\n",
      "Max diff:\n",
      " tensor([2.2737e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-14, 2.6645e-15, 3.5527e-15, 3.1086e-15, 3.5527e-15, 4.4409e-15,\n",
      "         6.2172e-15, 3.1086e-15, 3.5527e-15, 3.5527e-15, 4.4409e-15, 3.1086e-15,\n",
      "         5.3291e-15, 2.2204e-15, 5.3291e-15, 3.1086e-15, 5.3291e-15, 4.4409e-15,\n",
      "         3.5527e-15, 3.1086e-15, 2.6645e-15, 4.8850e-15, 4.4409e-15, 2.2204e-15,\n",
      "         1.4211e-14, 3.5527e-15, 2.6645e-15, 1.7764e-15, 5.7732e-15, 2.6645e-15,\n",
      "         2.2204e-15, 4.8850e-15, 2.6645e-15, 2.2204e-15, 3.1086e-15, 3.1086e-15,\n",
      "         3.1086e-15, 3.1086e-15, 7.1054e-15, 3.9968e-15, 2.6645e-15, 1.3323e-15,\n",
      "         3.5527e-15, 2.8422e-14, 2.6645e-15, 4.4409e-15, 1.9984e-15, 2.2204e-15,\n",
      "         2.4869e-14, 2.6645e-15, 2.6645e-15, 2.1316e-14, 2.6645e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 3.9968e-15, 6.2172e-15, 3.5527e-15,\n",
      "         4.4409e-15, 5.3291e-15, 8.8818e-15, 7.1054e-15, 5.3291e-15, 7.1054e-14,\n",
      "         1.0658e-14, 5.6843e-14, 4.2633e-14, 7.1054e-15, 4.9738e-14, 2.4869e-14,\n",
      "         7.1054e-15, 2.4869e-14, 3.5527e-14, 8.8818e-15, 8.5265e-14, 6.2172e-15,\n",
      "         4.9738e-14, 6.2172e-15, 1.2434e-14, 8.8818e-15, 4.4409e-15, 6.3949e-14,\n",
      "         4.9738e-14, 2.1316e-14, 4.9738e-14, 2.8422e-14, 4.2633e-14, 6.3949e-14,\n",
      "         6.2172e-15, 3.5527e-14, 1.7764e-14, 1.4211e-14, 1.2790e-13, 7.1054e-15,\n",
      "         1.5987e-14, 5.6843e-14, 3.5527e-14, 4.6185e-14, 7.8160e-14, 1.2790e-13,\n",
      "         2.8422e-14, 1.4211e-14, 8.8818e-15, 1.7764e-14, 2.4869e-14, 1.2790e-13,\n",
      "         7.1054e-14, 2.1316e-14, 2.1316e-14, 1.5987e-14, 1.2790e-13, 4.4409e-15,\n",
      "         1.2434e-14, 4.9738e-14, 6.2172e-15, 7.1054e-15, 1.2434e-14, 9.7700e-15,\n",
      "         9.9476e-14, 1.2434e-14, 1.9540e-14, 3.5527e-14, 7.1054e-15, 7.1054e-15,\n",
      "         1.4211e-14, 5.6843e-14, 1.4211e-13, 1.1369e-13, 5.6843e-14, 9.9476e-14,\n",
      "         4.2633e-14, 4.2633e-14, 9.9476e-14, 9.9476e-14, 1.7764e-14, 8.5265e-14,\n",
      "         7.8160e-14, 3.5527e-14, 2.6645e-15, 2.8422e-14, 4.9738e-14, 5.6843e-14,\n",
      "         1.4211e-14, 9.9476e-14, 9.9476e-14, 9.2371e-14, 8.5265e-14, 1.1369e-13,\n",
      "         1.2790e-13, 2.8422e-14, 5.6843e-14, 1.4211e-13, 5.6843e-14, 1.9895e-13,\n",
      "         4.2633e-14, 3.1974e-14, 2.1316e-14, 9.9476e-14, 1.7764e-14, 2.8422e-14,\n",
      "         2.1316e-14, 8.8818e-15, 7.1054e-14, 2.4869e-14, 7.1054e-14, 2.1316e-14,\n",
      "         1.5632e-13, 7.1054e-14, 7.9936e-15, 1.2790e-13, 5.6843e-14, 1.5632e-13,\n",
      "         2.8422e-14, 2.8422e-14, 1.5987e-14, 4.2633e-14, 2.1316e-14, 3.5527e-14,\n",
      "         1.4211e-14, 8.5265e-14, 8.8818e-15, 1.4211e-14, 1.4211e-13, 8.5265e-14,\n",
      "         4.9738e-14, 5.6843e-14, 7.1054e-14, 7.1054e-14, 8.8818e-15, 1.7053e-13,\n",
      "         5.6843e-14, 9.9476e-14, 1.1369e-13, 6.7502e-14, 8.5265e-14, 9.2371e-14,\n",
      "         9.9476e-14, 7.8160e-14, 8.5265e-14, 5.6843e-14, 1.1369e-13, 4.2633e-14,\n",
      "         9.9476e-14, 1.4211e-13, 8.5265e-14, 8.5265e-14, 1.2790e-13, 1.1013e-13,\n",
      "         1.1369e-13, 5.6843e-14, 7.8160e-14, 1.7053e-13, 7.1054e-14, 1.1369e-13,\n",
      "         5.6843e-14, 1.1369e-13, 7.1054e-14, 1.4211e-13, 9.9476e-14, 1.9895e-13,\n",
      "         8.5265e-14, 9.9476e-14, 1.4211e-13, 5.6843e-14, 1.1369e-13, 1.0658e-14,\n",
      "         1.7053e-13, 1.9895e-13, 1.7053e-13, 1.1369e-13, 1.1369e-13, 1.1369e-13,\n",
      "         1.8474e-13, 1.2790e-13, 1.1369e-13, 5.6843e-14, 7.8160e-14, 7.1054e-14,\n",
      "         7.1054e-14, 7.1054e-14, 6.3949e-14, 8.5265e-14, 8.5265e-14, 7.1054e-14,\n",
      "         7.1054e-14, 1.2790e-13, 1.1369e-13, 1.2790e-13, 6.3949e-14, 1.1369e-13,\n",
      "         8.5265e-14, 8.5265e-14, 2.2737e-13, 4.9738e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 79: layer3.3.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 79\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 79\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 79\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 79\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 79\n",
      "Max diff:\n",
      " tensor([9.9476e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.8850e-15, 8.8818e-16, 1.1102e-15, 1.1102e-15, 1.1102e-15, 1.3323e-15,\n",
      "         1.9984e-15, 9.9920e-16, 9.9920e-16, 1.1102e-15, 1.5543e-15, 8.8818e-16,\n",
      "         1.5543e-15, 6.6613e-16, 1.7764e-15, 9.9920e-16, 1.7764e-15, 1.5543e-15,\n",
      "         1.1102e-15, 8.8818e-16, 8.8818e-16, 1.3323e-15, 1.3323e-15, 6.6613e-16,\n",
      "         3.9968e-15, 1.1102e-15, 6.6613e-16, 5.5511e-16, 1.7764e-15, 8.8818e-16,\n",
      "         6.6613e-16, 1.5543e-15, 8.8818e-16, 6.6613e-16, 1.1102e-15, 9.9920e-16,\n",
      "         8.8818e-16, 7.7716e-16, 2.2204e-15, 1.2212e-15, 8.8818e-16, 4.4409e-16,\n",
      "         1.3323e-15, 7.9936e-15, 8.8818e-16, 1.4433e-15, 6.1062e-16, 6.6613e-16,\n",
      "         7.1054e-15, 8.8818e-16, 7.7716e-16, 6.2172e-15, 8.8818e-16, 1.1102e-15,\n",
      "         1.1102e-15, 1.1102e-15, 1.1102e-15, 1.2212e-15, 1.7764e-15, 1.1102e-15,\n",
      "         1.3323e-15, 1.7764e-15, 2.6645e-15, 2.2204e-15, 1.7764e-15, 2.1316e-14,\n",
      "         3.5527e-15, 1.5987e-14, 1.2434e-14, 2.4425e-15, 1.7764e-14, 7.1054e-15,\n",
      "         2.2204e-15, 7.1054e-15, 1.0658e-14, 2.6645e-15, 1.7764e-14, 1.9984e-15,\n",
      "         1.4211e-14, 2.2204e-15, 4.4409e-15, 3.1086e-15, 1.5543e-15, 1.7764e-14,\n",
      "         1.7764e-14, 6.6613e-15, 1.7764e-14, 5.3291e-15, 7.1054e-15, 1.7764e-14,\n",
      "         2.2204e-15, 7.1054e-15, 5.3291e-15, 4.8850e-15, 5.6843e-14, 2.4425e-15,\n",
      "         5.3291e-15, 1.4211e-14, 6.2172e-15, 2.8866e-15, 2.1316e-14, 2.8422e-14,\n",
      "         8.8818e-15, 5.3291e-15, 3.1086e-15, 6.2172e-15, 7.1054e-15, 3.9080e-14,\n",
      "         2.1316e-14, 7.1054e-15, 7.1054e-15, 4.8850e-15, 1.4211e-14, 1.3323e-15,\n",
      "         4.4409e-15, 1.2434e-14, 2.2204e-15, 2.2204e-15, 4.4409e-15, 3.3307e-15,\n",
      "         2.1316e-14, 3.5527e-15, 6.2172e-15, 6.2172e-15, 2.2204e-15, 2.6645e-15,\n",
      "         5.3291e-15, 1.5987e-14, 3.5527e-14, 3.1974e-14, 1.7764e-14, 2.8422e-14,\n",
      "         1.2434e-14, 1.0658e-14, 2.8422e-14, 3.5527e-14, 3.5527e-15, 1.7764e-14,\n",
      "         2.1316e-14, 1.2434e-14, 8.8818e-16, 7.1054e-15, 4.7740e-15, 1.4211e-14,\n",
      "         5.3291e-15, 1.9540e-14, 2.4869e-14, 1.2434e-14, 1.5099e-14, 3.5527e-14,\n",
      "         3.5527e-14, 8.8818e-15, 1.7764e-14, 5.3291e-14, 1.7764e-14, 7.8160e-14,\n",
      "         1.4211e-14, 8.8818e-15, 8.8818e-15, 3.1974e-14, 5.3291e-15, 9.7700e-15,\n",
      "         7.1054e-15, 2.6645e-15, 2.1316e-14, 1.0658e-14, 1.2434e-14, 6.2172e-15,\n",
      "         3.1974e-14, 1.0658e-14, 2.6645e-15, 2.4869e-14, 1.4211e-14, 5.6843e-14,\n",
      "         8.8818e-15, 1.0658e-14, 6.2172e-15, 1.0658e-14, 7.1054e-15, 1.0658e-14,\n",
      "         5.3291e-15, 1.5987e-14, 2.6645e-15, 4.4409e-15, 4.2633e-14, 2.1316e-14,\n",
      "         1.5987e-14, 1.9540e-14, 2.1316e-14, 2.1316e-14, 3.1086e-15, 3.5527e-14,\n",
      "         1.4211e-14, 1.7764e-14, 2.4869e-14, 1.6431e-14, 2.1316e-14, 1.6875e-14,\n",
      "         2.8422e-14, 2.4869e-14, 1.7764e-14, 1.2434e-14, 3.9080e-14, 1.5987e-14,\n",
      "         2.4869e-14, 2.6645e-14, 1.4211e-14, 2.4869e-14, 3.1974e-14, 2.2204e-14,\n",
      "         2.4869e-14, 1.2434e-14, 1.7764e-14, 3.1974e-14, 1.7764e-14, 3.1974e-14,\n",
      "         1.2434e-14, 2.8422e-14, 1.7764e-14, 3.1974e-14, 3.5527e-14, 5.6843e-14,\n",
      "         2.1316e-14, 3.5527e-14, 3.5527e-14, 1.4211e-14, 2.8422e-14, 3.5527e-15,\n",
      "         4.9738e-14, 9.9476e-14, 7.8160e-14, 2.1316e-14, 2.4869e-14, 2.3093e-14,\n",
      "         3.9080e-14, 2.8422e-14, 4.2633e-14, 8.8818e-15, 1.5987e-14, 1.2434e-14,\n",
      "         9.7700e-15, 1.4211e-14, 1.6875e-14, 1.3323e-14, 4.2633e-14, 1.7764e-14,\n",
      "         1.7764e-14, 2.8422e-14, 4.9738e-14, 3.0198e-14, 1.0658e-14, 2.8422e-14,\n",
      "         2.4869e-14, 1.7764e-14, 3.1974e-14, 1.3323e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 80: layer3.3.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 80\n",
      "Max diff:\n",
      " tensor([2.0428e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.0214e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5099e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.9968e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4425e-15, 5.3291e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.3291e-15, 0.0000e+00, 0.0000e+00, 1.6431e-14, 0.0000e+00, 4.2188e-15,\n",
      "         0.0000e+00, 1.7764e-15, 0.0000e+00, 3.7748e-15, 0.0000e+00, 0.0000e+00,\n",
      "         3.5527e-15, 7.9936e-15, 0.0000e+00, 0.0000e+00, 2.0428e-14, 9.2149e-15,\n",
      "         0.0000e+00, 6.4393e-15, 4.4409e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         1.0658e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.8255e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8874e-15, 1.7764e-15, 0.0000e+00,\n",
      "         6.6613e-16, 0.0000e+00, 0.0000e+00, 7.9936e-15, 1.4433e-15, 7.8271e-15,\n",
      "         4.8021e-15, 5.1625e-15, 1.0436e-14, 6.8834e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.2768e-15, 0.0000e+00, 6.6613e-15, 3.9968e-15, 0.0000e+00,\n",
      "         3.6637e-15, 1.4433e-15, 0.0000e+00, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([ 86, 100, 129, 132, 142, 148, 168, 172, 173, 184, 192, 195, 197, 199,\n",
      "        201, 204, 205, 208, 209, 211, 212, 214, 216, 224, 231, 232, 234, 237,\n",
      "        238, 239, 240, 241, 242, 243, 247, 249, 250, 252, 253, 255])\n",
      "\n",
      "failing Cout = tensor([ 86, 100, 129, 132, 142, 148, 168, 172, 173, 184, 192, 195, 197, 199,\n",
      "        201, 204, 205, 208, 209, 211, 212, 214, 216, 224, 231, 232, 234, 237,\n",
      "        238, 239, 240, 241, 242, 243, 247, 249, 250, 252, 253, 255])  (len = 40)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 81: layer3.3.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 81\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 81\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  4,  5,  6, 10, 12, 15, 17, 23, 26, 27, 29, 32, 33, 34, 42,\n",
      "        44, 45, 47, 50, 51, 52, 55, 58, 59, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144,\n",
      "        145, 146, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "        162, 163, 164, 165, 166, 168, 169, 171, 173, 174, 176, 178, 179, 182,\n",
      "        183, 186, 187, 188, 190]) to machine 2\n",
      "\t\t sending C_out tensor([194, 196, 198, 201, 202, 204, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "        216, 217, 218, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
      "        233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 246, 247, 249,\n",
      "        250, 251, 252, 253, 254]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 81\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21,\n",
      "        24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
      "        43, 44, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 81\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 81\n",
      "Max diff:\n",
      " tensor([1.7958e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.9936e-15, 4.4409e-15, 8.4377e-15, 5.7732e-15, 3.3307e-15, 3.3307e-15,\n",
      "         6.5503e-15, 2.9421e-15, 9.9920e-15, 9.3259e-15, 2.7756e-16, 7.5495e-15,\n",
      "         4.4409e-16, 7.5495e-15, 1.9984e-15, 1.1546e-14, 1.6653e-16, 7.1054e-15,\n",
      "         1.1102e-16, 4.8850e-15, 8.3267e-17, 7.1054e-15, 5.0793e-15, 2.6645e-15,\n",
      "         2.2204e-16, 3.9968e-15, 3.9968e-15, 3.5527e-15, 1.9984e-15, 2.4425e-15,\n",
      "         6.6613e-15, 4.4409e-15, 2.4425e-15, 9.1038e-15, 4.4409e-15, 3.5527e-15,\n",
      "         8.4377e-15, 5.9952e-15, 2.8866e-15, 3.2613e-16, 1.2434e-14, 2.2204e-16,\n",
      "         3.8858e-15, 9.7145e-17, 1.4877e-14, 6.4393e-15, 4.5797e-16, 2.4425e-15,\n",
      "         3.9968e-15, 9.9920e-15, 1.2434e-14, 2.0817e-16, 3.7748e-15, 8.8818e-15,\n",
      "         2.2204e-15, 1.6653e-15, 7.1054e-15, 3.7748e-15, 7.1054e-15, 7.3275e-15,\n",
      "         5.7732e-15, 6.6613e-16, 4.4409e-15, 1.9429e-16, 9.0483e-15, 6.2172e-15,\n",
      "         5.3291e-15, 4.8850e-15, 4.8850e-15, 8.6597e-15, 7.3830e-15, 1.0200e-14,\n",
      "         6.4393e-15, 6.7446e-15, 7.3275e-15, 1.0436e-14, 5.2180e-15, 7.1054e-15,\n",
      "         5.3291e-15, 3.5527e-15, 7.8826e-15, 7.1054e-15, 3.9968e-15, 1.0880e-14,\n",
      "         9.7700e-15, 1.2518e-14, 5.4401e-15, 9.7700e-15, 1.0658e-14, 5.8981e-15,\n",
      "         7.1054e-15, 6.2172e-15, 5.3291e-15, 8.6597e-15, 6.6613e-15, 4.3299e-15,\n",
      "         3.9968e-15, 1.0436e-14, 9.7700e-15, 6.2172e-15, 1.0991e-14, 5.5511e-15,\n",
      "         9.1038e-15, 8.3267e-15, 5.7732e-15, 6.5503e-15, 7.5495e-15, 1.2434e-14,\n",
      "         7.1054e-15, 9.3259e-15, 7.9936e-15, 8.2157e-15, 8.3267e-15, 6.6613e-15,\n",
      "         5.4401e-15, 2.7062e-15, 8.2157e-15, 8.6597e-15, 5.2180e-15, 4.8850e-15,\n",
      "         6.8834e-15, 6.6613e-15, 4.2188e-15, 6.6613e-15, 3.1086e-15, 7.9936e-15,\n",
      "         8.2157e-15, 8.4377e-15, 4.4409e-15, 9.7700e-15, 9.3259e-15, 9.6589e-15,\n",
      "         7.9936e-15, 5.3291e-15, 8.8818e-15, 8.2157e-15, 7.1054e-15, 1.0658e-14,\n",
      "         7.6883e-15, 9.1038e-15, 7.9936e-15, 1.1324e-14, 8.2157e-15, 8.5487e-15,\n",
      "         1.0214e-14, 7.1054e-15, 4.8850e-15, 7.1054e-15, 9.9920e-15, 7.5495e-15,\n",
      "         8.4377e-15, 6.2172e-15, 1.7958e-14, 7.9936e-15, 1.2434e-14, 7.3275e-15,\n",
      "         9.7700e-15, 9.7700e-15, 6.1062e-15, 7.9936e-15, 1.5987e-14, 9.7700e-15,\n",
      "         9.9920e-15, 1.6626e-14, 9.7700e-15, 7.5703e-15, 9.7700e-15, 6.6613e-15,\n",
      "         6.6613e-15, 7.1887e-15, 5.3291e-15, 1.0270e-14, 9.7700e-15, 1.0658e-14,\n",
      "         1.2212e-14, 7.1609e-15, 9.7700e-15, 8.8818e-15, 1.3767e-14, 6.4393e-15,\n",
      "         1.5099e-14, 4.8850e-15, 5.7732e-15, 1.0658e-14, 7.9936e-15, 6.8834e-15,\n",
      "         7.2164e-15, 7.1054e-15, 8.8818e-15, 8.4377e-15, 1.1824e-14, 6.6613e-15,\n",
      "         9.8810e-15, 4.4409e-15, 8.8818e-15, 5.6621e-15, 6.6613e-15, 8.4377e-15,\n",
      "         6.3560e-15, 1.0214e-14, 1.5987e-14, 9.7700e-15, 1.0658e-14, 9.5479e-15,\n",
      "         9.4369e-15, 1.0214e-14, 1.1546e-14, 1.1102e-14, 1.2670e-14, 8.4377e-15,\n",
      "         1.3323e-14, 1.7319e-14, 1.4655e-14, 6.2172e-15, 1.0214e-14, 1.1102e-14,\n",
      "         8.8818e-15, 8.4377e-15, 7.1054e-15, 9.7700e-15, 1.5099e-14, 1.1990e-14,\n",
      "         9.4924e-15, 1.1546e-14, 1.1102e-14, 9.7700e-15, 7.5495e-15, 1.1990e-14,\n",
      "         9.7700e-15, 8.4377e-15, 9.6589e-15, 1.0658e-14, 1.7764e-14, 7.1054e-15,\n",
      "         1.1102e-14, 8.4377e-15, 7.9936e-15, 7.1054e-15, 6.6613e-15, 1.0214e-14,\n",
      "         6.2172e-15, 1.5099e-14, 1.1546e-14, 9.3259e-15, 8.8818e-15, 9.3259e-15,\n",
      "         1.0880e-14, 7.9936e-15, 7.9936e-15, 8.6597e-15, 5.7732e-15, 1.4211e-14,\n",
      "         1.2434e-14, 1.0214e-14, 7.1054e-15, 1.3767e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 82: layer3.3.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 82\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 82\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 82\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 82\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 82\n",
      "Max diff:\n",
      " tensor([8.3267e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-15, 1.8874e-15, 2.2204e-15, 1.7764e-15, 1.0547e-15, 5.5511e-16,\n",
      "         1.8874e-15, 4.4409e-16, 1.7764e-15, 4.3160e-15, 4.1633e-17, 2.3315e-15,\n",
      "         1.5266e-16, 1.7764e-15, 7.7716e-16, 3.9968e-15, 6.9389e-17, 3.8858e-16,\n",
      "         3.4694e-17, 1.3045e-15, 3.4694e-17, 1.7764e-15, 1.0270e-15, 9.7145e-17,\n",
      "         6.9389e-17, 1.1102e-16, 6.6613e-16, 1.1102e-15, 3.3307e-16, 7.7716e-16,\n",
      "         3.3307e-16, 2.2204e-15, 1.3878e-15, 2.6645e-15, 6.6613e-16, 6.6613e-16,\n",
      "         1.7764e-15, 1.0547e-15, 5.5511e-17, 1.1796e-16, 4.2188e-15, 6.9389e-17,\n",
      "         1.2802e-15, 3.1225e-17, 7.1054e-15, 1.2212e-15, 1.5266e-16, 6.6613e-16,\n",
      "         9.4369e-16, 2.3315e-15, 3.1086e-15, 6.9389e-17, 2.2204e-16, 3.1086e-15,\n",
      "         4.4409e-16, 4.9960e-16, 2.5535e-15, 4.9960e-16, 3.3307e-15, 5.5511e-16,\n",
      "         1.4433e-15, 2.2204e-16, 1.5543e-15, 6.2450e-17, 2.7651e-15, 1.4433e-15,\n",
      "         4.9960e-16, 5.4123e-16, 1.1102e-15, 2.3315e-15, 1.0825e-15, 2.4009e-15,\n",
      "         1.6653e-15, 4.9960e-16, 2.4425e-15, 2.7756e-15, 1.4294e-15, 1.3323e-15,\n",
      "         4.3715e-16, 1.5543e-15, 1.2768e-15, 2.1094e-15, 6.6613e-16, 2.6923e-15,\n",
      "         2.2204e-15, 2.2274e-15, 2.2204e-15, 1.7764e-15, 1.9984e-15, 1.5127e-15,\n",
      "         1.9984e-15, 7.7716e-16, 1.1102e-15, 2.5535e-15, 1.9984e-15, 8.3267e-16,\n",
      "         7.7716e-16, 4.4409e-15, 2.5535e-15, 1.9984e-15, 3.4417e-15, 7.7716e-16,\n",
      "         2.3315e-15, 2.0713e-15, 9.4369e-16, 5.2389e-16, 2.4425e-15, 2.4841e-15,\n",
      "         1.1796e-15, 1.5543e-15, 2.6645e-15, 6.9389e-16, 1.4017e-15, 6.7654e-16,\n",
      "         2.2760e-15, 3.8858e-16, 1.1380e-15, 2.3870e-15, 1.6376e-15, 8.0491e-16,\n",
      "         1.9984e-15, 2.2204e-15, 1.0270e-15, 1.4433e-15, 5.1348e-16, 2.4425e-15,\n",
      "         1.9984e-15, 1.7764e-15, 1.7764e-15, 4.2188e-15, 2.9976e-15, 4.5519e-15,\n",
      "         3.1086e-15, 4.7184e-16, 3.1086e-15, 2.1094e-15, 2.1302e-15, 3.3307e-15,\n",
      "         3.1503e-15, 2.2204e-15, 1.6653e-15, 3.7748e-15, 2.6645e-15, 2.4234e-15,\n",
      "         3.9968e-15, 2.5535e-15, 1.2768e-15, 1.8874e-15, 3.6637e-15, 2.6645e-15,\n",
      "         4.9960e-16, 3.1086e-15, 6.0507e-15, 4.8850e-15, 3.7748e-15, 2.9447e-15,\n",
      "         2.8866e-15, 3.8858e-15, 2.1927e-15, 4.9960e-16, 5.7732e-15, 1.6653e-15,\n",
      "         8.8818e-16, 8.3267e-15, 3.7748e-15, 1.7764e-15, 4.8850e-15, 9.9920e-16,\n",
      "         1.5543e-15, 3.4139e-15, 6.6613e-16, 4.6629e-15, 4.4409e-15, 3.1364e-15,\n",
      "         3.7748e-15, 3.4972e-15, 4.2188e-15, 1.6653e-15, 2.2204e-15, 5.5511e-16,\n",
      "         5.3291e-15, 1.7764e-15, 1.3323e-15, 4.6629e-15, 2.1094e-15, 1.2212e-15,\n",
      "         3.2196e-15, 9.8532e-16, 1.7764e-15, 1.9984e-15, 1.1657e-15, 9.9920e-16,\n",
      "         1.9984e-15, 1.1102e-15, 1.4988e-15, 1.0339e-15, 1.4988e-15, 1.7764e-15,\n",
      "         1.1657e-15, 3.7748e-15, 2.8311e-15, 2.2204e-15, 3.1086e-15, 1.3878e-15,\n",
      "         1.0547e-15, 4.4409e-15, 2.8866e-15, 2.3315e-15, 2.3315e-15, 2.3315e-15,\n",
      "         2.2204e-15, 6.4393e-15, 3.9135e-15, 1.9984e-15, 4.8850e-15, 3.7748e-15,\n",
      "         1.4988e-15, 2.1094e-15, 2.4425e-15, 1.9984e-15, 2.2204e-15, 3.2752e-15,\n",
      "         2.3592e-15, 2.2204e-15, 3.4417e-15, 3.5527e-15, 1.5266e-15, 2.9976e-15,\n",
      "         1.5543e-15, 1.7764e-15, 1.5335e-15, 3.1086e-15, 1.8874e-15, 2.3315e-15,\n",
      "         2.1094e-15, 1.8874e-15, 1.5266e-15, 1.1102e-15, 1.6653e-15, 1.3323e-15,\n",
      "         1.6653e-15, 4.4409e-15, 3.5527e-15, 8.3267e-16, 3.5527e-15, 3.3307e-15,\n",
      "         1.6237e-15, 1.3323e-15, 3.5527e-15, 2.1094e-15, 9.9920e-16, 2.5535e-15,\n",
      "         2.9976e-15, 3.3307e-15, 1.7764e-15, 2.9976e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 83: layer3.3.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 83\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-15, 1.8874e-15, 2.2204e-15, 4.2188e-15, 1.0547e-15, 8.3267e-16,\n",
      "         1.8874e-15, 4.4409e-16, 1.7764e-15, 4.3160e-15, 4.1633e-17, 2.3315e-15,\n",
      "         1.5266e-16, 1.7764e-15, 2.2204e-15, 3.9968e-15, 6.9389e-17, 3.8858e-16,\n",
      "         3.4694e-17, 2.2204e-15, 3.4694e-17, 1.7764e-15, 1.0270e-15, 2.5535e-15,\n",
      "         6.9389e-17, 1.1102e-16, 6.6613e-16, 2.8033e-15, 3.3307e-16, 3.5527e-15,\n",
      "         4.9960e-16, 4.8295e-15, 1.3878e-15, 4.3299e-15, 1.3323e-15, 6.6613e-16,\n",
      "         1.9984e-15, 1.0547e-15, 6.6613e-16, 1.1796e-16, 6.4393e-15, 6.9389e-17,\n",
      "         2.7200e-15, 3.1225e-17, 9.7700e-15, 1.2212e-15, 1.5266e-16, 6.6613e-16,\n",
      "         9.4369e-16, 2.3315e-15, 3.7748e-15, 6.9389e-17, 2.2204e-16, 3.1086e-15,\n",
      "         1.3323e-15, 4.9960e-16, 2.5535e-15, 4.9960e-16, 4.6629e-15, 1.3600e-15,\n",
      "         2.4425e-15, 3.0531e-16, 1.5543e-15, 6.2450e-17, 4.4409e-15, 7.5495e-15,\n",
      "         6.2172e-15, 6.2172e-15, 1.5543e-15, 3.1086e-15, 1.2434e-14, 6.4393e-15,\n",
      "         3.1086e-15, 4.8850e-15, 2.4425e-15, 4.4409e-15, 7.5495e-15, 9.7700e-15,\n",
      "         4.3715e-16, 1.5543e-15, 7.1609e-15, 4.6387e-15, 6.6613e-16, 8.2157e-15,\n",
      "         9.7700e-15, 6.8834e-15, 6.2172e-15, 1.7764e-15, 9.7700e-15, 8.8818e-15,\n",
      "         1.9984e-15, 3.1086e-15, 7.5495e-15, 2.5535e-15, 2.9976e-15, 6.6613e-15,\n",
      "         5.7732e-15, 4.4409e-15, 2.5535e-15, 1.1546e-14, 3.5527e-15, 8.3267e-16,\n",
      "         4.8850e-15, 8.8818e-15, 9.4369e-16, 8.8818e-15, 2.8866e-15, 6.1062e-15,\n",
      "         3.9968e-15, 5.1070e-15, 5.3291e-15, 6.6613e-15, 1.4017e-15, 4.8850e-15,\n",
      "         4.1078e-15, 6.4393e-15, 4.8850e-15, 2.3870e-15, 5.5511e-15, 5.3291e-15,\n",
      "         7.7716e-15, 2.2204e-15, 4.4409e-15, 4.4409e-15, 2.6645e-15, 7.1054e-15,\n",
      "         1.9984e-15, 3.3307e-15, 1.7764e-15, 5.2736e-15, 2.9976e-15, 4.5519e-15,\n",
      "         3.9413e-15, 4.7184e-16, 1.2879e-14, 2.1094e-15, 2.4425e-15, 4.6629e-15,\n",
      "         1.1435e-14, 2.2204e-15, 2.7200e-15, 3.7748e-15, 2.6645e-15, 1.2212e-14,\n",
      "         9.3259e-15, 2.5535e-15, 4.4409e-15, 1.8874e-15, 1.4211e-14, 4.8850e-15,\n",
      "         9.7700e-15, 3.1086e-15, 6.0507e-15, 4.8850e-15, 3.7748e-15, 7.5495e-15,\n",
      "         3.1086e-15, 4.5519e-15, 3.1086e-15, 4.9960e-16, 6.8834e-15, 2.2204e-15,\n",
      "         3.9968e-15, 8.3267e-15, 3.7748e-15, 2.1094e-15, 7.5495e-15, 9.9920e-16,\n",
      "         2.8422e-14, 3.4139e-15, 3.1086e-15, 8.8818e-15, 4.4409e-15, 7.7716e-15,\n",
      "         5.3291e-15, 7.4385e-15, 4.2188e-15, 1.6653e-15, 6.2172e-15, 5.5511e-16,\n",
      "         5.3291e-15, 1.7764e-15, 1.3323e-15, 4.6629e-15, 2.1094e-15, 6.2172e-15,\n",
      "         7.5495e-15, 3.6082e-15, 1.7764e-14, 6.8834e-15, 1.1657e-15, 3.5527e-15,\n",
      "         8.8818e-15, 2.3093e-14, 7.7716e-15, 2.6645e-15, 2.2204e-15, 7.6605e-15,\n",
      "         7.0222e-15, 7.3275e-15, 8.8818e-15, 4.4409e-15, 8.4377e-15, 1.3878e-15,\n",
      "         8.8818e-15, 5.7732e-15, 7.4940e-15, 1.5987e-14, 7.1054e-15, 5.3291e-15,\n",
      "         7.9936e-15, 2.8422e-14, 1.0658e-14, 8.6597e-15, 4.8850e-15, 3.7748e-15,\n",
      "         5.3291e-15, 3.5527e-15, 3.7748e-15, 6.6613e-15, 5.7732e-15, 3.1974e-14,\n",
      "         6.4393e-15, 7.1054e-15, 3.4417e-15, 7.1054e-15, 1.0658e-14, 6.6613e-15,\n",
      "         1.5987e-14, 9.3259e-15, 7.8826e-15, 1.1324e-14, 2.1316e-14, 4.9960e-15,\n",
      "         7.1054e-15, 5.9952e-15, 5.4956e-15, 1.2434e-14, 5.7732e-15, 7.2164e-15,\n",
      "         1.5543e-15, 4.4409e-15, 7.9936e-15, 1.7764e-15, 3.5527e-15, 8.8818e-15,\n",
      "         8.1601e-15, 9.5479e-15, 3.5527e-15, 6.2172e-15, 1.0658e-14, 7.9936e-15,\n",
      "         2.8866e-15, 4.9960e-15, 5.3291e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 84: layer3.3.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 84\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.4001e-16, 1.5959e-15, 4.6144e-16, 4.2188e-15, 3.7470e-16, 0.0000e+00,\n",
      "         6.6613e-16, 0.0000e+00, 3.0531e-16, 4.3160e-15, 0.0000e+00, 2.3315e-15,\n",
      "         0.0000e+00, 3.0531e-16, 2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-15, 0.0000e+00, 1.4433e-15, 0.0000e+00, 2.5535e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8033e-15, 0.0000e+00, 3.5527e-15,\n",
      "         0.0000e+00, 4.8295e-15, 1.3878e-15, 4.2188e-15, 7.7716e-16, 0.0000e+00,\n",
      "         1.9984e-15, 1.9429e-16, 5.5511e-16, 0.0000e+00, 6.4393e-15, 0.0000e+00,\n",
      "         2.7200e-15, 0.0000e+00, 4.8850e-15, 0.0000e+00, 0.0000e+00, 1.2490e-16,\n",
      "         4.4409e-16, 2.6021e-17, 6.6613e-16, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00, 2.8866e-15, 1.2212e-15,\n",
      "         2.4425e-15, 3.0531e-16, 5.5511e-16, 0.0000e+00, 4.4409e-15, 7.5495e-15,\n",
      "         6.2172e-15, 6.2172e-15, 1.5543e-15, 3.1086e-15, 1.2434e-14, 6.4393e-15,\n",
      "         3.1086e-15, 4.8850e-15, 1.5266e-15, 4.4409e-15, 7.5495e-15, 9.7700e-15,\n",
      "         4.3715e-16, 1.5543e-15, 7.1609e-15, 4.6387e-15, 6.6613e-16, 8.2157e-15,\n",
      "         9.7700e-15, 6.8834e-15, 6.2172e-15, 0.0000e+00, 9.7700e-15, 8.8818e-15,\n",
      "         1.1935e-15, 3.1086e-15, 7.5495e-15, 8.6042e-16, 2.9976e-15, 6.6613e-15,\n",
      "         5.7732e-15, 1.6515e-15, 1.0231e-15, 1.1546e-14, 1.2768e-15, 8.3267e-16,\n",
      "         4.8850e-15, 1.1102e-15, 6.6613e-16, 8.8818e-15, 1.0547e-15, 6.1062e-15,\n",
      "         3.9968e-15, 5.1070e-15, 5.3291e-15, 6.6613e-15, 8.8818e-16, 4.8850e-15,\n",
      "         2.9421e-15, 6.4393e-15, 4.8850e-15, 2.3870e-15, 5.3291e-15, 5.3291e-15,\n",
      "         7.7716e-15, 9.4369e-16, 4.4409e-15, 4.4409e-15, 2.6645e-15, 6.1062e-15,\n",
      "         1.9984e-15, 2.6645e-15, 1.4433e-15, 5.2736e-15, 2.9976e-15, 6.6613e-16,\n",
      "         3.7748e-15, 4.7184e-16, 1.2879e-14, 1.6098e-15, 2.1302e-15, 4.4409e-15,\n",
      "         1.1435e-14, 1.5543e-15, 2.7200e-15, 7.2164e-16, 6.6613e-16, 1.2212e-14,\n",
      "         9.3259e-15, 9.5757e-16, 4.4409e-15, 8.3267e-16, 1.4211e-14, 4.8850e-15,\n",
      "         9.7700e-15, 3.1086e-15, 6.0507e-15, 2.5396e-15, 3.7748e-15, 7.5495e-15,\n",
      "         3.1086e-15, 4.5519e-15, 3.1086e-15, 0.0000e+00, 3.1086e-15, 1.3323e-15,\n",
      "         3.9968e-15, 3.8997e-15, 1.4433e-15, 1.8596e-15, 7.5495e-15, 0.0000e+00,\n",
      "         2.8422e-14, 1.3878e-15, 3.1086e-15, 8.8818e-15, 4.4409e-16, 7.7716e-15,\n",
      "         5.3291e-15, 7.4385e-15, 3.8858e-16, 2.0817e-17, 6.2172e-15, 5.5511e-16,\n",
      "         0.0000e+00, 1.2212e-15, 2.4980e-16, 4.6629e-15, 7.7716e-16, 6.2172e-15,\n",
      "         7.5495e-15, 2.6645e-15, 1.7764e-14, 6.8834e-15, 0.0000e+00, 3.5527e-15,\n",
      "         8.8818e-15, 2.3093e-14, 7.7716e-15, 2.6645e-15, 1.7764e-15, 7.1054e-15,\n",
      "         5.1070e-15, 7.3275e-15, 8.8818e-15, 4.4409e-15, 8.4377e-15, 1.3323e-15,\n",
      "         8.8818e-15, 5.7732e-15, 6.1617e-15, 1.5987e-14, 7.1054e-15, 5.3291e-15,\n",
      "         7.9936e-15, 2.8422e-14, 1.0658e-14, 1.1657e-15, 2.9976e-15, 1.7764e-15,\n",
      "         5.3291e-15, 3.5527e-15, 3.7748e-15, 6.6613e-15, 5.7732e-15, 3.1974e-14,\n",
      "         6.4393e-15, 7.1054e-15, 3.4417e-15, 7.1054e-15, 1.0658e-14, 6.6613e-15,\n",
      "         1.5987e-14, 9.3259e-15, 7.8826e-15, 1.0658e-14, 2.1316e-14, 4.9960e-15,\n",
      "         7.1054e-15, 5.9952e-15, 5.4956e-15, 1.2434e-14, 5.7732e-15, 6.2172e-15,\n",
      "         1.5543e-15, 2.2204e-15, 7.9936e-15, 1.7764e-15, 3.5527e-15, 8.8818e-15,\n",
      "         8.1601e-15, 9.5479e-15, 3.5527e-15, 6.2172e-15, 1.0658e-14, 7.9936e-15,\n",
      "         1.9706e-15, 4.9960e-15, 3.5527e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   6,   8,   9,  11,  13,  14,  19,  21,  23,\n",
      "         27,  29,  31,  32,  33,  34,  36,  37,  38,  40,  42,  44,  47,  48,\n",
      "         49,  50,  53,  56,  58,  59,  60,  61,  62,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   6,   8,   9,  11,  13,  14,  19,  21,  23,\n",
      "         27,  29,  31,  32,  33,  34,  36,  37,  38,  40,  42,  44,  47,  48,\n",
      "         49,  50,  53,  56,  58,  59,  60,  61,  62,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 224)\n",
      "passing Cout = tensor([54])  (len = 1)\n",
      "\n",
      "Executing module 85: layer3.4.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 85\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 85\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 85\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 85\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 85\n",
      "Max diff:\n",
      " tensor([2.8422e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.1054e-15, 5.3291e-15, 8.8818e-15, 7.1054e-15, 3.1086e-15, 3.5527e-15,\n",
      "         4.4409e-15, 4.9738e-14, 7.1054e-15, 3.5527e-15, 3.5527e-15, 3.1086e-15,\n",
      "         6.2172e-15, 1.7764e-14, 7.9936e-15, 6.2172e-15, 7.1054e-15, 3.5527e-15,\n",
      "         2.2204e-15, 3.5527e-15, 1.4211e-14, 3.5527e-15, 4.4409e-15, 5.3291e-15,\n",
      "         3.5527e-15, 2.2204e-15, 5.3291e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15,\n",
      "         1.7764e-15, 5.3291e-15, 3.1086e-15, 4.8850e-15, 3.1086e-15, 5.3291e-15,\n",
      "         1.0658e-14, 3.1086e-15, 3.5527e-15, 2.2204e-15, 3.5527e-15, 2.2204e-15,\n",
      "         2.2204e-15, 8.8818e-15, 3.5527e-15, 4.4409e-15, 3.9968e-15, 1.4211e-14,\n",
      "         7.1054e-15, 4.4409e-15, 4.4409e-15, 3.5527e-15, 5.3291e-15, 1.7764e-15,\n",
      "         4.4409e-15, 1.2434e-14, 3.5527e-15, 3.5527e-15, 3.1086e-15, 1.0658e-14,\n",
      "         4.8850e-15, 3.1086e-15, 6.2172e-15, 1.4211e-14, 4.4409e-15, 6.2172e-15,\n",
      "         3.9968e-15, 5.6843e-14, 1.1369e-13, 6.3949e-14, 1.0658e-14, 1.7764e-14,\n",
      "         1.0658e-14, 3.5527e-15, 5.6843e-14, 1.0658e-14, 7.1054e-14, 1.7764e-14,\n",
      "         7.4607e-14, 1.2434e-14, 2.8422e-14, 8.8818e-15, 5.6843e-14, 2.8422e-14,\n",
      "         5.6843e-14, 1.1369e-13, 5.3291e-15, 2.4869e-14, 7.8160e-14, 1.7764e-14,\n",
      "         1.4211e-14, 3.1086e-15, 3.5527e-14, 3.1974e-14, 2.8422e-14, 6.2172e-15,\n",
      "         5.3291e-15, 7.1054e-15, 7.1054e-15, 7.1054e-15, 1.4211e-14, 5.3291e-15,\n",
      "         2.4869e-14, 7.1054e-14, 1.4211e-13, 7.1054e-14, 7.1054e-14, 1.0658e-14,\n",
      "         3.5527e-14, 5.6843e-14, 9.9476e-14, 3.5527e-15, 1.0658e-14, 7.1054e-14,\n",
      "         7.1054e-15, 1.5987e-14, 3.5527e-14, 2.8422e-14, 4.2633e-14, 1.4211e-14,\n",
      "         3.5527e-15, 2.8422e-14, 1.1369e-13, 1.2790e-13, 2.1316e-14, 1.0658e-14,\n",
      "         4.2633e-14, 5.6843e-14, 7.1054e-14, 7.1054e-15, 8.5265e-14, 1.9895e-13,\n",
      "         7.6383e-14, 4.9738e-14, 1.7053e-13, 3.1974e-14, 1.1369e-13, 6.3949e-14,\n",
      "         3.5527e-14, 1.0658e-14, 1.5987e-14, 8.5265e-14, 6.3949e-14, 4.4409e-14,\n",
      "         2.4869e-14, 1.9895e-13, 1.9540e-14, 1.0658e-13, 7.1054e-14, 1.7764e-13,\n",
      "         5.6843e-14, 4.2633e-14, 1.5632e-13, 1.4211e-13, 5.6843e-14, 4.2633e-14,\n",
      "         7.1054e-14, 1.1369e-13, 1.1369e-13, 4.4409e-15, 2.4869e-14, 9.9476e-14,\n",
      "         7.1054e-15, 5.6843e-14, 1.1369e-13, 3.5527e-14, 4.9738e-14, 3.5527e-14,\n",
      "         6.3949e-14, 7.1054e-14, 1.1369e-13, 7.1054e-14, 1.1369e-13, 1.1369e-13,\n",
      "         2.8422e-14, 4.9738e-14, 7.1054e-14, 1.9540e-14, 4.9738e-14, 1.5987e-14,\n",
      "         2.4869e-14, 8.5265e-14, 4.2633e-14, 2.4869e-14, 1.2790e-13, 2.1316e-14,\n",
      "         5.6843e-14, 6.3949e-14, 1.0658e-14, 2.2737e-13, 1.4211e-14, 7.1054e-14,\n",
      "         2.8422e-13, 1.0658e-13, 4.6185e-14, 6.3949e-14, 8.5265e-14, 9.9476e-14,\n",
      "         4.7962e-14, 1.1369e-13, 9.9476e-14, 9.5923e-14, 7.1054e-14, 8.5265e-14,\n",
      "         8.5265e-14, 5.6843e-14, 7.1054e-14, 5.6843e-14, 7.8160e-14, 8.5265e-14,\n",
      "         8.5265e-14, 7.1054e-14, 1.7053e-13, 1.8474e-13, 4.9738e-14, 1.7764e-13,\n",
      "         1.7053e-13, 2.1316e-14, 7.1054e-14, 8.5265e-14, 8.1712e-14, 1.4211e-13,\n",
      "         4.2633e-14, 4.2633e-14, 8.5265e-14, 1.7053e-13, 6.0396e-14, 1.1369e-13,\n",
      "         7.8160e-14, 5.9258e-14, 7.8160e-14, 1.9895e-13, 1.4211e-13, 9.2371e-14,\n",
      "         9.9476e-14, 7.1054e-14, 8.5265e-14, 9.9476e-14, 9.9476e-14, 8.8818e-14,\n",
      "         9.9476e-14, 1.2079e-13, 8.5265e-14, 1.2790e-13, 1.4211e-13, 5.6843e-14,\n",
      "         1.3500e-13, 7.1054e-14, 7.1054e-14, 1.4211e-13, 8.5265e-14, 6.3949e-14,\n",
      "         1.1369e-13, 7.1054e-14, 9.9476e-14, 1.2790e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 86: layer3.4.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 86\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 86\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 86\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 86\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 86\n",
      "Max diff:\n",
      " tensor([9.9476e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.2204e-15, 1.7764e-15, 2.6645e-15, 2.2204e-15, 7.7716e-16, 1.3323e-15,\n",
      "         1.3323e-15, 8.8818e-15, 2.2204e-15, 1.1102e-15, 1.1102e-15, 9.9920e-16,\n",
      "         1.9984e-15, 3.5527e-15, 2.2204e-15, 1.9984e-15, 1.7764e-15, 8.8818e-16,\n",
      "         7.7716e-16, 9.9920e-16, 3.5527e-15, 1.1102e-15, 1.3323e-15, 1.5543e-15,\n",
      "         1.1102e-15, 6.6613e-16, 1.5543e-15, 2.2204e-15, 2.2204e-15, 1.7764e-15,\n",
      "         5.5511e-16, 1.5543e-15, 9.9920e-16, 1.5543e-15, 8.8818e-16, 1.5543e-15,\n",
      "         3.1086e-15, 8.8818e-16, 1.1102e-15, 7.7716e-16, 1.1102e-15, 7.7716e-16,\n",
      "         6.6613e-16, 2.6645e-15, 1.1102e-15, 1.3323e-15, 1.3323e-15, 3.5527e-15,\n",
      "         2.2204e-15, 1.1102e-15, 1.3323e-15, 1.1102e-15, 1.5543e-15, 5.5511e-16,\n",
      "         1.5543e-15, 3.5527e-15, 8.8818e-16, 1.1102e-15, 8.8818e-16, 3.5527e-15,\n",
      "         1.5543e-15, 8.8818e-16, 1.7764e-15, 3.9968e-15, 1.3323e-15, 1.7764e-15,\n",
      "         1.1102e-15, 1.7764e-14, 2.8422e-14, 1.7764e-14, 3.5527e-15, 6.2172e-15,\n",
      "         3.5527e-15, 1.2212e-15, 1.2434e-14, 3.1086e-15, 2.1316e-14, 6.2172e-15,\n",
      "         1.7764e-14, 4.4409e-15, 7.1054e-15, 2.6645e-15, 1.7764e-14, 7.9936e-15,\n",
      "         1.4211e-14, 2.8422e-14, 1.7764e-15, 6.2172e-15, 2.3093e-14, 5.3291e-15,\n",
      "         4.4409e-15, 8.8818e-16, 8.8818e-15, 9.7700e-15, 7.1054e-15, 1.9984e-15,\n",
      "         1.5543e-15, 2.4425e-15, 2.2204e-15, 1.9984e-15, 4.4409e-15, 1.7764e-15,\n",
      "         7.9936e-15, 1.5987e-14, 3.9080e-14, 2.1316e-14, 1.7764e-14, 3.5527e-15,\n",
      "         8.8818e-15, 1.5987e-14, 2.8422e-14, 1.3323e-15, 3.5527e-15, 2.4869e-14,\n",
      "         2.4425e-15, 5.3291e-15, 7.9936e-15, 8.8818e-15, 1.0658e-14, 4.4409e-15,\n",
      "         1.1102e-15, 7.9936e-15, 3.1974e-14, 6.3949e-14, 7.1054e-15, 3.5527e-15,\n",
      "         1.4211e-14, 1.0658e-14, 1.5987e-14, 2.2204e-15, 1.7764e-14, 8.5265e-14,\n",
      "         8.8818e-15, 1.0658e-14, 4.6185e-14, 7.1054e-15, 3.5527e-14, 1.5987e-14,\n",
      "         1.0658e-14, 3.5527e-15, 6.2172e-15, 1.7764e-14, 1.7764e-14, 9.3259e-15,\n",
      "         8.8818e-15, 5.6843e-14, 7.1054e-15, 2.3093e-14, 2.8422e-14, 3.9080e-14,\n",
      "         2.1316e-14, 1.4211e-14, 2.4869e-14, 4.9738e-14, 1.7764e-14, 1.0658e-14,\n",
      "         3.1974e-14, 4.2633e-14, 2.1316e-14, 1.3323e-15, 8.8818e-15, 2.4869e-14,\n",
      "         2.2204e-15, 1.9540e-14, 2.4869e-14, 1.2434e-14, 1.4211e-14, 1.2434e-14,\n",
      "         2.1316e-14, 1.2434e-14, 2.8422e-14, 8.8818e-15, 1.5987e-14, 2.4869e-14,\n",
      "         7.1054e-15, 1.5987e-14, 2.1316e-14, 7.1054e-15, 1.7764e-14, 5.7732e-15,\n",
      "         7.9936e-15, 2.8422e-14, 1.2434e-14, 1.0658e-14, 3.1974e-14, 8.8818e-15,\n",
      "         1.0658e-14, 1.4211e-14, 4.4409e-15, 5.6843e-14, 4.4409e-15, 2.4869e-14,\n",
      "         9.9476e-14, 3.1974e-14, 7.9936e-15, 1.3323e-14, 2.4869e-14, 1.6875e-14,\n",
      "         1.0658e-14, 3.1974e-14, 2.1316e-14, 1.5099e-14, 1.2434e-14, 1.9540e-14,\n",
      "         1.7764e-14, 8.8818e-15, 1.2434e-14, 1.2434e-14, 9.7700e-15, 1.7764e-14,\n",
      "         1.0658e-14, 2.1316e-14, 6.0396e-14, 3.1974e-14, 8.8818e-15, 3.1974e-14,\n",
      "         5.6843e-14, 7.1054e-15, 2.4869e-14, 1.5987e-14, 1.5987e-14, 4.2633e-14,\n",
      "         1.0658e-14, 1.7764e-14, 2.4869e-14, 3.3751e-14, 1.8652e-14, 2.4869e-14,\n",
      "         2.1316e-14, 5.3291e-15, 1.5987e-14, 5.3291e-14, 5.6843e-14, 1.7764e-14,\n",
      "         2.8422e-14, 2.1316e-14, 1.4211e-14, 2.3093e-14, 3.1974e-14, 1.2434e-14,\n",
      "         3.5527e-14, 2.8422e-14, 1.2434e-14, 4.9738e-14, 3.5527e-14, 1.5099e-14,\n",
      "         3.1974e-14, 1.7764e-14, 1.4211e-14, 3.9080e-14, 1.7764e-14, 9.3259e-15,\n",
      "         1.7764e-14, 1.5987e-14, 3.9080e-14, 4.2633e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 87: layer3.4.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 87\n",
      "Max diff:\n",
      " tensor([1.8652e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9984e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1038e-15, 0.0000e+00,\n",
      "         5.6344e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3259e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6431e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-15, 5.8842e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0658e-14, 7.9936e-15, 7.9103e-15, 0.0000e+00, 4.8850e-15,\n",
      "         3.8580e-15, 0.0000e+00, 0.0000e+00, 1.5099e-14, 1.2212e-15, 0.0000e+00,\n",
      "         0.0000e+00, 5.2736e-15, 8.4377e-15, 3.5527e-15, 0.0000e+00, 8.8818e-15,\n",
      "         1.1102e-15, 3.9968e-15, 0.0000e+00, 1.3323e-14, 8.8818e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8834e-15, 1.2268e-14, 0.0000e+00,\n",
      "         9.3259e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00, 1.8652e-14, 0.0000e+00,\n",
      "         7.5495e-15, 5.3013e-15, 1.2212e-15, 5.9952e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1546e-14, 0.0000e+00, 4.4409e-15,\n",
      "         0.0000e+00, 1.9151e-15, 1.9984e-15, 0.0000e+00, 0.0000e+00, 1.5099e-14,\n",
      "         0.0000e+00, 2.3315e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 6.2172e-15,\n",
      "         0.0000e+00, 3.5527e-15, 5.3291e-15, 1.1102e-14]], dtype=torch.float64)\n",
      " tensor([ 78, 118, 123, 130, 132, 143, 149, 186, 187, 193, 194, 195, 197, 198,\n",
      "        201, 202, 205, 206, 207, 209, 210, 211, 213, 214, 219, 220, 222, 224,\n",
      "        226, 228, 229, 230, 231, 237, 239, 241, 242, 245, 247, 250, 251, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([ 78, 118, 123, 130, 132, 143, 149, 186, 187, 193, 194, 195, 197, 198,\n",
      "        201, 202, 205, 206, 207, 209, 210, 211, 213, 214, 219, 220, 222, 224,\n",
      "        226, 228, 229, 230, 231, 237, 239, 241, 242, 245, 247, 250, 251, 253,\n",
      "        254, 255])  (len = 44)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 88: layer3.4.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 88\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 88\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  9, 11, 12, 13, 14, 19, 21, 23, 26, 27, 28, 33, 35, 36,\n",
      "        37, 39, 40, 43, 47, 48, 49, 50, 53, 54, 57, 58, 59, 60, 62]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 148, 150, 151, 152, 153, 154, 156, 157, 158,\n",
      "        160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174,\n",
      "        175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189,\n",
      "        190]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 88\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 14, 15, 16, 18, 23, 24, 25, 26,\n",
      "        27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46,\n",
      "        47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  86,  87,  88,  90,  91,  92,  93,\n",
      "         94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 88\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 88\n",
      "Max diff:\n",
      " tensor([2.0872e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.6629e-15, 5.3291e-15, 9.7700e-15, 6.6891e-15, 2.6645e-15, 4.4409e-15,\n",
      "         5.7732e-15, 1.1435e-14, 1.2434e-14, 3.7748e-15, 9.7700e-15, 5.3291e-15,\n",
      "         2.4980e-16, 7.9936e-15, 1.2434e-14, 3.2335e-15, 4.4409e-16, 2.2204e-15,\n",
      "         1.6653e-16, 3.9968e-15, 7.1054e-15, 3.1086e-15, 5.3291e-15, 5.3291e-15,\n",
      "         2.2204e-16, 4.8850e-15, 4.8850e-15, 6.2172e-15, 2.6645e-15, 7.2858e-15,\n",
      "         8.8818e-15, 7.9936e-15, 3.5527e-15, 8.7153e-15, 4.4409e-15, 9.0483e-15,\n",
      "         5.3291e-15, 4.4409e-15, 6.9944e-15, 1.6653e-16, 1.0436e-14, 2.7756e-16,\n",
      "         3.2752e-15, 3.3307e-16, 8.4377e-15, 5.3291e-15, 1.3878e-16, 4.4409e-15,\n",
      "         8.8818e-15, 3.1086e-15, 7.9936e-15, 2.2204e-16, 5.3291e-15, 6.4393e-15,\n",
      "         5.7732e-15, 7.9936e-15, 7.1679e-15, 5.1070e-15, 1.9984e-15, 8.8818e-15,\n",
      "         2.9976e-15, 4.5519e-15, 4.8850e-15, 3.3307e-16, 5.3291e-15, 5.3291e-15,\n",
      "         5.9952e-15, 6.8834e-15, 1.0769e-14, 1.4211e-14, 8.4377e-15, 8.3683e-15,\n",
      "         8.4377e-15, 1.2712e-14, 9.1038e-15, 7.1054e-15, 1.1990e-14, 1.6803e-14,\n",
      "         7.9936e-15, 7.9936e-15, 1.1102e-14, 8.4377e-15, 6.2172e-15, 9.7700e-15,\n",
      "         6.2172e-15, 1.0658e-14, 8.8818e-15, 1.0658e-14, 7.9936e-15, 1.2434e-14,\n",
      "         9.3259e-15, 9.1038e-15, 5.3291e-15, 9.7700e-15, 1.0214e-14, 1.1990e-14,\n",
      "         1.0658e-14, 1.4211e-14, 7.7716e-15, 9.7700e-15, 1.3323e-14, 8.8818e-15,\n",
      "         8.8818e-15, 1.1546e-14, 1.0214e-14, 6.6613e-15, 1.1990e-14, 1.2434e-14,\n",
      "         1.4211e-14, 1.1005e-14, 7.1054e-15, 8.4377e-15, 7.1054e-15, 9.1038e-15,\n",
      "         1.0214e-14, 1.3323e-14, 9.3259e-15, 8.8818e-15, 6.8834e-15, 5.3291e-15,\n",
      "         1.3323e-14, 1.6875e-14, 8.8818e-15, 4.2188e-15, 1.0658e-14, 6.1062e-15,\n",
      "         7.9936e-15, 3.5527e-15, 6.6613e-15, 1.2434e-14, 7.1054e-15, 1.0658e-14,\n",
      "         9.7700e-15, 7.1054e-15, 1.3323e-14, 2.0872e-14, 1.2434e-14, 1.0658e-14,\n",
      "         9.7700e-15, 9.1038e-15, 1.1227e-14, 1.2434e-14, 1.5099e-14, 1.1546e-14,\n",
      "         8.4377e-15, 1.1102e-14, 1.4433e-14, 1.2434e-14, 8.6597e-15, 8.8818e-15,\n",
      "         9.3259e-15, 7.1054e-15, 1.4211e-14, 9.7700e-15, 1.2434e-14, 6.4393e-15,\n",
      "         1.0658e-14, 8.8818e-15, 1.3323e-14, 7.1054e-15, 1.0658e-14, 1.0658e-14,\n",
      "         9.3259e-15, 1.0658e-14, 1.2434e-14, 8.8818e-15, 1.0658e-14, 1.2434e-14,\n",
      "         1.1546e-14, 1.0658e-14, 7.3275e-15, 9.7700e-15, 1.0658e-14, 7.7716e-15,\n",
      "         1.6431e-14, 1.6875e-14, 8.4377e-15, 1.4211e-14, 1.3323e-14, 1.4211e-14,\n",
      "         1.4211e-14, 1.0880e-14, 8.8818e-15, 8.3822e-15, 1.5987e-14, 1.5987e-14,\n",
      "         1.0436e-14, 9.3259e-15, 1.2879e-14, 1.0658e-14, 7.9936e-15, 9.7700e-15,\n",
      "         1.1213e-14, 1.4211e-14, 9.1038e-15, 1.1546e-14, 9.7700e-15, 1.2212e-14,\n",
      "         1.0658e-14, 9.2149e-15, 1.0658e-14, 1.2212e-14, 1.0214e-14, 1.4211e-14,\n",
      "         1.0214e-14, 1.3989e-14, 1.5987e-14, 1.5987e-14, 1.0436e-14, 1.2434e-14,\n",
      "         7.9936e-15, 1.3323e-14, 1.2434e-14, 1.1990e-14, 1.2879e-14, 1.0214e-14,\n",
      "         1.0658e-14, 1.5987e-14, 1.3323e-14, 1.4211e-14, 1.5543e-14, 1.7097e-14,\n",
      "         1.0658e-14, 1.1546e-14, 1.6542e-14, 1.3323e-14, 1.4211e-14, 1.2434e-14,\n",
      "         7.9936e-15, 1.2879e-14, 1.2434e-14, 1.3101e-14, 1.2434e-14, 1.0436e-14,\n",
      "         9.7700e-15, 1.0658e-14, 9.3259e-15, 1.4211e-14, 1.4988e-14, 1.3101e-14,\n",
      "         1.0325e-14, 9.7700e-15, 1.3323e-14, 1.1546e-14, 1.0658e-14, 1.0436e-14,\n",
      "         1.5099e-14, 1.0991e-14, 1.2434e-14, 1.1546e-14, 1.0214e-14, 1.0658e-14,\n",
      "         1.0658e-14, 1.0658e-14, 9.9920e-15, 1.4877e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 89: layer3.4.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 89\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 89\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 89\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 89\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 89\n",
      "Max diff:\n",
      " tensor([9.6589e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.8874e-15, 1.1102e-16, 3.5527e-15, 1.2074e-15, 4.9960e-16, 1.7764e-15,\n",
      "         7.7716e-16, 5.2180e-15, 3.1086e-15, 1.5890e-15, 2.7756e-16, 8.8818e-16,\n",
      "         8.3267e-17, 3.1086e-15, 4.8850e-15, 1.5821e-15, 1.6653e-16, 1.1102e-16,\n",
      "         5.5511e-17, 4.7184e-16, 1.1102e-15, 6.6613e-16, 1.5543e-15, 8.3267e-17,\n",
      "         7.6328e-17, 2.7756e-17, 6.6613e-16, 3.5527e-15, 1.1102e-16, 3.6776e-16,\n",
      "         2.8866e-15, 3.1086e-15, 8.0491e-16, 1.1657e-15, 1.3323e-15, 3.1364e-15,\n",
      "         9.9920e-16, 7.7716e-16, 2.6645e-15, 6.9389e-17, 2.8311e-15, 9.7145e-17,\n",
      "         7.9103e-16, 1.3878e-16, 3.8303e-15, 1.9984e-15, 4.8572e-17, 1.8874e-15,\n",
      "         2.4425e-15, 1.6653e-16, 3.2196e-15, 8.3267e-17, 1.9984e-15, 2.2482e-15,\n",
      "         2.2204e-15, 4.8850e-15, 2.6090e-15, 5.5511e-17, 3.7817e-16, 4.4409e-15,\n",
      "         4.4409e-16, 1.2768e-15, 7.7716e-16, 1.1102e-16, 1.7764e-15, 1.1102e-15,\n",
      "         6.1062e-16, 1.2768e-15, 1.2768e-15, 3.5527e-15, 1.6653e-15, 1.8041e-15,\n",
      "         9.9920e-16, 3.6082e-15, 2.5535e-15, 1.7764e-15, 2.8311e-15, 3.2335e-15,\n",
      "         3.8858e-16, 1.5543e-15, 1.7764e-15, 3.3307e-15, 1.9984e-15, 2.2204e-15,\n",
      "         2.5535e-15, 1.1657e-15, 2.3315e-15, 3.1086e-15, 6.3404e-16, 3.9968e-15,\n",
      "         1.9984e-15, 1.8874e-15, 9.4369e-16, 1.9984e-15, 2.9976e-15, 1.2212e-15,\n",
      "         1.8874e-15, 5.3291e-15, 2.6645e-15, 2.1094e-15, 5.7732e-15, 8.8818e-16,\n",
      "         2.6645e-15, 9.9920e-16, 1.4433e-15, 2.2204e-15, 3.3307e-15, 3.1086e-15,\n",
      "         3.1086e-15, 2.1927e-15, 2.2204e-15, 1.5543e-15, 8.8818e-16, 1.2212e-15,\n",
      "         3.7470e-16, 2.6645e-15, 8.3267e-16, 2.2204e-15, 1.5543e-15, 1.2212e-15,\n",
      "         2.4425e-15, 6.2172e-15, 2.4425e-15, 7.7716e-16, 2.8866e-15, 1.3600e-15,\n",
      "         2.2204e-15, 4.7184e-16, 2.4425e-15, 3.3307e-15, 1.0547e-15, 3.3307e-15,\n",
      "         3.7748e-15, 3.5527e-15, 3.4417e-15, 5.3291e-15, 5.7732e-15, 5.3291e-15,\n",
      "         4.2188e-15, 5.4401e-15, 3.1919e-15, 3.5527e-15, 7.9936e-15, 4.1078e-15,\n",
      "         2.6645e-15, 4.8850e-15, 5.3291e-15, 3.3307e-15, 1.9984e-15, 3.1086e-15,\n",
      "         2.7756e-15, 2.8866e-15, 3.7748e-15, 2.8866e-15, 2.6645e-15, 1.7764e-15,\n",
      "         5.7732e-15, 2.2204e-15, 5.9952e-15, 2.2204e-15, 5.7732e-15, 1.5543e-15,\n",
      "         3.3307e-16, 4.6629e-15, 5.7732e-15, 3.1086e-15, 3.7748e-15, 4.4409e-15,\n",
      "         3.9968e-15, 2.2204e-15, 1.7764e-15, 5.3291e-15, 2.7756e-15, 2.3315e-15,\n",
      "         9.6589e-15, 7.9936e-15, 1.5543e-15, 5.3291e-15, 1.3323e-15, 3.5527e-15,\n",
      "         5.7732e-15, 3.7748e-15, 1.7764e-15, 2.1337e-16, 8.4377e-15, 2.8866e-15,\n",
      "         5.3291e-15, 2.4425e-15, 2.1823e-15, 3.3307e-15, 3.9968e-15, 3.3307e-16,\n",
      "         2.2083e-15, 3.1086e-15, 1.4849e-15, 1.1102e-15, 2.1094e-15, 3.3584e-15,\n",
      "         2.4425e-15, 3.6360e-15, 2.1094e-15, 3.6637e-15, 4.1356e-15, 1.7764e-15,\n",
      "         2.9629e-15, 4.3299e-15, 4.6629e-15, 2.6645e-15, 2.4425e-15, 2.6645e-15,\n",
      "         2.2204e-15, 3.1086e-15, 4.8850e-15, 2.9976e-15, 3.9968e-15, 1.7208e-15,\n",
      "         2.4425e-15, 5.5511e-15, 5.3291e-15, 2.4425e-15, 3.8858e-15, 4.2188e-15,\n",
      "         2.1094e-15, 2.3315e-15, 4.7184e-15, 3.9968e-15, 2.8866e-15, 3.2196e-15,\n",
      "         1.2212e-15, 3.4417e-15, 2.7200e-15, 3.9968e-15, 3.5527e-15, 3.5388e-15,\n",
      "         1.6653e-15, 2.4425e-15, 1.1935e-15, 2.2204e-15, 1.7486e-15, 3.1503e-15,\n",
      "         2.3384e-15, 1.9984e-15, 6.2172e-15, 1.6653e-15, 2.2968e-15, 4.0523e-15,\n",
      "         2.2204e-15, 2.3315e-15, 4.8850e-15, 2.5535e-15, 1.4433e-15, 1.4433e-15,\n",
      "         2.2204e-15, 2.6645e-15, 3.7748e-15, 3.4972e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 90: layer3.4.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 90\n",
      "Max diff:\n",
      " tensor([3.2863e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.8874e-15, 1.5543e-15, 3.5527e-15, 4.4409e-15, 4.9960e-16, 1.7764e-15,\n",
      "         7.7716e-16, 5.2180e-15, 3.1086e-15, 5.2180e-15, 2.7756e-16, 2.2204e-15,\n",
      "         8.3267e-17, 3.1086e-15, 5.7732e-15, 1.5821e-15, 1.6653e-16, 1.1102e-16,\n",
      "         5.5511e-17, 1.9984e-15, 1.1102e-15, 1.7764e-15, 1.5543e-15, 2.5258e-15,\n",
      "         7.6328e-17, 2.7756e-17, 6.6613e-16, 3.8858e-15, 1.1102e-16, 3.5527e-15,\n",
      "         2.8866e-15, 4.8850e-15, 1.5821e-15, 4.3299e-15, 1.3323e-15, 3.1364e-15,\n",
      "         1.9984e-15, 8.6042e-16, 2.6645e-15, 6.9389e-17, 4.9960e-15, 9.7145e-17,\n",
      "         2.7756e-15, 1.3878e-16, 7.7716e-15, 1.9984e-15, 4.8572e-17, 1.8874e-15,\n",
      "         2.4425e-15, 1.6653e-16, 3.2196e-15, 8.3267e-17, 1.9984e-15, 2.2482e-15,\n",
      "         2.2204e-15, 4.8850e-15, 3.2474e-15, 5.5511e-17, 3.0254e-15, 4.4409e-15,\n",
      "         2.2204e-15, 1.2768e-15, 1.2698e-15, 1.1102e-16, 5.3291e-15, 8.2157e-15,\n",
      "         6.2172e-15, 7.1054e-15, 2.1372e-15, 3.9968e-15, 1.0658e-14, 6.8834e-15,\n",
      "         2.8866e-15, 4.4409e-15, 2.5535e-15, 5.3291e-15, 7.9936e-15, 1.0658e-14,\n",
      "         5.8287e-16, 1.5543e-15, 8.2157e-15, 3.9968e-15, 2.2204e-15, 8.8818e-15,\n",
      "         9.3259e-15, 6.9944e-15, 6.2172e-15, 3.1086e-15, 9.7700e-15, 1.0658e-14,\n",
      "         1.9984e-15, 4.4409e-15, 6.6613e-15, 1.9984e-15, 3.9968e-15, 7.3830e-15,\n",
      "         4.6629e-15, 5.3291e-15, 2.6645e-15, 1.1324e-14, 5.7732e-15, 9.9920e-16,\n",
      "         5.9952e-15, 1.2212e-15, 1.4433e-15, 9.7700e-15, 3.3307e-15, 5.7732e-15,\n",
      "         3.9968e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15, 1.4988e-15, 4.8850e-15,\n",
      "         3.1086e-15, 6.6613e-15, 4.8850e-15, 2.4425e-15, 4.8850e-15, 5.6621e-15,\n",
      "         7.5495e-15, 6.2172e-15, 4.4409e-15, 4.6629e-15, 3.1086e-15, 6.1062e-15,\n",
      "         2.7756e-15, 2.6645e-15, 2.4425e-15, 5.3291e-15, 3.9968e-15, 3.3307e-15,\n",
      "         3.7748e-15, 3.5527e-15, 1.1546e-14, 5.3291e-15, 5.7732e-15, 7.1054e-15,\n",
      "         1.5099e-14, 5.3291e-15, 3.4972e-15, 3.5527e-15, 7.9936e-15, 1.0880e-14,\n",
      "         7.1054e-15, 4.8850e-15, 5.6621e-15, 3.3307e-15, 1.4211e-14, 4.4409e-15,\n",
      "         9.7700e-15, 3.7748e-15, 6.2172e-15, 3.8858e-15, 3.3307e-15, 6.2172e-15,\n",
      "         6.1062e-15, 5.5511e-15, 5.9952e-15, 2.2204e-15, 5.7732e-15, 2.2204e-15,\n",
      "         3.5527e-15, 6.9389e-15, 5.7732e-15, 3.1086e-15, 7.1054e-15, 4.4409e-15,\n",
      "         2.6645e-14, 2.2204e-15, 2.1094e-15, 8.8818e-15, 2.7756e-15, 9.1038e-15,\n",
      "         1.1768e-14, 1.0658e-14, 1.5543e-15, 5.3291e-15, 6.6613e-15, 3.5527e-15,\n",
      "         5.7732e-15, 3.4972e-15, 1.7764e-15, 4.6629e-15, 8.4377e-15, 5.5511e-15,\n",
      "         7.5495e-15, 3.9968e-15, 1.7764e-14, 9.3259e-15, 3.9968e-15, 3.4417e-15,\n",
      "         9.7700e-15, 2.4869e-14, 8.8818e-15, 2.8866e-15, 3.2196e-15, 6.2172e-15,\n",
      "         6.2172e-15, 7.9936e-15, 7.9936e-15, 4.8850e-15, 9.3259e-15, 1.7764e-15,\n",
      "         1.0658e-14, 8.2157e-15, 7.1054e-15, 1.6875e-14, 8.8818e-15, 7.1054e-15,\n",
      "         8.2157e-15, 2.6645e-14, 1.4211e-14, 2.9976e-15, 3.9968e-15, 3.1086e-15,\n",
      "         6.2172e-15, 6.2172e-15, 4.8850e-15, 6.6613e-15, 6.6613e-15, 3.2863e-14,\n",
      "         6.4393e-15, 8.8818e-15, 4.7184e-15, 1.0658e-14, 1.2434e-14, 7.7716e-15,\n",
      "         1.5987e-14, 8.8818e-15, 7.1054e-15, 1.1546e-14, 2.1316e-14, 8.5487e-15,\n",
      "         7.9936e-15, 7.5495e-15, 5.8842e-15, 1.4211e-14, 6.2172e-15, 4.4409e-15,\n",
      "         2.6368e-15, 3.0254e-15, 7.1054e-15, 2.2204e-15, 4.6629e-15, 1.0658e-14,\n",
      "         7.7716e-15, 9.7700e-15, 5.5511e-15, 5.3291e-15, 1.0658e-14, 8.8818e-15,\n",
      "         3.1086e-15, 3.7748e-15, 5.1070e-15, 1.1990e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 91: layer3.4.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 91\n",
      "Max diff:\n",
      " tensor([3.2863e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.4286e-16, 1.5543e-15, 1.7764e-15, 4.4409e-15, 1.3878e-16, 9.9920e-16,\n",
      "         0.0000e+00, 5.2180e-15, 0.0000e+00, 9.9920e-16, 0.0000e+00, 2.2204e-15,\n",
      "         0.0000e+00, 2.5396e-15, 1.3323e-15, 1.1796e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9984e-15, 0.0000e+00, 1.4433e-15, 1.1102e-16, 2.5258e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 3.5527e-15,\n",
      "         2.2204e-16, 0.0000e+00, 1.5821e-15, 2.6645e-15, 1.7607e-16, 2.3037e-15,\n",
      "         1.9984e-15, 1.3878e-16, 0.0000e+00, 0.0000e+00, 4.9960e-15, 0.0000e+00,\n",
      "         2.7756e-15, 0.0000e+00, 5.3291e-15, 1.5543e-15, 0.0000e+00, 7.2164e-16,\n",
      "         3.3307e-16, 0.0000e+00, 8.8818e-16, 0.0000e+00, 1.3045e-15, 1.2212e-15,\n",
      "         1.0547e-15, 9.4369e-16, 2.2204e-15, 0.0000e+00, 3.0254e-15, 0.0000e+00,\n",
      "         2.2204e-15, 3.4001e-16, 5.5511e-16, 0.0000e+00, 5.3291e-15, 8.2157e-15,\n",
      "         6.2172e-15, 7.1054e-15, 2.1372e-15, 3.9968e-15, 1.0658e-14, 5.1070e-15,\n",
      "         2.8866e-15, 4.4409e-15, 1.6653e-16, 5.3291e-15, 7.9936e-15, 1.0658e-14,\n",
      "         5.8287e-16, 9.9920e-16, 3.7748e-15, 3.9968e-15, 0.0000e+00, 8.8818e-15,\n",
      "         9.3259e-15, 6.9944e-15, 6.2172e-15, 0.0000e+00, 9.7700e-15, 7.1054e-15,\n",
      "         7.7716e-16, 4.4409e-15, 6.6613e-15, 0.0000e+00, 3.8858e-15, 1.7764e-15,\n",
      "         4.6629e-15, 0.0000e+00, 2.6645e-15, 1.1324e-14, 7.7716e-16, 9.9920e-16,\n",
      "         5.9952e-15, 5.0654e-16, 0.0000e+00, 9.7700e-15, 1.6653e-16, 3.5527e-15,\n",
      "         3.9968e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15, 3.1225e-16, 4.8850e-15,\n",
      "         2.0539e-15, 6.6613e-15, 4.8850e-15, 1.5543e-15, 4.8850e-15, 5.6621e-15,\n",
      "         7.5495e-15, 0.0000e+00, 4.4409e-15, 4.6629e-15, 3.1086e-15, 6.1062e-15,\n",
      "         2.1094e-15, 2.6645e-15, 1.8874e-15, 3.3307e-15, 0.0000e+00, 1.2490e-15,\n",
      "         2.7478e-15, 0.0000e+00, 1.1546e-14, 5.3291e-15, 1.0686e-15, 0.0000e+00,\n",
      "         1.5099e-14, 4.8850e-15, 3.4972e-15, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         7.1054e-15, 0.0000e+00, 5.6621e-15, 7.2164e-16, 1.4211e-14, 4.4409e-15,\n",
      "         9.7700e-15, 2.8866e-15, 1.9429e-15, 3.3307e-16, 3.2196e-15, 6.2172e-15,\n",
      "         4.4409e-15, 5.5511e-15, 5.9952e-15, 0.0000e+00, 1.1102e-15, 2.2204e-15,\n",
      "         3.5527e-15, 6.9389e-15, 4.8572e-15, 0.0000e+00, 7.1054e-15, 0.0000e+00,\n",
      "         2.6645e-14, 6.6613e-16, 2.1094e-15, 8.8818e-15, 1.9984e-15, 9.1038e-15,\n",
      "         9.6589e-15, 7.7716e-15, 0.0000e+00, 0.0000e+00, 6.6613e-15, 0.0000e+00,\n",
      "         0.0000e+00, 3.4972e-15, 0.0000e+00, 4.6629e-15, 2.4425e-15, 1.5543e-15,\n",
      "         7.5495e-15, 3.9968e-15, 1.7764e-14, 9.3259e-15, 2.3870e-15, 3.4417e-15,\n",
      "         9.7700e-15, 2.4869e-14, 8.8818e-15, 2.8866e-15, 3.2196e-15, 6.2172e-15,\n",
      "         6.2172e-15, 7.9936e-15, 7.9936e-15, 4.8850e-15, 9.3259e-15, 1.1657e-15,\n",
      "         1.0658e-14, 8.2157e-15, 7.1054e-15, 1.6875e-14, 8.8818e-15, 7.1054e-15,\n",
      "         8.2157e-15, 2.6645e-14, 1.4211e-14, 1.3878e-15, 3.3307e-15, 3.1086e-15,\n",
      "         6.2172e-15, 6.2172e-15, 4.2188e-15, 6.6613e-15, 6.6613e-15, 3.2863e-14,\n",
      "         4.8850e-15, 8.8818e-15, 2.8866e-15, 1.0658e-14, 1.2434e-14, 7.7716e-15,\n",
      "         1.5987e-14, 8.8818e-15, 7.1054e-15, 1.1546e-14, 2.1316e-14, 8.5487e-15,\n",
      "         7.9936e-15, 7.5495e-15, 5.8842e-15, 1.4211e-14, 6.2172e-15, 4.4409e-15,\n",
      "         2.4425e-15, 3.0254e-15, 5.3291e-15, 2.2204e-15, 4.6629e-15, 1.0658e-14,\n",
      "         7.7716e-15, 9.7700e-15, 2.7200e-15, 5.3291e-15, 1.0658e-14, 8.8818e-15,\n",
      "         5.5511e-16, 3.1086e-15, 5.1070e-15, 1.1990e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   7,   9,  11,  13,  14,  15,  19,  21,\n",
      "         22,  23,  27,  29,  30,  32,  33,  34,  35,  36,  37,  40,  42,  44,\n",
      "         45,  47,  48,  50,  52,  53,  54,  55,  56,  58,  60,  61,  62,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  83,  84,  85,  86,  88,  89,  90,  91,  92,  94,  95,\n",
      "         96,  98,  99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 131, 132, 134, 135, 136, 138, 139, 140, 143, 144, 146,\n",
      "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161,\n",
      "        162, 163, 164, 166, 168, 169, 170, 171, 172, 173, 174, 175, 178, 181,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   7,   9,  11,  13,  14,  15,  19,  21,\n",
      "         22,  23,  27,  29,  30,  32,  33,  34,  35,  36,  37,  40,  42,  44,\n",
      "         45,  47,  48,  50,  52,  53,  54,  55,  56,  58,  60,  61,  62,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  83,  84,  85,  86,  88,  89,  90,  91,  92,  94,  95,\n",
      "         96,  98,  99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 131, 132, 134, 135, 136, 138, 139, 140, 143, 144, 146,\n",
      "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161,\n",
      "        162, 163, 164, 166, 168, 169, 170, 171, 172, 173, 174, 175, 178, 181,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 213)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 92: layer3.5.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 92\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 92\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 92\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 92\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 92\n",
      "Max diff:\n",
      " tensor([3.1264e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 3.1086e-15, 2.6645e-15, 2.2204e-15, 2.6645e-15, 1.0658e-14,\n",
      "         3.5527e-15, 3.1086e-15, 2.2204e-15, 7.1054e-15, 4.4409e-15, 3.5527e-15,\n",
      "         4.4409e-15, 5.3291e-15, 1.2434e-14, 1.7764e-15, 3.1086e-15, 6.2172e-15,\n",
      "         3.5527e-15, 2.6645e-15, 7.1054e-15, 1.4211e-14, 1.2434e-14, 3.5527e-15,\n",
      "         6.2172e-15, 1.0658e-14, 4.4409e-15, 3.9968e-15, 2.2204e-15, 2.6645e-15,\n",
      "         3.5527e-15, 3.1086e-15, 2.2204e-15, 6.2172e-15, 2.8422e-14, 6.2172e-15,\n",
      "         1.7764e-15, 2.2204e-15, 6.2172e-15, 5.3291e-15, 3.5527e-15, 3.1086e-15,\n",
      "         3.5527e-15, 5.3291e-15, 6.2172e-15, 3.5527e-15, 3.9968e-15, 3.1086e-15,\n",
      "         6.2172e-15, 1.7764e-15, 2.8422e-14, 1.5543e-15, 3.5527e-15, 5.3291e-15,\n",
      "         3.5527e-15, 1.4211e-14, 3.5527e-15, 1.3323e-15, 3.5527e-15, 4.4409e-15,\n",
      "         4.4409e-15, 5.3291e-15, 8.8818e-15, 3.9968e-15, 6.3949e-14, 8.5265e-14,\n",
      "         4.2633e-14, 7.1054e-14, 5.6843e-14, 2.1316e-14, 7.1054e-15, 4.9738e-14,\n",
      "         6.2172e-15, 5.7732e-15, 6.2172e-15, 7.1054e-14, 3.5527e-14, 2.4869e-14,\n",
      "         8.8818e-15, 1.4211e-14, 4.2633e-14, 2.8422e-14, 5.3291e-15, 7.9936e-15,\n",
      "         2.1316e-14, 8.5265e-14, 7.1054e-14, 7.1054e-14, 4.9738e-14, 2.4869e-14,\n",
      "         1.2434e-14, 4.9738e-14, 4.9738e-14, 8.5265e-14, 3.1974e-14, 8.8818e-15,\n",
      "         6.2172e-15, 5.3291e-15, 4.9738e-14, 1.4211e-14, 4.9738e-14, 1.1369e-13,\n",
      "         1.2790e-13, 7.1054e-15, 1.2434e-14, 8.5265e-14, 7.9936e-15, 2.1316e-14,\n",
      "         2.4869e-14, 2.1316e-14, 3.1974e-14, 3.5527e-14, 1.1369e-13, 1.1369e-13,\n",
      "         3.9080e-14, 2.1316e-14, 3.1974e-14, 2.4869e-14, 8.5265e-14, 8.8818e-15,\n",
      "         4.2633e-14, 1.4211e-13, 5.3291e-15, 2.8422e-14, 5.3291e-15, 3.9968e-15,\n",
      "         7.8160e-14, 8.5265e-14, 2.4869e-14, 1.4211e-13, 6.3949e-14, 7.8160e-14,\n",
      "         4.9738e-14, 9.9476e-14, 9.9476e-14, 1.2434e-14, 1.5632e-13, 8.5265e-14,\n",
      "         2.8422e-14, 6.3949e-14, 7.1054e-14, 5.6843e-14, 1.5987e-14, 1.4211e-14,\n",
      "         2.4869e-14, 4.9738e-14, 6.2172e-15, 3.1974e-14, 1.1369e-13, 1.4211e-13,\n",
      "         5.6843e-14, 9.9476e-14, 4.9738e-14, 8.5265e-14, 6.3949e-14, 1.1369e-13,\n",
      "         7.4607e-14, 1.5987e-14, 1.2790e-13, 1.4211e-14, 5.6843e-14, 9.9476e-14,\n",
      "         2.4869e-14, 1.2790e-13, 1.7053e-13, 4.2633e-14, 7.1054e-14, 9.9476e-14,\n",
      "         1.7764e-14, 1.1369e-13, 5.6843e-14, 8.5265e-14, 6.3949e-14, 1.4211e-13,\n",
      "         1.0658e-14, 1.2434e-14, 1.1369e-13, 1.4211e-13, 2.8422e-14, 7.8160e-14,\n",
      "         1.5632e-13, 3.5527e-14, 6.2172e-15, 6.3949e-14, 5.6843e-14, 4.7073e-14,\n",
      "         4.2633e-14, 8.5265e-14, 6.2172e-15, 8.5265e-14, 8.5265e-14, 1.0658e-13,\n",
      "         8.5265e-14, 1.9895e-13, 5.6843e-14, 7.1054e-14, 1.1369e-13, 1.2790e-13,\n",
      "         4.2633e-14, 7.1054e-14, 1.5632e-13, 9.9476e-14, 5.6843e-14, 5.6843e-14,\n",
      "         5.3291e-14, 7.1054e-14, 1.2790e-13, 9.9476e-14, 9.9476e-14, 3.5527e-14,\n",
      "         5.6843e-14, 1.4211e-13, 7.1054e-14, 7.1054e-14, 9.2371e-14, 9.9476e-14,\n",
      "         6.3949e-14, 2.5580e-13, 3.1264e-13, 7.8160e-14, 5.6843e-14, 7.1054e-14,\n",
      "         1.4211e-13, 7.1054e-14, 9.9476e-14, 6.3949e-14, 9.9476e-14, 1.1369e-13,\n",
      "         4.9738e-14, 9.9476e-14, 5.6843e-14, 1.8474e-13, 9.2371e-14, 1.2790e-13,\n",
      "         1.1369e-13, 2.2737e-13, 1.2790e-13, 1.9895e-13, 4.0856e-14, 9.9476e-14,\n",
      "         4.9738e-14, 2.2737e-13, 1.7053e-13, 8.5265e-14, 8.5265e-14, 7.1054e-14,\n",
      "         8.5265e-14, 1.1369e-13, 1.0658e-13, 1.2790e-13, 1.9185e-13, 7.8160e-14,\n",
      "         1.8474e-13, 6.7502e-14, 8.5265e-14, 7.1054e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 93: layer3.5.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 93\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 93\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 93\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 93\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 93\n",
      "Max diff:\n",
      " tensor([1.1369e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 8.8818e-16, 6.6613e-16, 5.5511e-16, 7.7716e-16, 3.1086e-15,\n",
      "         8.8818e-16, 8.8818e-16, 8.8818e-16, 1.9984e-15, 1.3323e-15, 9.9920e-16,\n",
      "         1.1102e-15, 1.5543e-15, 2.6645e-15, 5.5511e-16, 9.9920e-16, 1.9984e-15,\n",
      "         8.8818e-16, 6.6613e-16, 1.9984e-15, 4.4409e-15, 3.1086e-15, 1.1102e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.3323e-15, 1.1102e-15, 6.6613e-16, 8.8818e-16,\n",
      "         1.1102e-15, 8.8818e-16, 6.6613e-16, 1.7764e-15, 8.8818e-15, 1.7764e-15,\n",
      "         6.6613e-16, 6.6613e-16, 1.7764e-15, 1.5543e-15, 9.9920e-16, 8.8818e-16,\n",
      "         9.9920e-16, 1.7764e-15, 1.5543e-15, 1.1102e-15, 1.1102e-15, 8.8818e-16,\n",
      "         1.7764e-15, 5.5511e-16, 8.8818e-15, 4.4409e-16, 1.1102e-15, 1.5543e-15,\n",
      "         1.1102e-15, 3.5527e-15, 1.1102e-15, 4.4409e-16, 9.9920e-16, 1.2212e-15,\n",
      "         1.3323e-15, 1.5543e-15, 2.2204e-15, 9.9920e-16, 1.4211e-14, 2.1316e-14,\n",
      "         7.9936e-15, 1.5987e-14, 1.2434e-14, 5.3291e-15, 2.2204e-15, 1.5987e-14,\n",
      "         1.7764e-15, 1.8874e-15, 2.2204e-15, 2.1316e-14, 8.8818e-15, 7.9936e-15,\n",
      "         3.1086e-15, 4.4409e-15, 1.0658e-14, 7.1054e-15, 1.7764e-15, 2.6645e-15,\n",
      "         5.3291e-15, 2.4869e-14, 2.1316e-14, 2.4869e-14, 1.4211e-14, 8.8818e-15,\n",
      "         3.5527e-15, 1.2434e-14, 1.2434e-14, 1.4211e-14, 8.8818e-15, 2.6645e-15,\n",
      "         1.9984e-15, 1.7764e-15, 1.2434e-14, 3.5527e-15, 6.2172e-15, 2.4869e-14,\n",
      "         3.5527e-14, 2.2204e-15, 4.4409e-15, 1.9540e-14, 2.4425e-15, 6.2172e-15,\n",
      "         6.2172e-15, 5.3291e-15, 7.9936e-15, 1.0658e-14, 3.5527e-14, 2.4869e-14,\n",
      "         1.2434e-14, 5.3291e-15, 8.8818e-15, 7.9936e-15, 2.1316e-14, 2.6645e-15,\n",
      "         7.9936e-15, 3.9080e-14, 1.5543e-15, 8.8818e-15, 1.5543e-15, 1.1102e-15,\n",
      "         2.6645e-14, 1.5987e-14, 8.8818e-15, 2.8422e-14, 1.9540e-14, 2.1316e-14,\n",
      "         1.2434e-14, 1.9540e-14, 1.7764e-14, 3.1086e-15, 4.9738e-14, 1.4211e-14,\n",
      "         7.9936e-15, 9.7700e-15, 1.4211e-14, 1.5987e-14, 6.2172e-15, 4.4409e-15,\n",
      "         6.2172e-15, 1.2434e-14, 1.7764e-15, 7.9936e-15, 3.5527e-14, 2.8422e-14,\n",
      "         1.4211e-14, 1.4211e-14, 5.3291e-15, 1.4211e-14, 2.4869e-14, 3.1974e-14,\n",
      "         1.5543e-14, 4.8850e-15, 3.5527e-14, 4.4409e-15, 1.7764e-14, 4.2633e-14,\n",
      "         7.1054e-15, 2.4869e-14, 5.6843e-14, 1.0658e-14, 2.3093e-14, 2.8422e-14,\n",
      "         6.2172e-15, 4.9738e-14, 1.4211e-14, 2.1316e-14, 1.7764e-14, 4.9738e-14,\n",
      "         3.5527e-15, 4.4409e-15, 2.4869e-14, 3.1974e-14, 8.8818e-15, 2.1316e-14,\n",
      "         3.1974e-14, 7.1054e-15, 1.9984e-15, 1.7764e-14, 7.1054e-15, 8.2157e-15,\n",
      "         1.0658e-14, 2.1316e-14, 2.2204e-15, 3.0198e-14, 2.4869e-14, 1.9540e-14,\n",
      "         2.1316e-14, 4.9738e-14, 1.5987e-14, 1.7764e-14, 2.1316e-14, 2.8422e-14,\n",
      "         4.8850e-15, 1.7764e-14, 3.9080e-14, 2.1316e-14, 1.2434e-14, 1.7764e-14,\n",
      "         1.3323e-14, 2.4869e-14, 2.1316e-14, 1.7764e-14, 2.3093e-14, 1.7764e-14,\n",
      "         1.1990e-14, 4.6185e-14, 2.8422e-14, 1.4211e-14, 2.1316e-14, 2.3093e-14,\n",
      "         1.2434e-14, 7.1054e-14, 1.0658e-13, 1.7764e-14, 1.4211e-14, 1.4211e-14,\n",
      "         3.5527e-14, 2.1316e-14, 2.4869e-14, 1.0658e-14, 2.8422e-14, 4.2633e-14,\n",
      "         9.3259e-15, 1.7764e-14, 1.0658e-14, 5.6843e-14, 1.7764e-14, 3.1974e-14,\n",
      "         3.1974e-14, 1.1369e-13, 3.5527e-14, 6.3949e-14, 5.4401e-15, 3.1974e-14,\n",
      "         1.1990e-14, 9.2371e-14, 6.3949e-14, 1.4211e-14, 1.7764e-14, 2.4869e-14,\n",
      "         2.1316e-14, 2.3093e-14, 2.3093e-14, 3.5527e-14, 4.9738e-14, 2.3093e-14,\n",
      "         4.9738e-14, 1.1546e-14, 3.9080e-14, 1.5987e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 94: layer3.5.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 94\n",
      "Max diff:\n",
      " tensor([1.1990e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6056e-15,\n",
      "         0.0000e+00, 2.1094e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3028e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2188e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1546e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8874e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.2172e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.8866e-15, 0.0000e+00, 7.9936e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.7748e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         5.3291e-15, 0.0000e+00, 8.8818e-15, 1.3323e-15, 0.0000e+00, 0.0000e+00,\n",
      "         4.8850e-15, 1.1990e-14, 3.5527e-15, 0.0000e+00, 4.4409e-15, 0.0000e+00,\n",
      "         3.5527e-15, 1.0658e-14, 5.3291e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.1054e-15, 4.4409e-16, 0.0000e+00, 9.1038e-15, 1.0214e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5535e-15, 3.1086e-15, 4.4409e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4817e-15, 0.0000e+00, 0.0000e+00,\n",
      "         9.3259e-15, 0.0000e+00, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 0.0000e+00,\n",
      "         1.1990e-14, 0.0000e+00, 0.0000e+00, 3.7748e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.5049e-15, 7.1054e-15, 0.0000e+00, 7.7716e-15, 3.5527e-15,\n",
      "         0.0000e+00, 1.1546e-14, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 65,  67, 102, 126, 131, 136, 145, 150, 156, 158, 180, 185, 191, 192,\n",
      "        194, 195, 198, 199, 200, 202, 204, 205, 206, 210, 211, 213, 214, 219,\n",
      "        220, 221, 225, 228, 230, 238, 240, 243, 247, 248, 250, 251, 253])\n",
      "\n",
      "failing Cout = tensor([ 65,  67, 102, 126, 131, 136, 145, 150, 156, 158, 180, 185, 191, 192,\n",
      "        194, 195, 198, 199, 200, 202, 204, 205, 206, 210, 211, 213, 214, 219,\n",
      "        220, 221, 225, 228, 230, 238, 240, 243, 247, 248, 250, 251, 253])  (len = 41)\n",
      "passing Cout = tensor([215])  (len = 1)\n",
      "\n",
      "Executing module 95: layer3.5.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 95\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 95\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  6,  8,  9, 10, 13, 14, 17, 18, 19, 20, 21, 22, 23,\n",
      "        25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46,\n",
      "        47, 49, 50, 52, 53, 54, 55, 57, 58, 60, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "        144, 145, 147, 148, 149, 151, 152, 153, 155, 156, 157, 158, 160, 161,\n",
      "        163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177,\n",
      "        178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234,\n",
      "        236, 237, 238, 239, 240, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 95\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        56, 58, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 95\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 95\n",
      "Max diff:\n",
      " tensor([1.2434e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 6.2172e-15, 5.3291e-15, 1.5543e-15, 3.0254e-15, 2.2204e-15,\n",
      "         2.1094e-15, 5.7732e-15, 2.1649e-15, 4.0523e-15, 3.3307e-15, 5.5511e-15,\n",
      "         2.7756e-16, 3.5527e-15, 4.3854e-15, 3.9968e-15, 2.7756e-16, 3.1086e-15,\n",
      "         1.6653e-16, 4.4409e-15, 3.3307e-15, 5.1070e-15, 1.2434e-14, 4.4409e-15,\n",
      "         1.9429e-16, 1.8874e-15, 2.8866e-15, 3.1086e-15, 3.7748e-15, 3.4694e-15,\n",
      "         3.9968e-15, 3.9968e-15, 1.4433e-15, 5.3291e-15, 1.7764e-15, 3.9968e-15,\n",
      "         6.2172e-15, 4.1078e-15, 4.4964e-15, 1.9429e-16, 6.2172e-15, 4.4409e-16,\n",
      "         1.7764e-15, 1.9429e-16, 4.3299e-15, 7.1054e-15, 1.2490e-16, 5.7732e-15,\n",
      "         5.7732e-15, 4.4409e-15, 7.1054e-15, 2.7756e-16, 4.4409e-15, 8.8818e-15,\n",
      "         4.2188e-15, 3.5527e-15, 4.2188e-15, 2.6645e-15, 2.6645e-15, 4.4409e-15,\n",
      "         4.6629e-15, 2.6645e-15, 8.8818e-15, 3.3307e-16, 4.8850e-15, 6.6613e-15,\n",
      "         5.7732e-15, 3.7748e-15, 5.3291e-15, 3.5527e-15, 3.8997e-15, 7.9936e-15,\n",
      "         5.2180e-15, 4.8850e-15, 4.8850e-15, 5.5511e-15, 7.1054e-15, 7.1054e-15,\n",
      "         8.8818e-15, 5.1764e-15, 4.7184e-15, 7.9936e-15, 5.3291e-15, 6.2172e-15,\n",
      "         8.4377e-15, 6.2172e-15, 2.7756e-15, 8.8818e-15, 5.2180e-15, 8.8818e-15,\n",
      "         8.8818e-15, 4.4409e-15, 6.9944e-15, 5.3291e-15, 7.1054e-15, 1.1102e-14,\n",
      "         3.9968e-15, 1.0658e-14, 7.9936e-15, 1.0658e-14, 5.3291e-15, 5.9952e-15,\n",
      "         5.1070e-15, 9.1038e-15, 9.3259e-15, 6.2172e-15, 6.2172e-15, 5.2180e-15,\n",
      "         4.8850e-15, 1.0658e-14, 5.9952e-15, 8.8818e-15, 7.1054e-15, 4.4409e-15,\n",
      "         4.4409e-15, 7.1054e-15, 6.2172e-15, 7.9936e-15, 4.4409e-15, 7.7716e-15,\n",
      "         7.1054e-15, 2.8866e-15, 5.4401e-15, 9.3259e-15, 8.8818e-15, 7.1054e-15,\n",
      "         9.3259e-15, 7.1054e-15, 1.2434e-14, 7.5495e-15, 6.2172e-15, 8.4377e-15,\n",
      "         7.9936e-15, 7.1054e-15, 7.9936e-15, 7.8826e-15, 7.1054e-15, 7.0777e-15,\n",
      "         1.2434e-14, 5.7732e-15, 5.3291e-15, 1.0658e-14, 6.2172e-15, 7.7993e-15,\n",
      "         7.7716e-15, 1.0658e-14, 1.0658e-14, 1.0658e-14, 7.2720e-15, 7.9936e-15,\n",
      "         7.2442e-15, 7.9936e-15, 7.1054e-15, 1.1546e-14, 5.7732e-15, 8.4655e-15,\n",
      "         1.2434e-14, 6.2172e-15, 5.7454e-15, 5.7732e-15, 6.2172e-15, 7.5495e-15,\n",
      "         6.2172e-15, 7.1054e-15, 1.0658e-14, 5.3291e-15, 1.0658e-14, 7.9936e-15,\n",
      "         7.1054e-15, 4.8850e-15, 1.2434e-14, 8.8818e-15, 7.1054e-15, 7.9936e-15,\n",
      "         9.7700e-15, 8.7708e-15, 8.8818e-15, 8.8818e-15, 9.3259e-15, 6.4393e-15,\n",
      "         8.4377e-15, 7.5495e-15, 5.3291e-15, 7.3275e-15, 6.6613e-15, 6.6613e-15,\n",
      "         7.9936e-15, 9.7700e-15, 8.8818e-15, 8.8818e-15, 6.2172e-15, 9.7700e-15,\n",
      "         8.8818e-15, 8.8818e-15, 7.1054e-15, 7.1054e-15, 6.4393e-15, 7.9936e-15,\n",
      "         8.4377e-15, 1.0214e-14, 1.2434e-14, 7.5495e-15, 7.1054e-15, 1.2434e-14,\n",
      "         4.6629e-15, 7.1054e-15, 6.2172e-15, 8.8818e-15, 7.9936e-15, 6.8834e-15,\n",
      "         6.6613e-15, 1.1546e-14, 1.2434e-14, 6.2172e-15, 1.0658e-14, 9.7700e-15,\n",
      "         9.7700e-15, 1.1990e-14, 7.1054e-15, 8.6597e-15, 1.0658e-14, 7.7716e-15,\n",
      "         7.9936e-15, 9.7700e-15, 8.8818e-15, 9.1038e-15, 1.0658e-14, 7.1054e-15,\n",
      "         6.2172e-15, 7.1054e-15, 7.9936e-15, 5.3291e-15, 8.8818e-15, 1.0658e-14,\n",
      "         5.4401e-15, 9.3259e-15, 7.5495e-15, 1.0658e-14, 7.9936e-15, 7.1054e-15,\n",
      "         7.9936e-15, 7.1054e-15, 8.4377e-15, 8.8818e-15, 6.2172e-15, 1.1102e-14,\n",
      "         1.1546e-14, 5.3291e-15, 1.0658e-14, 7.9936e-15, 8.8818e-15, 8.6597e-15,\n",
      "         1.0658e-14, 9.3259e-15, 1.0658e-14, 1.0103e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 96: layer3.5.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 96\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 96\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 96\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 96\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 96\n",
      "Max diff:\n",
      " tensor([6.2172e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 2.2204e-15, 1.5543e-15, 3.0531e-16, 2.7756e-17, 8.3267e-17,\n",
      "         5.5511e-16, 1.2768e-15, 3.0531e-16, 7.7716e-16, 5.5511e-16, 1.2212e-15,\n",
      "         8.3267e-17, 1.9984e-15, 7.0777e-16, 1.5543e-15, 1.1102e-16, 5.5511e-17,\n",
      "         5.5511e-17, 1.7764e-15, 8.8818e-16, 3.8858e-16, 3.5527e-15, 1.7764e-15,\n",
      "         6.9389e-17, 4.7184e-16, 1.1102e-15, 5.5511e-16, 8.8818e-16, 5.1348e-16,\n",
      "         1.1102e-15, 2.7756e-16, 1.5266e-16, 1.1102e-15, 6.6613e-16, 8.8818e-16,\n",
      "         3.7748e-15, 8.0491e-16, 2.7756e-17, 6.2450e-17, 1.1102e-15, 1.3878e-16,\n",
      "         2.4113e-16, 6.9389e-17, 8.8818e-16, 1.3323e-15, 4.1633e-17, 2.3315e-15,\n",
      "         1.5543e-15, 1.2212e-15, 1.7764e-15, 8.3267e-17, 1.0825e-15, 2.2204e-15,\n",
      "         1.1102e-15, 6.6613e-16, 9.9920e-16, 2.2204e-16, 8.8818e-16, 1.1102e-15,\n",
      "         1.0547e-15, 8.8818e-16, 3.5527e-15, 1.3878e-16, 8.3267e-16, 1.2212e-15,\n",
      "         1.3878e-15, 6.1062e-16, 8.8818e-16, 3.8858e-16, 7.4940e-16, 1.1102e-15,\n",
      "         8.8905e-16, 1.2212e-15, 1.1102e-15, 7.7716e-16, 1.3323e-15, 2.2760e-15,\n",
      "         8.8818e-16, 1.5543e-15, 8.2573e-16, 2.8866e-15, 1.3323e-15, 1.7764e-15,\n",
      "         2.4980e-15, 7.7716e-16, 3.5041e-16, 3.5527e-15, 3.1919e-16, 1.5543e-15,\n",
      "         3.5527e-15, 1.0547e-15, 9.3675e-16, 2.4425e-15, 1.5543e-15, 1.3323e-15,\n",
      "         8.8818e-16, 3.9968e-15, 3.9968e-15, 1.9984e-15, 2.1094e-15, 8.1879e-16,\n",
      "         1.1102e-15, 1.5786e-15, 8.8818e-16, 1.5543e-15, 1.7764e-15, 1.7764e-15,\n",
      "         8.7430e-16, 8.8818e-16, 1.9429e-15, 1.7764e-15, 2.2204e-15, 8.8818e-16,\n",
      "         8.3267e-16, 2.0539e-15, 8.3267e-16, 1.5543e-15, 8.8818e-16, 2.8866e-15,\n",
      "         1.3323e-15, 1.9429e-16, 2.4980e-16, 3.1086e-15, 9.4369e-16, 1.7764e-15,\n",
      "         2.3315e-15, 2.4980e-16, 5.3291e-15, 2.8866e-15, 3.1086e-15, 3.5527e-15,\n",
      "         3.9968e-15, 3.1086e-15, 2.7756e-15, 3.7748e-15, 3.1086e-15, 3.1086e-15,\n",
      "         4.8850e-15, 2.4425e-15, 1.7764e-15, 7.7716e-16, 6.6613e-16, 3.9968e-15,\n",
      "         1.4988e-15, 2.2204e-15, 3.1086e-15, 4.3299e-15, 2.5466e-15, 1.9984e-15,\n",
      "         1.3878e-15, 2.4425e-15, 1.9984e-15, 5.7732e-15, 6.6613e-16, 4.1633e-15,\n",
      "         6.2172e-15, 2.4425e-15, 2.3315e-15, 4.4409e-16, 1.3323e-15, 2.7756e-15,\n",
      "         4.9960e-16, 4.4409e-15, 3.5527e-15, 1.7764e-15, 4.8850e-15, 3.9968e-15,\n",
      "         3.9968e-15, 1.3323e-15, 3.9968e-15, 4.2188e-15, 2.4425e-15, 1.6653e-15,\n",
      "         5.9952e-15, 4.8850e-15, 1.9984e-15, 3.5527e-15, 2.2204e-15, 1.9984e-15,\n",
      "         1.8874e-15, 1.8874e-15, 2.6645e-15, 1.7764e-15, 3.3307e-15, 1.4433e-15,\n",
      "         3.1086e-15, 3.1086e-15, 2.6645e-15, 3.5527e-15, 1.7764e-15, 2.4425e-15,\n",
      "         2.1649e-15, 1.7764e-15, 1.7764e-15, 6.6613e-16, 1.4433e-15, 1.1657e-15,\n",
      "         2.3315e-15, 2.7756e-15, 1.9984e-15, 1.9984e-15, 1.1102e-15, 2.6645e-15,\n",
      "         5.5511e-16, 2.8866e-15, 1.1102e-15, 1.5543e-15, 1.2212e-15, 1.4572e-15,\n",
      "         9.4369e-16, 4.3299e-15, 3.5527e-15, 1.9984e-15, 3.5527e-15, 2.2204e-15,\n",
      "         1.5543e-15, 5.1070e-15, 1.3323e-15, 2.1094e-15, 1.9984e-15, 2.1094e-15,\n",
      "         1.3323e-15, 2.3315e-15, 2.3870e-15, 2.2204e-15, 2.2204e-15, 1.7764e-15,\n",
      "         4.1633e-16, 1.3323e-15, 2.2204e-15, 6.6613e-16, 9.9920e-16, 2.5535e-15,\n",
      "         9.5063e-16, 1.7764e-15, 1.1657e-15, 2.6645e-15, 1.1102e-15, 1.4433e-15,\n",
      "         2.2204e-15, 2.2204e-15, 2.9976e-15, 8.8818e-16, 1.9984e-15, 3.1086e-15,\n",
      "         1.9984e-15, 8.8818e-16, 3.5527e-15, 1.7764e-15, 1.3323e-15, 1.0963e-15,\n",
      "         2.2204e-15, 1.2212e-15, 3.1086e-15, 1.8492e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 97: layer3.5.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 97\n",
      "Max diff:\n",
      " tensor([3.3751e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 2.4425e-15, 1.8319e-15, 4.4964e-15, 1.3878e-16, 9.9920e-16,\n",
      "         5.5511e-16, 5.7732e-15, 3.0531e-16, 8.3267e-16, 5.5511e-16, 1.8874e-15,\n",
      "         8.3267e-17, 2.6645e-15, 1.0270e-15, 1.5543e-15, 1.1102e-16, 5.5511e-17,\n",
      "         5.5511e-17, 3.7748e-15, 8.8818e-16, 1.3323e-15, 3.5527e-15, 2.3315e-15,\n",
      "         6.9389e-17, 4.7184e-16, 1.1102e-15, 6.6613e-16, 8.8818e-16, 3.8858e-15,\n",
      "         1.1102e-15, 2.7756e-16, 1.4710e-15, 3.1086e-15, 6.6613e-16, 2.3037e-15,\n",
      "         4.2188e-15, 8.0491e-16, 2.7756e-17, 6.2450e-17, 5.3291e-15, 1.3878e-16,\n",
      "         2.7756e-15, 6.9389e-17, 5.4401e-15, 1.7764e-15, 4.1633e-17, 2.3315e-15,\n",
      "         1.5543e-15, 1.2212e-15, 1.7764e-15, 8.3267e-17, 1.9429e-15, 2.2204e-15,\n",
      "         1.1102e-15, 7.2164e-16, 3.2196e-15, 2.2204e-16, 3.0531e-15, 1.1102e-15,\n",
      "         2.3315e-15, 8.8818e-16, 3.5527e-15, 1.3878e-16, 5.7732e-15, 7.9936e-15,\n",
      "         6.6613e-15, 7.1054e-15, 2.1927e-15, 3.9968e-15, 1.2434e-14, 5.1070e-15,\n",
      "         2.7756e-15, 4.4409e-15, 1.1102e-15, 4.8850e-15, 7.9936e-15, 8.8818e-15,\n",
      "         1.1102e-15, 1.5543e-15, 3.9968e-15, 5.1070e-15, 1.3323e-15, 8.8818e-15,\n",
      "         7.9936e-15, 7.0222e-15, 6.2172e-15, 3.5527e-15, 9.7700e-15, 6.9944e-15,\n",
      "         3.5527e-15, 4.2188e-15, 6.4393e-15, 2.4425e-15, 3.5527e-15, 2.4980e-15,\n",
      "         4.6629e-15, 3.9968e-15, 3.9968e-15, 1.1990e-14, 2.1094e-15, 9.9920e-16,\n",
      "         6.2172e-15, 1.5786e-15, 8.8818e-16, 9.7700e-15, 1.7764e-15, 3.5527e-15,\n",
      "         3.9968e-15, 5.2180e-15, 5.3291e-15, 6.8834e-15, 2.2204e-15, 4.8850e-15,\n",
      "         1.7764e-15, 6.8834e-15, 4.8850e-15, 1.7764e-15, 4.4409e-15, 6.4393e-15,\n",
      "         7.1054e-15, 1.9429e-16, 4.4409e-15, 5.3291e-15, 3.1086e-15, 5.9952e-15,\n",
      "         2.8866e-15, 2.6645e-15, 5.3291e-15, 5.1070e-15, 3.1086e-15, 3.5527e-15,\n",
      "         3.9968e-15, 3.1086e-15, 1.2434e-14, 6.8834e-15, 3.1086e-15, 3.1086e-15,\n",
      "         1.5765e-14, 3.9968e-15, 4.1078e-15, 7.7716e-16, 6.6613e-16, 7.1054e-15,\n",
      "         7.1054e-15, 2.2204e-15, 5.9952e-15, 4.3299e-15, 1.5099e-14, 6.2172e-15,\n",
      "         9.7700e-15, 3.3307e-15, 2.3870e-15, 5.7732e-15, 2.9976e-15, 7.5495e-15,\n",
      "         7.1054e-15, 5.3291e-15, 6.4393e-15, 4.4409e-16, 1.3323e-15, 3.1086e-15,\n",
      "         3.5527e-15, 6.8834e-15, 4.8850e-15, 1.7764e-15, 7.9936e-15, 3.9968e-15,\n",
      "         2.6645e-14, 1.3323e-15, 4.8850e-15, 8.8818e-15, 2.4425e-15, 9.4369e-15,\n",
      "         1.0214e-14, 8.4377e-15, 1.9984e-15, 3.5527e-15, 7.1054e-15, 1.9984e-15,\n",
      "         1.8874e-15, 3.9413e-15, 2.6645e-15, 5.3291e-15, 3.3307e-15, 2.2204e-15,\n",
      "         9.7700e-15, 5.2180e-15, 1.8208e-14, 1.0214e-14, 2.9976e-15, 4.3299e-15,\n",
      "         9.7700e-15, 2.3093e-14, 8.8818e-15, 3.1641e-15, 2.7756e-15, 5.3291e-15,\n",
      "         8.4377e-15, 7.1054e-15, 7.9936e-15, 5.3291e-15, 9.7700e-15, 2.6645e-15,\n",
      "         1.0658e-14, 8.8818e-15, 7.7716e-15, 1.7764e-14, 8.6597e-15, 7.3275e-15,\n",
      "         8.6597e-15, 2.7534e-14, 1.4211e-14, 2.4425e-15, 4.4409e-15, 3.9968e-15,\n",
      "         6.2172e-15, 8.4377e-15, 4.6629e-15, 6.8834e-15, 6.8834e-15, 3.3751e-14,\n",
      "         4.8850e-15, 8.8818e-15, 3.7748e-15, 1.0658e-14, 1.2434e-14, 7.1054e-15,\n",
      "         1.5987e-14, 9.3259e-15, 7.7716e-15, 1.2434e-14, 2.1316e-14, 1.1102e-14,\n",
      "         7.5495e-15, 8.6597e-15, 5.2736e-15, 1.5987e-14, 5.9952e-15, 4.4409e-15,\n",
      "         3.3307e-15, 3.9968e-15, 7.1054e-15, 2.4425e-15, 4.2188e-15, 1.1102e-14,\n",
      "         8.3267e-15, 9.7700e-15, 3.5527e-15, 5.3291e-15, 1.0658e-14, 8.8818e-15,\n",
      "         2.2204e-15, 2.6645e-15, 5.5511e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 98: layer3.5.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 98\n",
      "Max diff:\n",
      " tensor([3.3751e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 2.4425e-15, 1.8319e-15, 4.4964e-15, 0.0000e+00, 9.9920e-16,\n",
      "         0.0000e+00, 4.4409e-15, 0.0000e+00, 8.3267e-16, 1.6653e-16, 1.8874e-15,\n",
      "         0.0000e+00, 2.6645e-15, 3.0531e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-15, 4.4409e-16, 1.1102e-15, 0.0000e+00, 1.9984e-15,\n",
      "         0.0000e+00, 5.5511e-17, 0.0000e+00, 6.6613e-16, 6.7307e-16, 3.8858e-15,\n",
      "         2.2204e-16, 8.3267e-17, 1.4710e-15, 3.1086e-15, 2.2204e-16, 1.1102e-15,\n",
      "         2.3870e-15, 7.7716e-16, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         2.7756e-15, 0.0000e+00, 5.4401e-15, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         1.5543e-15, 3.0531e-16, 0.0000e+00, 0.0000e+00, 1.5543e-15, 1.1657e-15,\n",
      "         1.1102e-15, 2.2204e-16, 3.2196e-15, 3.2960e-17, 3.0531e-15, 0.0000e+00,\n",
      "         2.3315e-15, 8.8818e-16, 0.0000e+00, 0.0000e+00, 5.7732e-15, 2.2204e-15,\n",
      "         6.6613e-15, 7.1054e-15, 1.5543e-15, 3.9968e-15, 1.2434e-14, 5.1070e-15,\n",
      "         2.7756e-15, 4.4409e-15, 7.4940e-16, 4.8850e-15, 7.9936e-15, 8.8818e-15,\n",
      "         1.2490e-16, 8.8818e-16, 3.9968e-15, 4.4409e-15, 8.3267e-17, 8.8818e-15,\n",
      "         7.9936e-15, 7.0222e-15, 6.2172e-15, 9.9920e-16, 9.7700e-15, 6.9944e-15,\n",
      "         1.2768e-15, 4.2188e-15, 6.4393e-15, 9.7145e-16, 3.5527e-15, 2.4980e-15,\n",
      "         4.6629e-15, 2.7756e-15, 2.8311e-15, 1.1990e-14, 2.1094e-15, 9.9920e-16,\n",
      "         6.2172e-15, 1.5786e-15, 3.3480e-16, 9.7700e-15, 0.0000e+00, 3.5527e-15,\n",
      "         3.9968e-15, 5.2180e-15, 5.3291e-15, 6.6613e-15, 8.8818e-16, 4.8850e-15,\n",
      "         1.6653e-15, 6.8834e-15, 4.8850e-15, 8.3267e-17, 4.4409e-15, 6.4393e-15,\n",
      "         0.0000e+00, 1.3878e-16, 4.4409e-15, 5.3291e-15, 3.1086e-15, 4.4409e-15,\n",
      "         1.4433e-15, 2.4425e-15, 0.0000e+00, 5.1070e-15, 1.6653e-15, 3.2196e-15,\n",
      "         3.5527e-15, 1.6653e-15, 1.2434e-14, 3.1086e-15, 9.1593e-16, 2.0331e-15,\n",
      "         1.5765e-14, 3.9968e-15, 3.5527e-15, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         7.1054e-15, 0.0000e+00, 4.4409e-15, 4.3299e-15, 1.5099e-14, 3.5527e-15,\n",
      "         9.7700e-15, 3.3307e-15, 2.3870e-15, 1.5543e-15, 2.9976e-15, 7.5495e-15,\n",
      "         4.6629e-15, 5.3291e-15, 6.4393e-15, 0.0000e+00, 0.0000e+00, 3.1086e-15,\n",
      "         3.5527e-15, 0.0000e+00, 3.1086e-15, 4.4409e-16, 7.9936e-15, 1.2212e-15,\n",
      "         2.6645e-14, 6.6613e-16, 2.1094e-15, 8.8818e-15, 2.2204e-15, 9.4369e-15,\n",
      "         8.8818e-15, 8.4377e-15, 6.3838e-16, 4.9960e-16, 7.1054e-15, 1.2768e-15,\n",
      "         4.8572e-16, 2.6645e-15, 0.0000e+00, 5.3291e-15, 1.7208e-15, 5.5511e-16,\n",
      "         9.7700e-15, 5.2180e-15, 1.8208e-14, 1.0214e-14, 6.1062e-16, 2.2204e-15,\n",
      "         9.7700e-15, 2.3093e-14, 8.8818e-15, 2.6645e-15, 2.6645e-15, 5.3291e-15,\n",
      "         8.4377e-15, 7.1054e-15, 7.9936e-15, 5.3291e-15, 9.7700e-15, 1.9429e-16,\n",
      "         1.0658e-14, 8.8818e-15, 7.7716e-15, 1.7764e-14, 8.6597e-15, 3.9968e-15,\n",
      "         8.6597e-15, 2.7534e-14, 1.4211e-14, 2.4425e-15, 1.5266e-15, 3.9968e-15,\n",
      "         6.2172e-15, 8.4377e-15, 4.6629e-15, 6.8834e-15, 6.8834e-15, 3.3751e-14,\n",
      "         4.8850e-15, 8.8818e-15, 3.7748e-15, 1.0658e-14, 1.2434e-14, 7.1054e-15,\n",
      "         1.5987e-14, 9.3259e-15, 7.7716e-15, 1.2434e-14, 2.1316e-14, 4.4409e-15,\n",
      "         7.5495e-15, 2.4425e-15, 2.6645e-15, 1.5987e-14, 5.9952e-15, 4.4409e-15,\n",
      "         2.6645e-15, 2.8866e-15, 7.1054e-15, 2.4425e-15, 4.2188e-15, 1.1102e-14,\n",
      "         7.1054e-15, 9.7700e-15, 3.3307e-15, 5.3291e-15, 1.0658e-14, 8.8818e-15,\n",
      "         6.8695e-16, 2.6645e-15, 4.4409e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   5,   7,   9,  10,  11,  13,  14,  19,  20,  21,\n",
      "         23,  25,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  40,\n",
      "         42,  44,  47,  48,  49,  52,  53,  54,  55,  56,  57,  58,  60,  61,\n",
      "         64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121,\n",
      "        122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 161, 162, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   5,   7,   9,  10,  11,  13,  14,  19,  20,  21,\n",
      "         23,  25,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  40,\n",
      "         42,  44,  47,  48,  49,  52,  53,  54,  55,  56,  57,  58,  60,  61,\n",
      "         64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121,\n",
      "        122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 161, 162, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 224)\n",
      "passing Cout = tensor([45])  (len = 1)\n",
      "\n",
      "Executing module 99: layer3.6.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 99\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 99\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 99\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 99\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 99\n",
      "Max diff:\n",
      " tensor([1.9895e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.6645e-15, 3.5527e-15, 2.2204e-15, 6.2172e-15, 1.2434e-14, 8.8818e-15,\n",
      "         7.1054e-15, 7.9936e-15, 2.8422e-14, 5.3291e-15, 2.8422e-14, 7.9936e-15,\n",
      "         6.2172e-15, 2.6645e-15, 3.1086e-15, 3.5527e-15, 6.2172e-15, 7.9936e-15,\n",
      "         2.6645e-15, 6.2172e-15, 3.1086e-15, 4.4409e-15, 3.1086e-15, 7.1054e-15,\n",
      "         3.1086e-15, 6.2172e-15, 3.1086e-15, 2.8422e-14, 8.8818e-15, 4.4409e-15,\n",
      "         3.5527e-15, 2.8422e-14, 2.6645e-15, 7.1054e-15, 7.1054e-15, 6.2172e-15,\n",
      "         4.4409e-15, 2.6645e-15, 3.5527e-14, 3.1086e-15, 4.4409e-15, 1.7764e-14,\n",
      "         3.9968e-15, 2.1316e-14, 2.6645e-15, 4.4409e-15, 7.9936e-15, 2.8422e-14,\n",
      "         3.5527e-15, 1.2434e-14, 2.6645e-15, 3.5527e-15, 2.6645e-15, 1.0658e-14,\n",
      "         2.6645e-15, 2.6645e-15, 3.5527e-15, 2.6645e-15, 6.2172e-15, 3.5527e-15,\n",
      "         3.5527e-15, 3.5527e-15, 1.7764e-15, 1.0658e-14, 2.8422e-14, 1.0658e-14,\n",
      "         7.9936e-15, 5.3291e-15, 3.5527e-14, 2.8422e-14, 1.7764e-14, 5.3291e-15,\n",
      "         3.5527e-14, 3.5527e-14, 4.2633e-14, 2.8422e-14, 4.9738e-14, 1.5987e-14,\n",
      "         1.2790e-13, 3.5527e-14, 1.0658e-14, 7.1054e-15, 8.5265e-14, 7.1054e-14,\n",
      "         5.6843e-14, 1.2434e-14, 8.5265e-14, 4.9738e-14, 1.4211e-14, 2.1316e-14,\n",
      "         5.6843e-14, 2.4869e-14, 4.2633e-14, 5.6843e-14, 7.1054e-14, 4.9738e-14,\n",
      "         7.1054e-14, 2.1316e-14, 1.4211e-14, 1.7764e-14, 3.5527e-14, 9.9476e-14,\n",
      "         6.2172e-15, 1.7764e-14, 3.1974e-14, 8.5265e-14, 8.8818e-15, 7.1054e-15,\n",
      "         2.4869e-14, 7.1054e-14, 1.4211e-14, 1.7764e-14, 6.2172e-15, 4.2633e-14,\n",
      "         4.4409e-15, 8.5265e-14, 6.2172e-15, 1.7764e-14, 3.5527e-15, 2.1316e-14,\n",
      "         3.1974e-14, 1.5987e-14, 4.2633e-14, 8.5265e-14, 3.9968e-15, 3.5527e-14,\n",
      "         4.9738e-14, 5.3291e-15, 1.1369e-13, 2.1316e-14, 8.8818e-15, 5.6843e-14,\n",
      "         4.9738e-14, 1.2790e-13, 2.3093e-14, 7.9936e-15, 5.6843e-14, 4.9738e-14,\n",
      "         4.4409e-15, 1.1369e-13, 6.3949e-14, 4.9738e-14, 1.1369e-13, 9.9476e-14,\n",
      "         1.2079e-13, 8.8818e-15, 1.2790e-13, 5.6843e-14, 3.5527e-14, 5.6843e-14,\n",
      "         8.5265e-14, 1.0658e-14, 2.1316e-14, 1.7764e-14, 5.6843e-14, 5.6843e-14,\n",
      "         7.1054e-14, 2.4869e-14, 9.9476e-14, 1.4211e-14, 3.5527e-14, 1.1369e-13,\n",
      "         1.2790e-13, 1.4211e-14, 2.1316e-14, 8.5265e-14, 3.5527e-14, 9.9476e-14,\n",
      "         5.6843e-14, 1.4211e-13, 3.5527e-14, 8.5265e-14, 7.1054e-14, 4.9738e-14,\n",
      "         7.8160e-14, 4.4409e-15, 7.1054e-14, 2.1316e-14, 7.1054e-14, 8.5265e-14,\n",
      "         1.2434e-14, 7.8160e-14, 3.1974e-14, 1.5632e-13, 1.2434e-14, 3.9080e-14,\n",
      "         1.7053e-13, 1.4211e-14, 8.8818e-15, 2.8422e-14, 1.0658e-14, 1.4211e-13,\n",
      "         9.9476e-14, 8.5265e-14, 4.9738e-14, 4.9738e-14, 5.6843e-14, 7.1054e-14,\n",
      "         1.0658e-14, 5.6843e-14, 7.1054e-14, 6.3949e-14, 7.1054e-14, 7.1054e-14,\n",
      "         9.9476e-14, 3.5527e-14, 6.3949e-14, 7.1054e-14, 4.2633e-14, 1.7053e-13,\n",
      "         8.5265e-14, 1.0658e-13, 1.1369e-13, 4.7073e-14, 5.6843e-14, 1.2790e-13,\n",
      "         8.5265e-14, 4.9738e-14, 9.9476e-14, 4.2633e-14, 7.1054e-14, 1.2790e-13,\n",
      "         6.3949e-14, 4.9738e-14, 7.1054e-14, 6.3949e-14, 4.2633e-14, 9.9476e-14,\n",
      "         1.4211e-13, 1.9895e-13, 5.6843e-14, 2.8422e-14, 5.6843e-14, 1.8474e-13,\n",
      "         1.1369e-13, 4.9738e-14, 4.6185e-14, 1.1369e-13, 4.9738e-14, 7.1054e-14,\n",
      "         7.1054e-14, 7.8160e-14, 1.1369e-13, 7.1054e-14, 1.2790e-13, 7.8160e-14,\n",
      "         1.1369e-13, 3.5527e-14, 1.4211e-13, 4.9738e-14, 8.5265e-14, 9.2371e-14,\n",
      "         8.5265e-14, 1.7764e-14, 4.9738e-14, 8.5265e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 100: layer3.6.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 100\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 100\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 100\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 100\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 100\n",
      "Max diff:\n",
      " tensor([7.1054e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.7716e-16, 9.9920e-16, 6.6613e-16, 1.7764e-15, 3.1086e-15, 2.2204e-15,\n",
      "         1.7764e-15, 2.2204e-15, 3.5527e-15, 1.3323e-15, 7.1054e-15, 2.2204e-15,\n",
      "         1.7764e-15, 7.7716e-16, 8.8818e-16, 1.1102e-15, 1.7764e-15, 1.9984e-15,\n",
      "         6.6613e-16, 1.5543e-15, 7.7716e-16, 1.3323e-15, 1.1102e-15, 1.9984e-15,\n",
      "         8.8818e-16, 1.5543e-15, 8.8818e-16, 4.4409e-15, 2.2204e-15, 1.3323e-15,\n",
      "         8.8818e-16, 6.2172e-15, 7.7716e-16, 1.9984e-15, 1.7764e-15, 1.7764e-15,\n",
      "         8.8818e-16, 6.6613e-16, 7.1054e-15, 9.9920e-16, 1.1102e-15, 5.3291e-15,\n",
      "         1.1102e-15, 6.2172e-15, 6.6613e-16, 1.1102e-15, 1.9984e-15, 7.1054e-15,\n",
      "         1.1102e-15, 3.1086e-15, 7.7716e-16, 9.9920e-16, 8.8818e-16, 2.6645e-15,\n",
      "         6.6613e-16, 7.7716e-16, 1.1102e-15, 6.6613e-16, 1.9984e-15, 1.1102e-15,\n",
      "         1.1102e-15, 8.8818e-16, 5.5511e-16, 2.2204e-15, 8.8818e-15, 3.5527e-15,\n",
      "         2.4425e-15, 1.5543e-15, 8.8818e-15, 7.1054e-15, 5.3291e-15, 1.5543e-15,\n",
      "         1.0658e-14, 8.8818e-15, 1.0658e-14, 8.8818e-15, 1.4211e-14, 4.4409e-15,\n",
      "         4.9738e-14, 8.8818e-15, 3.5527e-15, 2.2204e-15, 1.5987e-14, 1.4211e-14,\n",
      "         1.4211e-14, 3.5527e-15, 2.8422e-14, 1.2434e-14, 4.4409e-15, 5.3291e-15,\n",
      "         1.0658e-14, 7.1054e-15, 1.7764e-14, 1.7764e-14, 1.7764e-14, 1.4211e-14,\n",
      "         2.1316e-14, 7.1054e-15, 4.4409e-15, 5.3291e-15, 1.2434e-14, 4.2633e-14,\n",
      "         1.9984e-15, 5.3291e-15, 7.1054e-15, 2.1316e-14, 2.6645e-15, 2.4425e-15,\n",
      "         7.9936e-15, 2.1316e-14, 4.4409e-15, 3.9968e-15, 1.9984e-15, 8.8818e-15,\n",
      "         1.3323e-15, 2.1316e-14, 2.2204e-15, 5.3291e-15, 1.1102e-15, 6.2172e-15,\n",
      "         8.8818e-15, 5.3291e-15, 1.2434e-14, 3.1974e-14, 1.3323e-15, 1.0658e-14,\n",
      "         8.8818e-15, 1.3323e-15, 3.5527e-14, 5.3291e-15, 2.6645e-15, 1.9540e-14,\n",
      "         1.4211e-14, 2.8422e-14, 7.9936e-15, 2.6645e-15, 1.9540e-14, 1.2434e-14,\n",
      "         1.5543e-15, 3.5527e-14, 1.5987e-14, 1.4211e-14, 3.1974e-14, 3.1974e-14,\n",
      "         4.2633e-14, 3.1086e-15, 3.5527e-14, 1.5987e-14, 7.9936e-15, 2.1316e-14,\n",
      "         2.1316e-14, 3.1086e-15, 6.2172e-15, 5.3291e-15, 1.7764e-14, 1.4211e-14,\n",
      "         1.7764e-14, 5.3291e-15, 2.4869e-14, 3.9968e-15, 1.2434e-14, 4.2633e-14,\n",
      "         4.2633e-14, 5.3291e-15, 5.3291e-15, 2.4869e-14, 8.8818e-15, 2.4869e-14,\n",
      "         1.0658e-14, 3.1974e-14, 1.0658e-14, 2.4869e-14, 2.1316e-14, 1.2434e-14,\n",
      "         2.4869e-14, 1.3323e-15, 1.7764e-14, 4.4409e-15, 1.4211e-14, 2.1316e-14,\n",
      "         4.4409e-15, 2.3093e-14, 8.8818e-15, 4.9738e-14, 4.4409e-15, 1.1546e-14,\n",
      "         6.3949e-14, 4.4409e-15, 2.6645e-15, 5.3291e-15, 3.5527e-15, 1.2434e-14,\n",
      "         1.5987e-14, 1.7764e-14, 9.7700e-15, 7.9936e-15, 1.2434e-14, 1.9540e-14,\n",
      "         3.1086e-15, 1.0658e-14, 1.7764e-14, 1.1546e-14, 2.1316e-14, 1.7764e-14,\n",
      "         1.5987e-14, 1.4211e-14, 9.7700e-15, 2.1316e-14, 7.1054e-15, 3.9080e-14,\n",
      "         2.4869e-14, 1.9540e-14, 2.4869e-14, 1.1435e-14, 2.4869e-14, 3.1974e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.8422e-14, 1.0658e-14, 1.4211e-14, 4.9738e-14,\n",
      "         1.4211e-14, 8.8818e-15, 2.3093e-14, 1.9540e-14, 1.0658e-14, 3.5527e-14,\n",
      "         2.8422e-14, 7.1054e-14, 1.4211e-14, 1.0658e-14, 1.2434e-14, 4.2633e-14,\n",
      "         2.4869e-14, 1.4211e-14, 7.9936e-15, 2.4869e-14, 1.4211e-14, 1.7764e-14,\n",
      "         2.4869e-14, 1.5987e-14, 4.2633e-14, 1.9540e-14, 2.4869e-14, 1.3323e-14,\n",
      "         2.8422e-14, 1.4211e-14, 3.1974e-14, 1.0658e-14, 2.4869e-14, 2.3093e-14,\n",
      "         2.6645e-14, 4.4409e-15, 1.2434e-14, 2.1316e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 101: layer3.6.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 101\n",
      "Max diff:\n",
      " tensor([1.3101e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9968e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.1641e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.3259e-15, 0.0000e+00, 9.9920e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.2736e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.8263e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.2172e-15, 0.0000e+00, 5.7732e-15, 5.8009e-15, 7.9936e-15, 1.2879e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6931e-15,\n",
      "         6.1617e-15, 0.0000e+00, 7.3275e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-15, 0.0000e+00, 3.5527e-15, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4988e-15, 1.3323e-15, 0.0000e+00,\n",
      "         3.3654e-15, 4.4409e-15, 0.0000e+00, 6.6058e-15, 1.0214e-14, 1.8735e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7764e-15, 1.3101e-14, 6.4115e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.3315e-15, 0.0000e+00, 0.0000e+00, 1.9429e-15, 4.4409e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4369e-16, 6.1062e-15, 8.8818e-15,\n",
      "         2.2204e-15, 0.0000e+00, 5.1070e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([100, 140, 144, 146, 156, 173, 181, 192, 194, 195, 196, 197, 203, 204,\n",
      "        206, 211, 213, 215, 219, 220, 222, 223, 225, 226, 227, 230, 234, 235,\n",
      "        236, 241, 244, 245, 249, 250, 251, 252, 254])\n",
      "\n",
      "failing Cout = tensor([100, 140, 144, 146, 156, 173, 181, 192, 194, 195, 196, 197, 203, 204,\n",
      "        206, 211, 213, 215, 219, 220, 222, 223, 225, 226, 227, 230, 234, 235,\n",
      "        236, 241, 244, 245, 249, 250, 251, 252, 254])  (len = 37)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 102: layer3.6.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 102\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 102\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  7, 10, 22, 24, 26, 28, 30, 31, 32, 36, 38, 41, 44, 46,\n",
      "        49, 51, 52, 55, 57, 60, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([130, 131, 134, 135, 136, 137, 138, 140, 142, 143, 144, 148, 149, 151,\n",
      "        152, 153, 162, 164, 166, 168, 171, 174, 175, 178, 181, 182, 183, 187,\n",
      "        191]) to machine 2\n",
      "\t\t sending C_out tensor([193, 194, 196, 197, 199, 200, 202, 203, 204, 207, 208, 210, 212, 214,\n",
      "        216, 217, 221, 225, 231, 232, 236, 237, 239, 242, 246, 247, 250, 251,\n",
      "        253, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 102\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  2,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 19, 21, 22,\n",
      "        23, 24, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
      "        44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62,\n",
      "        63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  79,\n",
      "         80,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "         95,  96,  97,  98,  99, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 125, 126,\n",
      "        127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250,\n",
      "        251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 102\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 102\n",
      "Max diff:\n",
      " tensor([1.4655e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.9968e-15, 2.9421e-15, 6.2172e-15, 4.4409e-15, 4.6629e-15, 2.1094e-15,\n",
      "         6.7724e-15, 5.5511e-15, 5.1070e-15, 4.6629e-15, 3.1086e-15, 5.6621e-15,\n",
      "         4.6629e-15, 5.9952e-15, 5.5511e-16, 5.1070e-15, 9.7145e-17, 6.2172e-15,\n",
      "         3.5527e-15, 8.4377e-15, 1.9984e-15, 7.5495e-15, 3.8303e-15, 6.4393e-15,\n",
      "         1.3878e-16, 3.3307e-15, 3.2752e-15, 5.2736e-15, 1.6029e-15, 3.9968e-15,\n",
      "         5.3291e-15, 3.9968e-15, 5.5511e-15, 7.7716e-15, 3.6637e-15, 6.9944e-15,\n",
      "         4.4409e-15, 5.3291e-15, 3.1086e-15, 8.0448e-17, 3.5527e-15, 5.2180e-15,\n",
      "         4.7740e-15, 1.1102e-16, 3.9135e-15, 4.4409e-15, 3.5527e-15, 3.9968e-15,\n",
      "         4.7740e-15, 3.8858e-15, 5.1625e-15, 1.9429e-16, 3.8858e-15, 2.6645e-15,\n",
      "         2.2482e-15, 3.5250e-15, 3.9968e-15, 2.8866e-15, 5.9952e-15, 4.2744e-15,\n",
      "         2.3315e-15, 4.1078e-15, 4.4409e-15, 1.3878e-16, 4.5519e-15, 2.8866e-15,\n",
      "         4.4409e-15, 3.3168e-15, 4.8850e-15, 7.5495e-15, 2.8866e-15, 3.6082e-15,\n",
      "         5.5511e-15, 5.9952e-15, 2.6645e-15, 5.3291e-15, 3.5527e-15, 6.6613e-15,\n",
      "         1.8874e-15, 5.2180e-15, 7.9936e-15, 4.4409e-15, 5.7732e-15, 6.8834e-15,\n",
      "         4.9058e-15, 5.1625e-15, 6.4670e-15, 4.4270e-15, 4.8850e-15, 5.7732e-15,\n",
      "         5.7732e-15, 5.2180e-15, 7.3275e-15, 5.9952e-15, 6.1062e-15, 6.2172e-15,\n",
      "         5.9952e-15, 4.4409e-15, 6.6613e-15, 6.9944e-15, 6.2172e-15, 2.4425e-15,\n",
      "         4.7184e-15, 6.2172e-15, 7.1054e-15, 4.4409e-15, 6.4393e-15, 4.9405e-15,\n",
      "         6.2172e-15, 5.5511e-15, 5.3291e-15, 4.3854e-15, 4.6629e-15, 1.9984e-15,\n",
      "         9.3259e-15, 5.3291e-15, 3.5527e-15, 6.2172e-15, 5.4956e-15, 3.1641e-15,\n",
      "         2.8866e-15, 4.2188e-15, 3.3307e-15, 3.1086e-15, 3.4417e-15, 4.8850e-15,\n",
      "         3.4417e-15, 3.1086e-15, 6.4393e-15, 6.6613e-15, 4.2188e-15, 5.9952e-15,\n",
      "         6.0507e-15, 7.1054e-15, 6.8834e-15, 6.2172e-15, 4.8850e-15, 4.4409e-15,\n",
      "         4.8850e-15, 8.4377e-15, 6.4393e-15, 5.1070e-15, 5.3291e-15, 7.1609e-15,\n",
      "         4.4409e-15, 5.3291e-15, 7.5495e-15, 4.8850e-15, 7.1054e-15, 6.4393e-15,\n",
      "         4.2744e-15, 6.2172e-15, 5.3291e-15, 8.8818e-15, 7.1054e-15, 3.8858e-15,\n",
      "         7.9936e-15, 8.7985e-15, 3.9968e-15, 4.8850e-15, 6.6613e-15, 6.9944e-15,\n",
      "         4.2188e-15, 4.4409e-15, 5.3291e-15, 6.6613e-15, 4.6629e-15, 4.4409e-15,\n",
      "         6.2172e-15, 4.4409e-15, 5.3291e-15, 7.9936e-15, 7.3275e-15, 7.9936e-15,\n",
      "         8.8818e-15, 9.3259e-15, 9.8810e-15, 5.5511e-15, 3.9968e-15, 8.6597e-15,\n",
      "         5.3291e-15, 7.1054e-15, 5.3291e-15, 4.4409e-15, 5.3291e-15, 6.2172e-15,\n",
      "         7.1054e-15, 4.7740e-15, 7.9936e-15, 6.2172e-15, 5.4401e-15, 6.4393e-15,\n",
      "         7.5495e-15, 7.1054e-15, 8.8818e-15, 5.9952e-15, 6.4393e-15, 6.6613e-15,\n",
      "         9.1038e-15, 7.9936e-15, 5.7732e-15, 8.4377e-15, 6.2172e-15, 7.7716e-15,\n",
      "         8.9928e-15, 8.4377e-15, 6.3283e-15, 5.9952e-15, 4.8850e-15, 4.8850e-15,\n",
      "         6.6613e-15, 6.6613e-15, 5.7732e-15, 5.4956e-15, 5.7732e-15, 8.3267e-15,\n",
      "         5.7732e-15, 8.2157e-15, 7.1054e-15, 6.2172e-15, 7.4385e-15, 5.5511e-15,\n",
      "         7.5495e-15, 5.8495e-15, 7.3275e-15, 7.9936e-15, 7.9936e-15, 7.1054e-15,\n",
      "         6.2172e-15, 7.3275e-15, 5.9397e-15, 5.9674e-15, 7.3275e-15, 8.7708e-15,\n",
      "         6.8834e-15, 7.1054e-15, 5.5060e-15, 6.4115e-15, 7.1054e-15, 6.2172e-15,\n",
      "         5.5511e-15, 7.1054e-15, 8.9928e-15, 6.2172e-15, 7.9936e-15, 1.4655e-14,\n",
      "         5.7732e-15, 6.6613e-15, 6.2172e-15, 5.3291e-15, 6.6613e-15, 5.5511e-15,\n",
      "         8.6597e-15, 7.2026e-15, 8.4377e-15, 7.5495e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 103: layer3.6.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 103\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 103\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 103\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 103\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 103\n",
      "Max diff:\n",
      " tensor([5.1070e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.7756e-16, 5.9848e-16, 2.8866e-15, 4.7184e-16, 2.1094e-15, 7.7716e-16,\n",
      "         2.3037e-15, 1.5994e-15, 1.9984e-15, 1.4433e-15, 7.7716e-16, 2.1649e-15,\n",
      "         1.3323e-15, 2.1649e-15, 6.9389e-17, 1.9984e-15, 3.4694e-17, 2.4425e-15,\n",
      "         1.1102e-15, 2.4425e-15, 3.6776e-16, 1.8874e-15, 1.6098e-15, 2.6645e-15,\n",
      "         4.1633e-17, 6.1062e-16, 6.6613e-16, 2.6090e-15, 3.3307e-16, 4.5797e-16,\n",
      "         1.4433e-15, 1.4433e-15, 2.5535e-15, 9.9920e-16, 1.3323e-15, 1.1102e-15,\n",
      "         1.3323e-15, 2.2204e-15, 6.5226e-16, 2.7756e-17, 1.4988e-15, 1.3323e-15,\n",
      "         7.3552e-16, 4.1633e-17, 5.8981e-16, 7.0777e-16, 6.1062e-16, 8.8818e-16,\n",
      "         1.8874e-15, 4.4409e-16, 1.6653e-15, 6.9389e-17, 1.0547e-15, 7.7716e-16,\n",
      "         7.7716e-16, 6.9389e-16, 1.1657e-15, 1.3323e-15, 1.8874e-15, 8.8818e-16,\n",
      "         6.1062e-16, 1.7764e-15, 2.2204e-15, 4.1633e-17, 8.3093e-16, 4.5797e-16,\n",
      "         6.6613e-16, 6.6613e-16, 4.1633e-16, 1.5543e-15, 3.8858e-16, 3.3307e-16,\n",
      "         5.4123e-16, 1.7208e-15, 1.3323e-15, 1.3323e-15, 9.9920e-16, 1.1102e-15,\n",
      "         3.8858e-16, 1.6653e-15, 1.3323e-15, 1.1102e-15, 2.0695e-15, 2.7756e-15,\n",
      "         1.2074e-15, 4.1633e-16, 1.4641e-15, 1.6653e-15, 3.0531e-16, 7.3552e-16,\n",
      "         3.1086e-15, 6.9389e-16, 1.5543e-15, 1.9984e-15, 1.5543e-15, 1.2768e-15,\n",
      "         1.4433e-15, 8.8818e-16, 1.5543e-15, 2.0539e-15, 3.8858e-16, 2.2204e-16,\n",
      "         1.1935e-15, 1.3323e-15, 1.4433e-15, 1.7764e-15, 2.5535e-15, 8.3267e-16,\n",
      "         1.6653e-15, 5.8287e-16, 1.2212e-15, 1.3600e-15, 1.2768e-15, 3.8858e-16,\n",
      "         1.7764e-15, 1.3323e-15, 2.7756e-16, 2.7756e-15, 9.4369e-16, 8.0491e-16,\n",
      "         3.8858e-16, 8.8818e-16, 4.7184e-16, 5.2736e-16, 4.1633e-16, 1.4710e-15,\n",
      "         4.7184e-16, 4.6838e-17, 2.2812e-15, 1.7764e-15, 1.1657e-15, 1.5543e-15,\n",
      "         1.6653e-15, 1.4988e-15, 1.6653e-15, 1.7764e-15, 1.1102e-15, 1.7764e-15,\n",
      "         1.3323e-15, 1.4433e-15, 9.1593e-16, 1.6653e-15, 2.8866e-15, 1.8596e-15,\n",
      "         8.0491e-16, 1.7764e-15, 1.6653e-15, 3.3307e-16, 2.3037e-15, 3.7748e-15,\n",
      "         2.0539e-15, 2.4425e-15, 1.1102e-15, 2.6645e-15, 1.9984e-15, 6.1062e-16,\n",
      "         1.3323e-15, 4.3299e-15, 6.6613e-16, 7.7716e-16, 1.6653e-15, 1.4988e-15,\n",
      "         1.9689e-16, 1.3323e-15, 1.5543e-15, 1.9984e-15, 8.8818e-16, 1.9984e-15,\n",
      "         1.9984e-15, 1.3323e-15, 1.5543e-15, 2.1094e-15, 1.5821e-15, 1.4988e-15,\n",
      "         1.1102e-15, 4.5519e-15, 3.5250e-15, 1.4433e-15, 1.5959e-16, 3.1086e-15,\n",
      "         5.6205e-16, 1.9984e-15, 1.2212e-15, 4.4409e-16, 2.6645e-15, 8.8818e-16,\n",
      "         2.3315e-15, 5.5511e-16, 8.8818e-16, 8.3267e-16, 1.0547e-15, 2.5535e-15,\n",
      "         1.7764e-15, 1.2212e-15, 1.9429e-15, 9.9920e-16, 1.8596e-15, 2.4425e-15,\n",
      "         2.1094e-15, 3.1086e-15, 1.3323e-15, 2.3315e-15, 1.3323e-15, 1.2212e-15,\n",
      "         2.3315e-15, 3.4070e-15, 1.7486e-15, 1.2212e-15, 1.1657e-15, 9.9920e-16,\n",
      "         1.1657e-15, 2.6645e-15, 2.3315e-15, 1.4710e-15, 2.1094e-15, 1.5821e-15,\n",
      "         1.2212e-15, 2.8588e-15, 1.9984e-15, 1.6653e-15, 1.2490e-15, 2.2204e-15,\n",
      "         2.0955e-15, 1.6376e-15, 2.6645e-15, 2.7756e-15, 1.7764e-15, 1.4433e-15,\n",
      "         1.1935e-15, 1.1657e-15, 2.7756e-15, 1.4710e-15, 9.4369e-16, 2.6645e-15,\n",
      "         1.5543e-15, 1.2490e-15, 7.4246e-16, 1.0547e-15, 8.3267e-16, 8.8818e-16,\n",
      "         1.9290e-15, 1.8874e-15, 2.6090e-15, 9.8532e-16, 3.1086e-15, 5.1070e-15,\n",
      "         1.1102e-15, 1.2768e-15, 2.6645e-15, 1.3323e-15, 1.3878e-15, 1.3618e-15,\n",
      "         1.8041e-15, 1.7625e-15, 1.9013e-15, 1.6653e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 104: layer3.6.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 104\n",
      "Max diff:\n",
      " tensor([3.5527e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.4433e-15, 2.4425e-15, 2.8866e-15, 4.4964e-15, 2.1094e-15, 1.6653e-15,\n",
      "         2.3037e-15, 4.3299e-15, 1.9984e-15, 1.4433e-15, 7.7716e-16, 2.1649e-15,\n",
      "         1.3323e-15, 3.3584e-15, 3.0531e-16, 1.9984e-15, 3.4694e-17, 2.4425e-15,\n",
      "         1.1102e-15, 2.8866e-15, 4.7184e-16, 1.8874e-15, 1.6098e-15, 2.3315e-15,\n",
      "         4.1633e-17, 6.1062e-16, 6.6613e-16, 2.6090e-15, 8.3961e-16, 3.7748e-15,\n",
      "         1.4433e-15, 1.4433e-15, 2.9976e-15, 3.1086e-15, 1.3323e-15, 1.1102e-15,\n",
      "         2.5535e-15, 3.1086e-15, 6.5226e-16, 2.7756e-17, 6.8834e-15, 1.3323e-15,\n",
      "         2.7756e-15, 4.1633e-17, 5.5511e-15, 7.0777e-16, 6.1062e-16, 1.6653e-15,\n",
      "         1.8874e-15, 4.4409e-16, 1.6653e-15, 6.9389e-17, 2.4425e-15, 1.2212e-15,\n",
      "         1.1102e-15, 6.9389e-16, 3.0531e-15, 1.3323e-15, 3.0531e-15, 8.8818e-16,\n",
      "         2.3315e-15, 1.7764e-15, 2.2204e-15, 4.1633e-17, 5.3291e-15, 2.2204e-15,\n",
      "         6.4393e-15, 7.1054e-15, 1.5543e-15, 4.4409e-15, 1.2434e-14, 5.0376e-15,\n",
      "         2.4425e-15, 4.4409e-15, 1.3323e-15, 4.4409e-15, 8.4377e-15, 8.8818e-15,\n",
      "         3.8858e-16, 1.9984e-15, 3.9968e-15, 3.9968e-15, 2.0695e-15, 9.9920e-15,\n",
      "         8.8818e-15, 6.9111e-15, 6.2172e-15, 1.6653e-15, 9.7700e-15, 7.1054e-15,\n",
      "         3.1086e-15, 4.6074e-15, 6.4393e-15, 1.9984e-15, 3.6082e-15, 2.3592e-15,\n",
      "         4.8850e-15, 2.6645e-15, 3.0531e-15, 1.2768e-14, 2.1649e-15, 1.1657e-15,\n",
      "         6.2172e-15, 1.8319e-15, 1.4433e-15, 9.7700e-15, 2.5535e-15, 3.5527e-15,\n",
      "         3.6637e-15, 5.5511e-15, 4.8850e-15, 6.1062e-15, 1.2768e-15, 4.9405e-15,\n",
      "         1.7764e-15, 7.1054e-15, 4.8850e-15, 2.7756e-15, 4.8850e-15, 6.4393e-15,\n",
      "         3.8858e-16, 8.8818e-16, 4.8850e-15, 5.3291e-15, 3.1086e-15, 4.8850e-15,\n",
      "         1.3323e-15, 2.6645e-15, 2.2812e-15, 4.8850e-15, 2.4425e-15, 3.2752e-15,\n",
      "         3.7748e-15, 2.0539e-15, 1.2434e-14, 3.5527e-15, 1.1102e-15, 2.8866e-15,\n",
      "         1.5765e-14, 3.5527e-15, 3.3307e-15, 1.6653e-15, 2.8866e-15, 7.1054e-15,\n",
      "         7.9936e-15, 1.7764e-15, 4.8850e-15, 4.4409e-15, 1.6875e-14, 3.8858e-15,\n",
      "         1.0214e-14, 3.6637e-15, 2.4425e-15, 2.6645e-15, 2.6090e-15, 8.4377e-15,\n",
      "         5.3291e-15, 6.2172e-15, 6.6613e-15, 7.7716e-16, 1.6653e-15, 3.6637e-15,\n",
      "         3.5527e-15, 1.3323e-15, 2.8866e-15, 1.9984e-15, 7.9936e-15, 1.9984e-15,\n",
      "         2.8422e-14, 1.3323e-15, 2.2204e-15, 8.8818e-15, 1.9984e-15, 9.3259e-15,\n",
      "         8.8818e-15, 9.7700e-15, 3.5250e-15, 1.4433e-15, 7.5495e-15, 3.1086e-15,\n",
      "         5.6205e-16, 2.8866e-15, 1.2212e-15, 5.7732e-15, 2.6645e-15, 7.3032e-16,\n",
      "         1.2101e-14, 5.4956e-15, 1.8652e-14, 1.0214e-14, 1.0547e-15, 2.5535e-15,\n",
      "         9.7700e-15, 2.4869e-14, 8.8818e-15, 2.4702e-15, 2.2204e-15, 6.2172e-15,\n",
      "         7.9936e-15, 8.8818e-15, 8.4377e-15, 6.2172e-15, 1.0658e-14, 1.2212e-15,\n",
      "         1.2434e-14, 8.8818e-15, 8.2157e-15, 1.7764e-14, 7.7716e-15, 4.4409e-15,\n",
      "         8.4377e-15, 2.8422e-14, 1.4211e-14, 2.2204e-15, 2.1094e-15, 3.5527e-15,\n",
      "         6.2172e-15, 8.0769e-15, 4.9960e-15, 6.5503e-15, 6.8834e-15, 3.5527e-14,\n",
      "         5.2180e-15, 8.8818e-15, 3.7748e-15, 1.0658e-14, 1.2434e-14, 7.5495e-15,\n",
      "         1.5987e-14, 9.5479e-15, 9.6589e-15, 1.4211e-14, 2.1316e-14, 5.3291e-15,\n",
      "         7.5495e-15, 2.2204e-15, 2.8866e-15, 1.7764e-14, 6.2172e-15, 3.9968e-15,\n",
      "         3.5527e-15, 3.3307e-15, 9.7145e-15, 2.9976e-15, 7.3275e-15, 1.2434e-14,\n",
      "         7.1054e-15, 1.0658e-14, 3.9968e-15, 5.5511e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.8041e-15, 2.8866e-15, 4.4409e-15, 1.1990e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 105: layer3.6.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 105\n",
      "Max diff:\n",
      " tensor([3.5527e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.4433e-15, 2.4425e-15, 2.2204e-16, 4.4964e-15, 2.1094e-15, 1.6653e-15,\n",
      "         2.7756e-16, 4.1633e-15, 1.6653e-16, 1.3878e-15, 0.0000e+00, 2.1649e-15,\n",
      "         0.0000e+00, 3.3584e-15, 3.0531e-16, 3.1225e-16, 0.0000e+00, 6.4532e-16,\n",
      "         0.0000e+00, 2.4425e-15, 4.7184e-16, 9.4369e-16, 1.0825e-15, 2.2204e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6090e-15, 8.3961e-16, 3.7748e-15,\n",
      "         1.3045e-15, 8.4655e-16, 1.5543e-15, 3.1086e-15, 3.8858e-16, 5.6899e-16,\n",
      "         2.5535e-15, 1.8041e-15, 6.5226e-16, 0.0000e+00, 6.8834e-15, 7.1644e-16,\n",
      "         2.7756e-15, 0.0000e+00, 5.5511e-15, 4.2327e-16, 0.0000e+00, 1.6653e-15,\n",
      "         1.5543e-15, 4.1633e-16, 1.6098e-15, 0.0000e+00, 9.4369e-16, 1.2212e-15,\n",
      "         1.1102e-15, 4.1633e-16, 3.0531e-15, 4.4409e-16, 3.0531e-15, 0.0000e+00,\n",
      "         2.3315e-15, 1.5543e-15, 2.2204e-15, 0.0000e+00, 5.3291e-15, 2.2204e-15,\n",
      "         6.4393e-15, 7.1054e-15, 1.5543e-15, 4.4409e-15, 1.2434e-14, 4.9960e-15,\n",
      "         2.4425e-15, 4.4409e-15, 1.2212e-15, 4.4409e-15, 8.4377e-15, 8.8818e-15,\n",
      "         1.9429e-16, 1.9984e-15, 3.9968e-15, 3.9968e-15, 2.0695e-15, 9.9920e-15,\n",
      "         8.8818e-15, 6.9111e-15, 6.2172e-15, 1.0825e-15, 9.7700e-15, 7.1054e-15,\n",
      "         1.3323e-15, 4.6074e-15, 6.4393e-15, 1.1380e-15, 1.7764e-15, 2.3592e-15,\n",
      "         4.8850e-15, 2.6645e-15, 2.1094e-15, 1.2768e-14, 2.1094e-15, 1.1657e-15,\n",
      "         6.2172e-15, 1.6653e-15, 9.1593e-16, 9.7700e-15, 1.6098e-15, 3.5527e-15,\n",
      "         3.6637e-15, 5.5511e-15, 4.8850e-15, 6.1062e-15, 8.8818e-16, 4.9405e-15,\n",
      "         1.7764e-15, 7.1054e-15, 4.8850e-15, 4.9960e-16, 4.8850e-15, 6.4393e-15,\n",
      "         2.6888e-16, 5.5511e-16, 4.8850e-15, 5.3291e-15, 3.1086e-15, 4.8850e-15,\n",
      "         1.3323e-15, 2.6645e-15, 2.2812e-15, 4.8850e-15, 2.4425e-15, 3.2752e-15,\n",
      "         3.7748e-15, 1.4988e-15, 1.2434e-14, 3.5527e-15, 1.1102e-15, 2.4425e-15,\n",
      "         8.8818e-15, 3.5527e-15, 2.6992e-15, 8.3267e-16, 2.8866e-15, 7.1054e-15,\n",
      "         7.9936e-15, 1.3323e-15, 4.8850e-15, 4.4409e-15, 1.6875e-14, 2.1372e-15,\n",
      "         1.0214e-14, 3.6637e-15, 2.4425e-15, 1.6723e-15, 1.1102e-15, 8.4377e-15,\n",
      "         5.3291e-15, 6.2172e-15, 6.6613e-15, 0.0000e+00, 1.4710e-15, 3.6637e-15,\n",
      "         3.5527e-15, 1.0790e-15, 2.8866e-15, 6.3838e-16, 7.9936e-15, 1.9984e-15,\n",
      "         2.8422e-14, 7.9103e-16, 2.2204e-15, 8.8818e-15, 1.9984e-15, 9.3259e-15,\n",
      "         8.8818e-15, 9.7700e-15, 3.5250e-15, 6.3838e-16, 7.5495e-15, 4.9613e-16,\n",
      "         3.5388e-16, 2.8103e-15, 2.3679e-16, 5.7732e-15, 2.2204e-15, 7.3032e-16,\n",
      "         1.2101e-14, 5.4956e-15, 1.8652e-14, 1.0214e-14, 5.1348e-16, 4.4409e-16,\n",
      "         9.7700e-15, 2.4869e-14, 8.8818e-15, 2.4702e-15, 2.2204e-15, 6.2172e-15,\n",
      "         7.9936e-15, 8.8818e-15, 8.4377e-15, 6.2172e-15, 1.0658e-14, 9.8532e-16,\n",
      "         1.2434e-14, 8.4377e-15, 8.2157e-15, 1.7764e-14, 7.7716e-15, 4.4409e-15,\n",
      "         8.4377e-15, 2.8422e-14, 1.4211e-14, 2.2204e-15, 2.1094e-15, 3.5527e-15,\n",
      "         6.2172e-15, 8.0769e-15, 4.9960e-15, 6.5503e-15, 6.8834e-15, 3.5527e-14,\n",
      "         4.6629e-15, 8.8818e-15, 3.7748e-15, 1.0658e-14, 1.2434e-14, 7.5495e-15,\n",
      "         1.5987e-14, 9.5479e-15, 9.6589e-15, 1.4211e-14, 2.1316e-14, 5.3291e-15,\n",
      "         7.5495e-15, 2.2204e-15, 2.8866e-15, 1.7764e-14, 6.2172e-15, 3.9968e-15,\n",
      "         3.5527e-15, 3.3307e-15, 1.8319e-15, 2.9976e-15, 3.4417e-15, 1.2434e-14,\n",
      "         7.1054e-15, 1.0658e-14, 3.9968e-15, 5.5511e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.8041e-15, 2.8866e-15, 4.4409e-15, 1.1990e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  13,  14,  15,\n",
      "         17,  19,  20,  21,  22,  23,  27,  28,  29,  30,  31,  32,  33,  34,\n",
      "         35,  36,  37,  38,  40,  41,  42,  44,  45,  47,  48,  49,  50,  52,\n",
      "         53,  54,  55,  56,  57,  58,  60,  61,  62,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
      "        153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  13,  14,  15,\n",
      "         17,  19,  20,  21,  22,  23,  27,  28,  29,  30,  31,  32,  33,  34,\n",
      "         35,  36,  37,  38,  40,  41,  42,  44,  45,  47,  48,  49,  50,  52,\n",
      "         53,  54,  55,  56,  57,  58,  60,  61,  62,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
      "        153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 242)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 106: layer3.7.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 106\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 106\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 106\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 106\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 106\n",
      "Max diff:\n",
      " tensor([2.2737e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.2172e-15, 7.9936e-15, 6.2172e-15, 1.4211e-14, 4.4409e-15, 4.4409e-15,\n",
      "         6.2172e-15, 3.1086e-15, 1.2434e-14, 3.5527e-15, 8.8818e-15, 4.4409e-15,\n",
      "         1.2434e-14, 5.3291e-15, 6.2172e-15, 2.1316e-14, 8.8818e-15, 6.2172e-15,\n",
      "         4.8850e-15, 4.8850e-15, 5.3291e-15, 3.1086e-15, 4.4409e-15, 2.1316e-14,\n",
      "         1.1546e-14, 3.9968e-15, 4.4409e-15, 3.5527e-15, 5.3291e-15, 1.0658e-14,\n",
      "         2.1316e-14, 2.2204e-15, 3.5527e-15, 7.1054e-15, 6.2172e-15, 6.2172e-15,\n",
      "         1.4211e-14, 3.1086e-15, 8.8818e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15,\n",
      "         3.5527e-15, 5.3291e-15, 8.8818e-15, 1.4211e-14, 4.4409e-15, 2.6645e-15,\n",
      "         3.5527e-15, 3.5527e-15, 4.4409e-15, 5.3291e-15, 6.2172e-15, 2.6645e-15,\n",
      "         3.9968e-15, 6.2172e-15, 3.1086e-15, 8.8818e-15, 3.1086e-15, 3.5527e-15,\n",
      "         1.0658e-14, 6.2172e-15, 1.7764e-15, 3.5527e-15, 8.8818e-15, 8.5265e-14,\n",
      "         1.0658e-14, 8.8818e-15, 8.8818e-15, 7.1054e-15, 5.6843e-14, 4.9738e-14,\n",
      "         6.3949e-14, 3.1974e-14, 1.7764e-14, 4.9738e-14, 3.5527e-14, 5.3291e-15,\n",
      "         2.8422e-14, 2.4869e-14, 8.8818e-15, 3.5527e-15, 4.2633e-14, 2.8422e-14,\n",
      "         6.2172e-15, 1.1546e-14, 7.1054e-14, 5.3291e-15, 2.4869e-14, 8.5265e-14,\n",
      "         5.3291e-15, 2.1316e-14, 3.1974e-14, 4.4409e-15, 1.4211e-14, 2.4869e-14,\n",
      "         1.4211e-13, 7.1054e-14, 9.7700e-15, 2.8422e-14, 7.1054e-15, 1.7764e-14,\n",
      "         1.7764e-14, 1.0658e-14, 1.2434e-14, 2.4869e-14, 1.5987e-14, 8.8818e-15,\n",
      "         7.1054e-15, 1.2790e-13, 7.1054e-15, 1.4211e-14, 4.4409e-15, 5.3291e-15,\n",
      "         1.2434e-14, 3.5527e-15, 4.2633e-14, 2.1316e-14, 5.6843e-14, 3.5527e-15,\n",
      "         6.2172e-15, 1.4211e-14, 2.4869e-14, 6.2172e-15, 2.1316e-14, 3.5527e-15,\n",
      "         2.4869e-14, 7.1054e-15, 4.2633e-14, 4.2633e-14, 6.3949e-14, 5.6843e-14,\n",
      "         2.8422e-14, 1.4211e-14, 6.3949e-14, 7.1054e-14, 1.7764e-14, 4.9738e-14,\n",
      "         1.1369e-13, 6.3949e-14, 1.1369e-13, 9.9476e-14, 8.5265e-14, 4.2633e-14,\n",
      "         1.4211e-13, 4.4409e-15, 1.5987e-14, 7.1054e-14, 8.5265e-14, 4.2633e-14,\n",
      "         2.3093e-14, 8.8818e-15, 8.5265e-14, 1.5987e-14, 3.5527e-14, 1.0658e-14,\n",
      "         5.6843e-14, 1.2790e-13, 1.2790e-13, 4.2633e-14, 1.5987e-14, 1.4211e-13,\n",
      "         6.3949e-14, 1.1369e-13, 7.8160e-14, 1.5987e-14, 2.4869e-14, 7.1054e-14,\n",
      "         1.4211e-14, 7.1054e-14, 9.9476e-14, 6.2172e-15, 1.8474e-13, 4.9738e-14,\n",
      "         1.4211e-14, 7.1054e-14, 5.6399e-14, 4.2633e-14, 4.0856e-14, 8.5265e-14,\n",
      "         9.9476e-14, 4.2633e-14, 2.8422e-14, 5.6843e-14, 3.5527e-14, 9.9476e-14,\n",
      "         2.8422e-14, 4.2633e-14, 1.5632e-13, 7.1054e-14, 3.5527e-14, 2.1316e-14,\n",
      "         9.9476e-14, 1.1369e-13, 4.2633e-14, 1.3500e-13, 4.2633e-14, 7.1054e-14,\n",
      "         6.0396e-14, 8.5265e-14, 6.3949e-14, 6.3949e-14, 5.3291e-14, 5.7732e-14,\n",
      "         1.2790e-13, 7.1054e-14, 9.9476e-14, 9.9476e-14, 1.1369e-13, 6.3949e-14,\n",
      "         1.4211e-13, 4.2633e-14, 7.1054e-14, 1.2790e-13, 9.2371e-14, 5.6843e-14,\n",
      "         8.5265e-14, 7.8160e-14, 5.6843e-14, 4.9738e-14, 9.9476e-14, 9.9476e-14,\n",
      "         6.5281e-14, 4.7073e-14, 1.5632e-13, 5.6843e-14, 5.5067e-14, 6.0396e-14,\n",
      "         1.1369e-13, 9.9476e-14, 9.9476e-14, 7.1054e-14, 3.5527e-14, 9.2371e-14,\n",
      "         8.5265e-14, 7.8160e-14, 1.2790e-13, 1.4211e-13, 5.5067e-14, 7.8160e-14,\n",
      "         7.1054e-14, 1.1369e-13, 8.5265e-14, 7.8160e-14, 9.9476e-14, 1.5632e-13,\n",
      "         9.9476e-14, 2.2737e-13, 6.3949e-14, 7.1054e-14, 3.0198e-14, 5.5955e-14,\n",
      "         1.5632e-13, 5.6843e-14, 1.2079e-13, 1.9895e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 107: layer3.7.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 107\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 107\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 107\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 107\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 107\n",
      "Max diff:\n",
      " tensor([8.5265e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-15, 1.9984e-15, 1.5543e-15, 4.4409e-15, 1.1102e-15, 1.4433e-15,\n",
      "         1.5543e-15, 7.7716e-16, 2.6645e-15, 1.1102e-15, 2.2204e-15, 1.1102e-15,\n",
      "         3.1086e-15, 1.3323e-15, 1.5543e-15, 4.4409e-15, 2.2204e-15, 1.7764e-15,\n",
      "         1.3323e-15, 1.3323e-15, 1.5543e-15, 8.8818e-16, 1.1102e-15, 3.9968e-15,\n",
      "         3.1086e-15, 1.2212e-15, 1.1102e-15, 9.9920e-16, 1.5543e-15, 2.6645e-15,\n",
      "         5.3291e-15, 5.5511e-16, 8.8818e-16, 1.7764e-15, 1.5543e-15, 1.5543e-15,\n",
      "         3.1086e-15, 8.8818e-16, 2.6645e-15, 1.5543e-15, 1.5543e-15, 1.7764e-15,\n",
      "         9.9920e-16, 1.3323e-15, 2.6645e-15, 3.9968e-15, 1.3323e-15, 8.8818e-16,\n",
      "         1.1102e-15, 1.1102e-15, 1.2212e-15, 1.7764e-15, 1.5543e-15, 7.7716e-16,\n",
      "         1.3323e-15, 1.5543e-15, 8.8818e-16, 2.6645e-15, 9.9920e-16, 1.1102e-15,\n",
      "         3.1086e-15, 1.9984e-15, 4.9960e-16, 9.9920e-16, 2.2204e-15, 1.9540e-14,\n",
      "         3.1086e-15, 2.6645e-15, 2.6645e-15, 2.2204e-15, 1.2434e-14, 1.0658e-14,\n",
      "         8.8818e-15, 7.9936e-15, 5.3291e-15, 1.4211e-14, 8.8818e-15, 1.3323e-15,\n",
      "         8.8818e-15, 6.2172e-15, 2.2204e-15, 1.1102e-15, 1.0658e-14, 7.9936e-15,\n",
      "         1.7764e-15, 2.8866e-15, 1.7764e-14, 1.4433e-15, 5.3291e-15, 2.4869e-14,\n",
      "         1.3323e-15, 5.3291e-15, 8.8818e-15, 1.3323e-15, 4.4409e-15, 6.2172e-15,\n",
      "         4.2633e-14, 1.5987e-14, 2.8866e-15, 7.9936e-15, 2.2204e-15, 4.4409e-15,\n",
      "         4.4409e-15, 2.4425e-15, 3.1086e-15, 7.1054e-15, 3.5527e-15, 2.6645e-15,\n",
      "         1.9984e-15, 4.2633e-14, 1.9984e-15, 3.5527e-15, 1.3323e-15, 1.3323e-15,\n",
      "         3.1086e-15, 9.9920e-16, 8.8818e-15, 3.9968e-15, 1.9540e-14, 1.1102e-15,\n",
      "         1.7764e-15, 3.9968e-15, 2.6645e-15, 1.5543e-15, 5.3291e-15, 1.1102e-15,\n",
      "         7.1054e-15, 1.3323e-15, 1.2434e-14, 1.1546e-14, 1.2434e-14, 8.8818e-15,\n",
      "         7.1054e-15, 3.9968e-15, 1.2434e-14, 2.1316e-14, 5.7732e-15, 1.2434e-14,\n",
      "         3.1974e-14, 1.7764e-14, 2.8422e-14, 1.2434e-14, 1.7764e-14, 9.7700e-15,\n",
      "         2.4869e-14, 1.3323e-15, 3.9968e-15, 1.7764e-14, 1.9540e-14, 1.2434e-14,\n",
      "         7.1054e-15, 2.6645e-15, 3.5527e-14, 4.8850e-15, 8.8818e-15, 3.1086e-15,\n",
      "         1.0658e-14, 3.5527e-14, 1.7764e-14, 1.2434e-14, 4.4409e-15, 4.2633e-14,\n",
      "         2.1316e-14, 1.7764e-14, 2.4869e-14, 3.5527e-15, 7.1054e-15, 1.7764e-14,\n",
      "         4.4409e-15, 1.7764e-14, 2.8422e-14, 1.7764e-15, 3.9080e-14, 1.2434e-14,\n",
      "         3.9968e-15, 2.4869e-14, 8.8818e-15, 1.2434e-14, 9.1038e-15, 2.4869e-14,\n",
      "         2.8422e-14, 1.2434e-14, 8.8818e-15, 1.0658e-14, 1.1546e-14, 1.2434e-14,\n",
      "         6.2172e-15, 1.1546e-14, 2.6645e-14, 1.2434e-14, 8.8818e-15, 6.2172e-15,\n",
      "         2.4869e-14, 3.6415e-14, 1.4211e-14, 3.3751e-14, 8.8818e-15, 1.5987e-14,\n",
      "         9.7700e-15, 1.4211e-14, 7.9936e-15, 1.5987e-14, 1.2434e-14, 1.0103e-14,\n",
      "         3.5527e-14, 1.7764e-14, 3.1974e-14, 2.8422e-14, 2.8422e-14, 2.4869e-14,\n",
      "         4.2633e-14, 1.5987e-14, 1.4211e-14, 3.1974e-14, 2.4869e-14, 9.3259e-15,\n",
      "         2.4869e-14, 1.5987e-14, 1.2434e-14, 9.7700e-15, 1.4211e-14, 2.4869e-14,\n",
      "         1.7986e-14, 8.2157e-15, 3.0198e-14, 1.2434e-14, 1.6875e-14, 1.1546e-14,\n",
      "         2.8422e-14, 2.1316e-14, 1.5987e-14, 1.4211e-14, 8.8818e-15, 2.1316e-14,\n",
      "         3.0198e-14, 2.8422e-14, 2.8422e-14, 5.3291e-14, 1.1990e-14, 1.3323e-14,\n",
      "         1.5987e-14, 4.2633e-14, 2.3093e-14, 1.5099e-14, 1.5987e-14, 4.2633e-14,\n",
      "         2.1316e-14, 8.5265e-14, 1.9540e-14, 2.1316e-14, 4.8850e-15, 8.7708e-15,\n",
      "         4.6185e-14, 1.2434e-14, 2.3093e-14, 6.3949e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 108: layer3.7.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 108\n",
      "Max diff:\n",
      " tensor([1.7986e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8850e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0658e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.9936e-15, 0.0000e+00, 1.7764e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.2172e-15, 0.0000e+00, 0.0000e+00, 9.1038e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.2172e-15, 0.0000e+00, 3.5527e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.7740e-15, 0.0000e+00, 7.9936e-15, 7.0499e-15,\n",
      "         0.0000e+00, 1.2143e-15, 0.0000e+00, 2.6923e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.4147e-15, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         2.1372e-15, 0.0000e+00, 3.5527e-15, 3.5527e-15, 0.0000e+00, 3.1086e-15,\n",
      "         1.7986e-14, 3.9968e-15, 0.0000e+00, 4.1633e-15, 3.3307e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2720e-15, 1.2185e-14,\n",
      "         0.0000e+00, 6.2172e-15, 0.0000e+00, 0.0000e+00, 4.4409e-15, 3.5527e-15,\n",
      "         6.2172e-15, 0.0000e+00, 4.9960e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1070e-15, 4.8850e-15, 7.5495e-15,\n",
      "         0.0000e+00, 0.0000e+00, 7.3275e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 65, 129, 147, 162, 164, 175, 178, 193, 195, 200, 202, 203, 205, 207,\n",
      "        212, 215, 216, 218, 219, 221, 222, 223, 225, 226, 232, 233, 235, 238,\n",
      "        239, 240, 242, 249, 250, 251, 254])\n",
      "\n",
      "failing Cout = tensor([ 65, 129, 147, 162, 164, 175, 178, 193, 195, 200, 202, 203, 205, 207,\n",
      "        212, 215, 216, 218, 219, 221, 222, 223, 225, 226, 232, 233, 235, 238,\n",
      "        239, 240, 242, 249, 250, 251, 254])  (len = 35)\n",
      "passing Cout = tensor([156])  (len = 1)\n",
      "\n",
      "Executing module 109: layer3.7.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 109\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 109\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 2,  4,  7, 10, 11, 12, 16, 18, 19, 30, 33, 35, 38, 40, 41, 45, 49, 53,\n",
      "        55, 58, 61]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([129, 130, 140, 143, 146, 148, 159, 168, 170, 171, 172, 173, 176, 177,\n",
      "        178, 181, 182, 184, 186, 187, 190]) to machine 2\n",
      "\t\t sending C_out tensor([193, 194, 199, 202, 203, 205, 206, 208, 209, 211, 212, 214, 222, 223,\n",
      "        226, 227, 231, 233, 235, 236, 237, 238, 239, 240, 244, 251, 252, 253,\n",
      "        254]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 109\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60,\n",
      "        61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 109\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 109\n",
      "Max diff:\n",
      " tensor([1.5987e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.6613e-15, 6.6613e-15, 6.2172e-15, 2.5535e-15, 4.8850e-15, 2.4425e-15,\n",
      "         4.4409e-15, 3.8858e-15, 3.7748e-15, 5.3291e-15, 4.7184e-15, 5.7732e-15,\n",
      "         8.4377e-15, 7.1054e-15, 3.5527e-15, 5.3291e-15, 3.3307e-16, 4.4409e-15,\n",
      "         4.5519e-15, 4.4409e-15, 7.5495e-15, 7.5495e-15, 3.4417e-15, 4.4409e-15,\n",
      "         1.6653e-16, 4.2188e-15, 3.5527e-15, 2.4425e-15, 4.4409e-15, 2.2204e-15,\n",
      "         5.5511e-15, 5.3291e-15, 1.6653e-15, 8.4377e-15, 7.1054e-15, 3.9968e-15,\n",
      "         3.5527e-15, 3.2196e-15, 4.6629e-15, 5.8981e-17, 3.5527e-15, 5.3291e-15,\n",
      "         4.4409e-15, 4.4409e-16, 4.5519e-15, 3.5527e-15, 4.4409e-15, 3.2752e-15,\n",
      "         3.9968e-15, 3.5527e-15, 1.4211e-14, 3.3307e-16, 4.6629e-15, 4.6907e-15,\n",
      "         5.7732e-15, 7.0222e-15, 2.2204e-15, 7.1054e-15, 3.7748e-15, 7.1054e-15,\n",
      "         3.7748e-15, 3.5527e-15, 8.2157e-15, 2.7756e-16, 5.7732e-15, 8.4377e-15,\n",
      "         6.6613e-15, 7.1054e-15, 4.4409e-15, 3.9968e-15, 6.5503e-15, 6.6613e-15,\n",
      "         5.3291e-15, 4.6629e-15, 6.2172e-15, 5.3291e-15, 5.7732e-15, 6.4393e-15,\n",
      "         2.4425e-15, 7.1054e-15, 3.5527e-15, 1.0547e-14, 3.3307e-15, 9.7700e-15,\n",
      "         5.7732e-15, 5.1070e-15, 7.8826e-15, 2.8866e-15, 7.6605e-15, 3.7748e-15,\n",
      "         8.8818e-15, 4.4409e-15, 7.1054e-15, 4.4409e-15, 3.8303e-15, 7.3552e-15,\n",
      "         8.6597e-15, 8.8818e-15, 1.5987e-14, 7.4385e-15, 6.8834e-15, 6.4393e-15,\n",
      "         9.7700e-15, 6.6613e-15, 4.5519e-15, 7.1054e-15, 6.6613e-15, 3.7748e-15,\n",
      "         8.4377e-15, 5.1070e-15, 8.8818e-15, 4.3299e-15, 4.2188e-15, 3.4417e-15,\n",
      "         7.5495e-15, 7.8826e-15, 7.9936e-15, 6.2172e-15, 5.9952e-15, 3.5527e-15,\n",
      "         8.1046e-15, 6.2172e-15, 4.9960e-15, 3.7748e-15, 4.0523e-15, 5.8842e-15,\n",
      "         5.3291e-15, 7.9936e-15, 4.1078e-15, 5.5511e-15, 6.6613e-15, 5.7732e-15,\n",
      "         6.6613e-15, 8.4377e-15, 7.7716e-15, 8.8818e-15, 5.1070e-15, 1.1546e-14,\n",
      "         8.4377e-15, 8.8818e-15, 1.4211e-14, 9.7700e-15, 9.7700e-15, 6.2172e-15,\n",
      "         4.4409e-15, 9.3259e-15, 7.1054e-15, 7.3275e-15, 7.9936e-15, 1.5987e-14,\n",
      "         8.8818e-15, 5.3291e-15, 9.7700e-15, 1.1546e-14, 5.3291e-15, 8.8818e-15,\n",
      "         9.3259e-15, 6.2172e-15, 7.9936e-15, 8.8818e-15, 9.7700e-15, 5.7732e-15,\n",
      "         5.5511e-15, 1.1546e-14, 8.8818e-15, 1.0714e-14, 7.9936e-15, 1.0658e-14,\n",
      "         1.2434e-14, 8.8818e-15, 7.1054e-15, 6.6613e-15, 9.7700e-15, 6.6613e-15,\n",
      "         1.0658e-14, 7.9936e-15, 6.8834e-15, 1.0658e-14, 1.1546e-14, 4.4409e-15,\n",
      "         7.9936e-15, 6.6613e-15, 6.6613e-15, 5.1070e-15, 6.2172e-15, 7.1054e-15,\n",
      "         4.8850e-15, 7.9936e-15, 8.8818e-15, 6.0507e-15, 5.3291e-15, 8.8818e-15,\n",
      "         7.8271e-15, 8.8818e-15, 1.0214e-14, 1.2879e-14, 7.1054e-15, 1.0658e-14,\n",
      "         1.0658e-14, 9.3259e-15, 1.0658e-14, 7.1054e-15, 1.1546e-14, 8.8818e-15,\n",
      "         6.4393e-15, 7.9936e-15, 7.9936e-15, 6.8834e-15, 7.9936e-15, 7.9936e-15,\n",
      "         1.2434e-14, 9.7700e-15, 8.4377e-15, 7.9936e-15, 7.1054e-15, 6.2172e-15,\n",
      "         8.8818e-15, 9.1038e-15, 7.1054e-15, 9.4369e-15, 9.3259e-15, 8.4377e-15,\n",
      "         9.7700e-15, 9.7700e-15, 1.1990e-14, 9.9920e-15, 9.7700e-15, 1.1546e-14,\n",
      "         8.4377e-15, 7.5495e-15, 1.1158e-14, 1.1102e-14, 7.1054e-15, 8.5834e-15,\n",
      "         6.6613e-15, 5.3291e-15, 7.1054e-15, 1.0214e-14, 7.0222e-15, 9.7700e-15,\n",
      "         8.8818e-15, 7.1054e-15, 7.7716e-15, 7.1054e-15, 7.1054e-15, 1.5099e-14,\n",
      "         8.4377e-15, 6.8834e-15, 1.2434e-14, 6.6613e-15, 1.5099e-14, 7.1054e-15,\n",
      "         7.9936e-15, 1.5099e-14, 6.6613e-15, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 110: layer3.7.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 110\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 110\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 110\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 110\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 110\n",
      "Max diff:\n",
      " tensor([7.1054e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.0547e-15, 2.8866e-15, 1.2212e-15, 3.8858e-16, 1.2212e-15, 6.6613e-16,\n",
      "         1.5543e-15, 5.5511e-17, 8.3267e-16, 1.8874e-15, 1.6653e-16, 1.4433e-15,\n",
      "         2.6645e-15, 1.3323e-15, 1.3323e-15, 1.5543e-15, 1.1102e-16, 9.9920e-16,\n",
      "         1.1657e-15, 1.3323e-15, 2.3315e-15, 2.2204e-15, 1.0547e-15, 1.2212e-15,\n",
      "         6.9389e-17, 1.9984e-15, 3.8858e-16, 3.8858e-16, 1.8874e-15, 4.9960e-16,\n",
      "         7.7716e-16, 2.4425e-15, 5.5511e-16, 2.1094e-15, 2.6645e-15, 1.1102e-15,\n",
      "         5.5511e-16, 1.8874e-15, 1.9984e-15, 2.0817e-17, 4.1373e-16, 7.7716e-16,\n",
      "         3.8511e-16, 1.3878e-16, 1.2768e-15, 6.6613e-16, 1.4433e-15, 1.5543e-15,\n",
      "         6.5226e-16, 1.3323e-15, 5.7732e-15, 1.1102e-16, 1.7764e-15, 2.4425e-15,\n",
      "         1.3323e-15, 1.6098e-15, 1.1102e-15, 2.8866e-15, 9.4369e-16, 1.7764e-15,\n",
      "         1.1657e-15, 9.4369e-16, 3.7748e-15, 9.7145e-17, 1.4433e-15, 2.8866e-15,\n",
      "         2.1094e-15, 1.4433e-15, 6.1062e-16, 6.9389e-16, 8.3267e-16, 1.2768e-15,\n",
      "         7.7716e-16, 1.1657e-15, 1.9984e-15, 9.9920e-16, 8.6042e-16, 1.3878e-15,\n",
      "         5.5511e-16, 9.9920e-16, 4.4409e-16, 4.5519e-15, 4.9960e-16, 1.7764e-15,\n",
      "         1.1102e-15, 6.3838e-16, 1.8457e-15, 7.3552e-16, 7.6328e-16, 4.9960e-16,\n",
      "         1.9984e-15, 7.7716e-16, 8.8818e-16, 1.3323e-15, 9.1593e-16, 8.0491e-16,\n",
      "         1.9984e-15, 2.6090e-15, 5.3291e-15, 4.8572e-16, 2.4980e-15, 8.3267e-16,\n",
      "         2.6645e-15, 5.1348e-16, 8.3267e-16, 2.2204e-15, 2.3870e-15, 9.9920e-16,\n",
      "         1.9568e-15, 6.6613e-16, 1.6653e-15, 6.5226e-16, 8.3267e-17, 3.3307e-16,\n",
      "         1.4988e-15, 9.8532e-16, 8.4655e-16, 8.3267e-16, 1.0547e-15, 1.1102e-15,\n",
      "         1.4988e-15, 1.1102e-16, 6.2624e-16, 3.4694e-17, 2.4980e-16, 1.4988e-15,\n",
      "         6.6613e-16, 1.9984e-15, 7.2164e-16, 1.6653e-15, 1.2490e-16, 1.4433e-15,\n",
      "         1.3774e-15, 4.2188e-15, 1.4641e-15, 3.1086e-15, 2.4425e-15, 5.3291e-15,\n",
      "         1.6376e-15, 3.9968e-15, 4.2188e-15, 1.6653e-15, 4.8850e-15, 8.8818e-16,\n",
      "         9.9920e-16, 4.6629e-15, 3.1086e-15, 2.9976e-15, 1.6653e-15, 5.3291e-15,\n",
      "         2.5535e-15, 1.2212e-15, 1.7764e-15, 4.8850e-15, 1.5543e-15, 3.3307e-15,\n",
      "         3.5527e-15, 1.3323e-15, 1.7764e-15, 3.9968e-15, 2.6645e-15, 1.5543e-15,\n",
      "         3.0878e-16, 7.1054e-15, 2.2204e-15, 4.4895e-15, 2.6645e-15, 1.6653e-15,\n",
      "         2.8866e-15, 3.9968e-15, 2.2204e-15, 1.1657e-15, 3.3307e-15, 1.6653e-15,\n",
      "         3.9968e-15, 3.1086e-15, 2.4425e-15, 3.4417e-15, 1.2212e-15, 1.6653e-15,\n",
      "         1.2282e-15, 2.1094e-15, 3.7748e-15, 1.9984e-15, 3.1086e-15, 1.2768e-15,\n",
      "         3.1086e-15, 1.7764e-15, 2.6645e-15, 8.0491e-16, 6.6613e-16, 4.4409e-15,\n",
      "         2.9560e-15, 1.7764e-15, 2.9421e-15, 1.8874e-15, 1.4433e-15, 2.8866e-15,\n",
      "         1.9984e-15, 4.1078e-15, 1.8319e-15, 1.9984e-15, 2.2204e-15, 1.4433e-15,\n",
      "         1.3323e-15, 2.4425e-15, 1.6653e-15, 1.2212e-15, 2.2204e-15, 2.6645e-15,\n",
      "         3.5527e-15, 1.7764e-15, 2.3315e-15, 1.4433e-15, 3.2196e-15, 1.7764e-15,\n",
      "         2.4425e-15, 3.2752e-15, 2.2204e-15, 1.2490e-15, 6.3838e-16, 2.2204e-15,\n",
      "         2.8866e-15, 2.8866e-15, 4.8850e-15, 3.1919e-15, 3.9968e-15, 3.2196e-15,\n",
      "         1.8319e-15, 1.7764e-15, 2.2760e-15, 1.6376e-15, 9.9920e-16, 3.4694e-15,\n",
      "         8.8818e-16, 9.9920e-16, 1.1657e-15, 1.9429e-15, 1.2473e-15, 2.4425e-15,\n",
      "         3.5527e-15, 1.9984e-15, 1.7208e-15, 9.1593e-16, 2.6689e-15, 5.3013e-15,\n",
      "         1.3878e-15, 1.3323e-15, 3.9968e-15, 1.4710e-15, 3.3307e-15, 1.5543e-15,\n",
      "         1.6653e-15, 2.1094e-15, 2.6645e-15, 2.9976e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 111: layer3.7.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 111\n",
      "Max diff:\n",
      " tensor([3.4195e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.9984e-15, 2.8866e-15, 1.2212e-15, 4.5519e-15, 2.6645e-15, 2.3315e-15,\n",
      "         1.5543e-15, 4.1911e-15, 8.3267e-16, 1.8874e-15, 1.6653e-16, 2.1094e-15,\n",
      "         2.6645e-15, 4.1356e-15, 1.3323e-15, 1.5543e-15, 1.1102e-16, 9.9920e-16,\n",
      "         1.1657e-15, 2.6645e-15, 2.3315e-15, 2.2204e-15, 1.1657e-15, 2.3315e-15,\n",
      "         6.9389e-17, 1.9984e-15, 3.8858e-16, 2.5119e-15, 1.8874e-15, 4.1633e-15,\n",
      "         1.2490e-15, 2.4425e-15, 1.8041e-15, 3.9968e-15, 2.6645e-15, 1.1102e-15,\n",
      "         2.3176e-15, 2.0539e-15, 1.9984e-15, 2.0817e-17, 7.1054e-15, 8.8818e-16,\n",
      "         2.7756e-15, 1.3878e-16, 5.1625e-15, 7.7716e-16, 1.4433e-15, 1.5543e-15,\n",
      "         1.5543e-15, 1.3323e-15, 5.7732e-15, 1.1102e-16, 2.1094e-15, 2.2760e-15,\n",
      "         1.5543e-15, 1.5543e-15, 3.9968e-15, 2.8866e-15, 3.1364e-15, 1.7764e-15,\n",
      "         2.6645e-15, 1.3878e-15, 3.7748e-15, 9.7145e-17, 6.2172e-15, 3.1086e-15,\n",
      "         7.5495e-15, 7.1054e-15, 1.9984e-15, 4.6629e-15, 1.2434e-14, 4.6629e-15,\n",
      "         2.6645e-15, 4.8850e-15, 1.9984e-15, 5.3291e-15, 8.4377e-15, 9.3259e-15,\n",
      "         5.5511e-16, 2.3315e-15, 4.4409e-15, 6.6613e-15, 1.7486e-15, 1.1102e-14,\n",
      "         8.8818e-15, 6.9389e-15, 6.6613e-15, 1.2768e-15, 8.8818e-15, 6.8834e-15,\n",
      "         2.3870e-15, 4.6074e-15, 7.3275e-15, 2.2204e-15, 1.6653e-15, 2.6923e-15,\n",
      "         4.8850e-15, 3.4417e-15, 5.3291e-15, 1.2768e-14, 3.1086e-15, 1.2768e-15,\n",
      "         6.6613e-15, 1.7486e-15, 1.4988e-15, 9.7700e-15, 3.1086e-15, 3.1086e-15,\n",
      "         3.4417e-15, 5.8564e-15, 4.8850e-15, 5.9952e-15, 8.8818e-16, 4.7184e-15,\n",
      "         3.1641e-15, 7.1054e-15, 4.8850e-15, 8.3267e-16, 4.8850e-15, 6.5503e-15,\n",
      "         1.4988e-15, 5.5511e-16, 4.8850e-15, 5.3291e-15, 3.1086e-15, 5.3291e-15,\n",
      "         1.1102e-15, 2.6645e-15, 2.3367e-15, 5.3291e-15, 2.4425e-15, 3.2752e-15,\n",
      "         3.9968e-15, 5.1070e-15, 1.2434e-14, 4.4409e-15, 2.4425e-15, 5.3291e-15,\n",
      "         7.9936e-15, 5.1070e-15, 4.2188e-15, 1.6653e-15, 4.8850e-15, 7.1054e-15,\n",
      "         7.9936e-15, 4.6629e-15, 4.4409e-15, 6.4393e-15, 1.6875e-14, 5.3291e-15,\n",
      "         1.0658e-14, 4.5519e-15, 2.4425e-15, 4.8850e-15, 2.2204e-15, 7.9936e-15,\n",
      "         5.1070e-15, 7.2164e-15, 7.5495e-15, 3.9968e-15, 2.6645e-15, 4.2188e-15,\n",
      "         3.5527e-15, 7.1054e-15, 3.9690e-15, 4.4895e-15, 8.8818e-15, 1.6653e-15,\n",
      "         2.4869e-14, 3.9968e-15, 2.2204e-15, 1.0658e-14, 3.3307e-15, 1.0991e-14,\n",
      "         1.1324e-14, 1.0547e-14, 2.6645e-15, 2.8866e-15, 6.6613e-15, 1.6653e-15,\n",
      "         1.2282e-15, 3.1086e-15, 3.5527e-15, 6.4393e-15, 3.3307e-15, 1.3323e-15,\n",
      "         1.0991e-14, 5.1625e-15, 1.7764e-14, 1.0436e-14, 6.6613e-16, 4.4409e-15,\n",
      "         1.1546e-14, 2.3981e-14, 8.8818e-15, 2.4980e-15, 2.6645e-15, 7.1054e-15,\n",
      "         8.4377e-15, 6.5503e-15, 8.4377e-15, 7.9936e-15, 9.9920e-15, 1.9984e-15,\n",
      "         1.2434e-14, 9.7700e-15, 8.4377e-15, 1.7764e-14, 8.6597e-15, 5.3291e-15,\n",
      "         8.4377e-15, 2.9310e-14, 1.4211e-14, 2.6645e-15, 3.5527e-15, 3.5527e-15,\n",
      "         6.2172e-15, 7.7716e-15, 4.9960e-15, 6.8834e-15, 6.9389e-15, 3.4195e-14,\n",
      "         7.5495e-15, 9.7700e-15, 5.9952e-15, 1.0658e-14, 1.2434e-14, 8.8818e-15,\n",
      "         1.5987e-14, 9.7700e-15, 9.7700e-15, 1.3323e-14, 2.1316e-14, 5.7732e-15,\n",
      "         7.5495e-15, 1.7764e-15, 2.8866e-15, 1.7764e-14, 6.6613e-15, 5.3291e-15,\n",
      "         4.7740e-15, 3.4417e-15, 2.7756e-15, 3.5527e-15, 5.5511e-15, 1.1990e-14,\n",
      "         7.9936e-15, 1.1102e-14, 3.9968e-15, 6.2172e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.6653e-15, 3.3307e-15, 4.4409e-15, 1.2879e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 112: layer3.7.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 112\n",
      "Max diff:\n",
      " tensor([3.4195e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.9984e-15, 2.5535e-15, 6.9389e-16, 4.5519e-15, 1.7764e-15, 5.1868e-16,\n",
      "         1.0547e-15, 4.1911e-15, 0.0000e+00, 1.2768e-15, 0.0000e+00, 6.6613e-16,\n",
      "         0.0000e+00, 2.6090e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 2.4425e-15, 2.7409e-16, 1.3323e-15, 0.0000e+00, 3.4694e-16,\n",
      "         0.0000e+00, 1.9984e-15, 0.0000e+00, 2.5119e-15, 0.0000e+00, 4.1633e-15,\n",
      "         1.9429e-16, 1.2212e-15, 1.4710e-15, 3.9968e-15, 0.0000e+00, 3.8858e-16,\n",
      "         2.3176e-15, 1.1102e-15, 1.0270e-15, 0.0000e+00, 7.1054e-15, 0.0000e+00,\n",
      "         2.7756e-15, 0.0000e+00, 5.1625e-15, 0.0000e+00, 6.0368e-16, 1.5543e-15,\n",
      "         1.5543e-15, 8.7430e-16, 4.7184e-16, 0.0000e+00, 4.3715e-16, 2.2760e-15,\n",
      "         3.3307e-16, 3.8858e-16, 4.9960e-16, 0.0000e+00, 3.1364e-15, 0.0000e+00,\n",
      "         2.6645e-15, 1.3878e-15, 3.7748e-15, 0.0000e+00, 6.2172e-15, 3.1086e-15,\n",
      "         7.5495e-15, 7.1054e-15, 1.9984e-15, 4.6629e-15, 1.2434e-14, 4.6629e-15,\n",
      "         2.6645e-15, 4.8850e-15, 6.3838e-16, 5.3291e-15, 8.4377e-15, 9.3259e-15,\n",
      "         0.0000e+00, 2.3315e-15, 4.4409e-15, 6.6613e-15, 0.0000e+00, 1.1102e-14,\n",
      "         8.8818e-15, 1.2212e-15, 6.6613e-15, 1.2768e-15, 8.8818e-15, 6.8834e-15,\n",
      "         1.2768e-15, 4.6074e-15, 7.3275e-15, 0.0000e+00, 1.6653e-15, 2.6923e-15,\n",
      "         4.8850e-15, 3.4417e-15, 1.1102e-16, 1.2768e-14, 2.4425e-15, 9.9920e-16,\n",
      "         6.6613e-15, 1.7486e-15, 7.2164e-16, 9.7700e-15, 3.1086e-15, 3.1086e-15,\n",
      "         3.4417e-15, 5.8564e-15, 4.8850e-15, 5.9952e-15, 8.8818e-16, 4.7184e-15,\n",
      "         3.1641e-15, 7.1054e-15, 4.8850e-15, 4.9960e-16, 4.8850e-15, 6.5503e-15,\n",
      "         1.6653e-16, 5.5511e-16, 4.8850e-15, 5.3291e-15, 3.1086e-15, 5.3291e-15,\n",
      "         1.1102e-15, 2.6645e-15, 2.2204e-15, 5.3291e-15, 2.4425e-15, 1.3461e-15,\n",
      "         3.9968e-15, 1.7764e-15, 1.2434e-14, 4.4409e-15, 1.6653e-15, 0.0000e+00,\n",
      "         7.9936e-15, 5.1070e-15, 2.6645e-15, 5.2736e-16, 1.8874e-15, 7.1054e-15,\n",
      "         7.9936e-15, 1.4433e-15, 2.4425e-15, 6.4393e-15, 1.6875e-14, 0.0000e+00,\n",
      "         1.0658e-14, 1.5543e-15, 2.4425e-15, 0.0000e+00, 6.3838e-16, 7.9936e-15,\n",
      "         5.1070e-15, 7.2164e-15, 7.5495e-15, 6.1062e-16, 3.8858e-16, 4.2188e-15,\n",
      "         3.5527e-15, 0.0000e+00, 3.9690e-15, 2.9976e-15, 8.8818e-15, 1.4988e-15,\n",
      "         2.4869e-14, 9.5757e-16, 5.5511e-16, 1.0658e-14, 2.8866e-15, 1.0991e-14,\n",
      "         7.9936e-15, 1.0547e-14, 1.1102e-15, 0.0000e+00, 6.6613e-15, 7.2164e-16,\n",
      "         1.2282e-15, 3.1086e-15, 1.4433e-15, 6.4393e-15, 3.3307e-15, 1.3323e-15,\n",
      "         1.0658e-14, 3.5527e-15, 1.7764e-14, 1.0436e-14, 0.0000e+00, 2.6645e-15,\n",
      "         1.1546e-14, 2.3981e-14, 8.8818e-15, 3.8858e-16, 2.6645e-15, 7.1054e-15,\n",
      "         8.4377e-15, 6.5503e-15, 8.4377e-15, 7.9936e-15, 9.9920e-15, 2.7062e-16,\n",
      "         1.2434e-14, 9.7700e-15, 8.4377e-15, 1.7764e-14, 8.6597e-15, 5.3291e-15,\n",
      "         8.4377e-15, 2.9310e-14, 1.4211e-14, 2.6645e-15, 3.5527e-15, 3.5527e-15,\n",
      "         6.2172e-15, 7.7716e-15, 4.9960e-15, 6.8834e-15, 6.9389e-15, 3.4195e-14,\n",
      "         7.5495e-15, 9.7700e-15, 4.2188e-15, 1.0658e-14, 1.2434e-14, 8.8818e-15,\n",
      "         1.5987e-14, 9.7700e-15, 9.7700e-15, 1.3323e-14, 2.1316e-14, 5.7732e-15,\n",
      "         7.5495e-15, 1.7764e-15, 2.8866e-15, 1.7764e-14, 6.6613e-15, 5.3291e-15,\n",
      "         4.7740e-15, 3.4417e-15, 2.7756e-15, 3.5527e-15, 3.9968e-15, 1.1990e-14,\n",
      "         7.9936e-15, 1.1102e-14, 3.9968e-15, 6.2172e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.1102e-15, 3.3307e-15, 4.4409e-15, 1.2879e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   9,  11,  13,  17,  19,  20,\n",
      "         21,  23,  25,  27,  29,  30,  31,  32,  33,  35,  36,  37,  38,  40,\n",
      "         42,  44,  46,  47,  48,  49,  50,  52,  53,  54,  55,  56,  58,  60,\n",
      "         61,  62,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
      "         76,  77,  79,  80,  81,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150,\n",
      "        151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   9,  11,  13,  17,  19,  20,\n",
      "         21,  23,  25,  27,  29,  30,  31,  32,  33,  35,  36,  37,  38,  40,\n",
      "         42,  44,  46,  47,  48,  49,  50,  52,  53,  54,  55,  56,  58,  60,\n",
      "         61,  62,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
      "         76,  77,  79,  80,  81,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150,\n",
      "        151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 227)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 113: layer3.8.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 113\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 113\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 113\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 113\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 113\n",
      "Max diff:\n",
      " tensor([2.8422e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-15, 3.9968e-15, 1.0658e-14, 6.2172e-15, 3.5527e-15, 3.9968e-15,\n",
      "         5.3291e-15, 3.5527e-14, 3.5527e-15, 4.4409e-15, 4.4409e-15, 4.4409e-15,\n",
      "         1.0658e-14, 2.6645e-15, 1.4211e-14, 2.2204e-15, 2.1316e-14, 1.0658e-14,\n",
      "         1.4211e-14, 3.5527e-15, 5.3291e-15, 6.2172e-15, 1.7764e-14, 1.0658e-14,\n",
      "         5.3291e-15, 5.6843e-14, 3.5527e-15, 2.6645e-15, 3.5527e-15, 3.5527e-15,\n",
      "         1.7764e-14, 2.4869e-14, 1.7764e-14, 3.1086e-15, 2.1316e-14, 5.3291e-15,\n",
      "         2.2204e-15, 7.1054e-15, 4.4409e-15, 2.6645e-15, 3.5527e-14, 3.1086e-15,\n",
      "         1.4211e-14, 7.1054e-15, 3.1086e-15, 1.5987e-14, 3.5527e-15, 4.4409e-15,\n",
      "         5.6843e-14, 9.7700e-15, 8.8818e-15, 3.1086e-15, 3.5527e-15, 3.5527e-15,\n",
      "         3.1086e-15, 4.4409e-15, 4.4409e-15, 5.3291e-15, 1.7764e-14, 1.4211e-14,\n",
      "         1.7764e-15, 7.1054e-15, 3.9968e-15, 3.5527e-15, 2.8422e-14, 5.3291e-15,\n",
      "         1.7764e-14, 5.3291e-15, 5.3291e-15, 1.4211e-14, 1.4211e-14, 1.4211e-14,\n",
      "         3.5527e-14, 1.7764e-14, 2.4869e-14, 1.0658e-14, 2.1316e-14, 4.9738e-14,\n",
      "         4.9738e-14, 7.9936e-15, 4.4409e-15, 2.1316e-14, 1.5987e-14, 4.4409e-15,\n",
      "         4.2633e-14, 3.5527e-14, 7.1054e-15, 1.0658e-14, 8.8818e-15, 6.2172e-15,\n",
      "         8.8818e-15, 7.9936e-15, 7.9936e-15, 1.1369e-13, 3.1974e-14, 4.2633e-14,\n",
      "         4.4409e-15, 7.1054e-14, 2.4869e-14, 1.5987e-14, 3.5527e-14, 6.2172e-15,\n",
      "         2.4869e-14, 4.2633e-14, 3.9968e-15, 2.1316e-14, 7.1054e-15, 6.2172e-15,\n",
      "         1.1546e-14, 5.3291e-15, 3.5527e-14, 4.2633e-14, 5.7732e-15, 4.2633e-14,\n",
      "         4.9738e-14, 1.4211e-14, 9.2371e-14, 1.4211e-14, 1.5987e-14, 6.2172e-15,\n",
      "         4.2633e-14, 7.9936e-15, 2.8422e-14, 7.1054e-15, 5.6843e-14, 1.4211e-14,\n",
      "         3.5527e-14, 7.9936e-15, 4.2633e-14, 7.8160e-14, 8.5265e-14, 9.9476e-14,\n",
      "         1.2790e-13, 1.1369e-13, 9.9476e-14, 5.6843e-14, 8.5265e-14, 5.6843e-14,\n",
      "         4.4409e-15, 6.3949e-14, 3.5527e-14, 1.1369e-13, 7.1054e-14, 8.5265e-14,\n",
      "         7.1054e-15, 7.8160e-14, 4.4409e-15, 3.5527e-14, 1.7764e-14, 7.1054e-14,\n",
      "         1.0658e-14, 3.5527e-14, 1.1369e-13, 7.1054e-15, 8.5265e-14, 1.5987e-14,\n",
      "         9.9476e-14, 4.2633e-14, 1.2434e-14, 1.2790e-13, 4.2633e-14, 1.4211e-14,\n",
      "         4.2633e-14, 7.1054e-14, 1.5987e-14, 1.4211e-13, 2.1316e-14, 2.8422e-14,\n",
      "         1.2790e-13, 7.1054e-15, 2.8422e-14, 1.1369e-13, 4.2633e-14, 4.2633e-14,\n",
      "         2.1316e-14, 7.1054e-14, 1.7764e-14, 5.6843e-14, 3.5527e-14, 3.0198e-14,\n",
      "         3.1974e-14, 2.1316e-14, 1.2790e-13, 8.5265e-14, 3.1974e-14, 1.4211e-14,\n",
      "         6.3949e-14, 1.4211e-14, 4.9738e-14, 1.4211e-14, 9.9476e-14, 2.4869e-14,\n",
      "         1.4211e-13, 8.5265e-14, 1.2790e-13, 6.3949e-14, 9.2371e-14, 4.9738e-14,\n",
      "         3.9080e-14, 5.7732e-14, 7.8160e-14, 2.7001e-13, 1.1369e-13, 8.5265e-14,\n",
      "         1.1369e-13, 4.9738e-14, 1.7053e-13, 4.9738e-14, 1.1369e-13, 1.2790e-13,\n",
      "         1.1369e-13, 1.1369e-13, 9.9476e-14, 5.3291e-14, 6.3949e-14, 7.1054e-14,\n",
      "         9.2371e-14, 5.6843e-14, 6.3949e-14, 6.3949e-14, 5.7288e-14, 8.5265e-14,\n",
      "         8.5265e-14, 8.5265e-14, 9.9476e-14, 5.6843e-14, 1.0303e-13, 6.3949e-14,\n",
      "         3.5527e-14, 7.1054e-14, 7.1054e-14, 1.3500e-13, 9.9476e-14, 6.3949e-14,\n",
      "         1.1369e-13, 5.6843e-14, 1.2790e-13, 3.5527e-14, 2.8422e-13, 1.8474e-13,\n",
      "         4.6185e-14, 9.9476e-14, 7.8160e-14, 7.1054e-14, 1.8474e-13, 3.9080e-14,\n",
      "         8.5265e-14, 6.3949e-14, 5.6843e-14, 1.1369e-13, 1.2790e-13, 6.9278e-14,\n",
      "         1.0658e-13, 9.9476e-14, 1.2790e-13, 9.2371e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 114: layer3.8.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 114\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 114\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 114\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 114\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 114\n",
      "Max diff:\n",
      " tensor([1.1369e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3323e-15, 1.1102e-15, 3.1086e-15, 1.5543e-15, 8.8818e-16, 1.1102e-15,\n",
      "         1.3323e-15, 5.3291e-15, 9.9920e-16, 1.1102e-15, 1.1102e-15, 1.3323e-15,\n",
      "         2.2204e-15, 6.6613e-16, 3.1086e-15, 6.6613e-16, 4.4409e-15, 2.6645e-15,\n",
      "         3.1086e-15, 1.1102e-15, 1.4433e-15, 1.5543e-15, 3.5527e-15, 2.4425e-15,\n",
      "         1.5543e-15, 1.0658e-14, 8.8818e-16, 7.7716e-16, 8.8818e-16, 9.9920e-16,\n",
      "         3.1086e-15, 5.3291e-15, 3.5527e-15, 7.7716e-16, 4.4409e-15, 1.5543e-15,\n",
      "         5.5511e-16, 1.9984e-15, 1.1102e-15, 8.8818e-16, 7.1054e-15, 6.6613e-16,\n",
      "         3.1086e-15, 1.7764e-15, 7.7716e-16, 3.1086e-15, 1.1102e-15, 1.1102e-15,\n",
      "         7.9936e-15, 2.4425e-15, 1.7764e-15, 8.8818e-16, 9.9920e-16, 1.1102e-15,\n",
      "         7.7716e-16, 1.3323e-15, 1.1102e-15, 1.5543e-15, 3.9968e-15, 2.6645e-15,\n",
      "         5.5511e-16, 1.7764e-15, 8.8818e-16, 1.1102e-15, 7.1054e-15, 1.1102e-15,\n",
      "         4.4409e-15, 1.5543e-15, 1.5543e-15, 4.4409e-15, 4.4409e-15, 3.5527e-15,\n",
      "         4.4409e-15, 4.4409e-15, 6.2172e-15, 3.1086e-15, 5.3291e-15, 1.0658e-14,\n",
      "         1.4211e-14, 2.2204e-15, 1.1102e-15, 5.3291e-15, 4.4409e-15, 1.3323e-15,\n",
      "         7.9936e-15, 7.1054e-15, 2.2204e-15, 2.6645e-15, 2.6645e-15, 1.7764e-15,\n",
      "         2.2204e-15, 2.2204e-15, 2.4425e-15, 1.0658e-14, 7.9936e-15, 1.4211e-14,\n",
      "         1.1102e-15, 1.9540e-14, 5.3291e-15, 3.9968e-15, 6.2172e-15, 1.7764e-15,\n",
      "         5.3291e-15, 8.8818e-15, 1.1102e-15, 3.5527e-15, 2.2204e-15, 1.7764e-15,\n",
      "         3.3307e-15, 1.3323e-15, 8.8818e-15, 3.9968e-15, 1.6653e-15, 5.3291e-15,\n",
      "         7.9936e-15, 3.9968e-15, 2.4869e-14, 3.5527e-15, 3.5527e-15, 1.5543e-15,\n",
      "         1.0658e-14, 2.4425e-15, 7.9936e-15, 1.9984e-15, 1.0658e-14, 3.5527e-15,\n",
      "         8.8818e-15, 2.4425e-15, 1.2434e-14, 1.9540e-14, 2.8422e-14, 2.6645e-14,\n",
      "         3.1974e-14, 2.1316e-14, 2.1316e-14, 7.9936e-15, 2.1316e-14, 1.2434e-14,\n",
      "         1.1102e-15, 1.7764e-14, 7.1054e-15, 1.0658e-14, 1.5987e-14, 2.1316e-14,\n",
      "         1.7764e-15, 1.4211e-14, 1.3323e-15, 1.2434e-14, 3.9968e-15, 2.1316e-14,\n",
      "         3.1086e-15, 7.9936e-15, 3.1974e-14, 1.7764e-15, 2.8422e-14, 4.8850e-15,\n",
      "         2.1316e-14, 8.8818e-15, 3.5527e-15, 4.2633e-14, 7.9936e-15, 3.1086e-15,\n",
      "         1.0658e-14, 1.2434e-14, 4.4409e-15, 2.8422e-14, 4.4409e-15, 7.1054e-15,\n",
      "         1.7764e-14, 2.2204e-15, 7.9936e-15, 1.4211e-14, 7.1054e-15, 1.2434e-14,\n",
      "         4.4409e-15, 1.4211e-14, 5.3291e-15, 1.5987e-14, 7.9936e-15, 7.1054e-15,\n",
      "         1.0658e-14, 5.3291e-15, 3.5527e-14, 3.5527e-14, 8.8818e-15, 2.6645e-15,\n",
      "         1.5987e-14, 3.9968e-15, 1.4211e-14, 5.3291e-15, 2.1316e-14, 7.1054e-15,\n",
      "         4.2633e-14, 1.9540e-14, 3.5527e-14, 1.2434e-14, 2.1316e-14, 1.4211e-14,\n",
      "         6.6613e-15, 9.3259e-15, 1.4211e-14, 6.3949e-14, 2.8422e-14, 1.4211e-14,\n",
      "         2.8422e-14, 7.9936e-15, 2.4869e-14, 1.0658e-14, 1.7764e-14, 2.4869e-14,\n",
      "         3.1974e-14, 2.8422e-14, 2.1316e-14, 9.7700e-15, 7.9936e-15, 1.4211e-14,\n",
      "         2.4869e-14, 1.4211e-14, 1.3323e-14, 1.6875e-14, 1.3656e-14, 1.5987e-14,\n",
      "         1.9540e-14, 1.7764e-14, 2.8422e-14, 1.4211e-14, 2.3093e-14, 2.1316e-14,\n",
      "         1.2434e-14, 1.2434e-14, 1.7764e-14, 3.0198e-14, 2.4869e-14, 1.7764e-14,\n",
      "         3.1974e-14, 1.4211e-14, 3.1974e-14, 4.8850e-15, 1.1369e-13, 4.9738e-14,\n",
      "         7.1054e-15, 2.1316e-14, 1.5099e-14, 1.7764e-14, 4.9738e-14, 1.2434e-14,\n",
      "         2.4869e-14, 1.4211e-14, 1.0658e-14, 3.1974e-14, 2.6645e-14, 1.7764e-14,\n",
      "         2.1316e-14, 3.5527e-14, 3.1974e-14, 1.5987e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 115: layer3.8.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 115\n",
      "Max diff:\n",
      " tensor([1.4211e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8440e-15, 9.7700e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8842e-15, 2.2204e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.5527e-15, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.2149e-15, 0.0000e+00, 2.9976e-15, 5.5511e-15, 5.3291e-15,\n",
      "         1.3323e-15, 9.3259e-15, 1.7764e-15, 2.6645e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.9968e-15, 0.0000e+00, 5.7732e-15, 0.0000e+00, 0.0000e+00,\n",
      "         3.9968e-15, 0.0000e+00, 3.5527e-15, 3.7748e-15, 3.2196e-15, 0.0000e+00,\n",
      "         6.2172e-15, 0.0000e+00, 3.1086e-15, 2.8866e-15, 4.6629e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15, 4.4409e-15,\n",
      "         0.0000e+00, 0.0000e+00, 8.0491e-16, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 5.4956e-15, 0.0000e+00, 4.2188e-15, 7.1054e-15, 0.0000e+00,\n",
      "         7.1054e-15, 0.0000e+00, 0.0000e+00, 7.1054e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.2180e-15, 1.0547e-15, 0.0000e+00, 4.4409e-16, 1.4211e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15]], dtype=torch.float64)\n",
      " tensor([129, 130, 135, 140, 159, 160, 179, 186, 188, 193, 195, 196, 197, 198,\n",
      "        199, 200, 201, 205, 207, 210, 212, 213, 214, 216, 218, 219, 220, 226,\n",
      "        227, 230, 233, 235, 237, 238, 240, 243, 247, 248, 250, 251, 255])\n",
      "\n",
      "failing Cout = tensor([129, 130, 135, 140, 159, 160, 179, 186, 188, 193, 195, 196, 197, 198,\n",
      "        199, 200, 201, 205, 207, 210, 212, 213, 214, 216, 218, 219, 220, 226,\n",
      "        227, 230, 233, 235, 237, 238, 240, 243, 247, 248, 250, 251, 255])  (len = 41)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 116: layer3.8.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 116\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 116\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 116\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21,\n",
      "        22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
      "        40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
      "        59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  90,  91,  92,  93,\n",
      "         94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 116\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 116\n",
      "Max diff:\n",
      " tensor([1.9540e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 3.3307e-15, 2.0539e-15, 2.6645e-15, 3.9968e-15, 2.6645e-15,\n",
      "         6.9805e-15, 5.3291e-15, 1.9984e-15, 3.1086e-15, 6.5503e-15, 2.8866e-15,\n",
      "         7.5495e-15, 2.5535e-15, 3.0531e-15, 3.7748e-15, 5.7732e-15, 3.9968e-15,\n",
      "         2.8866e-15, 3.8858e-15, 2.3315e-15, 1.1102e-14, 9.1038e-15, 5.3291e-15,\n",
      "         1.5266e-16, 3.8858e-15, 2.4425e-15, 8.8818e-15, 4.6629e-15, 4.4409e-15,\n",
      "         5.3291e-15, 3.1086e-15, 5.3291e-15, 5.7732e-15, 7.1054e-15, 3.8858e-15,\n",
      "         7.5495e-15, 5.3291e-15, 2.2204e-15, 2.7756e-16, 1.0658e-14, 5.4123e-15,\n",
      "         5.3291e-15, 1.9429e-16, 3.9413e-15, 2.8866e-15, 3.5527e-15, 6.3283e-15,\n",
      "         7.9936e-15, 2.3037e-15, 7.1054e-15, 1.9429e-16, 1.7764e-15, 3.1086e-15,\n",
      "         9.7700e-15, 1.9429e-15, 9.5479e-15, 4.4409e-15, 7.3275e-15, 2.9352e-15,\n",
      "         3.9968e-15, 1.9360e-15, 3.3307e-15, 6.4393e-15, 3.1086e-15, 2.5535e-15,\n",
      "         4.4409e-15, 4.2188e-15, 1.0658e-14, 2.3315e-15, 4.8850e-15, 1.2434e-14,\n",
      "         2.8866e-15, 6.2172e-15, 1.4211e-14, 4.2744e-15, 7.9936e-15, 6.6613e-15,\n",
      "         2.7200e-15, 3.5527e-15, 3.9968e-15, 4.4409e-15, 6.6613e-15, 1.0658e-14,\n",
      "         4.4409e-15, 2.8866e-15, 2.6645e-15, 5.4956e-15, 2.4425e-15, 1.2434e-14,\n",
      "         8.6597e-15, 7.1054e-15, 6.2172e-15, 2.6645e-15, 4.5519e-15, 4.5519e-15,\n",
      "         1.0450e-14, 8.8818e-15, 1.2434e-14, 2.4425e-15, 3.1086e-15, 6.2172e-15,\n",
      "         1.1102e-14, 6.7168e-15, 9.7700e-15, 3.5527e-15, 5.3291e-15, 1.2434e-14,\n",
      "         1.2434e-14, 5.7732e-15, 3.9968e-15, 5.7732e-15, 5.3291e-15, 1.0658e-14,\n",
      "         1.6875e-14, 5.7732e-15, 3.3307e-15, 4.1078e-15, 7.9936e-15, 3.2196e-15,\n",
      "         3.1641e-15, 2.2204e-15, 3.5527e-15, 2.7478e-15, 3.4417e-15, 4.2188e-15,\n",
      "         4.9960e-15, 7.6605e-15, 6.2172e-15, 4.2188e-15, 5.7732e-15, 8.2157e-15,\n",
      "         7.9936e-15, 6.2172e-15, 6.6613e-15, 3.9968e-15, 4.8850e-15, 1.3323e-14,\n",
      "         1.3101e-14, 8.8818e-15, 9.7700e-15, 8.8818e-15, 5.9952e-15, 7.3275e-15,\n",
      "         4.8850e-15, 8.0491e-15, 5.7732e-15, 4.8850e-15, 9.5479e-15, 4.8850e-15,\n",
      "         4.8850e-15, 4.8850e-15, 7.1054e-15, 7.9936e-15, 3.5527e-15, 6.4393e-15,\n",
      "         6.6752e-15, 5.3291e-15, 6.2172e-15, 1.0658e-14, 5.3291e-15, 9.7700e-15,\n",
      "         3.9968e-15, 6.4393e-15, 7.9936e-15, 5.1070e-15, 4.6629e-15, 1.5987e-14,\n",
      "         7.5495e-15, 3.7748e-15, 3.5527e-15, 7.7438e-15, 5.7732e-15, 4.4409e-15,\n",
      "         1.2879e-14, 8.1046e-15, 7.1054e-15, 7.1054e-15, 4.8850e-15, 3.1086e-15,\n",
      "         4.2605e-15, 1.0658e-14, 5.3291e-15, 6.2172e-15, 4.6629e-15, 5.2180e-15,\n",
      "         6.6613e-15, 3.7748e-15, 4.4409e-15, 5.4678e-15, 2.7200e-15, 3.5527e-15,\n",
      "         8.8818e-15, 6.2172e-15, 1.1546e-14, 6.8279e-15, 6.4393e-15, 8.8818e-15,\n",
      "         1.2434e-14, 7.2720e-15, 7.5495e-15, 1.0658e-14, 8.8818e-15, 9.7700e-15,\n",
      "         1.2434e-14, 5.1070e-15, 6.6613e-15, 1.5099e-14, 5.3291e-15, 8.9928e-15,\n",
      "         1.2129e-14, 5.8842e-15, 5.7176e-15, 5.7732e-15, 5.7732e-15, 7.3275e-15,\n",
      "         6.6613e-15, 5.8842e-15, 7.9936e-15, 5.5511e-15, 7.9936e-15, 8.6597e-15,\n",
      "         6.6613e-15, 9.7700e-15, 7.1054e-15, 5.7732e-15, 7.9936e-15, 9.1038e-15,\n",
      "         8.6597e-15, 6.2172e-15, 7.3275e-15, 7.9936e-15, 1.0658e-14, 8.4377e-15,\n",
      "         7.1054e-15, 5.7732e-15, 1.4877e-14, 1.9540e-14, 3.7748e-15, 7.1054e-15,\n",
      "         8.4377e-15, 9.5479e-15, 4.8850e-15, 1.0658e-14, 5.7732e-15, 7.5495e-15,\n",
      "         7.1054e-15, 1.2879e-14, 6.7446e-15, 6.2172e-15, 7.9936e-15, 8.3822e-15,\n",
      "         6.3283e-15, 8.0491e-15, 6.6613e-15, 1.0436e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 117: layer3.8.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 117\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 117\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 117\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 117\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 117\n",
      "Max diff:\n",
      " tensor([7.9936e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 7.7716e-16, 2.7756e-17, 4.4409e-16, 2.2204e-15, 4.4409e-16,\n",
      "         1.7208e-15, 2.6645e-15, 4.4409e-16, 1.1102e-15, 3.2196e-15, 1.4433e-15,\n",
      "         1.1102e-15, 4.4409e-16, 3.4694e-16, 1.3878e-15, 5.5511e-16, 1.3323e-15,\n",
      "         5.5511e-16, 7.4940e-16, 1.1102e-15, 5.6621e-15, 3.7748e-15, 1.5543e-15,\n",
      "         5.5511e-17, 1.3531e-16, 7.7716e-16, 3.9968e-15, 2.0539e-15, 7.7716e-16,\n",
      "         2.4425e-15, 1.1102e-15, 1.8874e-15, 7.7716e-16, 1.8874e-15, 8.8818e-16,\n",
      "         3.9968e-15, 2.7756e-17, 1.3323e-15, 9.7145e-17, 8.8818e-16, 1.4364e-15,\n",
      "         7.7716e-16, 5.5511e-17, 8.6563e-16, 1.2212e-15, 4.4409e-16, 2.1649e-15,\n",
      "         2.7756e-16, 1.1657e-15, 2.7200e-15, 6.9389e-17, 7.7716e-16, 9.7145e-16,\n",
      "         3.9968e-15, 6.1062e-16, 2.9976e-15, 4.9960e-16, 1.3878e-15, 9.4369e-16,\n",
      "         3.0531e-16, 8.8818e-16, 1.6237e-15, 1.4433e-15, 2.0817e-16, 4.5103e-16,\n",
      "         1.3323e-15, 4.9960e-16, 2.3315e-15, 2.6671e-16, 5.5511e-16, 1.9984e-15,\n",
      "         7.2164e-16, 1.0512e-15, 4.2188e-15, 8.1879e-16, 1.3323e-15, 1.6653e-15,\n",
      "         3.8858e-16, 4.9960e-16, 4.4409e-16, 1.2768e-15, 2.6645e-15, 2.8866e-15,\n",
      "         1.0825e-15, 3.3307e-16, 9.7145e-17, 2.3315e-15, 9.0206e-17, 3.9968e-15,\n",
      "         2.8866e-15, 1.1102e-15, 1.1102e-15, 6.6613e-16, 1.0270e-15, 1.0270e-15,\n",
      "         1.3739e-15, 3.7748e-15, 2.4425e-15, 6.1062e-16, 1.1102e-15, 4.9960e-16,\n",
      "         3.7748e-15, 1.0408e-15, 6.6613e-16, 6.6613e-16, 2.2204e-15, 4.4409e-15,\n",
      "         2.4425e-15, 1.2212e-15, 4.9960e-16, 2.9143e-16, 5.5511e-17, 1.5543e-15,\n",
      "         7.9936e-15, 1.1380e-15, 2.2204e-16, 2.0817e-16, 1.7208e-15, 8.8818e-16,\n",
      "         4.9960e-16, 3.0531e-16, 7.2164e-16, 2.2204e-16, 2.0123e-16, 1.3323e-15,\n",
      "         9.1593e-16, 4.9960e-16, 2.4425e-15, 1.5543e-15, 9.9920e-16, 3.9968e-15,\n",
      "         1.4433e-15, 3.5527e-15, 1.3323e-15, 1.4433e-15, 2.0539e-15, 4.4409e-15,\n",
      "         3.6082e-15, 5.3291e-15, 2.4425e-15, 1.5543e-15, 1.9984e-15, 1.5127e-15,\n",
      "         9.9920e-16, 3.6915e-15, 1.7764e-15, 1.9984e-15, 2.3315e-15, 1.9984e-15,\n",
      "         1.5543e-15, 1.1310e-15, 2.5535e-15, 1.7764e-15, 7.7716e-16, 1.9984e-15,\n",
      "         1.2212e-15, 1.5543e-15, 1.9984e-15, 8.3267e-16, 3.1086e-15, 2.2204e-15,\n",
      "         4.1633e-16, 3.2196e-15, 1.5543e-15, 1.4433e-15, 2.1094e-15, 6.8834e-15,\n",
      "         2.4425e-15, 8.8818e-16, 1.5543e-15, 2.5188e-15, 2.1094e-15, 6.6613e-16,\n",
      "         6.2172e-15, 2.4564e-15, 2.4425e-15, 1.7764e-15, 7.2164e-16, 5.5511e-16,\n",
      "         6.6613e-16, 3.7748e-15, 1.7764e-15, 2.6645e-15, 1.1657e-15, 1.7833e-15,\n",
      "         2.4425e-15, 6.1062e-16, 1.2212e-15, 1.3878e-15, 5.5511e-17, 1.9984e-15,\n",
      "         2.4425e-15, 1.3323e-15, 2.4980e-15, 9.9920e-16, 9.9920e-16, 2.1788e-15,\n",
      "         2.6645e-15, 4.0801e-15, 2.0539e-15, 3.3307e-15, 1.3878e-15, 1.7764e-15,\n",
      "         3.1086e-15, 2.0539e-15, 1.5543e-15, 3.3307e-15, 1.4155e-15, 2.6923e-15,\n",
      "         3.0670e-15, 1.2212e-15, 1.4433e-15, 1.5543e-15, 1.7764e-15, 2.1927e-15,\n",
      "         1.8874e-15, 1.8319e-15, 3.7748e-15, 1.4433e-15, 1.7208e-15, 1.9984e-15,\n",
      "         1.8319e-15, 2.4425e-15, 3.1086e-15, 1.2733e-15, 2.4425e-15, 2.3315e-15,\n",
      "         2.4841e-15, 1.6653e-15, 2.2204e-15, 2.4425e-15, 2.4425e-15, 3.1086e-15,\n",
      "         1.7764e-15, 9.9920e-16, 2.8311e-15, 5.9952e-15, 8.0491e-16, 1.5543e-15,\n",
      "         2.6645e-15, 2.3315e-15, 1.8319e-15, 1.6653e-15, 2.0331e-15, 2.6645e-15,\n",
      "         1.5543e-15, 2.3315e-15, 1.9984e-15, 1.9984e-15, 1.9984e-15, 1.9706e-15,\n",
      "         1.5266e-15, 1.2976e-15, 1.8874e-15, 2.9976e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 118: layer3.8.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 118\n",
      "Max diff:\n",
      " tensor([3.4639e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-15, 2.8311e-15, 6.9389e-16, 4.4409e-15, 2.6645e-15, 4.9960e-16,\n",
      "         1.8874e-15, 4.4409e-15, 4.4409e-16, 1.2768e-15, 3.2196e-15, 1.4433e-15,\n",
      "         1.1102e-15, 2.7756e-15, 3.4694e-16, 1.3878e-15, 5.5511e-16, 1.3323e-15,\n",
      "         5.5511e-16, 2.6645e-15, 1.1102e-15, 5.6621e-15, 3.7748e-15, 1.5543e-15,\n",
      "         5.5511e-17, 1.8874e-15, 7.7716e-16, 6.2172e-15, 2.0539e-15, 4.3854e-15,\n",
      "         2.4425e-15, 1.5543e-15, 1.8874e-15, 3.9968e-15, 1.8874e-15, 8.8818e-16,\n",
      "         3.9968e-15, 1.1102e-15, 1.3323e-15, 9.7145e-17, 7.3275e-15, 1.4364e-15,\n",
      "         2.8866e-15, 5.5511e-17, 5.3013e-15, 1.2212e-15, 4.9960e-16, 3.7192e-15,\n",
      "         1.6376e-15, 1.1657e-15, 2.7200e-15, 6.9389e-17, 7.7716e-16, 2.7756e-15,\n",
      "         3.9968e-15, 6.1062e-16, 2.9976e-15, 4.9960e-16, 3.2196e-15, 9.4369e-16,\n",
      "         2.6645e-15, 1.4433e-15, 4.8850e-15, 1.4433e-15, 5.7732e-15, 2.9976e-15,\n",
      "         6.9944e-15, 7.1054e-15, 2.4425e-15, 4.6629e-15, 1.3323e-14, 4.1078e-15,\n",
      "         2.7200e-15, 4.1078e-15, 4.2188e-15, 5.3291e-15, 7.9936e-15, 8.8818e-15,\n",
      "         3.8858e-16, 2.4425e-15, 4.4409e-15, 6.2172e-15, 2.6645e-15, 1.2434e-14,\n",
      "         9.3259e-15, 1.3323e-15, 6.6613e-15, 2.8866e-15, 8.8818e-15, 6.5503e-15,\n",
      "         2.8866e-15, 4.3854e-15, 6.4393e-15, 6.6613e-16, 1.9984e-15, 3.0809e-15,\n",
      "         5.5511e-15, 4.9960e-15, 2.4425e-15, 1.2934e-14, 2.6645e-15, 1.1380e-15,\n",
      "         6.6613e-15, 1.5821e-15, 8.3267e-16, 8.8818e-15, 3.8303e-15, 4.4409e-15,\n",
      "         3.4417e-15, 5.8564e-15, 5.1070e-15, 6.1062e-15, 8.8818e-16, 5.4401e-15,\n",
      "         9.3259e-15, 7.3275e-15, 5.3291e-15, 5.5511e-16, 6.2172e-15, 6.7168e-15,\n",
      "         4.9960e-16, 6.3838e-16, 5.1070e-15, 5.3291e-15, 3.1086e-15, 6.1062e-15,\n",
      "         1.3323e-15, 2.6645e-15, 2.4425e-15, 5.1070e-15, 2.5535e-15, 3.9968e-15,\n",
      "         3.9968e-15, 3.5527e-15, 1.2434e-14, 4.4409e-15, 2.5258e-15, 4.4409e-15,\n",
      "         9.7700e-15, 7.1054e-15, 3.1086e-15, 1.5543e-15, 1.9984e-15, 7.5495e-15,\n",
      "         7.9936e-15, 3.6915e-15, 2.2204e-15, 6.6613e-15, 1.7764e-14, 1.9984e-15,\n",
      "         1.1546e-14, 1.7764e-15, 2.9976e-15, 1.7764e-15, 9.4369e-16, 8.4377e-15,\n",
      "         5.5511e-15, 7.2164e-15, 7.3275e-15, 8.3267e-16, 3.1086e-15, 4.6629e-15,\n",
      "         3.9968e-15, 3.2196e-15, 3.8025e-15, 3.1086e-15, 1.0658e-14, 6.8834e-15,\n",
      "         2.4869e-14, 8.8818e-16, 1.5543e-15, 1.0658e-14, 3.5527e-15, 1.0825e-14,\n",
      "         6.2172e-15, 1.1213e-14, 2.4425e-15, 1.7764e-15, 7.1054e-15, 7.2164e-16,\n",
      "         1.0547e-15, 3.7748e-15, 1.8874e-15, 3.5527e-15, 2.7756e-15, 1.7833e-15,\n",
      "         1.1768e-14, 3.5527e-15, 1.7542e-14, 1.0214e-14, 5.5511e-17, 2.7756e-15,\n",
      "         1.1546e-14, 2.4869e-14, 1.0658e-14, 1.1102e-15, 2.3870e-15, 7.9936e-15,\n",
      "         8.8818e-15, 7.9936e-15, 7.9936e-15, 7.1054e-15, 1.0214e-14, 1.7764e-15,\n",
      "         1.2879e-14, 1.0658e-14, 8.4377e-15, 1.5987e-14, 8.1046e-15, 5.5511e-15,\n",
      "         8.2157e-15, 3.0198e-14, 1.4211e-14, 2.8866e-15, 3.9968e-15, 3.9968e-15,\n",
      "         6.2172e-15, 9.3259e-15, 4.5519e-15, 7.1054e-15, 6.5503e-15, 3.4639e-14,\n",
      "         7.3830e-15, 9.7700e-15, 5.5511e-15, 1.0658e-14, 1.2434e-14, 9.3259e-15,\n",
      "         1.5099e-14, 1.0658e-14, 9.9920e-15, 1.3323e-14, 2.4869e-14, 7.3275e-15,\n",
      "         7.9936e-15, 1.7764e-15, 2.8311e-15, 1.5987e-14, 7.1054e-15, 6.2172e-15,\n",
      "         5.2180e-15, 5.1070e-15, 2.8866e-15, 4.2188e-15, 4.2188e-15, 1.1990e-14,\n",
      "         8.4377e-15, 1.1102e-14, 5.7732e-15, 6.6613e-15, 1.0658e-14, 9.7700e-15,\n",
      "         2.2204e-15, 2.8866e-15, 4.4409e-15, 1.4544e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 119: layer3.8.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 119\n",
      "Max diff:\n",
      " tensor([3.4639e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-16, 0.0000e+00, 6.9389e-16, 4.4409e-15, 2.6645e-15, 0.0000e+00,\n",
      "         1.3878e-15, 4.4409e-15, 1.1102e-16, 4.5103e-16, 1.7764e-15, 1.4433e-15,\n",
      "         0.0000e+00, 3.3307e-16, 3.0531e-16, 1.3323e-15, 2.4980e-16, 6.0065e-16,\n",
      "         0.0000e+00, 2.6645e-15, 4.4409e-16, 1.0339e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8874e-15, 5.8287e-16, 0.0000e+00, 1.2212e-15, 2.8866e-15,\n",
      "         9.4803e-16, 7.8410e-16, 1.8874e-15, 3.9968e-15, 0.0000e+00, 3.8858e-16,\n",
      "         1.5543e-15, 1.1102e-15, 1.3323e-15, 0.0000e+00, 7.3275e-15, 1.3878e-15,\n",
      "         2.8866e-15, 0.0000e+00, 5.3013e-15, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         1.5543e-15, 3.3307e-16, 2.7200e-15, 0.0000e+00, 7.7716e-16, 8.8818e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-16, 7.7716e-16,\n",
      "         2.6645e-15, 1.4433e-15, 4.8850e-15, 9.0206e-16, 5.7732e-15, 2.9976e-15,\n",
      "         6.9944e-15, 7.1054e-15, 2.4425e-15, 4.6629e-15, 1.3323e-14, 3.3307e-15,\n",
      "         2.7200e-15, 4.1078e-15, 0.0000e+00, 5.3291e-15, 7.9936e-15, 8.8818e-15,\n",
      "         3.6082e-16, 2.4425e-15, 4.4409e-15, 6.2172e-15, 5.2042e-16, 1.2434e-14,\n",
      "         9.3259e-15, 1.3323e-15, 6.6613e-15, 2.8866e-15, 8.8818e-15, 6.5503e-15,\n",
      "         2.8866e-15, 3.5527e-15, 6.4393e-15, 0.0000e+00, 1.5543e-15, 1.9984e-15,\n",
      "         5.5511e-15, 1.3323e-15, 0.0000e+00, 1.2934e-14, 1.0825e-15, 1.1380e-15,\n",
      "         6.6613e-15, 1.5821e-15, 0.0000e+00, 8.8818e-15, 3.8303e-15, 3.5527e-15,\n",
      "         2.9976e-15, 5.8564e-15, 5.1070e-15, 6.1062e-15, 8.8818e-16, 5.4401e-15,\n",
      "         0.0000e+00, 7.3275e-15, 5.3291e-15, 5.5511e-16, 6.2172e-15, 6.7168e-15,\n",
      "         2.4633e-16, 4.1633e-16, 5.1070e-15, 5.3291e-15, 3.1086e-15, 6.1062e-15,\n",
      "         1.3323e-15, 2.6645e-15, 7.2164e-16, 5.1070e-15, 2.5535e-15, 3.9968e-15,\n",
      "         3.9968e-15, 2.7756e-16, 1.2434e-14, 4.4409e-15, 2.4425e-15, 0.0000e+00,\n",
      "         9.7700e-15, 5.7732e-15, 3.1086e-15, 0.0000e+00, 1.1102e-15, 7.5495e-15,\n",
      "         7.9936e-15, 3.6915e-15, 2.2204e-15, 6.6613e-15, 1.7764e-14, 1.2768e-15,\n",
      "         1.1546e-14, 1.3323e-15, 2.9976e-15, 0.0000e+00, 3.5388e-16, 8.4377e-15,\n",
      "         5.5511e-15, 2.6645e-15, 7.3275e-15, 8.3267e-16, 7.2164e-16, 4.6629e-15,\n",
      "         3.9968e-15, 2.7756e-15, 9.4369e-16, 3.1086e-15, 1.0658e-14, 5.0515e-15,\n",
      "         2.4869e-14, 4.1633e-16, 1.5543e-15, 1.0658e-14, 3.5527e-15, 1.0825e-14,\n",
      "         2.6645e-15, 8.4377e-15, 0.0000e+00, 1.1657e-15, 7.1054e-15, 7.2164e-16,\n",
      "         8.0491e-16, 3.3307e-15, 0.0000e+00, 3.5527e-15, 2.7756e-15, 1.7833e-15,\n",
      "         1.1768e-14, 3.5527e-15, 1.7542e-14, 1.0214e-14, 0.0000e+00, 2.7756e-15,\n",
      "         1.1546e-14, 2.4869e-14, 1.0658e-14, 6.6613e-16, 2.2204e-15, 7.9936e-15,\n",
      "         8.8818e-15, 7.9936e-15, 7.9936e-15, 7.1054e-15, 1.0214e-14, 2.2204e-16,\n",
      "         1.2879e-14, 1.0658e-14, 8.4377e-15, 1.5987e-14, 6.8834e-15, 5.5511e-15,\n",
      "         6.8834e-15, 3.0198e-14, 1.4211e-14, 2.8866e-15, 3.9968e-15, 3.9968e-15,\n",
      "         6.2172e-15, 9.3259e-15, 2.7756e-15, 7.1054e-15, 6.5503e-15, 3.4639e-14,\n",
      "         5.3291e-15, 9.7700e-15, 5.2180e-15, 1.0658e-14, 1.2434e-14, 9.3259e-15,\n",
      "         1.5099e-14, 1.0658e-14, 9.9920e-15, 1.3323e-14, 2.4869e-14, 7.3275e-15,\n",
      "         7.9936e-15, 1.7764e-15, 2.4425e-15, 1.5987e-14, 7.1054e-15, 6.2172e-15,\n",
      "         1.1102e-15, 5.1070e-15, 2.8866e-15, 4.2188e-15, 4.2188e-15, 1.1990e-14,\n",
      "         8.4377e-15, 1.1102e-14, 5.7732e-15, 6.6613e-15, 1.0658e-14, 9.7700e-15,\n",
      "         1.1102e-15, 2.8866e-15, 4.4409e-15, 1.4544e-14]], dtype=torch.float64)\n",
      " tensor([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  13,  14,  15,  16,\n",
      "         17,  19,  20,  21,  25,  26,  28,  29,  30,  31,  32,  33,  35,  36,\n",
      "         37,  38,  40,  41,  42,  44,  47,  48,  49,  50,  52,  53,  58,  59,\n",
      "         60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "         89,  90,  91,  92,  94,  95,  96,  97,  99, 100, 101, 102, 103, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
      "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180,\n",
      "        181, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  13,  14,  15,  16,\n",
      "         17,  19,  20,  21,  25,  26,  28,  29,  30,  31,  32,  33,  35,  36,\n",
      "         37,  38,  40,  41,  42,  44,  47,  48,  49,  50,  52,  53,  58,  59,\n",
      "         60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "         89,  90,  91,  92,  94,  95,  96,  97,  99, 100, 101, 102, 103, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
      "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180,\n",
      "        181, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 227)\n",
      "passing Cout = tensor([5])  (len = 1)\n",
      "\n",
      "Executing module 120: layer3.9.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 120\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 120\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 120\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 120\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 120\n",
      "Max diff:\n",
      " tensor([1.8474e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.2172e-15, 1.0658e-14, 3.1086e-15, 8.8818e-15, 1.7764e-14, 5.3291e-15,\n",
      "         5.3291e-15, 6.2172e-15, 3.5527e-15, 7.9936e-15, 3.5527e-15, 2.1316e-14,\n",
      "         4.4409e-15, 7.1054e-14, 1.0658e-14, 2.8422e-14, 7.9936e-15, 6.3949e-14,\n",
      "         3.1086e-15, 2.2204e-15, 2.6645e-15, 2.4869e-14, 2.6645e-15, 3.9968e-15,\n",
      "         2.2204e-15, 1.7764e-14, 2.6645e-15, 4.4409e-15, 3.5527e-15, 2.6645e-15,\n",
      "         4.4409e-15, 4.2633e-14, 5.3291e-15, 2.1316e-14, 4.4409e-15, 3.1974e-14,\n",
      "         1.7764e-14, 2.1316e-14, 3.5527e-15, 2.2204e-15, 6.2172e-15, 4.2633e-14,\n",
      "         3.9968e-15, 5.3291e-15, 2.1316e-14, 4.4409e-15, 2.8422e-14, 7.1054e-15,\n",
      "         6.2172e-15, 1.0658e-14, 4.4409e-15, 4.4409e-15, 8.8818e-15, 5.3291e-15,\n",
      "         5.3291e-15, 5.3291e-15, 2.2204e-15, 1.7764e-14, 3.5527e-15, 2.1316e-14,\n",
      "         1.2434e-14, 5.3291e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15, 3.9968e-15,\n",
      "         7.9936e-15, 2.4869e-14, 2.4869e-14, 8.5265e-14, 6.2172e-15, 1.7764e-14,\n",
      "         4.4409e-15, 3.1086e-15, 6.2172e-15, 5.3291e-15, 2.8422e-14, 1.2434e-14,\n",
      "         1.4211e-14, 5.6843e-14, 3.1086e-15, 1.5987e-14, 5.3291e-15, 3.5527e-15,\n",
      "         1.7764e-14, 1.2434e-14, 4.9738e-14, 4.4409e-15, 6.2172e-15, 3.5527e-14,\n",
      "         1.0658e-14, 4.9738e-14, 8.8818e-15, 7.1054e-15, 5.6843e-14, 3.9968e-15,\n",
      "         1.5987e-14, 5.6843e-14, 4.4409e-15, 2.1316e-14, 8.8818e-15, 7.9936e-15,\n",
      "         6.2172e-15, 7.9936e-15, 4.9738e-14, 1.0658e-14, 6.3949e-14, 4.7962e-14,\n",
      "         4.9738e-14, 7.1054e-15, 7.1054e-14, 1.2434e-14, 1.0658e-14, 1.4211e-14,\n",
      "         1.2434e-14, 3.5527e-15, 7.1054e-15, 4.2633e-14, 8.5265e-14, 7.1054e-14,\n",
      "         1.2434e-14, 5.3291e-15, 8.5265e-14, 7.1054e-15, 1.2434e-14, 6.2172e-15,\n",
      "         7.9936e-15, 2.4869e-14, 1.4211e-14, 3.5527e-14, 4.2633e-14, 7.1054e-15,\n",
      "         2.1316e-14, 1.4211e-14, 1.4211e-14, 1.0658e-14, 7.1054e-14, 1.2434e-14,\n",
      "         6.3949e-14, 4.2633e-14, 3.5527e-14, 1.0658e-14, 1.7764e-14, 2.8422e-14,\n",
      "         2.8422e-14, 7.1054e-14, 8.5265e-14, 3.5527e-14, 2.4869e-14, 8.8818e-15,\n",
      "         1.5987e-14, 7.1054e-14, 5.3291e-15, 1.2790e-13, 4.2633e-14, 8.5265e-14,\n",
      "         1.1369e-13, 9.9476e-14, 3.1974e-14, 8.5265e-14, 1.0658e-13, 7.9936e-15,\n",
      "         7.1054e-14, 5.6843e-14, 1.5987e-14, 8.5265e-14, 8.8818e-15, 7.8160e-14,\n",
      "         4.9738e-14, 1.5632e-13, 4.2633e-14, 1.5987e-14, 7.8160e-14, 2.8422e-14,\n",
      "         9.9476e-14, 4.9738e-14, 3.5527e-14, 2.1316e-14, 7.1054e-15, 4.2633e-14,\n",
      "         2.8422e-14, 3.5527e-14, 2.8422e-14, 4.6185e-14, 8.5265e-14, 9.7700e-15,\n",
      "         7.8160e-14, 7.1054e-14, 7.1054e-14, 1.1369e-13, 7.1054e-14, 6.3949e-14,\n",
      "         6.3949e-14, 6.3949e-14, 8.5265e-14, 9.9476e-14, 2.4869e-14, 6.3949e-14,\n",
      "         5.6843e-14, 1.1369e-13, 6.3949e-14, 4.4409e-14, 1.1369e-13, 1.2790e-13,\n",
      "         5.3291e-14, 1.8474e-13, 5.6843e-14, 1.1369e-13, 4.2633e-14, 3.1974e-14,\n",
      "         1.1369e-13, 1.4211e-13, 1.4211e-13, 9.9476e-14, 4.9738e-14, 4.9738e-14,\n",
      "         7.1054e-14, 7.1054e-14, 8.5265e-14, 9.9476e-14, 6.0396e-14, 8.5265e-14,\n",
      "         8.5265e-14, 7.8160e-14, 6.3949e-14, 5.6843e-14, 5.6843e-14, 1.5632e-13,\n",
      "         3.9080e-14, 7.8160e-14, 1.2790e-13, 9.9476e-14, 9.9476e-14, 1.4211e-13,\n",
      "         7.1054e-14, 1.4211e-13, 5.6843e-14, 8.5265e-14, 8.5265e-14, 1.1369e-13,\n",
      "         5.6843e-14, 5.6843e-14, 7.8160e-14, 4.9738e-14, 1.5632e-13, 9.9476e-14,\n",
      "         8.5265e-14, 5.6843e-14, 7.8160e-14, 9.9476e-14, 9.9476e-14, 1.2790e-13,\n",
      "         8.8818e-14, 9.9476e-14, 6.3949e-14, 8.5265e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 121: layer3.9.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 121\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 121\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 121\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 121\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 121\n",
      "Max diff:\n",
      " tensor([5.6843e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5543e-15, 2.6645e-15, 7.7716e-16, 2.6645e-15, 4.4409e-15, 1.3323e-15,\n",
      "         1.1102e-15, 1.3323e-15, 9.9920e-16, 1.9984e-15, 9.9920e-16, 5.3291e-15,\n",
      "         8.8818e-16, 1.2434e-14, 2.2204e-15, 6.2172e-15, 1.6653e-15, 1.5987e-14,\n",
      "         7.7716e-16, 4.4409e-16, 5.5511e-16, 6.2172e-15, 6.6613e-16, 9.9920e-16,\n",
      "         4.4409e-16, 3.5527e-15, 7.7716e-16, 1.3323e-15, 8.8818e-16, 6.6613e-16,\n",
      "         9.9920e-16, 8.8818e-15, 1.3323e-15, 3.5527e-15, 8.8818e-16, 6.2172e-15,\n",
      "         4.4409e-15, 4.4409e-15, 9.9920e-16, 5.5511e-16, 1.3323e-15, 8.8818e-15,\n",
      "         1.1102e-15, 1.3323e-15, 3.5527e-15, 8.8818e-16, 5.3291e-15, 1.7764e-15,\n",
      "         1.7764e-15, 2.6645e-15, 1.3323e-15, 1.1102e-15, 2.2204e-15, 1.1102e-15,\n",
      "         1.3323e-15, 1.3323e-15, 5.5511e-16, 3.5527e-15, 8.8818e-16, 3.9968e-15,\n",
      "         2.6645e-15, 1.3323e-15, 8.8818e-16, 7.7716e-16, 8.8818e-16, 1.1102e-15,\n",
      "         1.9984e-15, 7.1054e-15, 6.2172e-15, 1.7764e-14, 1.7764e-15, 4.4409e-15,\n",
      "         1.1102e-15, 8.8818e-16, 1.5543e-15, 1.5543e-15, 5.3291e-15, 3.5527e-15,\n",
      "         3.5527e-15, 1.2434e-14, 8.8818e-16, 4.4409e-15, 1.5543e-15, 1.1102e-15,\n",
      "         2.6645e-15, 3.5527e-15, 1.0658e-14, 1.3323e-15, 1.5543e-15, 5.3291e-15,\n",
      "         2.6645e-15, 1.0658e-14, 2.6645e-15, 1.7764e-15, 1.2434e-14, 1.1102e-15,\n",
      "         3.9968e-15, 1.0658e-14, 1.3323e-15, 4.8850e-15, 2.2204e-15, 2.2204e-15,\n",
      "         1.3323e-15, 1.7764e-15, 1.4211e-14, 2.8866e-15, 2.1316e-14, 7.7716e-15,\n",
      "         4.8850e-15, 2.2204e-15, 1.4211e-14, 2.6645e-15, 2.6645e-15, 3.5527e-15,\n",
      "         3.1086e-15, 1.1102e-15, 2.2204e-15, 1.4211e-14, 1.7764e-14, 1.2434e-14,\n",
      "         3.1086e-15, 1.3323e-15, 1.0658e-14, 1.4433e-15, 2.4425e-15, 1.9984e-15,\n",
      "         1.5543e-15, 4.8850e-15, 4.4409e-15, 1.0658e-14, 7.1054e-15, 1.7764e-15,\n",
      "         5.3291e-15, 2.4425e-15, 3.1086e-15, 2.6645e-15, 1.7764e-14, 3.1086e-15,\n",
      "         1.4211e-14, 1.0658e-14, 8.8818e-15, 3.1086e-15, 5.3291e-15, 5.3291e-15,\n",
      "         7.1054e-15, 1.7764e-14, 2.8422e-14, 1.0658e-14, 6.2172e-15, 1.9984e-15,\n",
      "         3.9968e-15, 1.7764e-14, 1.1102e-15, 3.1974e-14, 1.0658e-14, 2.1316e-14,\n",
      "         2.1316e-14, 1.5987e-14, 7.1054e-15, 1.2434e-14, 4.9738e-14, 2.2204e-15,\n",
      "         1.4211e-14, 1.4211e-14, 4.4409e-15, 1.5987e-14, 1.9984e-15, 1.7764e-14,\n",
      "         1.2434e-14, 3.9080e-14, 6.2172e-15, 3.9968e-15, 1.7764e-14, 8.8818e-15,\n",
      "         2.3093e-14, 4.4409e-15, 6.2172e-15, 6.2172e-15, 2.2204e-15, 8.8818e-15,\n",
      "         7.9936e-15, 8.8818e-15, 7.9936e-15, 6.6613e-15, 1.7764e-14, 1.9984e-15,\n",
      "         2.8422e-14, 1.0658e-14, 8.8818e-15, 2.4869e-14, 1.5987e-14, 1.4211e-14,\n",
      "         1.2434e-14, 1.7764e-14, 2.1316e-14, 2.4869e-14, 7.1054e-15, 8.8818e-15,\n",
      "         1.4211e-14, 3.1974e-14, 1.4211e-14, 1.1990e-14, 2.4869e-14, 2.8422e-14,\n",
      "         9.7700e-15, 5.6843e-14, 8.8818e-15, 3.1974e-14, 9.7700e-15, 5.7732e-15,\n",
      "         1.9540e-14, 3.5527e-14, 3.5527e-14, 3.5527e-14, 8.8818e-15, 1.2434e-14,\n",
      "         1.7764e-14, 1.0658e-14, 1.9540e-14, 2.1316e-14, 1.5987e-14, 1.9540e-14,\n",
      "         2.1316e-14, 1.4211e-14, 1.4211e-14, 1.7764e-14, 1.9540e-14, 3.5527e-14,\n",
      "         1.2434e-14, 2.1316e-14, 3.1974e-14, 1.3323e-14, 2.8422e-14, 4.2633e-14,\n",
      "         1.7764e-14, 2.8422e-14, 1.0658e-14, 1.9540e-14, 2.8422e-14, 2.8422e-14,\n",
      "         7.9936e-15, 1.4211e-14, 3.1974e-14, 8.8818e-15, 3.9080e-14, 2.3093e-14,\n",
      "         2.1316e-14, 1.4211e-14, 2.3093e-14, 3.5527e-14, 3.1974e-14, 4.6185e-14,\n",
      "         2.3093e-14, 2.4869e-14, 1.5987e-14, 1.7764e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 122: layer3.9.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 122\n",
      "Max diff:\n",
      " tensor([2.1760e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8858e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7716e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2760e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1760e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.1649e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.2172e-15, 0.0000e+00, 0.0000e+00, 7.9936e-15, 0.0000e+00, 4.6213e-15,\n",
      "         0.0000e+00, 3.9413e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-15,\n",
      "         6.9944e-15, 2.6645e-15, 7.5495e-15, 1.1990e-14, 0.0000e+00, 3.7748e-15,\n",
      "         8.8818e-15, 0.0000e+00, 2.7200e-15, 0.0000e+00, 1.9984e-15, 2.8866e-15,\n",
      "         4.8017e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15,\n",
      "         0.0000e+00, 7.7716e-15, 0.0000e+00, 0.0000e+00, 6.9944e-15, 5.7732e-15,\n",
      "         0.0000e+00, 2.7200e-15, 1.2323e-14, 5.9952e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1078e-15, 0.0000e+00, 0.0000e+00,\n",
      "         3.1086e-15, 0.0000e+00, 0.0000e+00, 4.1356e-15, 1.3212e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7748e-15, 0.0000e+00, 0.0000e+00,\n",
      "         6.6613e-16, 2.6784e-15, 0.0000e+00, 0.0000e+00, 4.7740e-15, 0.0000e+00,\n",
      "         2.2204e-15, 0.0000e+00, 6.2172e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([107, 130, 139, 153, 160, 170, 176, 186, 189, 191, 193, 197, 198, 199,\n",
      "        200, 201, 203, 204, 206, 208, 209, 210, 215, 217, 220, 221, 223, 224,\n",
      "        225, 231, 234, 237, 238, 243, 246, 247, 250, 252, 254])\n",
      "\n",
      "failing Cout = tensor([107, 130, 139, 153, 160, 170, 176, 186, 189, 191, 193, 197, 198, 199,\n",
      "        200, 201, 203, 204, 206, 208, 209, 210, 215, 217, 220, 221, 223, 224,\n",
      "        225, 231, 234, 237, 238, 243, 246, 247, 250, 252, 254])  (len = 39)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 123: layer3.9.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 123\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 123\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 2,  4,  7, 13, 19, 24, 25, 29, 31, 34, 37, 38, 40, 41, 42, 43, 45, 46,\n",
      "        51, 52, 56, 57, 58, 59, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([137, 139, 145, 146, 148, 149, 157, 159, 168, 171, 176, 180, 183, 185]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 196, 197, 201, 202, 203, 204, 205, 210, 211, 212, 213,\n",
      "        214, 217, 218, 219, 221, 222, 223, 227, 228, 229, 231, 232, 233, 234,\n",
      "        235, 237, 241, 242, 244, 245, 246, 249, 250, 251, 252, 253, 254]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 123\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19,\n",
      "        20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
      "        39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
      "        58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123,\n",
      "        124, 125, 126]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 123\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 123\n",
      "Max diff:\n",
      " tensor([1.7319e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-15, 1.1657e-14, 6.4393e-15, 3.9968e-15, 2.2898e-15, 3.5527e-15,\n",
      "         4.4409e-15, 6.6613e-15, 4.4409e-15, 5.3291e-15, 9.7700e-15, 3.1086e-15,\n",
      "         9.1038e-15, 5.7732e-15, 9.3259e-15, 8.8818e-15, 4.2188e-15, 2.9976e-15,\n",
      "         1.0214e-14, 4.9960e-15, 2.0539e-15, 5.3291e-15, 3.4417e-15, 7.6605e-15,\n",
      "         4.9960e-15, 4.8850e-15, 7.9936e-15, 7.3275e-15, 1.3323e-15, 6.4948e-15,\n",
      "         7.5495e-15, 5.2180e-15, 6.2172e-15, 1.0214e-14, 2.7756e-15, 7.1054e-15,\n",
      "         5.5511e-15, 3.6082e-15, 5.3291e-15, 2.4980e-15, 6.6336e-15, 1.5099e-14,\n",
      "         4.6629e-15, 3.0531e-16, 7.1054e-15, 5.1070e-15, 6.2172e-15, 1.0658e-14,\n",
      "         4.7184e-15, 3.9968e-15, 1.0658e-14, 4.4409e-15, 4.4409e-15, 5.1625e-15,\n",
      "         7.1054e-15, 8.3267e-15, 9.7700e-15, 5.6621e-15, 7.7716e-15, 1.2768e-14,\n",
      "         3.9968e-15, 6.8834e-15, 7.9936e-15, 3.9968e-15, 5.7176e-15, 5.2180e-15,\n",
      "         6.6613e-15, 7.3552e-15, 6.2172e-15, 5.7732e-15, 1.0658e-14, 7.9936e-15,\n",
      "         8.7708e-15, 1.0214e-14, 7.1054e-15, 5.7732e-15, 9.3259e-15, 6.8834e-15,\n",
      "         6.4393e-15, 8.4377e-15, 5.7732e-15, 9.7700e-15, 1.3323e-14, 6.9389e-15,\n",
      "         6.2172e-15, 4.8850e-15, 7.9936e-15, 1.1990e-14, 9.3259e-15, 3.9968e-15,\n",
      "         5.3291e-15, 5.1070e-15, 8.2157e-15, 3.5527e-15, 4.2188e-15, 9.7700e-15,\n",
      "         6.6613e-15, 5.3291e-15, 8.2157e-15, 6.2172e-15, 8.2157e-15, 5.5511e-15,\n",
      "         6.2172e-15, 5.3291e-15, 4.5519e-15, 6.0507e-15, 4.4964e-15, 7.9936e-15,\n",
      "         7.1054e-15, 7.7716e-15, 7.6467e-15, 7.5495e-15, 6.8834e-15, 6.7446e-15,\n",
      "         8.8818e-15, 1.2434e-14, 6.2172e-15, 7.9936e-15, 8.7708e-15, 5.2736e-15,\n",
      "         3.9968e-15, 5.6621e-15, 7.9936e-15, 2.2204e-15, 6.4393e-15, 5.9952e-15,\n",
      "         6.4393e-15, 1.9984e-15, 1.1102e-14, 7.1748e-15, 7.6605e-15, 1.3323e-14,\n",
      "         1.1546e-14, 9.7700e-15, 6.2172e-15, 1.1102e-14, 7.1054e-15, 1.0658e-14,\n",
      "         8.6597e-15, 8.2157e-15, 1.1546e-14, 8.4377e-15, 9.7700e-15, 1.3156e-14,\n",
      "         8.8263e-15, 8.8818e-15, 9.7700e-15, 1.0658e-14, 1.7319e-14, 1.2434e-14,\n",
      "         9.7700e-15, 7.1054e-15, 1.5099e-14, 1.4211e-14, 8.8818e-15, 6.2172e-15,\n",
      "         1.5099e-14, 9.3259e-15, 1.1990e-14, 9.7700e-15, 1.1990e-14, 7.9936e-15,\n",
      "         7.2442e-15, 9.7700e-15, 8.8818e-15, 8.8818e-15, 1.0766e-14, 5.3291e-15,\n",
      "         1.1546e-14, 1.5987e-14, 9.3259e-15, 7.1054e-15, 8.4377e-15, 9.1038e-15,\n",
      "         8.8818e-15, 9.7700e-15, 8.4377e-15, 1.0214e-14, 8.2157e-15, 1.1768e-14,\n",
      "         7.1054e-15, 1.4211e-14, 7.9936e-15, 1.5099e-14, 7.1054e-15, 7.9936e-15,\n",
      "         1.0658e-14, 1.0658e-14, 1.1990e-14, 1.4655e-14, 8.8818e-15, 1.0658e-14,\n",
      "         7.9936e-15, 1.1102e-14, 1.7319e-14, 6.2172e-15, 6.1062e-15, 7.7716e-15,\n",
      "         5.7732e-15, 7.5495e-15, 8.2157e-15, 1.0658e-14, 6.6613e-15, 7.9936e-15,\n",
      "         7.1054e-15, 6.2172e-15, 1.0214e-14, 1.1102e-14, 7.5495e-15, 8.4377e-15,\n",
      "         1.2434e-14, 1.1546e-14, 1.2212e-14, 1.2212e-14, 1.2434e-14, 6.6613e-15,\n",
      "         7.9381e-15, 1.2101e-14, 7.4940e-15, 7.1054e-15, 7.9936e-15, 1.0658e-14,\n",
      "         1.0658e-14, 8.6597e-15, 1.0658e-14, 1.0658e-14, 6.6613e-15, 1.1102e-14,\n",
      "         1.2879e-14, 1.0658e-14, 1.5432e-14, 1.0658e-14, 1.3323e-14, 9.7700e-15,\n",
      "         7.5495e-15, 7.5495e-15, 1.0658e-14, 1.1102e-14, 8.6597e-15, 5.8842e-15,\n",
      "         9.7700e-15, 1.0658e-14, 1.1047e-14, 9.7700e-15, 1.0658e-14, 1.1519e-14,\n",
      "         7.1054e-15, 1.3323e-14, 9.3259e-15, 8.2157e-15, 1.4211e-14, 7.1054e-15,\n",
      "         1.2879e-14, 7.9936e-15, 7.5495e-15, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 124: layer3.9.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 124\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 124\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 124\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 124\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 124\n",
      "Max diff:\n",
      " tensor([7.9936e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.5511e-16, 6.0507e-15, 2.7756e-16, 4.9960e-16, 1.3878e-16, 6.1062e-16,\n",
      "         1.1102e-15, 1.1935e-15, 8.8818e-16, 2.6645e-15, 2.6645e-15, 8.8818e-16,\n",
      "         1.5543e-15, 2.1094e-15, 1.6653e-15, 3.5527e-15, 7.4940e-16, 4.0246e-16,\n",
      "         3.1086e-15, 2.2204e-15, 4.1633e-16, 2.6645e-15, 6.8001e-16, 3.6707e-15,\n",
      "         1.0617e-15, 1.6653e-16, 5.5511e-16, 2.4425e-15, 3.6776e-16, 1.2212e-15,\n",
      "         2.4425e-15, 8.3267e-16, 3.3307e-16, 3.7748e-15, 4.4409e-16, 1.1102e-15,\n",
      "         2.4425e-15, 7.7716e-16, 1.5543e-15, 6.1062e-16, 1.9568e-15, 3.6637e-15,\n",
      "         6.3838e-16, 1.1102e-16, 1.4988e-15, 1.3600e-15, 1.6653e-15, 4.4409e-15,\n",
      "         2.4147e-15, 2.2204e-16, 3.1086e-15, 1.2490e-15, 4.4409e-16, 1.5543e-15,\n",
      "         3.5527e-15, 2.5535e-15, 3.3307e-15, 3.6082e-16, 3.1086e-15, 4.9960e-15,\n",
      "         9.9920e-16, 1.8874e-15, 2.8866e-15, 7.7716e-16, 8.1771e-16, 1.1102e-15,\n",
      "         1.9984e-15, 1.7278e-15, 7.7716e-16, 6.1062e-16, 1.9984e-15, 1.4433e-15,\n",
      "         1.6931e-15, 1.6653e-15, 1.3323e-15, 1.9429e-15, 2.8866e-15, 1.6931e-15,\n",
      "         5.9674e-16, 2.2204e-15, 7.7716e-16, 2.4217e-15, 6.6613e-15, 1.8457e-15,\n",
      "         6.3838e-16, 3.7123e-16, 1.3323e-15, 3.9968e-15, 9.9920e-16, 9.4369e-16,\n",
      "         1.6653e-15, 7.1471e-16, 2.3315e-15, 8.8818e-16, 1.3878e-15, 1.4988e-15,\n",
      "         1.6653e-15, 1.1102e-15, 3.3307e-15, 2.1094e-15, 2.5362e-15, 9.9920e-16,\n",
      "         1.8874e-15, 8.3267e-16, 1.1449e-15, 1.3184e-15, 6.6613e-16, 2.4425e-15,\n",
      "         2.1094e-15, 6.6613e-16, 1.4017e-15, 9.9920e-16, 1.1241e-15, 1.1935e-15,\n",
      "         3.5527e-15, 2.4425e-15, 1.1102e-15, 8.8818e-16, 1.5821e-15, 2.8311e-15,\n",
      "         7.7716e-16, 6.8348e-16, 1.9984e-15, 2.7929e-16, 7.7716e-16, 1.2212e-15,\n",
      "         1.7764e-15, 4.4409e-16, 2.9976e-15, 1.8319e-15, 2.4425e-15, 7.1054e-15,\n",
      "         3.5527e-15, 2.8866e-15, 1.4572e-15, 2.7756e-15, 2.6645e-15, 2.3315e-15,\n",
      "         3.2196e-15, 2.4286e-15, 3.7748e-15, 4.2744e-15, 4.8850e-15, 3.4417e-15,\n",
      "         2.1649e-15, 2.2204e-15, 3.5527e-15, 3.9968e-15, 7.9936e-15, 2.6645e-15,\n",
      "         7.7716e-16, 2.4425e-15, 3.9968e-15, 6.2172e-15, 3.5527e-15, 1.5543e-15,\n",
      "         5.1070e-15, 3.2196e-15, 2.2204e-15, 1.9984e-15, 6.6613e-15, 1.7764e-15,\n",
      "         1.3461e-15, 6.2172e-15, 2.2204e-15, 8.8818e-16, 5.3291e-15, 1.8874e-15,\n",
      "         3.3307e-15, 4.4409e-15, 2.2204e-16, 2.6645e-15, 3.2196e-15, 3.3307e-15,\n",
      "         2.7756e-15, 6.2172e-15, 1.9984e-15, 3.7748e-15, 1.1657e-15, 5.9952e-15,\n",
      "         6.6613e-16, 3.3862e-15, 3.1086e-15, 3.1086e-15, 1.3323e-15, 2.4425e-15,\n",
      "         5.1070e-15, 1.9984e-15, 2.2204e-15, 3.9968e-15, 1.8874e-15, 1.1102e-15,\n",
      "         2.4425e-15, 2.8866e-15, 5.5511e-15, 9.9920e-16, 1.4155e-15, 1.6376e-15,\n",
      "         1.3323e-15, 3.1086e-15, 2.1094e-15, 2.6645e-15, 1.1657e-15, 1.1102e-15,\n",
      "         1.3323e-15, 1.7764e-15, 3.4417e-15, 2.4425e-15, 1.6653e-15, 2.8866e-15,\n",
      "         4.2188e-15, 2.9976e-15, 2.7756e-15, 4.1356e-15, 4.8850e-15, 1.4433e-15,\n",
      "         2.4702e-15, 4.1633e-15, 2.7200e-15, 1.9984e-15, 1.0547e-15, 3.1086e-15,\n",
      "         3.9968e-15, 1.5543e-15, 3.9968e-15, 3.5527e-15, 1.7764e-15, 4.2188e-15,\n",
      "         3.7748e-15, 2.8866e-15, 2.2760e-15, 2.8866e-15, 2.9976e-15, 2.8866e-15,\n",
      "         1.2768e-15, 1.1154e-15, 1.4958e-15, 2.9976e-15, 1.9984e-15, 1.5543e-15,\n",
      "         3.2196e-15, 2.2204e-15, 4.6074e-15, 1.5543e-15, 5.3291e-15, 3.2335e-15,\n",
      "         1.3323e-15, 5.1070e-15, 3.3307e-15, 2.1649e-15, 2.7756e-15, 1.6653e-15,\n",
      "         3.2196e-15, 1.4433e-15, 2.6645e-15, 2.9976e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 125: layer3.9.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 125\n",
      "Max diff:\n",
      " tensor([3.4195e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.5511e-16, 6.0507e-15, 6.6613e-16, 4.3299e-15, 2.6645e-15, 6.1062e-16,\n",
      "         2.1094e-15, 4.6629e-15, 8.8818e-16, 2.6645e-15, 2.6645e-15, 1.4988e-15,\n",
      "         1.5543e-15, 2.1094e-15, 1.6653e-15, 3.9968e-15, 7.4940e-16, 7.2164e-16,\n",
      "         3.1086e-15, 3.1086e-15, 4.4409e-16, 2.6645e-15, 6.8001e-16, 3.6707e-15,\n",
      "         1.0617e-15, 1.8319e-15, 6.1062e-16, 2.4425e-15, 1.2212e-15, 2.7200e-15,\n",
      "         2.4425e-15, 1.3045e-15, 1.7764e-15, 4.8850e-15, 4.4409e-16, 1.1102e-15,\n",
      "         2.4425e-15, 1.1102e-15, 1.5543e-15, 6.1062e-16, 6.7724e-15, 3.6637e-15,\n",
      "         2.8311e-15, 1.1102e-16, 5.8842e-15, 1.3600e-15, 1.6653e-15, 4.4409e-15,\n",
      "         2.3315e-15, 2.7756e-16, 3.3307e-15, 1.2490e-15, 7.7716e-16, 1.5543e-15,\n",
      "         3.5527e-15, 2.5535e-15, 3.3307e-15, 3.6082e-16, 3.1086e-15, 4.9960e-15,\n",
      "         2.8866e-15, 2.2204e-15, 4.5519e-15, 1.5543e-15, 6.2172e-15, 3.2196e-15,\n",
      "         7.5495e-15, 7.1054e-15, 2.5535e-15, 4.4409e-15, 1.1546e-14, 4.1633e-15,\n",
      "         3.4972e-15, 4.5797e-15, 1.3323e-15, 5.7732e-15, 7.5495e-15, 7.9936e-15,\n",
      "         5.9674e-16, 3.1780e-15, 4.8850e-15, 7.1054e-15, 6.6613e-15, 1.1546e-14,\n",
      "         9.3259e-15, 1.5543e-15, 6.6613e-15, 3.9968e-15, 7.9936e-15, 6.7724e-15,\n",
      "         3.7748e-15, 3.3307e-15, 7.3275e-15, 8.8818e-16, 1.4988e-15, 2.2204e-15,\n",
      "         5.8842e-15, 1.9429e-15, 3.3307e-15, 1.4877e-14, 2.5362e-15, 1.4433e-15,\n",
      "         6.6613e-15, 1.1935e-15, 1.1449e-15, 9.7700e-15, 4.1633e-15, 3.5527e-15,\n",
      "         4.3299e-15, 5.9466e-15, 5.3291e-15, 6.3283e-15, 1.3323e-15, 4.8295e-15,\n",
      "         3.5527e-15, 7.1054e-15, 5.7732e-15, 8.8818e-16, 6.5503e-15, 6.7724e-15,\n",
      "         8.5348e-16, 6.8348e-16, 4.8850e-15, 5.3291e-15, 2.6645e-15, 6.8834e-15,\n",
      "         1.7764e-15, 2.6645e-15, 2.9976e-15, 5.8842e-15, 2.8311e-15, 9.5479e-15,\n",
      "         5.3291e-15, 2.8866e-15, 1.4211e-14, 3.9968e-15, 3.9968e-15, 2.3315e-15,\n",
      "         1.1102e-14, 5.9952e-15, 4.4409e-15, 4.2744e-15, 4.8850e-15, 1.0658e-14,\n",
      "         7.9936e-15, 3.7748e-15, 3.5527e-15, 6.3283e-15, 1.9540e-14, 2.6645e-15,\n",
      "         1.0658e-14, 2.4425e-15, 5.3291e-15, 6.2172e-15, 3.5527e-15, 8.4377e-15,\n",
      "         9.3259e-15, 3.5527e-15, 6.8834e-15, 2.4425e-15, 6.6613e-15, 4.8850e-15,\n",
      "         3.5527e-15, 7.1054e-15, 2.4425e-15, 2.9976e-15, 1.5543e-14, 5.4401e-15,\n",
      "         2.3093e-14, 4.4409e-15, 1.5543e-15, 1.0658e-14, 3.7748e-15, 9.7700e-15,\n",
      "         2.7756e-15, 1.0658e-14, 1.9984e-15, 3.7748e-15, 7.5495e-15, 5.9952e-15,\n",
      "         9.9920e-16, 4.8850e-15, 3.1086e-15, 3.3307e-15, 3.0531e-15, 2.9976e-15,\n",
      "         1.3767e-14, 4.4409e-15, 1.8208e-14, 9.7700e-15, 1.8874e-15, 3.0531e-15,\n",
      "         1.2434e-14, 2.3981e-14, 8.8818e-15, 1.5543e-15, 2.4425e-15, 7.9936e-15,\n",
      "         8.9928e-15, 1.1102e-14, 8.4377e-15, 7.7716e-15, 9.7700e-15, 1.1102e-15,\n",
      "         1.2879e-14, 1.0658e-14, 9.5479e-15, 1.5543e-14, 6.4670e-15, 5.8842e-15,\n",
      "         1.1102e-14, 3.1086e-14, 1.4211e-14, 5.1070e-15, 7.1054e-15, 4.2188e-15,\n",
      "         6.6613e-15, 1.0214e-14, 3.4417e-15, 5.3291e-15, 6.6613e-15, 3.4195e-14,\n",
      "         7.7716e-15, 9.7700e-15, 6.1062e-15, 1.2434e-14, 1.2434e-14, 8.8818e-15,\n",
      "         1.5099e-14, 9.7700e-15, 1.1713e-14, 1.4211e-14, 2.6645e-14, 6.8834e-15,\n",
      "         7.5495e-15, 2.2204e-15, 3.2196e-15, 1.4211e-14, 6.4393e-15, 6.2172e-15,\n",
      "         3.2196e-15, 6.6613e-15, 4.6074e-15, 4.4409e-15, 5.3291e-15, 1.2434e-14,\n",
      "         8.4377e-15, 9.3259e-15, 7.1054e-15, 6.8834e-15, 1.0658e-14, 1.0658e-14,\n",
      "         3.2196e-15, 3.1086e-15, 4.4409e-15, 1.6764e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 126: layer3.9.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 126\n",
      "Max diff:\n",
      " tensor([3.4195e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.7184e-16, 6.0507e-15, 0.0000e+00, 4.3299e-15, 2.6645e-15, 0.0000e+00,\n",
      "         2.1094e-15, 4.6629e-15, 0.0000e+00, 1.9099e-15, 2.6645e-15, 1.4988e-15,\n",
      "         0.0000e+00, 0.0000e+00, 5.6205e-16, 0.0000e+00, 2.7756e-16, 3.6082e-16,\n",
      "         6.2450e-17, 1.2768e-15, 5.5511e-17, 1.4433e-15, 6.8001e-16, 3.6707e-15,\n",
      "         3.8858e-16, 1.8319e-15, 4.9960e-16, 2.4425e-15, 1.2212e-15, 2.7200e-15,\n",
      "         0.0000e+00, 9.2981e-16, 1.7764e-15, 4.8850e-15, 0.0000e+00, 4.7184e-16,\n",
      "         1.7208e-15, 1.1102e-15, 9.9920e-16, 0.0000e+00, 6.2172e-15, 2.4702e-15,\n",
      "         2.8311e-15, 0.0000e+00, 5.8842e-15, 0.0000e+00, 1.6653e-15, 1.3323e-15,\n",
      "         2.2204e-15, 0.0000e+00, 2.2204e-15, 4.3715e-16, 7.7716e-16, 0.0000e+00,\n",
      "         3.4972e-15, 9.9920e-16, 2.2204e-16, 2.7409e-16, 1.9429e-16, 1.4433e-15,\n",
      "         2.8866e-15, 1.4433e-15, 2.1649e-15, 3.8858e-16, 6.2172e-15, 3.2196e-15,\n",
      "         7.5495e-15, 7.1054e-15, 2.5535e-15, 4.4409e-15, 1.1546e-14, 2.2760e-15,\n",
      "         3.4972e-15, 4.5519e-15, 1.3323e-15, 5.7732e-15, 7.5495e-15, 7.9936e-15,\n",
      "         3.3307e-16, 3.1780e-15, 4.8850e-15, 7.1054e-15, 0.0000e+00, 1.1546e-14,\n",
      "         9.3259e-15, 1.5543e-15, 6.6613e-15, 1.8874e-15, 7.9936e-15, 0.0000e+00,\n",
      "         3.7748e-15, 3.3307e-15, 4.8850e-15, 0.0000e+00, 1.4988e-15, 2.2204e-15,\n",
      "         5.8842e-15, 1.9429e-15, 3.3307e-15, 1.4877e-14, 2.5362e-15, 1.4433e-15,\n",
      "         6.6613e-15, 8.8818e-16, 1.1449e-15, 9.7700e-15, 4.1633e-15, 2.2760e-15,\n",
      "         2.4425e-15, 5.9466e-15, 5.3291e-15, 6.3283e-15, 1.3323e-15, 4.8295e-15,\n",
      "         2.2204e-15, 7.1054e-15, 5.7732e-15, 5.5511e-16, 6.5503e-15, 4.6629e-15,\n",
      "         8.5348e-16, 6.8348e-16, 4.8850e-15, 5.3291e-15, 2.6645e-15, 4.8156e-15,\n",
      "         1.4710e-15, 2.6645e-15, 1.5543e-15, 5.8842e-15, 2.3870e-15, 4.2188e-15,\n",
      "         5.3291e-15, 4.8572e-16, 1.4211e-14, 3.9968e-15, 1.7764e-15, 4.9960e-16,\n",
      "         1.1102e-14, 5.9952e-15, 4.4409e-15, 4.2744e-15, 3.2196e-15, 1.0658e-14,\n",
      "         7.9936e-15, 1.0547e-15, 2.9421e-15, 6.3283e-15, 1.9540e-14, 5.1695e-16,\n",
      "         1.0658e-14, 2.4425e-15, 5.3291e-15, 0.0000e+00, 2.0296e-16, 8.4377e-15,\n",
      "         5.9952e-15, 3.5527e-15, 6.8834e-15, 0.0000e+00, 2.0539e-15, 4.8850e-15,\n",
      "         3.5527e-15, 4.8850e-15, 2.0539e-15, 0.0000e+00, 1.5543e-14, 4.4409e-15,\n",
      "         2.3093e-14, 1.5127e-15, 1.5543e-15, 1.0658e-14, 3.7748e-15, 9.7700e-15,\n",
      "         2.2204e-15, 9.7700e-15, 0.0000e+00, 2.1094e-15, 7.5495e-15, 2.8866e-15,\n",
      "         4.9960e-16, 4.8850e-15, 1.3878e-15, 3.3307e-15, 2.7200e-15, 2.6645e-15,\n",
      "         1.3767e-14, 4.1078e-15, 1.4211e-14, 9.7700e-15, 1.8874e-15, 3.0531e-15,\n",
      "         1.2434e-14, 2.3981e-14, 8.8818e-15, 6.9389e-16, 2.4425e-15, 7.9936e-15,\n",
      "         8.9928e-15, 1.1102e-14, 8.4377e-15, 7.7716e-15, 9.7700e-15, 3.6082e-16,\n",
      "         1.2879e-14, 1.0658e-14, 9.5479e-15, 1.5543e-14, 5.9952e-15, 4.8850e-15,\n",
      "         3.8858e-15, 3.1086e-14, 1.4211e-14, 5.1070e-15, 6.6613e-15, 4.2188e-15,\n",
      "         6.6613e-15, 1.0214e-14, 3.4417e-15, 5.3291e-15, 6.6613e-15, 3.4195e-14,\n",
      "         7.7716e-15, 9.7700e-15, 5.7732e-15, 1.2434e-14, 1.2434e-14, 8.8818e-15,\n",
      "         1.5099e-14, 9.7700e-15, 1.1713e-14, 1.4211e-14, 2.6645e-14, 6.8834e-15,\n",
      "         7.5495e-15, 2.2204e-15, 2.6645e-15, 1.4211e-14, 1.7764e-15, 6.2172e-15,\n",
      "         1.3323e-15, 6.6613e-15, 4.6074e-15, 4.4409e-15, 5.1070e-15, 1.2434e-14,\n",
      "         8.4377e-15, 9.3259e-15, 7.1054e-15, 6.8834e-15, 1.0658e-14, 1.0658e-14,\n",
      "         1.9984e-15, 3.1086e-15, 4.4409e-15, 1.2879e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   3,   4,   6,   7,   9,  10,  11,  14,  16,  17,  18,  19,\n",
      "         20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  31,  32,  33,  35,\n",
      "         36,  37,  38,  40,  41,  42,  44,  46,  47,  48,  50,  51,  52,  54,\n",
      "         55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  83,\n",
      "         84,  85,  86,  87,  88,  90,  91,  92,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156,\n",
      "        157, 158, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172,\n",
      "        173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "        188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "        202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
      "        216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "        230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
      "        244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   3,   4,   6,   7,   9,  10,  11,  14,  16,  17,  18,  19,\n",
      "         20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  31,  32,  33,  35,\n",
      "         36,  37,  38,  40,  41,  42,  44,  46,  47,  48,  50,  51,  52,  54,\n",
      "         55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  83,\n",
      "         84,  85,  86,  87,  88,  90,  91,  92,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156,\n",
      "        157, 158, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172,\n",
      "        173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "        188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "        202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
      "        216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "        230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
      "        244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 236)\n",
      "passing Cout = tensor([15])  (len = 1)\n",
      "\n",
      "Executing module 127: layer3.10.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 127\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 127\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 127\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 127\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 127\n",
      "Max diff:\n",
      " tensor([1.8474e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 5.3291e-15, 3.1086e-15, 6.2172e-15, 4.2633e-14, 6.2172e-15,\n",
      "         2.8422e-14, 1.7764e-14, 2.4869e-14, 6.2172e-15, 4.4409e-15, 5.3291e-15,\n",
      "         4.8850e-15, 7.1054e-15, 6.2172e-15, 7.1054e-15, 2.8422e-14, 2.6645e-15,\n",
      "         1.7764e-14, 2.1316e-14, 8.5265e-14, 2.6645e-15, 4.4409e-15, 1.2434e-14,\n",
      "         2.4869e-14, 6.2172e-15, 1.0658e-14, 4.4409e-15, 3.9968e-15, 3.5527e-15,\n",
      "         6.2172e-15, 7.1054e-15, 6.2172e-15, 3.1086e-15, 2.6645e-15, 1.7764e-14,\n",
      "         3.5527e-15, 2.2204e-15, 2.6645e-15, 5.3291e-15, 4.4409e-15, 5.7732e-15,\n",
      "         3.5527e-15, 3.1086e-15, 3.1086e-15, 1.0658e-14, 2.2204e-15, 1.5987e-14,\n",
      "         2.1316e-14, 3.5527e-15, 3.5527e-15, 5.3291e-15, 3.5527e-15, 3.1086e-15,\n",
      "         5.3291e-15, 6.2172e-15, 1.5987e-14, 3.1086e-15, 8.8818e-15, 3.1086e-15,\n",
      "         3.1086e-15, 1.0658e-14, 2.6645e-15, 5.6843e-14, 1.7764e-14, 1.7764e-14,\n",
      "         2.1316e-14, 2.8422e-14, 8.5265e-14, 7.9936e-15, 9.9476e-14, 2.8422e-14,\n",
      "         4.9738e-14, 1.4211e-14, 4.9738e-14, 7.9936e-15, 1.7764e-14, 7.1054e-15,\n",
      "         2.1316e-14, 3.9080e-14, 9.7700e-15, 5.6843e-14, 6.2172e-15, 7.1054e-14,\n",
      "         3.5527e-14, 1.4211e-14, 5.6843e-14, 7.1054e-15, 8.5265e-14, 8.8818e-15,\n",
      "         2.4869e-14, 2.8422e-14, 2.8422e-14, 3.9968e-15, 2.1316e-14, 9.9476e-14,\n",
      "         2.8422e-14, 5.6843e-14, 3.1974e-14, 2.1316e-14, 8.8818e-15, 3.5527e-14,\n",
      "         1.4211e-14, 3.5527e-14, 4.4409e-15, 5.3291e-15, 1.0658e-14, 4.2633e-14,\n",
      "         2.1316e-14, 2.8422e-14, 8.5265e-14, 3.1974e-14, 1.7764e-14, 5.3291e-15,\n",
      "         6.2172e-15, 1.7764e-14, 4.9738e-14, 2.1316e-14, 1.0658e-14, 3.5527e-14,\n",
      "         4.9738e-14, 1.0658e-14, 1.5987e-14, 5.3291e-15, 2.1316e-14, 1.5987e-14,\n",
      "         7.1054e-15, 3.9968e-15, 5.6843e-14, 6.3949e-14, 1.1369e-13, 6.3949e-14,\n",
      "         7.1054e-14, 4.9738e-14, 8.8818e-15, 2.4869e-14, 2.8422e-14, 3.1974e-14,\n",
      "         8.5265e-14, 2.1316e-14, 4.2633e-14, 1.2790e-13, 9.2371e-14, 2.8422e-14,\n",
      "         1.0658e-14, 5.6843e-14, 6.3949e-14, 3.5527e-14, 1.9540e-14, 7.1054e-15,\n",
      "         2.8422e-14, 4.4409e-15, 3.1974e-14, 2.4869e-14, 4.9738e-14, 8.5265e-14,\n",
      "         8.5265e-14, 8.5265e-14, 5.6843e-14, 2.1316e-14, 6.3949e-14, 4.2633e-14,\n",
      "         4.2633e-14, 5.6843e-14, 1.4211e-13, 6.2172e-15, 3.5527e-14, 5.6843e-14,\n",
      "         3.1974e-14, 8.5265e-14, 1.4211e-14, 7.1054e-15, 1.5987e-14, 5.3291e-15,\n",
      "         1.7764e-14, 7.1054e-14, 1.1369e-13, 7.8160e-14, 1.4211e-14, 1.2434e-14,\n",
      "         8.5265e-14, 1.2790e-13, 1.7764e-14, 4.9738e-14, 2.8422e-14, 1.2790e-13,\n",
      "         1.2790e-13, 6.2172e-15, 5.6843e-14, 7.1054e-15, 1.7764e-14, 2.4869e-14,\n",
      "         4.9738e-14, 7.8160e-14, 1.1369e-13, 4.9738e-14, 4.9738e-14, 7.8160e-14,\n",
      "         9.9476e-14, 8.5265e-14, 8.5265e-14, 1.1369e-13, 4.9738e-14, 1.1369e-13,\n",
      "         9.9476e-14, 1.3500e-13, 1.2790e-13, 8.5265e-14, 9.9476e-14, 3.5527e-14,\n",
      "         7.8160e-14, 1.2790e-13, 1.5632e-13, 7.6383e-14, 9.2371e-14, 8.5265e-14,\n",
      "         9.2371e-14, 1.2790e-13, 1.1369e-13, 7.8160e-14, 8.5265e-14, 9.9476e-14,\n",
      "         5.6843e-14, 1.8474e-13, 8.5265e-14, 1.2790e-13, 3.5527e-14, 5.6843e-14,\n",
      "         9.2371e-14, 1.4211e-13, 5.6843e-14, 1.4211e-13, 1.5632e-13, 8.5265e-14,\n",
      "         1.7053e-13, 8.5265e-14, 5.6843e-14, 6.3949e-14, 1.2790e-13, 7.8160e-14,\n",
      "         9.9476e-14, 1.4211e-13, 1.3500e-13, 7.8160e-14, 1.1369e-13, 8.5265e-14,\n",
      "         7.1054e-14, 7.1054e-14, 7.1054e-14, 6.3949e-14, 4.6185e-14, 7.8160e-14,\n",
      "         9.2371e-14, 1.2790e-13, 9.9476e-14, 2.1316e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 128: layer3.10.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 128\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 128\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 128\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 128\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 128\n",
      "Max diff:\n",
      " tensor([5.6843e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.6613e-16, 1.3323e-15, 6.6613e-16, 1.3323e-15, 6.2172e-15, 1.5543e-15,\n",
      "         3.9968e-15, 3.5527e-15, 4.4409e-15, 1.1102e-15, 1.1102e-15, 1.6653e-15,\n",
      "         1.2212e-15, 1.7764e-15, 1.5543e-15, 1.9984e-15, 6.2172e-15, 6.6613e-16,\n",
      "         3.5527e-15, 3.9968e-15, 2.4869e-14, 7.7716e-16, 1.1102e-15, 2.6645e-15,\n",
      "         7.1054e-15, 1.5543e-15, 1.7764e-15, 1.1102e-15, 9.9920e-16, 7.7716e-16,\n",
      "         1.3323e-15, 1.3323e-15, 1.5543e-15, 8.8818e-16, 6.6613e-16, 3.1086e-15,\n",
      "         1.1102e-15, 6.6613e-16, 6.6613e-16, 1.1102e-15, 7.7716e-16, 1.4433e-15,\n",
      "         8.8818e-16, 7.7716e-16, 6.6613e-16, 1.9984e-15, 4.4409e-16, 3.5527e-15,\n",
      "         4.4409e-15, 8.8818e-16, 8.8818e-16, 1.2212e-15, 8.8818e-16, 6.6613e-16,\n",
      "         1.3323e-15, 1.3323e-15, 3.1086e-15, 8.8818e-16, 1.9984e-15, 7.7716e-16,\n",
      "         7.7716e-16, 2.2204e-15, 8.8818e-16, 1.2434e-14, 4.4409e-15, 4.4409e-15,\n",
      "         4.8850e-15, 6.2172e-15, 2.8422e-14, 2.2204e-15, 2.8422e-14, 4.4409e-15,\n",
      "         1.0658e-14, 3.9968e-15, 1.1546e-14, 1.9984e-15, 3.5527e-15, 1.5543e-15,\n",
      "         3.5527e-15, 6.2172e-15, 1.7764e-15, 7.9936e-15, 1.3323e-15, 1.4211e-14,\n",
      "         7.9936e-15, 3.1086e-15, 1.2434e-14, 1.7764e-15, 1.5987e-14, 2.2204e-15,\n",
      "         5.3291e-15, 7.1054e-15, 4.4409e-15, 9.9920e-16, 4.4409e-15, 2.1316e-14,\n",
      "         7.1054e-15, 1.2434e-14, 5.3291e-15, 4.4409e-15, 1.9984e-15, 7.1054e-15,\n",
      "         2.6645e-15, 6.2172e-15, 1.2212e-15, 1.3323e-15, 2.2204e-15, 1.0658e-14,\n",
      "         3.5527e-15, 4.4409e-15, 1.7764e-14, 7.1054e-15, 4.4409e-15, 1.5543e-15,\n",
      "         1.7764e-15, 4.4409e-15, 8.8818e-15, 5.3291e-15, 2.8866e-15, 5.3291e-15,\n",
      "         1.4211e-14, 2.6645e-15, 3.5527e-15, 1.5543e-15, 4.4409e-15, 3.5527e-15,\n",
      "         1.7764e-15, 9.9920e-16, 8.8818e-15, 1.5987e-14, 1.5987e-14, 1.7764e-14,\n",
      "         2.1316e-14, 7.9936e-15, 2.2204e-15, 3.9968e-15, 6.2172e-15, 6.2172e-15,\n",
      "         1.4211e-14, 3.9968e-15, 8.4377e-15, 3.5527e-14, 2.3093e-14, 6.2172e-15,\n",
      "         2.2204e-15, 1.4211e-14, 1.2434e-14, 1.0658e-14, 5.3291e-15, 1.7764e-15,\n",
      "         6.2172e-15, 1.1102e-15, 6.2172e-15, 5.3291e-15, 1.0658e-14, 1.7764e-14,\n",
      "         2.8422e-14, 1.7764e-14, 1.0658e-14, 4.8850e-15, 1.7764e-14, 7.1054e-15,\n",
      "         7.1054e-15, 4.4409e-15, 3.5527e-14, 1.7764e-15, 6.2172e-15, 1.0658e-14,\n",
      "         6.2172e-15, 2.1316e-14, 3.5527e-15, 1.7764e-15, 3.9968e-15, 1.3323e-15,\n",
      "         5.3291e-15, 2.3093e-14, 2.4869e-14, 1.3323e-14, 3.9968e-15, 2.6645e-15,\n",
      "         1.7764e-14, 2.4869e-14, 3.5527e-15, 9.3259e-15, 7.9936e-15, 2.8422e-14,\n",
      "         4.9738e-14, 1.5543e-15, 1.4211e-14, 1.7764e-15, 3.9968e-15, 4.8850e-15,\n",
      "         8.4377e-15, 2.4869e-14, 2.1316e-14, 1.5987e-14, 1.2434e-14, 1.5987e-14,\n",
      "         1.7764e-14, 1.4211e-14, 1.7764e-14, 2.4869e-14, 1.2434e-14, 3.3751e-14,\n",
      "         1.7764e-14, 2.5757e-14, 2.8422e-14, 1.4211e-14, 2.3093e-14, 1.0658e-14,\n",
      "         2.4869e-14, 2.8422e-14, 3.9080e-14, 1.3101e-14, 1.9540e-14, 1.5987e-14,\n",
      "         1.9540e-14, 2.8422e-14, 2.4869e-14, 1.7764e-14, 2.1316e-14, 2.3093e-14,\n",
      "         2.1316e-14, 3.3751e-14, 1.5987e-14, 2.8422e-14, 9.7700e-15, 1.5099e-14,\n",
      "         2.8422e-14, 4.6185e-14, 1.7764e-14, 5.6843e-14, 3.1974e-14, 2.1316e-14,\n",
      "         4.6185e-14, 2.1316e-14, 1.0658e-14, 1.3323e-14, 4.2633e-14, 1.4211e-14,\n",
      "         2.4869e-14, 4.2633e-14, 2.4869e-14, 1.9540e-14, 2.4869e-14, 1.5987e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.1316e-14, 1.1546e-14, 9.7700e-15, 1.5987e-14,\n",
      "         3.5527e-14, 2.8422e-14, 1.7764e-14, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 129: layer3.10.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 129\n",
      "Max diff:\n",
      " tensor([1.3323e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.8770e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2172e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7764e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-14, 5.9674e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8858e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.3291e-15, 4.4409e-15, 4.5519e-15, 7.5495e-15, 0.0000e+00, 9.4369e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.2180e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3101e-14, 4.9960e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-14, 5.5511e-15,\n",
      "         0.0000e+00, 0.0000e+00, 5.3291e-15, 6.2172e-15, 0.0000e+00, 6.0507e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.2434e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3323e-15, 0.0000e+00, 4.6109e-15, 0.0000e+00, 5.8842e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.7716e-15, 7.5495e-15, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 66,  71,  83, 137, 141, 156, 160, 161, 175, 183, 192, 193, 194, 195,\n",
      "        197, 205, 208, 213, 214, 220, 221, 224, 225, 227, 230, 235, 237, 239,\n",
      "        243, 248, 249, 250])\n",
      "\n",
      "failing Cout = tensor([ 66,  71,  83, 137, 141, 156, 160, 161, 175, 183, 192, 193, 194, 195,\n",
      "        197, 205, 208, 213, 214, 220, 221, 224, 225, 227, 230, 235, 237, 239,\n",
      "        243, 248, 249, 250])  (len = 32)\n",
      "passing Cout = tensor([198])  (len = 1)\n",
      "\n",
      "Executing module 130: layer3.10.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 130\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 130\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  3,  4,  6,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23,\n",
      "        24, 28, 29, 31, 32, 33, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 49,\n",
      "        50, 53, 55, 56, 57, 58, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([130, 131, 133, 134, 135, 137, 138, 141, 142, 143, 144, 145, 147, 149,\n",
      "        150, 151, 152, 154, 155, 156, 157, 159, 160, 161, 163, 164, 165, 167,\n",
      "        168, 170, 171, 175, 176, 177, 178, 182, 184, 185, 186, 187, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 200, 201, 202, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 216, 217, 218, 219, 221, 222, 223, 226, 227, 228, 229,\n",
      "        230, 232, 233, 234, 235, 236, 238, 240, 241, 242, 243, 244, 246, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 130\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20,\n",
      "        21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42,\n",
      "        43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 130\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 130\n",
      "Max diff:\n",
      " tensor([1.2629e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.8866e-15, 3.9968e-15, 5.3291e-15, 5.2319e-15, 6.2172e-15, 4.3854e-15,\n",
      "         6.6613e-15, 4.3160e-15, 4.8850e-15, 2.8866e-15, 4.9544e-15, 5.7732e-15,\n",
      "         4.4409e-15, 9.3259e-15, 2.5535e-15, 2.4425e-15, 8.4377e-15, 5.3291e-15,\n",
      "         4.8850e-15, 5.5511e-17, 3.9968e-15, 2.6645e-15, 2.5535e-15, 1.9984e-15,\n",
      "         5.7732e-15, 5.1070e-15, 3.3307e-15, 4.4409e-15, 1.9151e-15, 3.5527e-15,\n",
      "         3.3307e-15, 2.7478e-15, 1.7208e-15, 4.4409e-15, 5.3291e-15, 5.3291e-15,\n",
      "         5.3291e-15, 2.1094e-15, 1.6653e-15, 4.7184e-15, 3.1086e-15, 1.2629e-14,\n",
      "         4.6629e-15, 1.5266e-16, 5.1070e-15, 1.7764e-15, 2.2204e-15, 5.1070e-15,\n",
      "         5.3221e-15, 4.1633e-15, 5.1764e-15, 2.5535e-15, 5.2736e-15, 5.3291e-15,\n",
      "         3.2196e-15, 4.4409e-15, 4.8850e-15, 2.7756e-15, 6.2172e-15, 3.2752e-15,\n",
      "         1.9706e-15, 5.3291e-15, 3.5527e-15, 6.8834e-15, 5.4401e-15, 4.8850e-15,\n",
      "         7.5495e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15, 9.7700e-15, 6.2172e-15,\n",
      "         3.7748e-15, 4.8850e-15, 4.3299e-15, 8.3267e-15, 8.4377e-15, 7.5495e-15,\n",
      "         4.8850e-15, 4.4409e-15, 4.4409e-15, 5.7732e-15, 4.5797e-15, 7.1054e-15,\n",
      "         7.1054e-15, 2.4425e-15, 4.4409e-15, 6.6613e-15, 5.5511e-15, 3.1086e-15,\n",
      "         5.4401e-15, 4.8850e-15, 2.4425e-15, 1.7764e-15, 4.4409e-15, 5.7732e-15,\n",
      "         5.7732e-15, 8.8818e-15, 4.3854e-15, 4.2188e-15, 3.1641e-15, 2.1094e-15,\n",
      "         5.3291e-15, 5.5511e-15, 5.4401e-15, 3.3862e-15, 8.1046e-15, 7.1054e-15,\n",
      "         4.4409e-15, 3.9968e-15, 4.8850e-15, 3.5527e-15, 5.4956e-15, 3.2196e-15,\n",
      "         8.2157e-15, 6.2172e-15, 4.8850e-15, 2.6645e-15, 4.6629e-15, 3.7192e-15,\n",
      "         1.0658e-14, 4.4409e-15, 2.6645e-15, 4.4409e-15, 6.2172e-15, 3.9968e-15,\n",
      "         4.4409e-15, 7.9936e-15, 1.1546e-14, 8.6597e-15, 8.8818e-15, 4.4409e-15,\n",
      "         4.4409e-15, 6.1617e-15, 6.9944e-15, 7.3275e-15, 7.9936e-15, 7.5495e-15,\n",
      "         6.6613e-15, 8.8818e-15, 6.2172e-15, 7.5495e-15, 6.8834e-15, 4.9960e-15,\n",
      "         4.8850e-15, 6.8834e-15, 6.2172e-15, 6.2172e-15, 7.9936e-15, 6.5781e-15,\n",
      "         6.6613e-15, 8.7708e-15, 7.9936e-15, 6.2172e-15, 6.2172e-15, 6.4393e-15,\n",
      "         8.8818e-15, 5.2180e-15, 9.1038e-15, 5.3291e-15, 2.9976e-15, 5.7732e-15,\n",
      "         6.6613e-15, 7.9936e-15, 7.9936e-15, 5.3291e-15, 7.1054e-15, 7.5495e-15,\n",
      "         7.1054e-15, 4.8850e-15, 4.4409e-15, 9.4647e-15, 6.3699e-15, 6.4393e-15,\n",
      "         5.8842e-15, 6.2172e-15, 7.5495e-15, 4.4409e-15, 5.7732e-15, 6.3283e-15,\n",
      "         1.0436e-14, 7.9936e-15, 5.7732e-15, 6.2172e-15, 5.1070e-15, 6.4948e-15,\n",
      "         1.0547e-14, 5.3291e-15, 9.7700e-15, 9.6589e-15, 5.7732e-15, 6.6613e-15,\n",
      "         4.4409e-15, 7.1054e-15, 4.8850e-15, 4.4409e-15, 4.8850e-15, 7.1054e-15,\n",
      "         1.1546e-14, 7.1054e-15, 8.6597e-15, 5.3291e-15, 6.2172e-15, 4.4409e-15,\n",
      "         6.4393e-15, 8.8818e-15, 6.2172e-15, 5.7732e-15, 8.8818e-15, 5.6899e-15,\n",
      "         6.2172e-15, 4.9960e-15, 5.7732e-15, 5.7732e-15, 8.1046e-15, 6.9944e-15,\n",
      "         6.6613e-15, 9.7700e-15, 9.7700e-15, 7.5495e-15, 6.4393e-15, 9.7700e-15,\n",
      "         7.9936e-15, 7.9936e-15, 6.8834e-15, 7.1054e-15, 7.1054e-15, 7.9936e-15,\n",
      "         5.6621e-15, 6.8834e-15, 5.3291e-15, 7.9936e-15, 4.8850e-15, 6.2172e-15,\n",
      "         1.2212e-14, 6.8834e-15, 8.8818e-15, 1.1546e-14, 4.8850e-15, 9.3259e-15,\n",
      "         7.9936e-15, 8.4377e-15, 9.7700e-15, 5.3291e-15, 6.4393e-15, 5.3291e-15,\n",
      "         6.2172e-15, 5.7732e-15, 5.1070e-15, 6.2172e-15, 1.0103e-14, 5.7732e-15,\n",
      "         7.9936e-15, 8.8818e-15, 7.1054e-15, 7.9936e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 131: layer3.10.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 131\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 131\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 131\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 131\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 131\n",
      "Max diff:\n",
      " tensor([5.0793e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.8818e-16, 1.6862e-15, 2.4425e-15, 9.1246e-16, 3.1086e-15, 9.8532e-16,\n",
      "         2.3315e-15, 3.0011e-16, 1.4433e-15, 2.7756e-16, 2.7756e-16, 2.4425e-15,\n",
      "         1.5543e-15, 3.2196e-15, 8.3267e-17, 1.3323e-15, 2.5535e-15, 1.3323e-15,\n",
      "         2.1094e-15, 1.3878e-17, 8.8818e-16, 5.5511e-16, 6.1062e-16, 8.8818e-16,\n",
      "         8.6042e-16, 2.3315e-15, 1.1657e-15, 1.2212e-15, 2.2898e-16, 5.8287e-16,\n",
      "         1.3323e-15, 1.6653e-16, 4.4409e-16, 1.5543e-15, 1.6098e-15, 2.0539e-15,\n",
      "         2.6645e-15, 1.3878e-16, 5.5511e-17, 1.1380e-15, 4.1633e-16, 5.0793e-15,\n",
      "         3.4694e-16, 5.5511e-17, 2.2204e-16, 2.7756e-16, 2.2204e-16, 1.6653e-15,\n",
      "         2.1788e-15, 5.5511e-17, 1.8180e-15, 6.1062e-16, 1.0547e-15, 2.6645e-15,\n",
      "         1.0547e-15, 1.9984e-15, 1.8874e-15, 9.9920e-16, 1.7764e-15, 1.2212e-15,\n",
      "         1.8735e-16, 6.6613e-16, 7.7716e-16, 1.5821e-15, 8.0491e-16, 1.0825e-15,\n",
      "         2.2204e-15, 1.6098e-15, 4.4409e-16, 1.1102e-15, 1.8874e-15, 1.5543e-15,\n",
      "         1.7521e-16, 1.3323e-15, 1.3878e-15, 2.3037e-15, 1.3323e-15, 1.6653e-15,\n",
      "         1.6653e-15, 1.9984e-15, 7.2164e-16, 1.9429e-15, 1.2768e-15, 1.5543e-15,\n",
      "         1.7764e-15, 2.9143e-16, 1.1935e-15, 3.5527e-15, 8.4655e-16, 2.2204e-16,\n",
      "         1.2212e-15, 5.9328e-16, 4.1633e-16, 6.6613e-16, 9.0206e-16, 1.4433e-15,\n",
      "         1.2212e-15, 1.9984e-15, 1.3323e-15, 9.9920e-16, 5.2736e-16, 3.7470e-16,\n",
      "         1.7764e-15, 7.7716e-16, 8.3961e-16, 4.7531e-16, 1.9706e-15, 2.6645e-15,\n",
      "         7.7716e-16, 3.6082e-16, 1.1657e-15, 1.1657e-15, 3.3307e-16, 3.0531e-16,\n",
      "         3.4417e-15, 9.1593e-16, 4.4409e-16, 5.8287e-16, 1.0270e-15, 7.7716e-16,\n",
      "         2.6645e-15, 7.2164e-16, 6.9389e-16, 9.9920e-16, 1.1657e-15, 5.5511e-16,\n",
      "         9.9920e-16, 1.4433e-15, 1.8874e-15, 2.6368e-15, 2.2204e-15, 1.2212e-15,\n",
      "         1.3323e-15, 2.1927e-15, 1.4988e-15, 2.2204e-15, 1.7764e-15, 3.1086e-15,\n",
      "         2.1094e-15, 3.1086e-15, 1.3323e-15, 2.1094e-15, 2.8033e-15, 1.4294e-15,\n",
      "         1.5266e-15, 1.6653e-15, 2.5535e-15, 1.5543e-15, 3.7748e-15, 1.1727e-15,\n",
      "         2.1094e-15, 3.9829e-15, 2.1094e-15, 1.1102e-15, 2.4425e-15, 2.9976e-15,\n",
      "         3.2196e-15, 1.4294e-15, 4.5519e-15, 8.8818e-16, 4.7184e-16, 7.2164e-16,\n",
      "         4.0246e-16, 3.1086e-15, 2.8866e-15, 2.6645e-15, 2.2204e-15, 2.3627e-15,\n",
      "         1.9984e-15, 2.1094e-15, 8.8818e-16, 1.9706e-15, 2.9698e-15, 1.8319e-15,\n",
      "         7.4940e-16, 2.2204e-15, 2.4425e-15, 1.4433e-15, 4.1633e-16, 6.1062e-16,\n",
      "         1.8319e-15, 2.6645e-15, 3.3307e-16, 8.8818e-16, 1.3323e-15, 2.4425e-15,\n",
      "         4.3299e-15, 1.1102e-15, 2.2204e-15, 3.1503e-15, 9.9920e-16, 1.3323e-15,\n",
      "         1.2212e-15, 2.2204e-15, 1.5543e-15, 8.3267e-16, 8.8818e-16, 1.9429e-15,\n",
      "         2.6645e-15, 3.1086e-15, 3.4417e-15, 1.6653e-15, 2.4425e-15, 1.0547e-15,\n",
      "         2.3315e-15, 4.4409e-15, 1.4988e-15, 1.1102e-15, 2.6645e-15, 1.9706e-15,\n",
      "         2.2204e-15, 1.1657e-15, 1.3323e-15, 1.7764e-15, 2.1233e-15, 1.5751e-15,\n",
      "         1.6653e-15, 3.1086e-15, 3.3307e-15, 2.2204e-15, 1.3323e-15, 3.9968e-15,\n",
      "         2.5535e-15, 1.9984e-15, 2.8866e-15, 2.1094e-15, 2.2204e-15, 2.4425e-15,\n",
      "         1.7868e-15, 1.8388e-15, 1.2768e-15, 2.2204e-15, 9.9920e-16, 1.2768e-15,\n",
      "         2.6645e-15, 9.8532e-16, 1.8874e-15, 3.3307e-15, 1.3323e-15, 1.6341e-15,\n",
      "         3.9968e-15, 2.7756e-15, 3.3307e-15, 8.8818e-16, 2.3870e-15, 1.5639e-15,\n",
      "         1.4433e-15, 1.4433e-15, 1.3878e-15, 2.2204e-15, 2.8866e-15, 1.6653e-15,\n",
      "         2.2204e-15, 2.6645e-15, 1.9706e-15, 1.9984e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 132: layer3.10.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 132\n",
      "Max diff:\n",
      " tensor([3.5305e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.8818e-16, 5.8842e-15, 2.4425e-15, 4.2188e-15, 3.3307e-15, 9.8532e-16,\n",
      "         2.3315e-15, 4.6629e-15, 1.4433e-15, 2.0539e-15, 2.7200e-15, 2.4425e-15,\n",
      "         1.5543e-15, 3.2196e-15, 5.6899e-16, 1.3323e-15, 2.5535e-15, 1.3323e-15,\n",
      "         2.1094e-15, 1.2768e-15, 8.8818e-16, 1.2768e-15, 7.4940e-16, 3.9413e-15,\n",
      "         8.6042e-16, 2.7756e-15, 1.1657e-15, 2.9421e-15, 1.3045e-15, 2.4425e-15,\n",
      "         1.3323e-15, 8.6042e-16, 1.7764e-15, 4.8850e-15, 1.6098e-15, 2.0539e-15,\n",
      "         2.6645e-15, 1.1102e-15, 9.9920e-16, 1.1380e-15, 6.4393e-15, 5.0793e-15,\n",
      "         2.7200e-15, 5.5511e-17, 5.7732e-15, 2.7756e-16, 1.6653e-15, 2.3315e-15,\n",
      "         2.2482e-15, 5.5511e-17, 1.8180e-15, 6.1062e-16, 1.1657e-15, 2.6645e-15,\n",
      "         3.7192e-15, 2.1094e-15, 1.8874e-15, 9.9920e-16, 1.7764e-15, 1.8319e-15,\n",
      "         3.1086e-15, 1.4433e-15, 1.9429e-15, 1.5821e-15, 6.2172e-15, 3.0254e-15,\n",
      "         6.5503e-15, 7.1054e-15, 2.6645e-15, 4.6629e-15, 1.2434e-14, 2.4425e-15,\n",
      "         3.5527e-15, 5.1070e-15, 1.8874e-15, 6.6613e-15, 7.9936e-15, 8.8818e-15,\n",
      "         1.7764e-15, 2.8866e-15, 4.8850e-15, 7.1054e-15, 1.2768e-15, 1.1990e-14,\n",
      "         7.9936e-15, 1.5543e-15, 7.7716e-15, 3.5527e-15, 7.9936e-15, 2.2204e-16,\n",
      "         3.9968e-15, 3.5527e-15, 4.6629e-15, 6.6613e-16, 1.7208e-15, 2.5535e-15,\n",
      "         5.4401e-15, 2.8866e-15, 2.9976e-15, 1.4988e-14, 2.5327e-15, 1.5266e-15,\n",
      "         6.2172e-15, 1.1102e-15, 1.3461e-15, 1.0658e-14, 3.7192e-15, 3.9968e-15,\n",
      "         2.6645e-15, 6.0785e-15, 5.3291e-15, 6.3283e-15, 1.3323e-15, 4.8850e-15,\n",
      "         4.6629e-15, 6.6613e-15, 5.7732e-15, 5.8287e-16, 6.5503e-15, 4.3854e-15,\n",
      "         2.6645e-15, 8.8818e-16, 4.3299e-15, 4.8850e-15, 3.1086e-15, 4.5519e-15,\n",
      "         2.1927e-15, 2.6645e-15, 1.8874e-15, 6.1062e-15, 2.3870e-15, 4.2188e-15,\n",
      "         5.3291e-15, 2.1927e-15, 1.4211e-14, 4.4409e-15, 2.6090e-15, 3.1086e-15,\n",
      "         1.1546e-14, 4.4409e-15, 4.4409e-15, 4.1217e-15, 3.3307e-15, 1.0658e-14,\n",
      "         8.4377e-15, 1.6653e-15, 3.1086e-15, 6.4393e-15, 1.9540e-14, 1.1727e-15,\n",
      "         1.0658e-14, 3.9829e-15, 5.5234e-15, 1.1102e-15, 2.4425e-15, 8.4377e-15,\n",
      "         5.3291e-15, 3.3307e-15, 1.0658e-14, 8.8818e-16, 2.2204e-15, 5.1070e-15,\n",
      "         3.5527e-15, 7.1054e-15, 3.1086e-15, 2.6645e-15, 1.6875e-14, 3.8858e-15,\n",
      "         2.3093e-14, 2.1094e-15, 1.4433e-15, 1.0658e-14, 4.8850e-15, 1.0658e-14,\n",
      "         2.2204e-15, 1.0214e-14, 2.4425e-15, 2.1094e-15, 7.5495e-15, 2.5535e-15,\n",
      "         1.8319e-15, 4.8850e-15, 1.3323e-15, 3.6637e-15, 2.9421e-15, 2.6645e-15,\n",
      "         1.4433e-14, 4.3299e-15, 1.4211e-14, 9.7700e-15, 1.8319e-15, 3.2752e-15,\n",
      "         1.0658e-14, 2.3981e-14, 1.0658e-14, 1.2768e-15, 3.1086e-15, 7.9936e-15,\n",
      "         8.8818e-15, 1.2434e-14, 8.8818e-15, 8.9928e-15, 1.0658e-14, 1.0547e-15,\n",
      "         1.1324e-14, 1.2434e-14, 1.0658e-14, 1.5543e-14, 7.3275e-15, 5.3291e-15,\n",
      "         4.1078e-15, 3.1974e-14, 1.4211e-14, 5.7732e-15, 5.5511e-15, 5.1070e-15,\n",
      "         6.6613e-15, 9.7700e-15, 4.6629e-15, 5.3846e-15, 6.6613e-15, 3.5305e-14,\n",
      "         7.3275e-15, 9.7700e-15, 7.9936e-15, 1.2434e-14, 1.4211e-14, 8.8818e-15,\n",
      "         1.4211e-14, 8.8818e-15, 1.1546e-14, 1.4211e-14, 2.6645e-14, 6.3283e-15,\n",
      "         7.1054e-15, 2.2204e-15, 2.6645e-15, 1.5987e-14, 2.2204e-15, 6.2172e-15,\n",
      "         3.9968e-15, 5.7732e-15, 5.2180e-15, 5.3291e-15, 4.9960e-15, 1.2879e-14,\n",
      "         8.4377e-15, 9.1038e-15, 7.1054e-15, 6.6613e-15, 1.2434e-14, 1.0214e-14,\n",
      "         2.2204e-15, 2.6645e-15, 4.6629e-15, 1.2212e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 133: layer3.10.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 133\n",
      "Max diff:\n",
      " tensor([3.5305e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.7184e-16, 5.8842e-15, 1.1523e-15, 4.2188e-15, 1.7764e-15, 7.4940e-16,\n",
      "         1.3878e-15, 4.6629e-15, 0.0000e+00, 2.0539e-15, 2.7200e-15, 1.2768e-15,\n",
      "         1.9429e-16, 1.6480e-15, 2.4980e-16, 5.5511e-16, 2.5535e-15, 0.0000e+00,\n",
      "         2.1094e-15, 1.2768e-15, 7.4940e-16, 1.2768e-15, 0.0000e+00, 3.9413e-15,\n",
      "         3.6082e-16, 2.7756e-15, 2.4980e-16, 1.3878e-15, 1.3045e-15, 2.4425e-15,\n",
      "         1.0478e-15, 0.0000e+00, 1.7764e-15, 4.8850e-15, 1.9429e-16, 8.7170e-17,\n",
      "         0.0000e+00, 1.1102e-15, 0.0000e+00, 5.1174e-16, 6.4393e-15, 2.6645e-15,\n",
      "         2.7200e-15, 0.0000e+00, 5.7732e-15, 0.0000e+00, 1.6653e-15, 2.3315e-15,\n",
      "         1.2768e-15, 0.0000e+00, 1.3323e-15, 1.0408e-16, 1.1657e-15, 2.3315e-15,\n",
      "         3.8858e-16, 1.8874e-15, 1.2212e-15, 2.0817e-16, 1.7764e-15, 1.7764e-15,\n",
      "         3.1086e-15, 1.4433e-15, 1.9429e-15, 1.5821e-15, 6.2172e-15, 3.0254e-15,\n",
      "         6.5503e-15, 7.1054e-15, 2.6645e-15, 4.6629e-15, 1.2434e-14, 1.7764e-15,\n",
      "         3.5527e-15, 5.1070e-15, 1.6653e-15, 6.6613e-15, 7.9936e-15, 8.8818e-15,\n",
      "         1.7764e-15, 1.7764e-15, 4.8850e-15, 7.1054e-15, 4.3021e-16, 1.1990e-14,\n",
      "         7.9936e-15, 1.5543e-15, 7.7716e-15, 1.9984e-15, 7.9936e-15, 2.0123e-16,\n",
      "         3.9968e-15, 3.5527e-15, 4.6629e-15, 2.4286e-16, 1.7208e-15, 2.5535e-15,\n",
      "         3.6637e-15, 2.7756e-15, 2.9976e-15, 1.4988e-14, 9.9920e-16, 1.5266e-15,\n",
      "         6.2172e-15, 1.1102e-15, 1.3461e-15, 1.0658e-14, 3.7192e-15, 1.1102e-15,\n",
      "         2.6645e-15, 2.2204e-15, 5.3291e-15, 6.2172e-15, 1.3323e-15, 4.8850e-15,\n",
      "         3.0531e-15, 6.6613e-15, 5.7732e-15, 5.5511e-16, 6.5503e-15, 4.3854e-15,\n",
      "         7.2164e-16, 8.8818e-16, 4.3299e-15, 4.8850e-15, 3.1086e-15, 4.5519e-15,\n",
      "         1.7764e-15, 2.6645e-15, 0.0000e+00, 6.1062e-15, 2.2204e-15, 4.2188e-15,\n",
      "         5.3291e-15, 1.6653e-15, 1.4211e-14, 4.4409e-15, 1.4433e-15, 1.4988e-15,\n",
      "         1.1546e-14, 4.4409e-15, 4.4409e-15, 4.1217e-15, 3.1086e-15, 1.0658e-14,\n",
      "         8.4377e-15, 1.1657e-15, 3.1086e-15, 6.4393e-15, 1.9540e-14, 6.8001e-16,\n",
      "         1.0658e-14, 3.5527e-15, 5.5234e-15, 0.0000e+00, 1.7764e-15, 8.4377e-15,\n",
      "         5.3291e-15, 3.3307e-15, 1.0658e-14, 0.0000e+00, 2.2204e-15, 5.1070e-15,\n",
      "         3.5527e-15, 3.9968e-15, 1.7764e-15, 0.0000e+00, 1.6875e-14, 3.7748e-15,\n",
      "         2.3093e-14, 9.9920e-16, 1.1102e-15, 1.0658e-14, 4.8850e-15, 1.0658e-14,\n",
      "         2.2204e-15, 1.0214e-14, 0.0000e+00, 2.1094e-15, 7.5495e-15, 2.5535e-15,\n",
      "         3.3307e-16, 4.8850e-15, 1.3323e-15, 3.6637e-15, 2.9421e-15, 2.6645e-15,\n",
      "         1.4433e-14, 4.3299e-15, 1.4211e-14, 9.7700e-15, 1.8319e-15, 5.5511e-16,\n",
      "         1.0658e-14, 2.3981e-14, 1.0658e-14, 4.0593e-16, 3.1086e-15, 7.9936e-15,\n",
      "         3.3168e-15, 1.2434e-14, 8.8818e-15, 8.9928e-15, 1.0658e-14, 1.0547e-15,\n",
      "         1.1324e-14, 1.2434e-14, 1.0658e-14, 1.5543e-14, 4.4409e-15, 5.3291e-15,\n",
      "         4.1078e-15, 3.1974e-14, 1.4211e-14, 5.7732e-15, 5.5511e-15, 5.1070e-15,\n",
      "         6.6613e-15, 9.7700e-15, 4.6629e-15, 3.9968e-15, 6.6613e-15, 3.5305e-14,\n",
      "         5.3291e-15, 9.7700e-15, 7.9936e-15, 1.2434e-14, 1.4211e-14, 8.8818e-15,\n",
      "         1.4211e-14, 8.8818e-15, 1.1546e-14, 1.4211e-14, 2.6645e-14, 6.3283e-15,\n",
      "         7.1054e-15, 2.2204e-15, 2.6645e-15, 1.5987e-14, 1.1380e-15, 6.2172e-15,\n",
      "         0.0000e+00, 5.7732e-15, 3.7192e-15, 5.3291e-15, 4.9960e-15, 1.2879e-14,\n",
      "         8.4377e-15, 9.1038e-15, 7.1054e-15, 6.6613e-15, 1.2434e-14, 1.0214e-14,\n",
      "         1.6653e-15, 2.6645e-15, 4.6629e-15, 1.2212e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  18,  19,  20,  21,  23,  24,  25,  26,  27,  28,  29,  30,\n",
      "         32,  33,  34,  35,  37,  39,  40,  41,  42,  44,  46,  47,  48,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135,\n",
      "        136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,\n",
      "        150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  18,  19,  20,  21,  23,  24,  25,  26,  27,  28,  29,  30,\n",
      "         32,  33,  34,  35,  37,  39,  40,  41,  42,  44,  46,  47,  48,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135,\n",
      "        136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,\n",
      "        150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 241)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 134: layer3.11.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 134\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 134\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 134\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 134\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 134\n",
      "Max diff:\n",
      " tensor([2.5580e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.9968e-15, 7.1054e-15, 5.3291e-15, 5.3291e-15, 1.5987e-14, 4.4409e-15,\n",
      "         6.2172e-15, 6.2172e-15, 7.9936e-15, 5.3291e-15, 3.5527e-15, 8.8818e-15,\n",
      "         3.1974e-14, 5.3291e-15, 5.7732e-15, 2.6645e-15, 3.9968e-15, 2.6645e-15,\n",
      "         7.1054e-15, 3.1974e-14, 1.2434e-14, 3.5527e-15, 6.2172e-15, 1.2434e-14,\n",
      "         4.8850e-15, 3.9968e-15, 1.0658e-14, 5.3291e-15, 1.2434e-14, 4.4409e-15,\n",
      "         6.2172e-15, 6.2172e-15, 3.1086e-15, 4.4409e-15, 8.8818e-15, 3.5527e-15,\n",
      "         4.4409e-15, 3.5527e-14, 6.2172e-15, 4.4409e-15, 2.8422e-14, 7.9936e-15,\n",
      "         3.1086e-15, 5.3291e-15, 8.8818e-15, 1.2434e-14, 3.1086e-15, 1.4211e-14,\n",
      "         1.0658e-14, 1.5987e-14, 3.5527e-15, 2.6645e-15, 4.4409e-15, 4.6185e-14,\n",
      "         2.6645e-15, 7.1054e-15, 3.5527e-15, 2.1316e-14, 2.6645e-15, 7.9936e-15,\n",
      "         2.1316e-14, 3.1086e-15, 7.9936e-15, 3.1086e-15, 3.1974e-14, 5.3291e-15,\n",
      "         4.2633e-14, 7.9936e-15, 3.5527e-14, 6.3949e-14, 7.9936e-15, 7.1054e-15,\n",
      "         7.9936e-15, 1.2434e-14, 8.5265e-14, 4.9738e-14, 3.5527e-15, 1.7764e-14,\n",
      "         4.9738e-14, 1.0658e-14, 3.9968e-15, 2.4869e-14, 1.7764e-14, 4.9738e-14,\n",
      "         2.4869e-14, 4.2633e-14, 1.0658e-14, 3.5527e-15, 5.3291e-15, 2.4869e-14,\n",
      "         2.8422e-14, 4.2633e-14, 4.9738e-14, 1.7764e-14, 7.1054e-14, 2.8422e-14,\n",
      "         5.3291e-15, 3.9968e-15, 1.7764e-14, 2.1316e-14, 4.9738e-14, 4.9738e-14,\n",
      "         8.8818e-15, 6.2172e-15, 9.7700e-15, 2.8422e-14, 4.4409e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.2434e-14, 2.2204e-15, 5.6843e-14, 3.5527e-14, 2.4425e-15,\n",
      "         1.2434e-14, 6.2172e-15, 2.8422e-14, 4.2633e-14, 3.1974e-14, 2.1316e-14,\n",
      "         9.9476e-14, 1.7764e-14, 1.2790e-13, 2.8422e-14, 8.8818e-15, 7.1054e-14,\n",
      "         1.7764e-14, 1.2434e-14, 4.9738e-14, 5.3291e-15, 1.2079e-13, 6.2172e-15,\n",
      "         3.1974e-14, 1.2434e-14, 2.8422e-14, 2.8422e-14, 8.8818e-15, 8.5265e-14,\n",
      "         3.5527e-14, 4.2633e-14, 1.7053e-13, 1.2434e-14, 1.0658e-14, 3.1974e-14,\n",
      "         5.6843e-14, 2.4869e-14, 3.1974e-14, 4.2633e-14, 4.2633e-14, 1.0658e-14,\n",
      "         1.5632e-13, 9.9476e-14, 9.9476e-14, 4.9738e-14, 1.2434e-14, 1.4211e-14,\n",
      "         1.0658e-14, 4.9738e-14, 1.0658e-14, 4.2633e-14, 5.6843e-14, 5.6843e-14,\n",
      "         1.0658e-14, 4.6185e-14, 7.9936e-15, 2.4869e-14, 7.9936e-15, 1.7764e-14,\n",
      "         1.0658e-14, 1.4211e-14, 8.8818e-15, 2.8422e-14, 3.5527e-14, 2.4869e-14,\n",
      "         1.7764e-14, 7.8160e-14, 2.4869e-14, 8.5265e-14, 4.2633e-14, 2.4869e-14,\n",
      "         4.7962e-14, 7.9936e-15, 1.0658e-14, 4.2633e-14, 2.8422e-14, 1.2434e-14,\n",
      "         1.5987e-14, 1.0658e-14, 5.6843e-14, 1.7764e-14, 3.9080e-14, 1.7764e-14,\n",
      "         1.1369e-13, 8.5265e-14, 7.1054e-14, 7.1054e-14, 1.1369e-13, 2.5580e-13,\n",
      "         1.7053e-13, 7.8160e-14, 9.9476e-14, 8.5265e-14, 7.8160e-14, 1.0658e-13,\n",
      "         1.0658e-13, 8.5265e-14, 9.9476e-14, 8.5265e-14, 1.4211e-13, 1.2790e-13,\n",
      "         8.5265e-14, 8.5265e-14, 9.9476e-14, 7.8160e-14, 1.1369e-13, 3.1974e-14,\n",
      "         1.8474e-13, 9.2371e-14, 8.5265e-14, 2.5580e-13, 7.8160e-14, 1.4211e-13,\n",
      "         1.1369e-13, 7.1054e-14, 1.4211e-13, 9.9476e-14, 1.4211e-13, 1.7053e-13,\n",
      "         4.4409e-14, 1.1369e-13, 1.1369e-13, 9.9476e-14, 7.8160e-14, 5.6843e-14,\n",
      "         1.1369e-13, 1.0658e-13, 8.5265e-14, 1.4211e-13, 1.4211e-13, 9.9476e-14,\n",
      "         7.8160e-14, 1.1369e-13, 8.5265e-14, 9.9476e-14, 1.7053e-13, 1.0658e-13,\n",
      "         1.2790e-13, 8.5265e-14, 5.6843e-14, 1.1369e-13, 8.8818e-15, 1.4211e-13,\n",
      "         9.9476e-14, 3.9080e-14, 1.1369e-13, 1.1369e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 135: layer3.11.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 135\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 135\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 135\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 135\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 135\n",
      "Max diff:\n",
      " tensor([7.1054e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 1.3323e-15, 1.3323e-15, 1.3323e-15, 3.5527e-15, 8.8818e-16,\n",
      "         1.5543e-15, 1.5543e-15, 1.7764e-15, 9.9920e-16, 7.7716e-16, 1.6653e-15,\n",
      "         7.1054e-15, 1.5543e-15, 1.1102e-15, 8.8818e-16, 9.9920e-16, 6.6613e-16,\n",
      "         1.7764e-15, 5.3291e-15, 3.1086e-15, 6.6613e-16, 1.3323e-15, 2.2204e-15,\n",
      "         1.1102e-15, 9.9920e-16, 1.9984e-15, 9.9920e-16, 2.6645e-15, 1.1102e-15,\n",
      "         1.5543e-15, 1.5543e-15, 7.7716e-16, 1.2212e-15, 2.2204e-15, 6.6613e-16,\n",
      "         1.2212e-15, 7.1054e-15, 1.7764e-15, 1.2212e-15, 6.2172e-15, 2.2204e-15,\n",
      "         7.7716e-16, 1.1102e-15, 1.9984e-15, 2.6645e-15, 7.7716e-16, 3.1086e-15,\n",
      "         2.6645e-15, 2.6645e-15, 9.9920e-16, 6.6613e-16, 1.1102e-15, 8.8818e-15,\n",
      "         6.6613e-16, 1.7764e-15, 6.6613e-16, 3.1086e-15, 6.6613e-16, 1.3323e-15,\n",
      "         4.4409e-15, 7.7716e-16, 1.9984e-15, 6.6613e-16, 5.3291e-15, 1.3323e-15,\n",
      "         5.3291e-15, 1.7764e-15, 7.1054e-15, 1.5987e-14, 1.7764e-15, 1.7764e-15,\n",
      "         1.9984e-15, 3.1086e-15, 2.1316e-14, 1.0658e-14, 8.8818e-16, 3.1086e-15,\n",
      "         1.2434e-14, 2.2204e-15, 8.8818e-16, 4.4409e-15, 4.4409e-15, 1.2434e-14,\n",
      "         3.9968e-15, 7.1054e-15, 2.6645e-15, 8.8818e-16, 1.3323e-15, 5.3291e-15,\n",
      "         7.1054e-15, 8.8818e-15, 6.2172e-15, 3.9968e-15, 1.0658e-14, 5.3291e-15,\n",
      "         1.5543e-15, 1.1102e-15, 3.9968e-15, 6.2172e-15, 8.8818e-15, 1.0658e-14,\n",
      "         1.7764e-15, 1.5543e-15, 1.7764e-15, 5.3291e-15, 9.9920e-16, 1.5543e-15,\n",
      "         1.5543e-15, 2.2204e-15, 6.6613e-16, 1.4211e-14, 6.2172e-15, 6.1062e-16,\n",
      "         3.1086e-15, 1.5543e-15, 5.3291e-15, 4.4409e-15, 7.1054e-15, 5.3291e-15,\n",
      "         2.8422e-14, 3.5527e-15, 2.1316e-14, 5.7732e-15, 2.2204e-15, 1.7764e-14,\n",
      "         3.1086e-15, 3.1086e-15, 7.1054e-15, 1.5543e-15, 1.5987e-14, 1.5543e-15,\n",
      "         6.2172e-15, 3.1086e-15, 5.3291e-15, 6.2172e-15, 1.7764e-15, 1.9540e-14,\n",
      "         8.8818e-15, 8.8818e-15, 5.3291e-14, 3.1086e-15, 2.2204e-15, 7.9936e-15,\n",
      "         6.2172e-15, 4.8850e-15, 7.1054e-15, 8.8818e-15, 8.8818e-15, 2.6645e-15,\n",
      "         3.5527e-14, 2.4869e-14, 2.4869e-14, 7.1054e-15, 3.1086e-15, 2.8866e-15,\n",
      "         2.6645e-15, 1.0658e-14, 1.7764e-15, 1.0658e-14, 7.9936e-15, 1.0658e-14,\n",
      "         3.1086e-15, 7.9936e-15, 1.9984e-15, 6.2172e-15, 1.7764e-15, 4.8850e-15,\n",
      "         2.2204e-15, 3.5527e-15, 2.6645e-15, 6.2172e-15, 1.1546e-14, 4.4409e-15,\n",
      "         3.5527e-15, 7.9936e-15, 6.2172e-15, 2.8422e-14, 1.0658e-14, 7.1054e-15,\n",
      "         1.2323e-14, 2.2204e-15, 3.5527e-15, 9.7700e-15, 7.1054e-15, 3.1086e-15,\n",
      "         3.9968e-15, 2.4425e-15, 7.1054e-15, 3.9968e-15, 9.7700e-15, 4.8850e-15,\n",
      "         3.1974e-14, 1.4211e-14, 1.5987e-14, 1.5987e-14, 2.3093e-14, 7.1054e-14,\n",
      "         3.5527e-14, 1.9540e-14, 2.3093e-14, 1.4211e-14, 1.7764e-14, 1.7764e-14,\n",
      "         3.0198e-14, 1.9540e-14, 1.9540e-14, 1.2434e-14, 4.2633e-14, 3.1974e-14,\n",
      "         1.7764e-14, 1.4211e-14, 1.7764e-14, 1.5987e-14, 2.1316e-14, 1.2434e-14,\n",
      "         6.3949e-14, 1.7764e-14, 2.1316e-14, 7.1054e-14, 2.3093e-14, 3.9080e-14,\n",
      "         2.4869e-14, 1.0658e-14, 3.5527e-14, 2.1316e-14, 3.9080e-14, 5.6843e-14,\n",
      "         7.9936e-15, 3.5527e-14, 2.4869e-14, 3.1974e-14, 2.1316e-14, 9.7700e-15,\n",
      "         2.8422e-14, 1.9540e-14, 2.1316e-14, 4.9738e-14, 3.0198e-14, 2.3093e-14,\n",
      "         2.8422e-14, 3.9080e-14, 1.7764e-14, 1.5987e-14, 3.5527e-14, 1.9540e-14,\n",
      "         3.9080e-14, 2.4869e-14, 1.7764e-14, 2.1316e-14, 2.2204e-15, 4.2633e-14,\n",
      "         2.1316e-14, 7.9936e-15, 2.4869e-14, 2.4869e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 136: layer3.11.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 136\n",
      "Max diff:\n",
      " tensor([6.9389e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5511e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3021e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.9389e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.6629e-15, 3.1641e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15,\n",
      "         2.4425e-15, 0.0000e+00, 4.7740e-15, 3.4001e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3307e-15, 0.0000e+00, 3.7748e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5543e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.7184e-16, 6.2172e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4139e-15, 2.7756e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 4.3299e-15, 0.0000e+00, 0.0000e+00,\n",
      "         6.8834e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 91, 118, 148, 180, 193, 194, 203, 204, 206, 207, 211, 213, 223, 228,\n",
      "        229, 235, 236, 242, 243, 246])\n",
      "\n",
      "failing Cout = tensor([ 91, 118, 148, 180, 193, 194, 203, 204, 206, 207, 211, 213, 223, 228,\n",
      "        229, 235, 236, 242, 243, 246])  (len = 20)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 137: layer3.11.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 137\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 137\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 2,  6, 11, 12, 16, 17, 18, 22, 23, 24, 28, 31, 35, 37, 39, 40, 42, 43,\n",
      "        45, 48, 51, 53, 56, 57, 59, 60, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 131, 135, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148,\n",
      "        149, 151, 152, 153, 156, 157, 161, 162, 163, 164, 165, 166, 168, 170,\n",
      "        174, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 197, 198, 199, 201, 202, 203, 204, 205, 206, 208,\n",
      "        209, 210, 211, 212, 213, 214, 218, 219, 220, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 234, 235, 236, 240, 241, 242, 243, 244, 245,\n",
      "        246, 249, 250, 252]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 137\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  2,  7, 10, 12, 15, 16, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 33,\n",
      "        35, 37, 39, 41, 43, 44, 45, 46, 47, 50, 53, 55, 56, 57, 58, 60, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  66,  73,  74,  78,  80,  82,  83,  84,  89,  90,  91,  94,  97,\n",
      "         98,  99, 100, 103, 104, 105, 106, 111, 114, 115, 116, 118, 122, 126]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 223,\n",
      "        224, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 238, 240, 241,\n",
      "        242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 137\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 137\n",
      "Max diff:\n",
      " tensor([6.3283e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.4433e-15, 1.9984e-15, 3.5527e-15, 1.3323e-15, 1.4433e-15, 1.5543e-15,\n",
      "         2.1094e-15, 1.7764e-15, 7.2164e-16, 8.8818e-16, 2.6645e-15, 1.4433e-15,\n",
      "         3.7748e-15, 2.8311e-15, 3.1086e-15, 8.8818e-16, 2.5535e-15, 1.6653e-15,\n",
      "         1.5821e-15, 3.9968e-15, 3.8025e-15, 1.5543e-15, 3.1086e-15, 2.8866e-15,\n",
      "         2.7756e-15, 4.4686e-15, 1.9984e-15, 2.4425e-15, 1.7764e-15, 8.6042e-16,\n",
      "         7.2164e-16, 2.3592e-15, 2.2204e-15, 2.0539e-15, 1.3323e-15, 1.5543e-15,\n",
      "         6.6613e-16, 3.5527e-15, 2.1918e-15, 1.8874e-15, 1.4988e-15, 9.4369e-16,\n",
      "         1.3323e-15, 4.5103e-17, 1.8874e-15, 1.5543e-15, 1.7208e-15, 2.4702e-15,\n",
      "         1.6653e-15, 1.6653e-15, 2.1094e-15, 1.5543e-15, 1.9984e-15, 1.1380e-15,\n",
      "         1.9984e-15, 1.7764e-15, 3.4972e-15, 7.4940e-16, 2.4425e-15, 1.7208e-15,\n",
      "         2.2204e-15, 2.6645e-15, 3.2196e-15, 2.6645e-15, 1.3323e-15, 1.1102e-15,\n",
      "         4.0801e-15, 1.1102e-15, 1.5543e-15, 1.0617e-15, 1.2768e-15, 4.4409e-16,\n",
      "         2.1094e-15, 4.2188e-15, 1.8874e-15, 4.5103e-16, 1.0617e-15, 2.4425e-15,\n",
      "         1.9984e-15, 1.6029e-15, 3.1086e-15, 2.4425e-15, 2.9976e-15, 3.3307e-15,\n",
      "         2.7200e-15, 8.3267e-16, 2.8588e-15, 1.5543e-15, 1.6653e-15, 1.8319e-15,\n",
      "         3.7748e-15, 2.2204e-15, 1.9984e-15, 1.5543e-15, 1.9984e-15, 1.5543e-15,\n",
      "         7.7716e-16, 5.1070e-15, 2.9976e-15, 2.3974e-15, 1.6306e-15, 2.8866e-15,\n",
      "         1.6653e-15, 1.8874e-15, 1.7764e-15, 4.6629e-15, 3.5527e-15, 2.4425e-15,\n",
      "         2.2204e-15, 1.8319e-15, 1.4710e-15, 1.9984e-15, 1.7208e-15, 1.1102e-15,\n",
      "         4.5519e-15, 1.9984e-15, 4.3299e-15, 1.7764e-15, 5.3291e-15, 9.9920e-16,\n",
      "         2.2204e-15, 6.4185e-16, 3.0809e-15, 1.4988e-15, 2.9976e-15, 1.2074e-15,\n",
      "         1.5543e-15, 1.5543e-15, 1.7764e-15, 2.3315e-15, 3.3862e-15, 2.6090e-15,\n",
      "         4.4686e-15, 1.9290e-15, 2.1649e-15, 2.6645e-15, 4.1078e-15, 3.4972e-15,\n",
      "         3.4417e-15, 3.1086e-15, 1.8874e-15, 3.5527e-15, 1.8041e-15, 2.6645e-15,\n",
      "         2.5743e-15, 2.9976e-15, 3.5527e-15, 1.7764e-15, 3.8858e-15, 2.3870e-15,\n",
      "         2.4702e-15, 3.8303e-15, 3.9968e-15, 2.4425e-15, 6.2172e-15, 2.5535e-15,\n",
      "         3.9968e-15, 3.9413e-15, 2.6090e-15, 3.3862e-15, 3.5527e-15, 2.8311e-15,\n",
      "         1.6653e-15, 3.2752e-15, 1.8180e-15, 3.1641e-15, 2.2760e-15, 3.5527e-15,\n",
      "         3.9413e-15, 3.2196e-15, 1.7764e-15, 2.4425e-15, 2.4702e-15, 2.7756e-15,\n",
      "         2.5535e-15, 6.3283e-15, 3.3307e-15, 3.4972e-15, 2.2204e-15, 1.6376e-15,\n",
      "         1.6653e-15, 3.1641e-15, 3.3307e-15, 3.1086e-15, 2.3315e-15, 1.9151e-15,\n",
      "         3.5527e-15, 1.5543e-15, 3.9968e-15, 4.4409e-15, 2.2204e-15, 4.2188e-15,\n",
      "         2.4425e-15, 2.1094e-15, 4.1078e-15, 2.2204e-15, 3.8858e-15, 2.5535e-15,\n",
      "         3.3307e-15, 4.2188e-15, 3.3307e-15, 2.8866e-15, 2.6923e-15, 3.0531e-15,\n",
      "         2.4980e-15, 3.1086e-15, 4.4409e-15, 1.9984e-15, 1.3323e-15, 2.2204e-15,\n",
      "         2.8866e-15, 4.4964e-15, 3.8858e-15, 3.2752e-15, 3.3584e-15, 2.1094e-15,\n",
      "         2.1094e-15, 4.6629e-15, 2.1094e-15, 3.5527e-15, 2.7756e-15, 2.8311e-15,\n",
      "         1.8874e-15, 3.9968e-15, 2.7200e-15, 4.8850e-15, 2.6090e-15, 4.6629e-15,\n",
      "         2.6645e-15, 1.8874e-15, 2.5535e-15, 3.1086e-15, 1.9429e-15, 3.9968e-15,\n",
      "         2.8866e-15, 1.7764e-15, 2.8866e-15, 4.2188e-15, 3.1086e-15, 2.9976e-15,\n",
      "         4.4964e-15, 3.5527e-15, 3.1086e-15, 3.1780e-15, 2.8866e-15, 4.0939e-15,\n",
      "         1.9429e-15, 3.9968e-15, 2.7756e-15, 3.9968e-15, 3.2196e-15, 2.4425e-15,\n",
      "         1.7764e-15, 2.8866e-15, 2.7756e-15, 2.2204e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 138: layer3.11.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 138\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 138\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 138\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 138\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 138\n",
      "Max diff:\n",
      " tensor([2.4425e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1102e-16, 1.6653e-16, 1.6653e-15, 5.7246e-17, 2.2204e-16, 5.5511e-16,\n",
      "         5.7246e-16, 4.4409e-16, 2.4980e-16, 2.4980e-16, 3.3307e-16, 1.3878e-16,\n",
      "         6.6613e-16, 1.0270e-15, 6.6613e-16, 1.6653e-16, 8.8818e-16, 5.5511e-16,\n",
      "         2.2204e-16, 7.2164e-16, 9.1593e-16, 3.3307e-16, 8.8818e-16, 4.4409e-16,\n",
      "         7.7716e-16, 6.6613e-16, 8.3614e-16, 8.8818e-16, 2.7756e-17, 1.5266e-16,\n",
      "         1.6653e-16, 7.7716e-16, 8.8818e-16, 2.7756e-16, 2.0123e-16, 5.8287e-16,\n",
      "         2.2844e-16, 1.4433e-15, 1.4086e-15, 8.3267e-16, 3.8858e-16, 2.2204e-16,\n",
      "         2.7756e-16, 1.3878e-17, 4.3021e-16, 1.6653e-16, 9.4369e-16, 1.1380e-15,\n",
      "         1.6653e-16, 8.8818e-16, 7.7716e-16, 3.8858e-16, 7.4940e-16, 4.8572e-16,\n",
      "         2.7756e-16, 4.4409e-16, 1.2351e-15, 2.7756e-16, 5.2736e-16, 6.9389e-16,\n",
      "         1.5959e-16, 1.0547e-15, 8.8818e-16, 3.3307e-16, 2.4980e-16, 3.0531e-16,\n",
      "         1.3045e-15, 2.7756e-16, 4.9960e-16, 1.0408e-16, 1.9429e-16, 6.9389e-17,\n",
      "         5.2736e-16, 6.9389e-16, 3.2353e-16, 4.1633e-17, 2.3245e-16, 7.7716e-16,\n",
      "         4.0462e-16, 7.2164e-16, 7.9450e-16, 7.3552e-16, 8.3267e-16, 9.4369e-16,\n",
      "         1.1380e-15, 1.5266e-16, 8.8818e-16, 8.8818e-16, 1.1037e-16, 3.4001e-16,\n",
      "         7.7716e-16, 2.7756e-16, 3.8858e-16, 4.4409e-16, 6.6613e-16, 2.7756e-16,\n",
      "         1.2490e-16, 2.0400e-15, 8.0838e-16, 6.5919e-16, 1.8041e-16, 4.0679e-16,\n",
      "         2.7756e-16, 2.1511e-16, 2.2204e-16, 6.3838e-16, 1.0547e-15, 6.3491e-16,\n",
      "         5.5511e-16, 3.1225e-16, 2.7756e-16, 3.3307e-16, 3.4001e-16, 3.0531e-16,\n",
      "         1.8041e-15, 6.6613e-16, 6.3838e-16, 2.2204e-16, 1.2768e-15, 3.6082e-16,\n",
      "         7.7716e-16, 2.0817e-16, 2.8449e-16, 2.4980e-16, 5.4123e-16, 9.7145e-17,\n",
      "         3.8164e-16, 4.3021e-16, 8.8818e-16, 6.1062e-16, 1.3045e-15, 8.6042e-16,\n",
      "         1.5543e-15, 2.7756e-16, 6.2450e-16, 4.9960e-16, 1.8319e-15, 8.8818e-16,\n",
      "         1.1657e-15, 6.6613e-16, 1.8735e-16, 1.2212e-15, 4.1633e-16, 6.6613e-16,\n",
      "         8.8818e-16, 8.2052e-16, 9.9920e-16, 7.7716e-16, 3.4694e-16, 8.8818e-16,\n",
      "         7.7716e-16, 4.0246e-16, 1.1102e-15, 6.6613e-16, 1.6653e-15, 3.3307e-16,\n",
      "         1.1102e-15, 1.3878e-15, 5.6552e-16, 1.1657e-15, 1.1657e-15, 3.3307e-16,\n",
      "         1.8041e-16, 1.4155e-15, 7.7716e-16, 6.6613e-16, 5.7766e-16, 1.3323e-15,\n",
      "         1.0547e-15, 7.7716e-16, 4.4409e-16, 1.1102e-15, 8.3267e-16, 8.0491e-16,\n",
      "         1.1657e-15, 2.4425e-15, 1.1102e-15, 1.0270e-15, 1.8041e-16, 2.7756e-16,\n",
      "         1.8041e-16, 9.5063e-16, 1.2212e-15, 1.2004e-15, 6.1062e-16, 5.5511e-16,\n",
      "         1.3323e-15, 3.8858e-16, 7.7716e-16, 6.6613e-16, 3.8858e-16, 1.6098e-15,\n",
      "         4.7184e-16, 6.3838e-16, 1.6098e-15, 3.0531e-16, 1.0547e-15, 2.2204e-16,\n",
      "         5.5511e-16, 1.6653e-15, 8.3267e-16, 8.0491e-16, 6.9389e-16, 7.4246e-16,\n",
      "         6.1062e-16, 1.2126e-15, 7.2164e-16, 4.7184e-16, 3.5041e-16, 8.3267e-16,\n",
      "         9.4369e-16, 1.4173e-15, 1.1657e-15, 6.5919e-16, 1.2074e-15, 6.6613e-16,\n",
      "         4.3368e-16, 8.8818e-16, 4.4409e-16, 1.2212e-15, 7.2164e-16, 9.9920e-16,\n",
      "         7.4940e-16, 8.6042e-16, 1.0270e-15, 1.9429e-15, 8.3267e-16, 1.4433e-15,\n",
      "         7.7716e-16, 4.9960e-16, 7.2164e-16, 7.7716e-16, 4.1633e-16, 1.4433e-15,\n",
      "         6.6613e-16, 3.8858e-16, 9.4369e-16, 1.4017e-15, 6.9389e-16, 8.3267e-16,\n",
      "         2.2760e-15, 9.4369e-16, 9.9920e-16, 4.9960e-16, 1.1102e-15, 1.4155e-15,\n",
      "         4.4409e-16, 7.7716e-16, 9.8532e-16, 1.1102e-15, 4.9960e-16, 7.2164e-16,\n",
      "         4.1633e-16, 7.2164e-16, 1.3323e-15, 5.5511e-16]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 139: layer3.11.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 139\n",
      "Max diff:\n",
      " tensor([3.4861e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.7184e-16, 5.9952e-15, 1.6653e-15, 4.2188e-15, 1.7208e-15, 7.4940e-16,\n",
      "         1.4433e-15, 4.4409e-15, 2.4980e-16, 2.1927e-15, 2.7200e-15, 1.2490e-15,\n",
      "         6.6613e-16, 1.4433e-15, 6.6613e-16, 5.5511e-16, 2.3870e-15, 5.5511e-16,\n",
      "         2.1094e-15, 1.3045e-15, 9.5757e-16, 1.2768e-15, 8.8818e-16, 3.9968e-15,\n",
      "         7.7716e-16, 3.0531e-15, 8.3614e-16, 1.7208e-15, 1.3045e-15, 2.4425e-15,\n",
      "         1.0408e-15, 7.7716e-16, 1.3323e-15, 4.4409e-15, 2.0123e-16, 5.8287e-16,\n",
      "         2.2844e-16, 1.8874e-15, 1.4086e-15, 8.3267e-16, 6.5503e-15, 2.7200e-15,\n",
      "         2.5258e-15, 1.3878e-17, 5.7732e-15, 1.6653e-16, 1.7764e-15, 2.3870e-15,\n",
      "         1.2768e-15, 8.8818e-16, 1.3323e-15, 3.8858e-16, 1.1657e-15, 2.3315e-15,\n",
      "         2.7756e-16, 1.8874e-15, 1.3878e-15, 2.7756e-16, 2.1094e-15, 1.9568e-15,\n",
      "         3.1086e-15, 1.9984e-15, 1.4433e-15, 1.5543e-15, 6.2172e-15, 3.0254e-15,\n",
      "         6.6058e-15, 7.1054e-15, 2.7200e-15, 4.6629e-15, 1.2434e-14, 1.7764e-15,\n",
      "         3.6637e-15, 4.8295e-15, 1.6653e-15, 6.6613e-15, 8.4377e-15, 8.8818e-15,\n",
      "         1.8874e-15, 1.7486e-15, 4.4409e-15, 7.5495e-15, 8.3267e-16, 1.1546e-14,\n",
      "         8.4377e-15, 1.5543e-15, 7.7716e-15, 1.6098e-15, 7.9936e-15, 3.4001e-16,\n",
      "         3.9968e-15, 3.6637e-15, 4.7740e-15, 4.4409e-16, 1.9429e-15, 2.5535e-15,\n",
      "         3.6152e-15, 2.0539e-15, 2.5535e-15, 1.4766e-14, 9.4369e-16, 1.6098e-15,\n",
      "         6.2172e-15, 1.1102e-15, 1.3461e-15, 1.0658e-14, 3.9413e-15, 1.2212e-15,\n",
      "         2.6645e-15, 1.9984e-15, 5.3291e-15, 6.2172e-15, 1.3323e-15, 4.6629e-15,\n",
      "         3.0531e-15, 7.1054e-15, 5.7732e-15, 5.5511e-16, 6.8279e-15, 4.3854e-15,\n",
      "         1.0547e-15, 8.8818e-16, 4.2188e-15, 4.4409e-15, 3.5527e-15, 4.5519e-15,\n",
      "         1.7764e-15, 2.8866e-15, 8.8818e-16, 6.2172e-15, 2.2204e-15, 4.4409e-15,\n",
      "         4.4409e-15, 1.5543e-15, 1.4211e-14, 4.4409e-15, 1.8319e-15, 1.4433e-15,\n",
      "         1.1102e-14, 4.4409e-15, 4.4409e-15, 4.0523e-15, 2.7756e-15, 1.0658e-14,\n",
      "         8.4377e-15, 1.0547e-15, 3.1086e-15, 6.1617e-15, 1.9540e-14, 8.8818e-16,\n",
      "         1.0658e-14, 3.5527e-15, 5.0238e-15, 6.6613e-16, 2.3315e-15, 8.1601e-15,\n",
      "         5.5511e-15, 2.7756e-15, 9.7700e-15, 1.1657e-15, 1.9984e-15, 5.1070e-15,\n",
      "         3.5527e-15, 4.2188e-15, 1.5543e-15, 6.6613e-16, 1.6875e-14, 3.7748e-15,\n",
      "         2.3093e-14, 1.1102e-15, 8.8818e-16, 1.1546e-14, 4.6629e-15, 1.0880e-14,\n",
      "         2.0539e-15, 1.1546e-14, 1.1102e-15, 2.1094e-15, 7.5495e-15, 2.4425e-15,\n",
      "         3.6082e-16, 4.6629e-15, 2.2204e-15, 3.9968e-15, 2.8866e-15, 3.1086e-15,\n",
      "         1.5099e-14, 4.3299e-15, 1.4211e-14, 9.7700e-15, 1.8319e-15, 1.6098e-15,\n",
      "         1.0658e-14, 2.3981e-14, 1.0658e-14, 6.3838e-16, 3.3307e-15, 7.9936e-15,\n",
      "         3.2196e-15, 1.3323e-14, 8.8818e-15, 9.1038e-15, 1.0658e-14, 1.5543e-15,\n",
      "         1.1546e-14, 1.2434e-14, 1.0658e-14, 1.5543e-14, 4.8850e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.1974e-14, 1.4211e-14, 5.5511e-15, 5.3291e-15, 5.3291e-15,\n",
      "         6.6613e-15, 9.7700e-15, 4.5519e-15, 3.8580e-15, 6.6613e-15, 3.4861e-14,\n",
      "         5.3291e-15, 9.7700e-15, 7.5495e-15, 1.2434e-14, 1.4211e-14, 8.8818e-15,\n",
      "         1.4211e-14, 9.3259e-15, 1.1657e-14, 1.4211e-14, 2.6645e-14, 6.3283e-15,\n",
      "         7.1054e-15, 2.4425e-15, 2.6645e-15, 1.5987e-14, 1.0686e-15, 6.2172e-15,\n",
      "         2.2760e-15, 5.3291e-15, 3.6082e-15, 5.5511e-15, 5.3291e-15, 1.2879e-14,\n",
      "         8.4377e-15, 9.1038e-15, 6.6613e-15, 6.8834e-15, 1.2434e-14, 1.0658e-14,\n",
      "         1.6098e-15, 2.6645e-15, 5.1070e-15, 1.2046e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 140: layer3.11.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 140\n",
      "Max diff:\n",
      " tensor([3.4861e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 5.9952e-15, 1.0547e-15, 4.2188e-15, 1.7208e-15, 0.0000e+00,\n",
      "         1.4433e-15, 4.4409e-15, 0.0000e+00, 2.1927e-15, 6.6613e-16, 1.2490e-15,\n",
      "         0.0000e+00, 8.3267e-16, 0.0000e+00, 5.5511e-16, 2.3870e-15, 0.0000e+00,\n",
      "         2.1094e-15, 8.0491e-16, 7.7716e-16, 1.2768e-15, 8.8818e-16, 3.9968e-15,\n",
      "         0.0000e+00, 2.4425e-15, 8.3614e-16, 1.7208e-15, 1.3045e-15, 2.4425e-15,\n",
      "         6.6613e-16, 0.0000e+00, 1.1657e-15, 4.4409e-15, 1.9429e-16, 5.8287e-16,\n",
      "         8.3267e-17, 1.8874e-15, 1.4086e-15, 0.0000e+00, 6.5503e-15, 2.7200e-15,\n",
      "         2.5258e-15, 0.0000e+00, 5.7732e-15, 0.0000e+00, 1.7764e-15, 2.3870e-15,\n",
      "         1.1657e-15, 0.0000e+00, 1.3323e-15, 3.7470e-16, 7.4940e-16, 2.3315e-15,\n",
      "         0.0000e+00, 1.8874e-15, 1.3878e-15, 0.0000e+00, 2.1094e-15, 1.9568e-15,\n",
      "         3.1086e-15, 1.9984e-15, 1.6653e-16, 1.2768e-15, 6.2172e-15, 3.0254e-15,\n",
      "         6.6058e-15, 7.1054e-15, 2.7200e-15, 4.6629e-15, 1.2434e-14, 1.7764e-15,\n",
      "         3.6637e-15, 4.8295e-15, 1.6653e-15, 6.6613e-15, 8.4377e-15, 8.8818e-15,\n",
      "         1.8874e-15, 1.7486e-15, 4.4409e-15, 7.5495e-15, 1.1796e-16, 1.1546e-14,\n",
      "         8.4377e-15, 1.5543e-15, 7.7716e-15, 1.3323e-15, 7.9936e-15, 2.7062e-16,\n",
      "         3.9968e-15, 3.6637e-15, 4.7740e-15, 4.4409e-16, 1.9429e-15, 2.5535e-15,\n",
      "         3.6152e-15, 2.0539e-15, 2.5535e-15, 1.4766e-14, 9.4369e-16, 1.6098e-15,\n",
      "         6.2172e-15, 1.1102e-15, 1.0547e-15, 1.0658e-14, 3.9413e-15, 1.2212e-15,\n",
      "         2.6645e-15, 1.9984e-15, 5.3291e-15, 6.2172e-15, 1.3323e-15, 4.6629e-15,\n",
      "         3.0531e-15, 7.1054e-15, 5.7732e-15, 5.5511e-16, 6.8279e-15, 4.3854e-15,\n",
      "         1.0547e-15, 8.8818e-16, 4.2188e-15, 4.4409e-15, 3.5527e-15, 4.5519e-15,\n",
      "         1.7764e-15, 2.8866e-15, 4.4409e-16, 6.2172e-15, 2.2204e-15, 4.4409e-15,\n",
      "         4.4409e-15, 1.3878e-15, 1.4211e-14, 4.4409e-15, 1.3323e-15, 1.4433e-15,\n",
      "         1.1102e-14, 4.4409e-15, 4.4409e-15, 4.0523e-15, 1.8041e-15, 1.0658e-14,\n",
      "         8.4377e-15, 1.0547e-15, 1.9984e-15, 4.4409e-15, 1.9540e-14, 7.3552e-16,\n",
      "         1.0658e-14, 3.5527e-15, 3.9968e-15, 0.0000e+00, 2.3315e-15, 8.1601e-15,\n",
      "         5.5511e-15, 2.7756e-15, 9.7700e-15, 7.0083e-16, 1.9984e-15, 5.1070e-15,\n",
      "         3.5527e-15, 4.2188e-15, 1.5543e-15, 0.0000e+00, 1.6875e-14, 3.7748e-15,\n",
      "         2.3093e-14, 9.4369e-16, 8.8818e-16, 1.1546e-14, 4.6629e-15, 1.0880e-14,\n",
      "         2.0539e-15, 1.1546e-14, 6.9389e-17, 2.1094e-15, 7.5495e-15, 2.4425e-15,\n",
      "         3.6082e-16, 4.6629e-15, 2.2204e-15, 3.9968e-15, 2.8866e-15, 3.1086e-15,\n",
      "         1.5099e-14, 4.3299e-15, 1.4211e-14, 9.7700e-15, 1.8319e-15, 7.6328e-16,\n",
      "         1.0658e-14, 2.3981e-14, 1.0658e-14, 2.9143e-16, 3.3307e-15, 7.9936e-15,\n",
      "         3.2196e-15, 1.3323e-14, 8.8818e-15, 9.1038e-15, 1.0658e-14, 1.5543e-15,\n",
      "         1.1546e-14, 1.2434e-14, 1.0658e-14, 1.5543e-14, 4.8850e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.1974e-14, 1.4211e-14, 5.5511e-15, 5.3291e-15, 5.3291e-15,\n",
      "         6.6613e-15, 9.7700e-15, 4.5519e-15, 3.8580e-15, 6.6613e-15, 3.4861e-14,\n",
      "         5.3291e-15, 9.7700e-15, 7.5495e-15, 1.2434e-14, 1.4211e-14, 8.8818e-15,\n",
      "         1.4211e-14, 9.3259e-15, 1.1657e-14, 1.4211e-14, 2.6645e-14, 6.3283e-15,\n",
      "         7.1054e-15, 2.4425e-15, 2.6645e-15, 1.5987e-14, 1.0686e-15, 6.2172e-15,\n",
      "         2.2204e-15, 5.3291e-15, 3.6082e-15, 5.5511e-15, 5.3291e-15, 1.2879e-14,\n",
      "         8.4377e-15, 9.1038e-15, 6.6613e-15, 6.8834e-15, 1.2434e-14, 1.0658e-14,\n",
      "         1.6098e-15, 2.6645e-15, 5.1070e-15, 1.2046e-14]], dtype=torch.float64)\n",
      " tensor([  1,   2,   3,   4,   6,   7,   9,  10,  11,  13,  15,  16,  18,  19,\n",
      "         20,  21,  22,  23,  25,  26,  27,  28,  29,  30,  32,  33,  34,  35,\n",
      "         36,  37,  38,  40,  41,  42,  44,  46,  47,  48,  50,  51,  52,  53,\n",
      "         55,  56,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   4,   6,   7,   9,  10,  11,  13,  15,  16,  18,  19,\n",
      "         20,  21,  22,  23,  25,  26,  27,  28,  29,  30,  32,  33,  34,  35,\n",
      "         36,  37,  38,  40,  41,  42,  44,  46,  47,  48,  50,  51,  52,  53,\n",
      "         55,  56,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])  (len = 240)\n",
      "passing Cout = tensor([57])  (len = 1)\n",
      "\n",
      "Executing module 141: layer3.12.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 141\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 141\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 141\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 141\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 141\n",
      "Max diff:\n",
      " tensor([2.8422e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.7700e-15, 2.6645e-15, 1.2434e-14, 8.8818e-15, 7.1054e-15, 3.5527e-15,\n",
      "         1.0658e-14, 8.8818e-15, 5.3291e-15, 6.2172e-15, 6.2172e-15, 1.7764e-14,\n",
      "         2.1316e-14, 4.4409e-15, 2.1316e-14, 4.4409e-15, 1.0658e-14, 2.6645e-15,\n",
      "         1.4211e-14, 5.3291e-15, 4.4409e-15, 2.8422e-14, 2.4869e-14, 1.2434e-14,\n",
      "         4.2633e-14, 7.9936e-15, 1.0658e-14, 4.9738e-14, 3.9968e-15, 5.3291e-15,\n",
      "         7.1054e-15, 2.4869e-14, 3.5527e-15, 4.4409e-15, 1.4211e-14, 3.1974e-14,\n",
      "         3.9968e-15, 8.8818e-15, 2.1316e-14, 7.1054e-15, 8.8818e-15, 4.4409e-15,\n",
      "         5.3291e-15, 3.1086e-15, 3.9968e-15, 3.5527e-15, 8.8818e-15, 1.0658e-14,\n",
      "         3.1086e-15, 6.2172e-15, 4.4409e-15, 4.4409e-15, 8.8818e-15, 1.2434e-14,\n",
      "         1.0658e-14, 8.8818e-15, 3.5527e-15, 2.1316e-14, 2.1316e-14, 2.4869e-14,\n",
      "         1.4211e-14, 3.5527e-14, 8.8818e-15, 7.1054e-15, 1.1369e-13, 4.9738e-14,\n",
      "         7.1054e-14, 1.2434e-14, 9.7700e-15, 9.7700e-15, 5.3291e-15, 3.1974e-14,\n",
      "         8.8818e-15, 1.9540e-14, 7.1054e-15, 1.2434e-14, 1.4211e-14, 2.4869e-14,\n",
      "         7.9936e-15, 4.4409e-15, 4.2633e-14, 4.2633e-14, 1.0658e-14, 3.9968e-15,\n",
      "         8.5265e-14, 4.6185e-14, 3.5527e-14, 4.9738e-14, 4.6185e-14, 7.9936e-15,\n",
      "         1.0658e-14, 4.9738e-14, 1.5987e-14, 1.7764e-14, 5.6843e-14, 1.4211e-14,\n",
      "         1.2434e-14, 5.7732e-15, 3.1974e-14, 7.1054e-15, 6.3949e-14, 3.1974e-14,\n",
      "         6.3949e-14, 1.2434e-14, 2.4869e-14, 8.8818e-15, 5.3291e-15, 5.3291e-15,\n",
      "         3.1974e-14, 2.6645e-15, 1.2434e-14, 2.1316e-14, 6.2172e-15, 3.5527e-14,\n",
      "         7.9936e-15, 2.8422e-14, 8.8818e-15, 4.2633e-14, 8.8818e-15, 6.3949e-14,\n",
      "         1.1369e-13, 8.8818e-15, 1.0658e-14, 7.9936e-15, 6.3949e-14, 3.5527e-14,\n",
      "         1.5987e-14, 2.4869e-14, 5.6843e-14, 2.8422e-14, 4.2633e-14, 9.9476e-14,\n",
      "         1.4211e-13, 4.2633e-14, 8.8818e-15, 7.1054e-15, 8.8818e-15, 7.9936e-15,\n",
      "         7.1054e-14, 3.5527e-14, 1.0658e-14, 1.7764e-14, 4.2633e-14, 8.8818e-15,\n",
      "         3.5527e-14, 1.2434e-14, 2.8422e-14, 2.3093e-14, 2.8422e-14, 3.5527e-14,\n",
      "         1.2790e-13, 3.9080e-14, 4.9738e-14, 9.2371e-14, 4.9738e-14, 8.5265e-14,\n",
      "         4.9738e-14, 1.7764e-14, 4.2633e-14, 9.7700e-15, 4.9738e-14, 1.4211e-14,\n",
      "         2.4869e-14, 2.1316e-14, 1.5987e-14, 5.6843e-14, 3.9080e-14, 3.5527e-14,\n",
      "         3.5527e-14, 1.1369e-13, 4.9738e-14, 6.3949e-14, 3.5527e-14, 1.4211e-14,\n",
      "         3.1974e-14, 8.8818e-15, 1.4211e-14, 9.7700e-15, 1.5987e-14, 6.3949e-14,\n",
      "         7.9936e-15, 8.8818e-15, 9.9476e-14, 4.2633e-14, 3.5527e-14, 6.3949e-14,\n",
      "         1.2790e-13, 2.8422e-14, 2.8422e-14, 1.5987e-14, 5.3291e-15, 6.3949e-14,\n",
      "         9.9476e-14, 9.9476e-14, 3.5527e-14, 1.4211e-13, 1.7053e-13, 9.2371e-14,\n",
      "         1.4211e-13, 1.1369e-13, 9.9476e-14, 5.3291e-14, 1.9895e-13, 8.5265e-14,\n",
      "         8.3933e-14, 7.1054e-14, 8.5265e-14, 7.1054e-14, 9.9476e-14, 1.4211e-13,\n",
      "         3.5527e-14, 5.6843e-14, 7.1054e-14, 1.1369e-13, 1.4211e-13, 7.1054e-14,\n",
      "         7.8160e-14, 1.5632e-13, 3.1974e-14, 5.6843e-14, 7.1054e-14, 6.3949e-14,\n",
      "         1.1369e-13, 9.9476e-14, 2.8422e-13, 1.7053e-13, 7.1054e-14, 3.1974e-14,\n",
      "         4.2633e-14, 1.1369e-13, 2.5580e-13, 1.1369e-13, 6.3949e-14, 4.2633e-14,\n",
      "         4.3521e-14, 6.3949e-14, 9.2371e-14, 3.1974e-14, 1.1369e-13, 8.5265e-14,\n",
      "         7.4607e-14, 6.3949e-14, 1.2079e-13, 2.4158e-13, 8.5265e-14, 1.5987e-14,\n",
      "         2.1316e-13, 8.5265e-14, 7.8160e-14, 1.1369e-13, 5.6843e-14, 1.2079e-13,\n",
      "         8.5265e-14, 1.7053e-13, 5.6843e-14, 1.7053e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 142: layer3.12.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 142\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 142\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 142\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 142\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 142\n",
      "Max diff:\n",
      " tensor([6.7502e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.6653e-15, 5.5511e-16, 2.4425e-15, 1.7764e-15, 1.4433e-15, 6.1062e-16,\n",
      "         1.9984e-15, 1.7764e-15, 1.1102e-15, 9.9920e-16, 1.2212e-15, 2.6645e-15,\n",
      "         4.4409e-15, 9.9920e-16, 3.1086e-15, 1.1102e-15, 1.7764e-15, 7.7716e-16,\n",
      "         2.8866e-15, 8.8818e-16, 1.1102e-15, 5.3291e-15, 4.4409e-15, 2.6645e-15,\n",
      "         5.3291e-15, 1.5543e-15, 1.5543e-15, 1.0658e-14, 9.9920e-16, 1.3323e-15,\n",
      "         1.5543e-15, 3.9968e-15, 8.8818e-16, 1.1102e-15, 2.6645e-15, 5.7732e-15,\n",
      "         8.8818e-16, 1.7764e-15, 3.9968e-15, 1.5543e-15, 1.7764e-15, 9.9920e-16,\n",
      "         9.9920e-16, 8.8818e-16, 9.4369e-16, 9.9920e-16, 1.2212e-15, 2.2204e-15,\n",
      "         7.7716e-16, 1.3323e-15, 8.8818e-16, 8.8818e-16, 1.5543e-15, 2.4425e-15,\n",
      "         2.2204e-15, 1.4433e-15, 7.7716e-16, 3.5527e-15, 2.6645e-15, 3.1086e-15,\n",
      "         2.6645e-15, 3.9968e-15, 1.5543e-15, 1.5543e-15, 2.1316e-14, 6.2172e-15,\n",
      "         1.7764e-14, 1.9984e-15, 1.9984e-15, 2.2204e-15, 1.1102e-15, 9.7700e-15,\n",
      "         2.4425e-15, 3.9968e-15, 1.7764e-15, 1.9984e-15, 2.4425e-15, 4.4409e-15,\n",
      "         1.7764e-15, 8.8818e-16, 8.8818e-15, 1.0658e-14, 2.2204e-15, 9.9920e-16,\n",
      "         1.4211e-14, 1.1102e-14, 2.6645e-15, 1.0658e-14, 9.7700e-15, 1.2212e-15,\n",
      "         2.6645e-15, 6.2172e-15, 3.1086e-15, 3.5527e-15, 2.2204e-15, 3.1086e-15,\n",
      "         3.1086e-15, 1.3323e-15, 4.4409e-15, 1.3323e-15, 1.0658e-14, 4.4409e-15,\n",
      "         1.5987e-14, 2.8866e-15, 4.4409e-15, 1.5543e-15, 1.5543e-15, 1.5543e-15,\n",
      "         6.2172e-15, 7.7716e-16, 3.1086e-15, 3.1086e-15, 1.2212e-15, 5.3291e-15,\n",
      "         1.9984e-15, 5.3291e-15, 2.2204e-15, 1.0658e-14, 1.6653e-15, 8.8818e-15,\n",
      "         1.4211e-14, 1.6653e-15, 3.1086e-15, 1.7764e-15, 2.1316e-14, 5.7732e-15,\n",
      "         3.1086e-15, 6.2172e-15, 8.8818e-15, 5.3291e-15, 9.7700e-15, 2.4869e-14,\n",
      "         5.6843e-14, 1.0658e-14, 2.2204e-15, 1.7764e-15, 2.2204e-15, 1.4433e-15,\n",
      "         1.2434e-14, 6.2172e-15, 2.6645e-15, 3.9968e-15, 8.8818e-15, 1.9984e-15,\n",
      "         8.8818e-15, 2.4425e-15, 7.9936e-15, 5.3291e-15, 4.4409e-15, 7.1054e-15,\n",
      "         2.4869e-14, 9.7700e-15, 7.1054e-15, 4.4409e-15, 7.9936e-15, 1.2434e-14,\n",
      "         8.8818e-15, 2.6645e-15, 7.9936e-15, 2.4425e-15, 1.0658e-14, 3.1086e-15,\n",
      "         4.4409e-15, 4.4409e-15, 3.1086e-15, 1.4211e-14, 9.7700e-15, 8.8818e-15,\n",
      "         7.9936e-15, 2.4869e-14, 1.4211e-14, 1.2434e-14, 7.1054e-15, 3.1086e-15,\n",
      "         7.1054e-15, 2.2204e-15, 3.5527e-15, 1.7764e-15, 3.9968e-15, 1.3323e-14,\n",
      "         2.2204e-15, 2.6645e-15, 2.1316e-14, 1.1546e-14, 7.9936e-15, 1.5987e-14,\n",
      "         1.9540e-14, 6.2172e-15, 7.9936e-15, 2.8866e-15, 1.3323e-15, 1.1546e-14,\n",
      "         2.4869e-14, 2.4869e-14, 1.4211e-14, 3.1974e-14, 3.1974e-14, 1.9540e-14,\n",
      "         3.5527e-14, 2.8422e-14, 2.4869e-14, 7.1054e-15, 5.6843e-14, 1.7764e-14,\n",
      "         1.1657e-14, 1.1546e-14, 1.5987e-14, 2.1316e-14, 2.1316e-14, 4.6185e-14,\n",
      "         7.1054e-15, 1.2434e-14, 2.1316e-14, 4.2633e-14, 3.5527e-14, 1.7764e-14,\n",
      "         2.4869e-14, 3.1974e-14, 8.8818e-15, 1.0658e-14, 1.5987e-14, 2.1316e-14,\n",
      "         3.5527e-14, 3.1974e-14, 4.2633e-14, 4.2633e-14, 1.0658e-14, 1.0658e-14,\n",
      "         8.8818e-15, 3.5527e-14, 4.6185e-14, 2.8422e-14, 9.7700e-15, 1.4211e-14,\n",
      "         8.2157e-15, 1.1990e-14, 1.8652e-14, 7.1054e-15, 4.2633e-14, 1.1546e-14,\n",
      "         1.7764e-14, 1.4211e-14, 2.8422e-14, 6.7502e-14, 2.4869e-14, 3.9968e-15,\n",
      "         5.6843e-14, 1.7764e-14, 1.2879e-14, 2.3093e-14, 9.7700e-15, 4.2633e-14,\n",
      "         1.2434e-14, 2.3093e-14, 1.2434e-14, 3.5527e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 143: layer3.12.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 143\n",
      "Max diff:\n",
      " tensor([1.1657e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.8850e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.8319e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.6082e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.2212e-15, 9.7700e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.1054e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.1657e-14, 5.4401e-15, 0.0000e+00, 8.8818e-15, 0.0000e+00, 5.9397e-15,\n",
      "         0.0000e+00, 7.4385e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         8.2157e-15, 2.8866e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15,\n",
      "         9.5479e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.1086e-15, 1.3323e-15, 2.8866e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 85, 128, 133, 139, 182, 183, 193, 201, 204, 205, 207, 209, 211, 216,\n",
      "        232, 234, 235, 239, 240, 248, 252, 253, 254])\n",
      "\n",
      "failing Cout = tensor([ 85, 128, 133, 139, 182, 183, 193, 201, 204, 205, 207, 209, 211, 216,\n",
      "        232, 234, 235, 239, 240, 248, 252, 253, 254])  (len = 23)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 144: layer3.12.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 144\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 144\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 4,  5,  6,  7,  9, 16, 19, 25, 27, 33, 36, 40, 41, 42, 45, 46, 47, 50,\n",
      "        55, 57, 61, 62]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 140, 143, 144, 154, 155, 156, 157, 162, 164, 168, 171, 174, 179,\n",
      "        185, 186, 189, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 201, 202, 208, 212, 215, 218, 222, 225, 226, 228, 230,\n",
      "        235, 241, 244, 245, 249, 250, 251, 254]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 144\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 18, 19, 20,\n",
      "        21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
      "        39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
      "        58, 59, 60, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  68,  69,  70,  71,  72,  73,  74,  75,  77,  79,  81,  83,\n",
      "         84,  86,  89,  90,  92,  93,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120,\n",
      "        123, 124, 125, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251,\n",
      "        252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 144\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 144\n",
      "Max diff:\n",
      " tensor([1.1546e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.2172e-15, 2.8866e-15, 1.0658e-14, 4.9544e-15, 3.2196e-15, 4.8850e-15,\n",
      "         3.1086e-15, 4.4409e-15, 5.5511e-15, 3.2196e-15, 4.8850e-15, 5.3291e-15,\n",
      "         3.9413e-15, 9.7700e-15, 6.4393e-15, 2.8866e-15, 5.3291e-15, 5.8287e-16,\n",
      "         4.4409e-15, 1.7764e-15, 4.4409e-15, 2.4980e-15, 4.4409e-15, 6.2172e-15,\n",
      "         4.8850e-15, 6.6613e-15, 1.9429e-15, 3.9968e-15, 2.4980e-15, 4.7740e-15,\n",
      "         5.3291e-15, 3.5527e-15, 5.3291e-15, 7.7716e-15, 4.8850e-15, 2.3870e-15,\n",
      "         6.2172e-15, 7.5356e-15, 4.9960e-15, 3.1086e-15, 3.9968e-15, 3.8858e-15,\n",
      "         4.8850e-15, 2.5535e-15, 6.6613e-15, 3.9968e-15, 3.5527e-15, 8.8818e-15,\n",
      "         1.1657e-15, 3.9968e-15, 9.7700e-15, 4.5519e-15, 7.3275e-15, 5.7732e-15,\n",
      "         4.4409e-15, 5.7732e-15, 2.4425e-15, 1.3323e-15, 3.7748e-15, 3.5527e-15,\n",
      "         2.5535e-15, 1.8319e-15, 1.7764e-15, 5.9952e-15, 3.6360e-15, 5.6621e-15,\n",
      "         1.8180e-15, 4.8850e-15, 5.3291e-15, 7.9936e-15, 5.9952e-15, 5.9952e-15,\n",
      "         2.1649e-15, 5.3291e-15, 5.3291e-15, 3.9968e-15, 8.4377e-15, 5.2180e-15,\n",
      "         3.2752e-15, 6.2172e-15, 6.2172e-15, 6.3838e-15, 1.8874e-15, 7.9936e-15,\n",
      "         1.9706e-15, 1.7764e-15, 4.4409e-15, 6.2172e-15, 9.3259e-15, 5.1070e-15,\n",
      "         4.4409e-15, 8.2573e-16, 3.5996e-15, 3.5527e-15, 3.4417e-15, 3.6637e-15,\n",
      "         3.9968e-15, 5.7732e-15, 5.5511e-15, 5.3291e-15, 5.3291e-15, 4.8850e-15,\n",
      "         3.2196e-15, 3.5527e-15, 5.3291e-15, 2.6645e-15, 7.5495e-15, 7.5495e-15,\n",
      "         7.5495e-15, 4.4409e-15, 3.5527e-15, 6.4393e-15, 5.3291e-15, 7.5495e-15,\n",
      "         4.4409e-15, 4.4409e-15, 2.8866e-15, 1.2212e-15, 6.2172e-15, 3.8858e-15,\n",
      "         3.8303e-15, 6.6613e-15, 2.4425e-15, 4.6629e-15, 4.4409e-15, 2.6645e-15,\n",
      "         2.4425e-15, 5.1903e-15, 4.9682e-15, 4.4409e-15, 6.2172e-15, 5.8842e-15,\n",
      "         7.1054e-15, 4.4409e-15, 5.1625e-15, 4.4409e-15, 5.3291e-15, 3.5527e-15,\n",
      "         5.5511e-15, 7.5495e-15, 4.4964e-15, 2.6645e-15, 7.9936e-15, 5.1070e-15,\n",
      "         5.9952e-15, 3.6360e-15, 4.2744e-15, 6.2172e-15, 5.3291e-15, 5.3291e-15,\n",
      "         7.5495e-15, 3.5527e-15, 5.3291e-15, 7.5495e-15, 3.7748e-15, 4.2188e-15,\n",
      "         7.1054e-15, 4.2188e-15, 4.8850e-15, 3.9968e-15, 7.9936e-15, 3.9968e-15,\n",
      "         3.6637e-15, 7.1054e-15, 2.8866e-15, 6.2172e-15, 6.6613e-15, 5.3291e-15,\n",
      "         7.9936e-15, 2.5535e-15, 4.6629e-15, 6.6613e-15, 5.1070e-15, 7.3830e-15,\n",
      "         4.8850e-15, 9.3259e-15, 7.7716e-15, 4.2188e-15, 4.2188e-15, 2.9421e-15,\n",
      "         3.4521e-15, 3.9968e-15, 6.6613e-15, 4.4409e-15, 8.3267e-15, 6.6613e-15,\n",
      "         6.1617e-15, 4.4409e-15, 4.4409e-15, 5.1070e-15, 9.1593e-15, 6.2172e-15,\n",
      "         4.4409e-15, 8.8818e-15, 4.8850e-15, 5.3291e-15, 8.8818e-15, 1.1324e-14,\n",
      "         7.9936e-15, 7.1054e-15, 6.3283e-15, 6.7724e-15, 4.8850e-15, 5.4401e-15,\n",
      "         5.9952e-15, 8.8818e-15, 4.9960e-15, 7.1054e-15, 4.8850e-15, 7.5495e-15,\n",
      "         6.2172e-15, 5.7732e-15, 7.3275e-15, 8.4377e-15, 5.3291e-15, 6.2172e-15,\n",
      "         9.3259e-15, 9.8255e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15, 7.2164e-15,\n",
      "         7.9936e-15, 9.7700e-15, 3.9968e-15, 6.5781e-15, 6.2172e-15, 5.5511e-15,\n",
      "         4.3299e-15, 4.6629e-15, 6.4393e-15, 6.2172e-15, 1.1546e-14, 5.2736e-15,\n",
      "         7.1887e-15, 5.7732e-15, 5.9952e-15, 5.5511e-15, 9.5479e-15, 5.3291e-15,\n",
      "         6.4393e-15, 9.3259e-15, 8.4377e-15, 7.0707e-15, 5.7732e-15, 7.5495e-15,\n",
      "         4.6629e-15, 5.7732e-15, 4.4409e-15, 8.2157e-15, 4.6629e-15, 9.1038e-15,\n",
      "         7.1054e-15, 4.6629e-15, 5.9674e-15, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 145: layer3.12.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 145\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 145\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 145\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 145\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 145\n",
      "Max diff:\n",
      " tensor([5.5511e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 7.7716e-16, 5.3291e-15, 1.0721e-15, 7.9797e-16, 7.7716e-16,\n",
      "         5.5511e-16, 1.2768e-15, 2.2204e-15, 1.7764e-15, 1.4433e-15, 8.0491e-16,\n",
      "         8.3267e-16, 5.5511e-15, 2.7756e-15, 2.9143e-16, 2.5535e-15, 2.2204e-16,\n",
      "         1.1102e-15, 7.7716e-16, 1.7764e-15, 7.2164e-16, 4.7184e-16, 1.8874e-15,\n",
      "         6.1062e-16, 1.4433e-15, 7.2164e-16, 1.4988e-15, 4.4409e-16, 6.1062e-16,\n",
      "         1.9984e-15, 8.8818e-16, 2.8866e-15, 2.2760e-15, 8.8818e-16, 6.9389e-18,\n",
      "         2.1094e-15, 2.8241e-15, 5.2042e-16, 1.3878e-16, 7.2164e-16, 1.2212e-15,\n",
      "         7.7716e-16, 7.2164e-16, 1.7764e-15, 2.3315e-15, 1.1102e-15, 4.8850e-15,\n",
      "         3.0531e-16, 1.1102e-16, 3.1086e-15, 1.5543e-15, 2.3592e-15, 2.7756e-15,\n",
      "         2.4425e-15, 1.5543e-15, 8.8818e-16, 4.9960e-16, 8.3267e-16, 1.6653e-15,\n",
      "         2.2204e-16, 4.5797e-16, 7.7716e-16, 2.1094e-15, 5.9674e-16, 1.4988e-15,\n",
      "         3.8858e-16, 1.6376e-15, 6.6613e-16, 1.1102e-15, 1.2768e-15, 9.7145e-16,\n",
      "         8.0491e-16, 1.6653e-15, 2.3315e-15, 1.0547e-15, 1.6653e-15, 1.3323e-15,\n",
      "         3.6082e-16, 1.4433e-15, 1.4433e-15, 1.8874e-15, 6.1062e-16, 1.8874e-15,\n",
      "         7.3639e-16, 6.9389e-17, 1.3323e-15, 7.7716e-16, 8.0491e-16, 2.7756e-15,\n",
      "         1.3878e-15, 1.3878e-16, 9.8532e-16, 1.3600e-15, 5.9674e-16, 7.2164e-16,\n",
      "         8.8818e-16, 2.2204e-15, 1.7208e-15, 1.8874e-15, 9.9920e-16, 8.3267e-16,\n",
      "         7.7716e-16, 3.3307e-16, 9.4369e-16, 8.0491e-16, 2.7756e-15, 2.3315e-15,\n",
      "         2.3315e-15, 9.4369e-16, 4.9960e-16, 1.2768e-15, 9.9920e-16, 2.3315e-15,\n",
      "         7.7716e-16, 1.1380e-15, 7.7716e-16, 6.5919e-17, 1.6931e-15, 2.7756e-16,\n",
      "         8.6042e-16, 1.3323e-15, 8.0491e-16, 1.5543e-15, 7.7716e-16, 9.4369e-16,\n",
      "         5.5511e-16, 1.2490e-15, 1.6098e-15, 8.3267e-16, 2.4425e-15, 2.8866e-15,\n",
      "         1.7764e-15, 1.6653e-15, 1.6653e-15, 5.5511e-16, 2.6645e-15, 1.4433e-15,\n",
      "         1.5543e-15, 2.6645e-15, 4.5450e-16, 3.3307e-16, 1.5543e-15, 1.7764e-15,\n",
      "         2.3315e-15, 9.6689e-16, 1.2212e-15, 1.9984e-15, 1.0686e-15, 1.2768e-15,\n",
      "         2.4425e-15, 9.9920e-16, 1.7764e-15, 1.3323e-15, 6.6613e-16, 1.2212e-15,\n",
      "         2.2204e-15, 1.6931e-15, 1.6653e-15, 1.1102e-15, 3.9968e-15, 1.2212e-15,\n",
      "         6.8001e-16, 2.2204e-15, 7.3899e-16, 1.3323e-15, 2.8866e-15, 3.1086e-15,\n",
      "         2.6645e-15, 9.9920e-16, 9.9920e-16, 2.2204e-15, 1.8319e-15, 1.7625e-15,\n",
      "         9.9920e-16, 5.5511e-15, 5.4401e-15, 1.4433e-15, 4.7878e-16, 4.1633e-16,\n",
      "         5.2736e-16, 8.8818e-16, 2.0539e-15, 1.5543e-15, 1.4988e-15, 3.1086e-15,\n",
      "         2.9698e-15, 1.1102e-15, 1.4433e-15, 7.7716e-16, 4.9960e-15, 3.9968e-15,\n",
      "         9.9920e-16, 3.1086e-15, 1.9013e-15, 1.2212e-15, 2.6645e-15, 1.8874e-15,\n",
      "         2.3315e-15, 1.4988e-15, 1.7625e-15, 2.4425e-15, 1.3323e-15, 1.3323e-15,\n",
      "         1.4988e-15, 3.2196e-15, 8.8818e-16, 1.7764e-15, 1.9984e-15, 2.5535e-15,\n",
      "         1.7764e-15, 1.5821e-15, 2.4425e-15, 2.2204e-15, 2.2204e-15, 2.8866e-15,\n",
      "         2.4425e-15, 3.4417e-15, 2.7756e-15, 2.2204e-15, 1.1657e-15, 2.1094e-15,\n",
      "         2.2204e-15, 3.2474e-15, 1.9984e-15, 2.6090e-15, 1.9984e-15, 1.6653e-15,\n",
      "         1.0825e-15, 1.1102e-15, 9.4369e-16, 1.7764e-15, 2.6090e-15, 1.4710e-15,\n",
      "         1.1102e-15, 1.3323e-15, 2.0539e-15, 1.5543e-15, 2.6645e-15, 1.2212e-15,\n",
      "         2.1094e-15, 2.7756e-15, 3.1086e-15, 1.7764e-15, 2.3315e-15, 2.8866e-15,\n",
      "         6.6613e-16, 2.3037e-15, 1.5543e-15, 2.7756e-15, 1.3045e-15, 3.7748e-15,\n",
      "         2.6645e-15, 1.5543e-15, 1.5266e-15, 2.2204e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 146: layer3.12.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 146\n",
      "Max diff:\n",
      " tensor([3.5083e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 5.9952e-15, 5.3291e-15, 3.9968e-15, 1.6098e-15, 7.7716e-16,\n",
      "         1.5543e-15, 4.6629e-15, 2.2204e-15, 2.5535e-15, 1.4433e-15, 1.2490e-15,\n",
      "         8.3267e-16, 5.5511e-15, 2.7756e-15, 5.5511e-16, 2.8311e-15, 2.2204e-16,\n",
      "         1.7764e-15, 8.0491e-16, 1.7764e-15, 1.2768e-15, 1.2212e-15, 4.1633e-15,\n",
      "         6.1062e-16, 2.0817e-15, 8.8818e-16, 2.1094e-15, 1.2490e-15, 2.6645e-15,\n",
      "         1.9984e-15, 8.8818e-16, 2.8866e-15, 4.8850e-15, 8.8818e-16, 5.8287e-16,\n",
      "         2.1094e-15, 2.8241e-15, 1.4294e-15, 1.3878e-16, 7.1054e-15, 2.3870e-15,\n",
      "         2.0262e-15, 7.2164e-16, 5.5511e-15, 2.3315e-15, 2.1094e-15, 4.8850e-15,\n",
      "         1.2212e-15, 1.1102e-16, 4.4409e-15, 1.5543e-15, 2.9421e-15, 2.7756e-15,\n",
      "         2.4425e-15, 1.9984e-15, 1.7902e-15, 4.9960e-16, 2.2204e-15, 1.9013e-15,\n",
      "         3.3307e-15, 2.1094e-15, 7.7716e-16, 2.1094e-15, 6.2172e-15, 3.2196e-15,\n",
      "         6.6058e-15, 7.1054e-15, 2.7756e-15, 5.0515e-15, 1.3323e-14, 2.1094e-15,\n",
      "         3.6637e-15, 5.1070e-15, 3.3307e-15, 5.7732e-15, 8.4377e-15, 7.9936e-15,\n",
      "         1.9984e-15, 2.0262e-15, 4.4409e-15, 7.9936e-15, 6.1062e-16, 1.1546e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.9936e-15, 1.5821e-15, 8.4377e-15, 2.7756e-15,\n",
      "         4.2188e-15, 3.6637e-15, 4.5519e-15, 1.3600e-15, 2.1094e-15, 2.5119e-15,\n",
      "         4.1078e-15, 1.8874e-15, 2.3037e-15, 1.6653e-14, 1.7764e-15, 1.4433e-15,\n",
      "         5.3291e-15, 1.4433e-15, 1.0547e-15, 1.0658e-14, 4.8850e-15, 2.3315e-15,\n",
      "         3.1086e-15, 2.4425e-15, 5.3291e-15, 6.2172e-15, 1.3323e-15, 4.3854e-15,\n",
      "         3.1641e-15, 6.9944e-15, 5.7732e-15, 5.5511e-16, 7.4385e-15, 4.2188e-15,\n",
      "         1.1102e-15, 1.5543e-15, 4.3299e-15, 4.4409e-15, 2.6645e-15, 4.4409e-15,\n",
      "         1.9984e-15, 2.2204e-15, 1.6098e-15, 5.7454e-15, 4.4409e-15, 4.3299e-15,\n",
      "         4.4409e-15, 1.6653e-15, 1.2434e-14, 4.8850e-15, 2.8866e-15, 1.6098e-15,\n",
      "         1.1102e-14, 3.5527e-15, 4.4409e-15, 3.9968e-15, 2.2204e-15, 1.0658e-14,\n",
      "         7.5495e-15, 1.0547e-15, 1.9984e-15, 3.9968e-15, 1.7764e-14, 1.2768e-15,\n",
      "         1.1546e-14, 3.7748e-15, 4.4409e-15, 1.3323e-15, 2.1649e-15, 8.8818e-15,\n",
      "         6.4393e-15, 3.7748e-15, 9.7700e-15, 1.1102e-15, 3.9968e-15, 4.6629e-15,\n",
      "         3.9968e-15, 4.4409e-15, 1.7764e-15, 1.3323e-15, 1.4211e-14, 3.3307e-15,\n",
      "         2.1316e-14, 9.9920e-16, 1.0547e-15, 1.0658e-14, 4.8295e-15, 1.0658e-14,\n",
      "         2.1927e-15, 1.1990e-14, 5.4401e-15, 1.8874e-15, 7.5495e-15, 2.3315e-15,\n",
      "         5.8287e-16, 4.6629e-15, 2.8866e-15, 2.9976e-15, 2.8866e-15, 3.5527e-15,\n",
      "         1.4655e-14, 4.5519e-15, 1.4211e-14, 9.7700e-15, 4.9960e-15, 3.9968e-15,\n",
      "         1.0658e-14, 2.3981e-14, 1.0658e-14, 1.2212e-15, 3.5527e-15, 7.9936e-15,\n",
      "         4.4409e-15, 1.3323e-14, 8.8818e-15, 9.6034e-15, 1.1546e-14, 1.3878e-15,\n",
      "         1.1768e-14, 1.2434e-14, 1.0214e-14, 1.5099e-14, 5.7732e-15, 4.4409e-15,\n",
      "         4.1078e-15, 3.1974e-14, 1.4211e-14, 6.3283e-15, 5.7732e-15, 6.4393e-15,\n",
      "         6.6613e-15, 1.0658e-14, 5.1070e-15, 4.1078e-15, 7.5495e-15, 3.5083e-14,\n",
      "         5.5511e-15, 9.7700e-15, 6.6613e-15, 1.2434e-14, 1.4211e-14, 9.7700e-15,\n",
      "         1.4211e-14, 9.3259e-15, 1.1657e-14, 1.3212e-14, 2.6645e-14, 7.1054e-15,\n",
      "         7.5495e-15, 2.4425e-15, 3.5527e-15, 1.4655e-14, 2.6645e-15, 7.1054e-15,\n",
      "         2.3315e-15, 6.2172e-15, 3.3307e-15, 5.3291e-15, 5.5511e-15, 1.2657e-14,\n",
      "         8.4377e-15, 8.2157e-15, 7.5495e-15, 7.5495e-15, 1.4211e-14, 9.1038e-15,\n",
      "         2.8866e-15, 3.3307e-15, 4.8850e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 147: layer3.12.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 147\n",
      "Max diff:\n",
      " tensor([3.5083e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.5535e-15, 5.9952e-15, 0.0000e+00, 3.9968e-15, 1.6098e-15, 0.0000e+00,\n",
      "         1.3323e-15, 4.6629e-15, 3.0531e-16, 1.7764e-15, 4.4409e-16, 1.2490e-15,\n",
      "         7.1471e-16, 5.5511e-15, 2.7756e-15, 5.5511e-16, 2.8311e-15, 0.0000e+00,\n",
      "         1.2212e-15, 3.0531e-16, 1.7764e-15, 6.7654e-17, 1.2212e-15, 4.1633e-15,\n",
      "         0.0000e+00, 1.8319e-15, 0.0000e+00, 2.1094e-15, 0.0000e+00, 2.6645e-15,\n",
      "         1.3878e-15, 8.8818e-16, 2.8866e-15, 4.8850e-15, 1.3878e-17, 5.8287e-16,\n",
      "         5.2736e-16, 2.6645e-15, 8.8818e-16, 0.0000e+00, 7.1054e-15, 1.6653e-15,\n",
      "         1.3323e-15, 6.4532e-16, 5.5511e-15, 1.6098e-15, 2.1094e-15, 1.1657e-15,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-15, 4.4062e-16, 2.9421e-15, 2.7756e-15,\n",
      "         3.8858e-16, 1.9984e-15, 1.2212e-15, 4.7184e-16, 2.2204e-15, 1.9013e-15,\n",
      "         3.3307e-15, 2.1094e-15, 0.0000e+00, 8.6736e-16, 6.2172e-15, 2.8866e-15,\n",
      "         6.6058e-15, 7.1054e-15, 2.7756e-15, 5.0515e-15, 1.3323e-14, 2.1094e-15,\n",
      "         3.6637e-15, 5.1070e-15, 3.3307e-15, 5.7732e-15, 8.4377e-15, 7.9936e-15,\n",
      "         1.9984e-15, 1.1102e-15, 4.4409e-15, 7.9936e-15, 0.0000e+00, 1.1546e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.9936e-15, 1.5821e-15, 8.4377e-15, 2.7756e-15,\n",
      "         4.2188e-15, 3.6637e-15, 4.5519e-15, 9.3675e-16, 2.1094e-15, 2.5119e-15,\n",
      "         3.5527e-15, 1.0686e-15, 1.9984e-15, 1.0103e-14, 1.2768e-15, 1.4433e-15,\n",
      "         5.3291e-15, 1.4433e-15, 8.8818e-16, 1.0658e-14, 4.5519e-15, 1.9238e-15,\n",
      "         3.1086e-15, 2.4425e-15, 5.3291e-15, 6.2172e-15, 1.3323e-15, 3.9968e-15,\n",
      "         3.1641e-15, 6.9944e-15, 5.7732e-15, 5.5511e-16, 7.4385e-15, 4.2188e-15,\n",
      "         1.1102e-15, 1.5543e-15, 4.3299e-15, 4.4409e-15, 2.6645e-15, 4.4409e-15,\n",
      "         1.9984e-15, 2.2204e-15, 8.1879e-16, 5.7454e-15, 4.4409e-15, 4.3299e-15,\n",
      "         4.4409e-15, 1.6653e-15, 1.2434e-14, 4.8850e-15, 1.4433e-15, 1.6098e-15,\n",
      "         1.1102e-14, 3.5527e-15, 4.4409e-15, 3.1086e-15, 1.7764e-15, 1.0658e-14,\n",
      "         7.5495e-15, 9.1593e-16, 1.5543e-15, 3.9968e-15, 1.7764e-14, 1.2768e-15,\n",
      "         1.1546e-14, 3.7748e-15, 4.4409e-15, 0.0000e+00, 2.1649e-15, 8.8818e-15,\n",
      "         6.4393e-15, 3.7748e-15, 9.7700e-15, 0.0000e+00, 2.6645e-15, 4.6629e-15,\n",
      "         3.9968e-15, 4.4409e-15, 1.7764e-15, 3.7470e-16, 1.4211e-14, 3.2196e-15,\n",
      "         2.1316e-14, 4.8572e-17, 5.5511e-16, 1.0658e-14, 4.8295e-15, 1.0658e-14,\n",
      "         2.1927e-15, 1.1990e-14, 4.8850e-15, 1.8874e-15, 7.5495e-15, 2.3315e-15,\n",
      "         1.0408e-16, 4.6629e-15, 1.0825e-15, 1.6653e-15, 2.8866e-15, 3.5527e-15,\n",
      "         1.4655e-14, 4.5519e-15, 1.4211e-14, 9.7700e-15, 1.4433e-15, 1.2212e-15,\n",
      "         1.0658e-14, 2.3981e-14, 1.0658e-14, 1.2212e-15, 3.5527e-15, 7.9936e-15,\n",
      "         4.4409e-15, 1.3323e-14, 8.8818e-15, 6.6613e-15, 1.1546e-14, 1.3878e-15,\n",
      "         1.1768e-14, 1.2434e-14, 1.0214e-14, 1.5099e-14, 5.7732e-15, 4.4409e-15,\n",
      "         4.1078e-15, 3.1974e-14, 1.4211e-14, 6.3283e-15, 5.7732e-15, 6.4393e-15,\n",
      "         6.6613e-15, 1.0658e-14, 4.8850e-15, 4.1078e-15, 7.5495e-15, 3.5083e-14,\n",
      "         5.3291e-15, 9.7700e-15, 6.6613e-15, 1.2434e-14, 1.4211e-14, 9.7700e-15,\n",
      "         1.4211e-14, 9.3259e-15, 6.2172e-15, 1.3212e-14, 2.6645e-14, 7.1054e-15,\n",
      "         7.5495e-15, 2.4425e-15, 3.5527e-15, 1.4655e-14, 2.6645e-15, 7.1054e-15,\n",
      "         2.3315e-15, 6.2172e-15, 2.6645e-15, 5.3291e-15, 5.5511e-15, 1.2657e-14,\n",
      "         8.4377e-15, 8.2157e-15, 7.5495e-15, 7.5495e-15, 1.4211e-14, 9.1038e-15,\n",
      "         1.2768e-15, 3.3307e-15, 4.8850e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  18,  19,  20,  21,  22,  23,  25,  27,  29,  30,  31,  32,  33,\n",
      "         34,  35,  36,  37,  38,  40,  41,  42,  43,  44,  45,  46,  47,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  63,  64,  65,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "        181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  18,  19,  20,  21,  22,  23,  25,  27,  29,  30,  31,  32,  33,\n",
      "         34,  35,  36,  37,  38,  40,  41,  42,  43,  44,  45,  46,  47,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  63,  64,  65,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "        181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])  (len = 243)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 148: layer3.13.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 148\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 148\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 148\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 148\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 148\n",
      "Max diff:\n",
      " tensor([2.2737e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.2633e-14, 6.2172e-15, 3.5527e-14, 3.9968e-15, 7.1054e-15, 6.2172e-15,\n",
      "         1.0658e-14, 3.1086e-15, 8.8818e-15, 2.4869e-14, 6.2172e-15, 1.0658e-14,\n",
      "         5.3291e-15, 2.1316e-14, 5.3291e-15, 1.2434e-14, 8.8818e-15, 5.3291e-15,\n",
      "         1.7764e-14, 4.4409e-15, 1.9540e-14, 4.2633e-14, 6.2172e-15, 1.7764e-14,\n",
      "         3.1086e-15, 4.4409e-15, 3.1086e-15, 4.2633e-14, 8.8818e-15, 4.9738e-14,\n",
      "         2.4869e-14, 2.1316e-14, 7.1054e-15, 4.6185e-14, 5.3291e-15, 4.8850e-15,\n",
      "         3.9968e-15, 1.7764e-14, 1.7764e-14, 1.7764e-14, 2.6645e-15, 4.4409e-15,\n",
      "         6.2172e-15, 1.2434e-14, 4.4409e-15, 2.4425e-15, 3.1086e-15, 3.5527e-14,\n",
      "         1.7764e-14, 1.7764e-14, 9.7700e-15, 1.9540e-14, 1.2434e-14, 9.7700e-15,\n",
      "         1.7764e-14, 3.9968e-15, 3.9968e-15, 1.4211e-14, 6.2172e-15, 7.1054e-15,\n",
      "         3.5527e-14, 4.4409e-15, 5.3291e-15, 5.3291e-15, 4.4409e-15, 7.1054e-14,\n",
      "         6.2172e-15, 7.1054e-15, 4.2633e-14, 9.7700e-15, 1.7764e-14, 7.1054e-15,\n",
      "         4.2633e-14, 1.4211e-14, 7.9936e-15, 7.9936e-15, 1.4211e-14, 8.8818e-15,\n",
      "         4.4409e-15, 5.3291e-15, 1.5987e-14, 8.8818e-15, 2.4869e-14, 2.8422e-14,\n",
      "         2.6645e-14, 2.8422e-14, 7.9936e-15, 8.8818e-15, 3.9968e-15, 8.8818e-15,\n",
      "         4.2633e-14, 4.2633e-14, 8.8818e-15, 4.4409e-15, 7.9936e-15, 4.9738e-14,\n",
      "         7.1054e-14, 4.9738e-14, 7.8160e-14, 7.1054e-14, 3.1086e-15, 7.1054e-15,\n",
      "         7.1054e-15, 3.9080e-14, 1.7764e-14, 2.8422e-14, 2.8422e-14, 6.2172e-15,\n",
      "         8.5265e-14, 4.2633e-14, 6.2172e-15, 1.4211e-14, 2.6645e-15, 4.9738e-14,\n",
      "         7.1054e-15, 7.1054e-15, 1.5987e-14, 2.8422e-14, 5.6843e-14, 8.8818e-15,\n",
      "         4.2633e-14, 1.4211e-14, 5.3291e-15, 8.8818e-15, 4.2633e-14, 3.5527e-15,\n",
      "         8.8818e-15, 7.1054e-14, 4.2633e-14, 1.5987e-14, 4.9738e-14, 4.9738e-14,\n",
      "         1.2434e-14, 1.2434e-14, 7.9936e-15, 1.7764e-14, 5.6843e-14, 1.2079e-13,\n",
      "         1.7764e-14, 5.6843e-14, 3.5527e-14, 7.9936e-15, 2.1316e-14, 8.8818e-15,\n",
      "         3.5527e-14, 1.5987e-14, 1.9540e-14, 2.8422e-14, 2.8422e-14, 8.5265e-14,\n",
      "         5.1514e-14, 3.9080e-14, 1.4211e-14, 1.7764e-14, 1.7764e-14, 1.7764e-14,\n",
      "         7.9936e-15, 3.1974e-14, 2.4869e-14, 1.7764e-14, 8.5265e-14, 1.5987e-14,\n",
      "         2.4869e-14, 7.1054e-14, 5.6843e-14, 2.1316e-14, 4.9738e-14, 3.5527e-14,\n",
      "         4.2633e-14, 6.3949e-14, 4.2633e-14, 3.5527e-14, 3.5527e-14, 4.2633e-14,\n",
      "         1.5987e-14, 7.9936e-15, 1.0658e-14, 5.6843e-14, 4.4409e-15, 3.9080e-14,\n",
      "         3.1974e-14, 4.9738e-14, 1.0658e-14, 5.6843e-14, 7.1054e-14, 6.2172e-15,\n",
      "         1.4211e-14, 2.4869e-14, 2.4869e-14, 1.7764e-14, 2.4869e-14, 1.2434e-14,\n",
      "         1.1369e-13, 8.5265e-14, 1.2790e-13, 4.2633e-14, 4.6185e-14, 4.6185e-14,\n",
      "         7.1054e-14, 6.3949e-14, 8.5265e-14, 1.5632e-13, 7.8160e-14, 1.1369e-13,\n",
      "         7.1054e-14, 8.5265e-14, 7.1054e-14, 1.0658e-13, 4.9738e-14, 2.4869e-14,\n",
      "         1.1369e-13, 5.6843e-14, 7.1054e-14, 4.2633e-14, 2.2737e-13, 6.3949e-14,\n",
      "         1.1369e-13, 9.9476e-14, 6.3949e-14, 3.1974e-14, 7.8160e-14, 4.9738e-14,\n",
      "         1.2790e-13, 7.1054e-14, 7.4607e-14, 1.2790e-13, 1.1369e-13, 4.9738e-14,\n",
      "         1.7053e-13, 9.9476e-14, 1.1369e-13, 4.9738e-14, 4.9738e-14, 8.5265e-14,\n",
      "         4.2633e-14, 1.2790e-13, 7.1054e-14, 1.1369e-13, 1.1369e-13, 7.1054e-14,\n",
      "         7.1054e-14, 7.1054e-14, 5.6843e-14, 1.1369e-13, 1.4211e-13, 9.9476e-14,\n",
      "         9.9476e-14, 7.8160e-14, 5.6843e-14, 4.2633e-14, 1.4211e-13, 8.5265e-14,\n",
      "         1.1369e-13, 4.9738e-14, 4.9738e-14, 3.1974e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 149: layer3.13.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 149\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 149\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 149\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 149\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 149\n",
      "Max diff:\n",
      " tensor([4.7962e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.2172e-15, 1.3323e-15, 6.2172e-15, 8.8818e-16, 1.9984e-15, 8.8818e-16,\n",
      "         1.7764e-15, 8.8818e-16, 1.5543e-15, 5.3291e-15, 1.1102e-15, 1.7764e-15,\n",
      "         8.8818e-16, 3.5527e-15, 1.3323e-15, 2.2204e-15, 1.9984e-15, 9.9920e-16,\n",
      "         3.5527e-15, 6.6613e-16, 3.5527e-15, 4.4409e-15, 9.9920e-16, 3.1086e-15,\n",
      "         7.7716e-16, 1.2212e-15, 6.1062e-16, 5.3291e-15, 1.7764e-15, 7.9936e-15,\n",
      "         4.4409e-15, 5.3291e-15, 1.2212e-15, 6.2172e-15, 1.1102e-15, 9.4369e-16,\n",
      "         9.9920e-16, 3.5527e-15, 3.1086e-15, 3.5527e-15, 7.7716e-16, 7.7716e-16,\n",
      "         9.9920e-16, 3.1086e-15, 8.8818e-16, 5.5511e-16, 7.7716e-16, 4.4409e-15,\n",
      "         3.9968e-15, 3.9968e-15, 2.2204e-15, 3.1086e-15, 2.6645e-15, 1.8874e-15,\n",
      "         3.1086e-15, 8.8818e-16, 6.6613e-16, 2.6645e-15, 1.3323e-15, 1.5543e-15,\n",
      "         6.2172e-15, 9.9920e-16, 1.1102e-15, 1.1102e-15, 1.1102e-15, 1.0658e-14,\n",
      "         1.3323e-15, 1.5543e-15, 7.1054e-15, 1.4433e-15, 3.9968e-15, 1.5543e-15,\n",
      "         6.2172e-15, 2.6645e-15, 1.2212e-15, 1.7764e-15, 2.6645e-15, 1.9984e-15,\n",
      "         7.7716e-16, 1.2212e-15, 2.6645e-15, 1.5543e-15, 5.3291e-15, 5.3291e-15,\n",
      "         4.4409e-15, 6.2172e-15, 1.7764e-15, 1.7764e-15, 8.8818e-16, 1.7764e-15,\n",
      "         1.2434e-14, 8.8818e-15, 1.4433e-15, 1.3323e-15, 1.9984e-15, 1.4211e-14,\n",
      "         1.0658e-14, 8.8818e-15, 1.7764e-14, 8.8818e-15, 8.8818e-16, 1.5543e-15,\n",
      "         1.7764e-15, 9.7700e-15, 3.1086e-15, 4.8850e-15, 7.1054e-15, 1.7764e-15,\n",
      "         1.2434e-14, 7.9936e-15, 1.3323e-15, 3.1086e-15, 6.6613e-16, 1.7764e-14,\n",
      "         1.7764e-15, 1.3323e-15, 3.1086e-15, 7.1054e-15, 8.8818e-15, 1.7764e-15,\n",
      "         8.8818e-15, 2.4425e-15, 1.3323e-15, 2.2204e-15, 4.8850e-15, 9.9920e-16,\n",
      "         2.2204e-15, 2.1316e-14, 8.8818e-15, 3.5527e-15, 8.8818e-15, 3.5527e-15,\n",
      "         3.1086e-15, 2.6645e-15, 1.5543e-15, 3.5527e-15, 1.0658e-14, 3.5527e-14,\n",
      "         3.3307e-15, 8.8818e-15, 7.9936e-15, 1.7764e-15, 4.4409e-15, 1.7764e-15,\n",
      "         7.1054e-15, 2.8866e-15, 3.9968e-15, 7.9936e-15, 3.5527e-15, 1.4211e-14,\n",
      "         1.1102e-14, 8.8818e-15, 3.5527e-15, 3.5527e-15, 3.5527e-15, 3.1086e-15,\n",
      "         1.7764e-15, 7.1054e-15, 5.3291e-15, 3.5527e-15, 2.1316e-14, 2.6645e-15,\n",
      "         3.9968e-15, 1.7764e-14, 1.0658e-14, 4.4409e-15, 9.7700e-15, 7.9936e-15,\n",
      "         7.1054e-15, 1.9540e-14, 8.8818e-15, 6.2172e-15, 3.5527e-15, 8.8818e-15,\n",
      "         2.6645e-15, 1.7764e-15, 2.2204e-15, 9.7700e-15, 1.2212e-15, 4.4409e-15,\n",
      "         6.2172e-15, 8.8818e-15, 1.9984e-15, 1.0658e-14, 1.7764e-14, 8.8818e-16,\n",
      "         2.6645e-15, 5.3291e-15, 4.4409e-15, 3.1086e-15, 4.4409e-15, 2.8866e-15,\n",
      "         2.1316e-14, 1.4211e-14, 1.9540e-14, 1.0658e-14, 9.7700e-15, 8.8818e-15,\n",
      "         1.4211e-14, 1.5987e-14, 1.2434e-14, 2.4869e-14, 1.8652e-14, 1.9540e-14,\n",
      "         1.7764e-14, 2.1316e-14, 1.5987e-14, 2.4869e-14, 7.9936e-15, 3.9968e-15,\n",
      "         2.3093e-14, 1.2434e-14, 1.5987e-14, 1.0658e-14, 4.7962e-14, 1.5987e-14,\n",
      "         2.4869e-14, 2.1316e-14, 1.2434e-14, 6.2172e-15, 2.8422e-14, 1.0658e-14,\n",
      "         2.6645e-14, 1.5987e-14, 1.5099e-14, 2.1316e-14, 1.5987e-14, 8.8818e-15,\n",
      "         4.2633e-14, 1.7764e-14, 2.6645e-14, 7.9936e-15, 1.1546e-14, 1.0658e-14,\n",
      "         1.0658e-14, 2.8422e-14, 1.4211e-14, 3.0198e-14, 1.9540e-14, 1.3323e-14,\n",
      "         1.1546e-14, 1.9540e-14, 1.4211e-14, 2.4869e-14, 3.1974e-14, 1.7764e-14,\n",
      "         3.9080e-14, 2.1316e-14, 1.2434e-14, 1.0658e-14, 2.8422e-14, 1.2434e-14,\n",
      "         2.4869e-14, 1.0658e-14, 9.7700e-15, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 150: layer3.13.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 150\n",
      "Max diff:\n",
      " tensor([1.5099e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2268e-14,\n",
      "         6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2434e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         5.3291e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2172e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.8850e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9952e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.8874e-15, 0.0000e+00, 8.9512e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7732e-15, 0.0000e+00,\n",
      "         5.7732e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4401e-15, 4.8850e-15,\n",
      "         0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5099e-14, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 6.2172e-15, 0.0000e+00, 0.0000e+00, 3.5527e-15,\n",
      "         0.0000e+00, 2.1094e-15, 3.9968e-15, 0.0000e+00, 0.0000e+00, 5.8842e-15,\n",
      "         1.1546e-14, 0.0000e+00, 0.0000e+00, 1.6653e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.7764e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.2760e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 65, 113, 114, 137, 147, 150, 177, 184, 192, 197, 200, 202, 208, 210,\n",
      "        214, 215, 218, 220, 224, 227, 230, 233, 235, 236, 239, 240, 243, 246,\n",
      "        254])\n",
      "\n",
      "failing Cout = tensor([ 65, 113, 114, 137, 147, 150, 177, 184, 192, 197, 200, 202, 208, 210,\n",
      "        214, 215, 218, 220, 224, 227, 230, 233, 235, 236, 239, 240, 243, 246,\n",
      "        254])  (len = 29)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 151: layer3.13.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 151\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 151\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 16, 17, 18, 20,\n",
      "        22, 23, 24, 25, 27, 28, 30, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 45,\n",
      "        46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 59, 61]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 145,\n",
      "        146, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163,\n",
      "        164, 165, 168, 170, 171, 173, 174, 175, 176, 177, 178, 180, 182, 184,\n",
      "        185, 186, 187, 188, 189, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 195, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209,\n",
      "        210, 212, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 151\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  2,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22,\n",
      "        23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41,\n",
      "        42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  76,  77,  78,\n",
      "         79,  80,  81,  83,  84,  85,  86,  87,  88,  90,  91,  92,  95,  96,\n",
      "         97,  98,  99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 151\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 151\n",
      "Max diff:\n",
      " tensor([1.5987e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.1054e-15, 1.6098e-15, 5.7732e-15, 4.4409e-15, 1.7764e-15, 5.3291e-15,\n",
      "         5.3291e-15, 4.4409e-15, 2.2204e-15, 2.8866e-15, 4.1633e-15, 8.4377e-15,\n",
      "         4.8850e-15, 3.5527e-15, 4.8850e-15, 1.7208e-15, 8.8818e-15, 3.1503e-15,\n",
      "         2.6645e-15, 5.9952e-15, 6.2172e-15, 2.3835e-15, 8.8818e-15, 4.4409e-15,\n",
      "         1.0214e-14, 7.9936e-15, 2.2204e-15, 1.2434e-14, 1.4433e-15, 4.4409e-15,\n",
      "         2.4425e-15, 4.3299e-15, 3.9968e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15,\n",
      "         1.4211e-14, 6.2172e-15, 5.3291e-15, 7.9936e-15, 1.3323e-15, 2.8866e-15,\n",
      "         6.6613e-15, 1.1546e-14, 2.2204e-15, 7.9936e-15, 2.6645e-15, 1.7764e-15,\n",
      "         2.5258e-15, 4.9682e-15, 4.4409e-15, 2.5535e-15, 2.9976e-15, 4.6629e-15,\n",
      "         4.8850e-15, 3.1086e-15, 1.7764e-15, 7.1054e-15, 4.4409e-15, 1.5821e-15,\n",
      "         2.5535e-15, 5.3291e-15, 1.0658e-14, 6.2172e-15, 7.1054e-15, 9.7700e-15,\n",
      "         3.5527e-15, 3.7192e-15, 3.1086e-15, 5.5511e-15, 8.8818e-15, 3.1086e-15,\n",
      "         4.4409e-15, 6.9944e-15, 4.7184e-15, 3.1086e-15, 4.8850e-15, 4.5519e-15,\n",
      "         3.6637e-15, 5.1070e-15, 3.5527e-15, 5.3291e-15, 7.1054e-15, 6.6613e-15,\n",
      "         4.4409e-15, 1.3323e-14, 7.1054e-15, 3.2196e-15, 1.0658e-14, 7.9936e-15,\n",
      "         6.4393e-15, 8.8818e-15, 8.4377e-15, 4.9127e-15, 7.1054e-15, 1.4211e-14,\n",
      "         3.5527e-15, 8.8818e-15, 5.1070e-15, 1.2434e-14, 5.3291e-15, 4.6907e-15,\n",
      "         9.7700e-15, 1.0658e-14, 3.3307e-15, 3.9968e-15, 8.8818e-15, 5.3291e-15,\n",
      "         7.1054e-15, 3.9968e-15, 4.3299e-15, 2.7894e-15, 3.7470e-15, 3.9968e-15,\n",
      "         3.3307e-15, 6.2172e-15, 5.5511e-15, 6.4393e-15, 3.9968e-15, 5.2180e-15,\n",
      "         6.6613e-15, 4.4409e-15, 6.2172e-15, 7.1054e-15, 4.8850e-15, 5.7732e-15,\n",
      "         1.0214e-14, 9.3259e-15, 7.9936e-15, 7.1054e-15, 5.3291e-15, 1.0103e-14,\n",
      "         6.6613e-15, 1.1990e-14, 4.8850e-15, 5.9952e-15, 6.6613e-15, 7.3275e-15,\n",
      "         8.8818e-15, 7.5495e-15, 6.2172e-15, 3.5527e-15, 4.8850e-15, 1.0658e-14,\n",
      "         3.5527e-15, 8.8818e-15, 6.2172e-15, 7.1054e-15, 1.2434e-14, 7.1054e-15,\n",
      "         7.5495e-15, 3.5527e-15, 7.1054e-15, 5.3291e-15, 3.9968e-15, 8.8818e-15,\n",
      "         6.2172e-15, 4.9960e-15, 6.2172e-15, 7.8826e-15, 9.7700e-15, 7.1054e-15,\n",
      "         8.1879e-15, 8.2157e-15, 7.9936e-15, 3.7748e-15, 4.4409e-15, 1.0214e-14,\n",
      "         7.1054e-15, 7.1054e-15, 7.9936e-15, 5.3291e-15, 4.3854e-15, 1.1546e-14,\n",
      "         5.7732e-15, 7.1054e-15, 4.6629e-15, 4.8850e-15, 6.5711e-15, 4.4409e-15,\n",
      "         9.7700e-15, 1.2434e-14, 1.1546e-14, 1.2434e-14, 3.2196e-15, 8.4377e-15,\n",
      "         6.6613e-15, 9.7700e-15, 8.8818e-15, 8.8818e-15, 5.3291e-15, 9.3467e-15,\n",
      "         5.7732e-15, 5.9952e-15, 7.1054e-15, 1.0658e-14, 1.1546e-14, 9.9920e-15,\n",
      "         6.2172e-15, 8.6042e-15, 7.9936e-15, 9.7700e-15, 5.5511e-15, 1.1546e-14,\n",
      "         7.9936e-15, 9.3259e-15, 1.0658e-14, 8.8818e-15, 1.3656e-14, 6.2172e-15,\n",
      "         7.4246e-15, 1.0658e-14, 7.9936e-15, 8.8818e-15, 7.9936e-15, 5.6621e-15,\n",
      "         8.8818e-15, 9.7700e-15, 1.4211e-14, 6.2172e-15, 6.2172e-15, 6.2172e-15,\n",
      "         6.2172e-15, 7.9936e-15, 9.7700e-15, 8.6597e-15, 6.6613e-15, 1.3323e-14,\n",
      "         7.1054e-15, 1.0658e-14, 5.3291e-15, 8.8818e-15, 1.5987e-14, 8.8818e-15,\n",
      "         6.5781e-15, 6.6613e-15, 7.9936e-15, 1.0658e-14, 1.4877e-14, 5.7732e-15,\n",
      "         1.0658e-14, 8.8818e-15, 5.7732e-15, 5.0515e-15, 7.5495e-15, 7.1054e-15,\n",
      "         6.2172e-15, 7.1054e-15, 1.0658e-14, 6.2172e-15, 6.2172e-15, 7.1054e-15,\n",
      "         7.9936e-15, 1.1324e-14, 5.7732e-15, 7.9936e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 152: layer3.13.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 152\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 152\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 152\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 152\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 152\n",
      "Max diff:\n",
      " tensor([7.9936e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3323e-15, 1.1102e-16, 2.4425e-15, 5.5511e-16, 4.4409e-16, 6.6613e-16,\n",
      "         2.6645e-15, 1.7764e-15, 4.9960e-16, 1.5543e-15, 1.1102e-15, 3.9968e-15,\n",
      "         2.4425e-15, 1.3323e-15, 1.1657e-15, 3.8858e-16, 2.2204e-15, 1.2212e-15,\n",
      "         8.8818e-16, 1.1102e-15, 4.4409e-15, 7.7716e-16, 3.1086e-15, 1.7764e-15,\n",
      "         4.6629e-15, 3.5527e-15, 5.6899e-16, 3.7748e-15, 6.3838e-16, 6.6613e-16,\n",
      "         7.7716e-16, 2.3870e-15, 9.9920e-16, 2.8866e-15, 1.7764e-15, 8.8818e-16,\n",
      "         7.1054e-15, 7.7716e-16, 1.9984e-15, 3.3307e-15, 8.3267e-17, 9.6451e-16,\n",
      "         7.7716e-16, 3.3307e-15, 3.1919e-16, 3.9968e-15, 8.3267e-17, 4.4409e-16,\n",
      "         2.2204e-16, 2.4702e-15, 1.6653e-16, 7.4940e-16, 6.1062e-16, 7.7716e-16,\n",
      "         2.2204e-15, 1.5543e-15, 6.6613e-16, 3.5527e-15, 8.8818e-16, 4.1633e-16,\n",
      "         4.8572e-17, 1.7764e-15, 5.7732e-15, 2.0817e-16, 1.3323e-15, 2.4425e-15,\n",
      "         3.8858e-16, 2.9143e-16, 3.8858e-16, 6.9736e-16, 2.2204e-15, 4.4409e-16,\n",
      "         9.9920e-16, 7.6328e-16, 1.8527e-15, 7.7716e-16, 1.2212e-15, 1.6168e-15,\n",
      "         1.3323e-15, 1.5543e-15, 1.6653e-16, 6.6613e-16, 2.2204e-15, 1.9984e-15,\n",
      "         7.7716e-16, 2.3419e-17, 1.1102e-15, 8.8818e-16, 6.6613e-16, 3.1086e-15,\n",
      "         2.3315e-15, 2.6645e-15, 2.2204e-15, 1.1935e-15, 8.8818e-16, 2.4425e-15,\n",
      "         1.6653e-16, 2.4425e-15, 2.3315e-15, 3.9968e-15, 1.7764e-15, 7.4246e-16,\n",
      "         1.3323e-15, 2.2204e-15, 6.3838e-16, 7.7022e-16, 3.5527e-15, 1.3878e-15,\n",
      "         2.2204e-15, 8.3267e-16, 4.5103e-16, 5.9674e-16, 2.5088e-16, 6.1062e-16,\n",
      "         1.6653e-15, 1.3323e-15, 1.3323e-15, 8.8818e-16, 6.6613e-16, 2.0019e-15,\n",
      "         1.2212e-15, 1.1102e-15, 3.6082e-16, 2.2204e-15, 3.8858e-16, 1.7764e-15,\n",
      "         1.7208e-15, 3.1086e-15, 1.3323e-15, 2.6645e-15, 1.7764e-15, 4.1633e-15,\n",
      "         1.2768e-15, 5.5511e-15, 1.0547e-15, 1.3045e-15, 2.1094e-15, 1.3323e-15,\n",
      "         2.6645e-15, 1.3878e-15, 1.1102e-15, 1.2212e-15, 2.7756e-15, 7.1054e-15,\n",
      "         7.7716e-16, 2.6645e-15, 9.9920e-16, 2.1094e-15, 2.0817e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.5543e-15, 2.8866e-15, 1.1102e-15, 1.0547e-15, 3.5527e-15,\n",
      "         2.8866e-15, 1.3878e-15, 7.7716e-16, 1.3323e-15, 3.9968e-15, 1.9984e-15,\n",
      "         8.0144e-16, 4.6629e-15, 3.1086e-15, 8.1879e-16, 1.4988e-15, 2.5535e-15,\n",
      "         2.2204e-15, 4.4409e-15, 3.5527e-15, 1.7764e-15, 1.5543e-15, 1.8874e-15,\n",
      "         3.1086e-15, 2.4425e-15, 1.6653e-15, 9.9920e-16, 8.3961e-16, 1.7764e-15,\n",
      "         3.3307e-15, 7.9936e-15, 3.9968e-15, 4.4409e-15, 4.9960e-16, 2.8866e-15,\n",
      "         2.8866e-15, 1.9984e-15, 2.8866e-15, 1.7764e-15, 1.3323e-15, 2.5535e-15,\n",
      "         2.1094e-15, 1.6653e-15, 2.8866e-15, 1.2212e-15, 2.8866e-15, 2.9976e-15,\n",
      "         1.5543e-15, 2.9143e-15, 3.1086e-15, 2.8866e-15, 6.6613e-16, 2.4425e-15,\n",
      "         2.6645e-15, 4.4409e-15, 2.6645e-15, 2.2204e-15, 3.0392e-15, 1.7764e-15,\n",
      "         2.5813e-15, 3.1086e-15, 2.2204e-15, 1.5543e-15, 2.2204e-15, 1.7902e-15,\n",
      "         3.1086e-15, 2.8866e-15, 3.7748e-15, 1.7764e-15, 1.5543e-15, 2.6645e-15,\n",
      "         2.6645e-15, 2.2204e-15, 3.9968e-15, 2.6645e-15, 2.5535e-15, 3.7748e-15,\n",
      "         1.9984e-15, 2.2204e-15, 1.1102e-15, 2.4425e-15, 4.4409e-15, 2.6645e-15,\n",
      "         1.3219e-15, 3.6776e-16, 1.6653e-15, 2.6645e-15, 3.1641e-15, 1.6653e-15,\n",
      "         3.1086e-15, 1.9984e-15, 2.2204e-15, 1.0547e-15, 3.3307e-15, 2.2204e-15,\n",
      "         1.3323e-15, 1.7764e-15, 3.1086e-15, 2.4425e-15, 2.2204e-15, 1.9984e-15,\n",
      "         2.6645e-15, 2.9976e-15, 1.6653e-15, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 153: layer3.13.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 153\n",
      "Max diff:\n",
      " tensor([3.3751e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.4425e-15, 5.9952e-15, 2.4425e-15, 3.9968e-15, 1.7764e-15, 6.6613e-16,\n",
      "         2.6645e-15, 5.7732e-15, 4.9960e-16, 2.4425e-15, 1.1102e-15, 3.9968e-15,\n",
      "         2.4425e-15, 5.7732e-15, 1.9984e-15, 6.1062e-16, 3.5527e-15, 1.2212e-15,\n",
      "         1.2212e-15, 1.1102e-15, 4.4409e-15, 7.7716e-16, 3.1086e-15, 3.3584e-15,\n",
      "         4.6629e-15, 3.5527e-15, 5.6899e-16, 4.2188e-15, 6.3838e-16, 2.6645e-15,\n",
      "         1.6098e-15, 2.3870e-15, 3.1086e-15, 5.7732e-15, 1.7764e-15, 8.8818e-16,\n",
      "         7.1054e-15, 2.8866e-15, 1.9984e-15, 3.3307e-15, 7.1054e-15, 1.7208e-15,\n",
      "         1.6653e-15, 3.1086e-15, 5.5511e-15, 3.9968e-15, 2.1094e-15, 1.1102e-15,\n",
      "         2.2204e-16, 2.4702e-15, 4.4409e-15, 7.4940e-16, 2.9421e-15, 3.1086e-15,\n",
      "         2.2204e-15, 2.4425e-15, 1.1102e-15, 3.5527e-15, 2.3315e-15, 1.9013e-15,\n",
      "         3.3307e-15, 2.1094e-15, 5.7732e-15, 7.7716e-16, 5.7732e-15, 2.3315e-15,\n",
      "         6.5781e-15, 7.1054e-15, 2.8866e-15, 5.0515e-15, 1.1546e-14, 1.9984e-15,\n",
      "         3.7748e-15, 5.2736e-15, 3.3307e-15, 6.2172e-15, 7.9936e-15, 8.2157e-15,\n",
      "         2.2482e-15, 1.5543e-15, 4.6629e-15, 7.9936e-15, 2.2204e-15, 1.1546e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7716e-15, 1.5543e-15, 8.4377e-15, 4.2188e-15,\n",
      "         3.6637e-15, 3.6637e-15, 5.9952e-15, 1.1935e-15, 2.4425e-15, 2.9421e-15,\n",
      "         3.4417e-15, 2.4425e-15, 2.3315e-15, 1.0547e-14, 1.9984e-15, 1.4710e-15,\n",
      "         5.3291e-15, 2.2204e-15, 1.1102e-15, 1.0658e-14, 4.4409e-15, 2.1927e-15,\n",
      "         3.7748e-15, 2.8866e-15, 5.3291e-15, 6.2172e-15, 1.3323e-15, 3.9968e-15,\n",
      "         3.1086e-15, 7.5495e-15, 5.9952e-15, 9.4369e-16, 7.1054e-15, 5.3291e-15,\n",
      "         1.4433e-15, 1.6931e-15, 4.4409e-15, 4.4409e-15, 2.6645e-15, 4.4409e-15,\n",
      "         1.7764e-15, 2.5535e-15, 1.3323e-15, 6.2172e-15, 6.2172e-15, 7.2164e-15,\n",
      "         4.4409e-15, 5.5511e-15, 1.2434e-14, 4.8850e-15, 2.1094e-15, 1.3808e-15,\n",
      "         9.7700e-15, 2.8866e-15, 4.8850e-15, 2.4980e-15, 2.7756e-15, 1.0658e-14,\n",
      "         7.9936e-15, 2.6645e-15, 1.2212e-15, 4.3299e-15, 1.7764e-14, 3.5527e-15,\n",
      "         1.1546e-14, 3.5527e-15, 4.8850e-15, 1.1102e-15, 1.4381e-15, 6.6613e-15,\n",
      "         6.2172e-15, 5.1625e-15, 9.7700e-15, 1.3323e-15, 3.9968e-15, 5.9952e-15,\n",
      "         3.9968e-15, 4.6629e-15, 3.1086e-15, 1.1657e-15, 1.4599e-14, 4.2188e-15,\n",
      "         2.1316e-14, 4.4409e-15, 3.5527e-15, 1.0658e-14, 4.9405e-15, 1.0436e-14,\n",
      "         3.1086e-15, 1.2879e-14, 5.3291e-15, 2.1094e-15, 7.9936e-15, 2.7756e-15,\n",
      "         3.3307e-15, 7.9936e-15, 3.9968e-15, 4.4409e-15, 3.3307e-15, 4.6629e-15,\n",
      "         1.4877e-14, 4.7184e-15, 1.4211e-14, 1.0658e-14, 1.3323e-15, 2.5535e-15,\n",
      "         1.0658e-14, 2.4869e-14, 1.2434e-14, 1.2768e-15, 3.3307e-15, 8.4377e-15,\n",
      "         4.8850e-15, 1.5099e-14, 8.8818e-15, 6.2728e-15, 1.1768e-14, 2.8866e-15,\n",
      "         1.2212e-14, 1.4211e-14, 1.1102e-14, 1.6431e-14, 5.3291e-15, 4.5519e-15,\n",
      "         3.0809e-15, 3.1086e-14, 1.7764e-14, 6.6613e-15, 6.2172e-15, 6.6613e-15,\n",
      "         7.9936e-15, 1.0436e-14, 5.6621e-15, 4.1078e-15, 7.9936e-15, 3.3751e-14,\n",
      "         6.2172e-15, 8.8818e-15, 5.8842e-15, 1.2434e-14, 1.5987e-14, 1.2434e-14,\n",
      "         1.5099e-14, 9.7700e-15, 6.2172e-15, 1.4100e-14, 2.6645e-14, 9.1038e-15,\n",
      "         8.8818e-15, 2.4425e-15, 4.4409e-15, 1.6875e-14, 3.4417e-15, 7.1054e-15,\n",
      "         3.9968e-15, 7.1054e-15, 4.4409e-15, 5.9952e-15, 6.6613e-15, 1.2434e-14,\n",
      "         8.4377e-15, 8.6597e-15, 7.1054e-15, 9.1038e-15, 1.4211e-14, 8.6597e-15,\n",
      "         2.6645e-15, 3.5527e-15, 5.7732e-15, 1.1324e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 154: layer3.13.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 154\n",
      "Max diff:\n",
      " tensor([3.1086e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 4.3299e-15, 1.3878e-15, 3.9968e-15, 1.1380e-15, 0.0000e+00,\n",
      "         1.5543e-15, 5.7732e-15, 4.9960e-16, 1.2768e-15, 8.8818e-16, 9.9920e-16,\n",
      "         1.3323e-15, 5.7732e-15, 1.9984e-15, 6.1062e-16, 3.5527e-15, 0.0000e+00,\n",
      "         7.2164e-16, 5.8287e-16, 5.5511e-16, 4.9960e-16, 0.0000e+00, 3.3584e-15,\n",
      "         3.0392e-15, 0.0000e+00, 5.6899e-16, 1.9984e-15, 6.3838e-16, 2.6645e-15,\n",
      "         1.6098e-15, 2.2204e-15, 3.1086e-15, 5.5511e-15, 9.9920e-16, 2.0817e-16,\n",
      "         1.1380e-15, 3.3307e-16, 1.9984e-15, 2.8311e-15, 7.1054e-15, 1.6653e-15,\n",
      "         1.6653e-15, 3.1086e-15, 5.5511e-15, 3.8858e-16, 2.1094e-15, 1.1102e-15,\n",
      "         8.3267e-17, 8.3267e-16, 4.4409e-15, 7.4940e-16, 2.6645e-15, 3.1086e-15,\n",
      "         4.9960e-16, 1.9984e-15, 7.7716e-16, 0.0000e+00, 2.3315e-15, 1.9013e-15,\n",
      "         3.3307e-15, 2.1094e-15, 5.7732e-15, 7.7716e-16, 5.7732e-15, 1.7902e-15,\n",
      "         6.5781e-15, 7.1054e-15, 1.6653e-15, 5.0515e-15, 1.1546e-14, 1.9984e-15,\n",
      "         3.7748e-15, 5.2736e-15, 3.3307e-15, 6.2172e-15, 7.9936e-15, 8.2157e-15,\n",
      "         1.7764e-15, 1.2212e-15, 4.6629e-15, 7.9936e-15, 3.3307e-16, 1.1546e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7716e-15, 7.4940e-16, 8.4377e-15, 2.0262e-15,\n",
      "         2.2204e-15, 3.6637e-15, 1.3878e-15, 5.5511e-17, 2.4425e-15, 2.2760e-15,\n",
      "         3.4417e-15, 0.0000e+00, 2.3315e-15, 7.1054e-15, 1.9984e-15, 1.4710e-15,\n",
      "         5.3291e-15, 1.1102e-15, 1.1102e-15, 1.0658e-14, 2.2204e-16, 1.3323e-15,\n",
      "         3.7748e-15, 2.4425e-15, 5.3291e-15, 6.2172e-15, 1.3323e-15, 3.9968e-15,\n",
      "         2.3315e-15, 7.5495e-15, 5.9952e-15, 9.4369e-16, 5.5511e-15, 5.3291e-15,\n",
      "         1.1380e-15, 1.6931e-15, 4.4409e-15, 4.4409e-15, 2.6645e-15, 4.4409e-15,\n",
      "         1.7764e-15, 2.5535e-15, 6.2103e-16, 6.2172e-15, 1.6653e-15, 4.1633e-15,\n",
      "         4.4409e-15, 5.5511e-15, 1.2434e-14, 4.8850e-15, 1.9984e-15, 4.9960e-16,\n",
      "         9.7700e-15, 2.8866e-15, 4.8850e-15, 2.4980e-15, 2.7756e-15, 1.0658e-14,\n",
      "         7.9936e-15, 0.0000e+00, 1.2212e-15, 4.3299e-15, 1.7764e-14, 0.0000e+00,\n",
      "         1.1546e-14, 3.5527e-15, 4.8850e-15, 0.0000e+00, 1.4381e-15, 6.6613e-15,\n",
      "         6.2172e-15, 5.1625e-15, 9.7700e-15, 8.2920e-16, 2.3315e-15, 5.9952e-15,\n",
      "         3.9968e-15, 6.3838e-16, 2.6645e-15, 1.1657e-15, 1.4599e-14, 4.2188e-15,\n",
      "         2.1316e-14, 9.4369e-16, 1.3878e-15, 1.0658e-14, 3.5527e-15, 1.0436e-14,\n",
      "         2.2204e-15, 1.2879e-14, 5.3291e-15, 4.7184e-16, 7.9936e-15, 2.7756e-15,\n",
      "         3.3307e-15, 2.6645e-15, 1.0825e-15, 1.2212e-15, 3.3307e-15, 4.6629e-15,\n",
      "         1.4877e-14, 4.7184e-15, 1.4211e-14, 1.0658e-14, 4.3715e-16, 2.2204e-15,\n",
      "         1.0658e-14, 2.4869e-14, 1.2434e-14, 1.2768e-15, 1.9429e-15, 8.4377e-15,\n",
      "         4.8850e-15, 1.5099e-14, 8.8818e-15, 6.2728e-15, 1.1768e-14, 2.8866e-15,\n",
      "         8.8818e-15, 1.4211e-14, 2.6645e-15, 1.6431e-14, 5.3291e-15, 3.5527e-15,\n",
      "         3.0809e-15, 3.1086e-14, 1.7764e-14, 6.6613e-15, 6.2172e-15, 6.6613e-15,\n",
      "         7.9936e-15, 1.0436e-14, 5.6621e-15, 4.1078e-15, 7.9936e-15, 1.9540e-14,\n",
      "         6.2172e-15, 8.8818e-15, 5.8842e-15, 1.2434e-14, 1.5987e-14, 1.2434e-14,\n",
      "         1.5099e-14, 9.7700e-15, 6.2172e-15, 1.4100e-14, 2.6645e-14, 9.1038e-15,\n",
      "         8.8818e-15, 2.4425e-15, 4.4409e-15, 1.4211e-14, 3.4417e-15, 7.1054e-15,\n",
      "         5.2736e-16, 7.1054e-15, 4.4409e-15, 5.9952e-15, 6.6613e-15, 1.2434e-14,\n",
      "         8.4377e-15, 8.6597e-15, 7.1054e-15, 9.1038e-15, 1.4211e-14, 7.9936e-15,\n",
      "         2.6645e-15, 3.5527e-15, 5.7732e-15, 1.1324e-14]], dtype=torch.float64)\n",
      " tensor([  1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  18,  19,  20,  21,  23,  24,  26,  27,  28,  29,  30,  31,  32,\n",
      "         33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
      "         47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,  61,\n",
      "         62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
      "         76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,\n",
      "         90,  91,  92,  93,  94,  95,  96,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147,\n",
      "        148, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
      "        164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
      "        178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
      "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  18,  19,  20,  21,  23,  24,  26,  27,  28,  29,  30,  31,  32,\n",
      "         33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
      "         47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,  61,\n",
      "         62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
      "         76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,\n",
      "         90,  91,  92,  93,  94,  95,  96,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147,\n",
      "        148, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
      "        164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
      "        178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
      "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])  (len = 246)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 155: layer3.14.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 155\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 155\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 155\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 155\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 155\n",
      "Max diff:\n",
      " tensor([2.4158e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 9.7700e-15, 1.5987e-14, 2.1316e-14, 7.1054e-15, 3.9968e-15,\n",
      "         4.4409e-15, 1.7764e-14, 3.1086e-15, 3.5527e-14, 6.2172e-15, 1.3323e-14,\n",
      "         5.3291e-15, 2.8422e-14, 4.4409e-15, 3.5527e-15, 9.7700e-15, 4.2633e-14,\n",
      "         7.1054e-15, 7.9936e-15, 2.1316e-14, 2.4869e-14, 8.8818e-15, 4.2633e-14,\n",
      "         1.7764e-14, 3.9080e-14, 3.1086e-15, 4.4409e-15, 1.0658e-14, 6.2172e-15,\n",
      "         1.0658e-14, 5.3291e-15, 7.9936e-15, 6.2172e-15, 5.3291e-15, 8.8818e-15,\n",
      "         4.9738e-14, 1.4211e-14, 1.2434e-14, 6.2172e-15, 6.2172e-15, 4.4409e-15,\n",
      "         3.5527e-14, 6.2172e-15, 5.3291e-15, 8.8818e-15, 4.2633e-14, 7.9936e-15,\n",
      "         6.2172e-15, 6.2172e-15, 7.1054e-15, 8.8818e-15, 6.3949e-14, 1.0658e-14,\n",
      "         6.3949e-14, 5.3291e-15, 2.8422e-14, 4.4409e-15, 4.4409e-15, 4.4409e-15,\n",
      "         8.8818e-15, 7.1054e-15, 6.2172e-15, 1.0658e-14, 2.1316e-14, 1.5987e-14,\n",
      "         1.2434e-14, 7.9936e-15, 8.8818e-15, 1.4211e-14, 1.5987e-14, 1.0658e-14,\n",
      "         1.4211e-14, 4.4409e-15, 3.1974e-14, 1.4211e-14, 2.4869e-14, 2.1316e-14,\n",
      "         1.3323e-14, 1.4211e-14, 8.8818e-15, 7.9936e-15, 2.1316e-14, 1.5987e-14,\n",
      "         1.2434e-14, 4.9738e-14, 1.2434e-14, 7.1054e-15, 4.2633e-14, 3.1974e-14,\n",
      "         2.4869e-14, 6.3949e-14, 4.9738e-14, 1.0658e-14, 3.1974e-14, 7.9936e-15,\n",
      "         8.8818e-15, 4.9738e-14, 1.7764e-14, 2.1316e-14, 1.0658e-14, 1.7764e-14,\n",
      "         8.5265e-14, 3.9080e-14, 1.0658e-14, 4.2633e-14, 4.4409e-15, 1.1546e-14,\n",
      "         6.3949e-14, 6.3949e-14, 8.8818e-15, 1.5987e-14, 8.8818e-15, 8.8818e-15,\n",
      "         6.2172e-15, 1.1546e-14, 7.1054e-14, 7.9936e-15, 3.1974e-14, 7.1054e-14,\n",
      "         4.2633e-14, 5.3291e-15, 3.5527e-14, 5.6843e-14, 4.2633e-14, 6.3949e-14,\n",
      "         3.1974e-14, 7.1054e-14, 4.6185e-14, 5.6843e-14, 1.2434e-14, 2.4869e-14,\n",
      "         7.1054e-14, 8.8818e-15, 1.4211e-14, 7.1054e-15, 8.8818e-15, 7.9936e-15,\n",
      "         6.3949e-14, 1.7764e-14, 1.2434e-14, 3.9080e-14, 3.5527e-14, 1.2790e-13,\n",
      "         3.1974e-14, 1.0658e-14, 4.9738e-14, 2.1316e-14, 7.1054e-14, 1.9540e-14,\n",
      "         1.2434e-14, 2.8422e-14, 4.2633e-14, 2.8422e-14, 2.4869e-14, 1.2434e-14,\n",
      "         7.9936e-15, 4.9738e-14, 3.5527e-14, 1.0658e-14, 2.4869e-14, 4.2633e-14,\n",
      "         3.1974e-14, 1.1369e-13, 3.1974e-14, 4.9738e-14, 4.9738e-14, 8.5265e-14,\n",
      "         5.3291e-15, 3.5527e-14, 7.1054e-14, 1.9540e-14, 8.5265e-14, 7.1054e-14,\n",
      "         5.3291e-15, 2.1316e-14, 2.1316e-14, 6.3949e-14, 1.2434e-14, 3.1974e-14,\n",
      "         7.9936e-15, 6.2172e-15, 1.0658e-14, 4.2633e-14, 1.7764e-14, 2.8422e-14,\n",
      "         2.1316e-14, 1.0658e-14, 8.8818e-15, 5.6843e-14, 9.7700e-15, 3.1974e-14,\n",
      "         7.1054e-14, 1.0658e-13, 1.5632e-13, 1.1369e-13, 5.3291e-14, 7.1054e-14,\n",
      "         1.7053e-13, 7.1054e-14, 9.9476e-14, 8.5265e-14, 9.2371e-14, 1.1369e-13,\n",
      "         9.2371e-14, 8.5265e-14, 8.5265e-14, 8.5265e-14, 1.1369e-13, 2.4158e-13,\n",
      "         1.5632e-13, 9.9476e-14, 8.5265e-14, 9.9476e-14, 1.1369e-13, 8.5265e-14,\n",
      "         9.2371e-14, 1.1369e-13, 1.1369e-13, 8.5265e-14, 8.5265e-14, 1.7053e-13,\n",
      "         5.6843e-14, 5.6843e-14, 7.8160e-14, 1.5632e-13, 3.1974e-14, 1.1369e-13,\n",
      "         1.7053e-13, 5.6843e-14, 8.5265e-14, 7.1054e-14, 6.3949e-14, 3.1974e-14,\n",
      "         9.9476e-14, 1.5632e-13, 9.9476e-14, 1.1369e-13, 4.2633e-14, 6.7502e-14,\n",
      "         4.2633e-14, 5.6843e-14, 8.5265e-14, 1.2790e-13, 1.1369e-13, 1.4211e-13,\n",
      "         1.1369e-13, 1.5632e-13, 9.2371e-14, 8.5265e-14, 4.9738e-14, 7.8160e-14,\n",
      "         1.1369e-13, 7.8160e-14, 9.9476e-14, 3.5527e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 156: layer3.14.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 156\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 156\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 156\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 156\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 156\n",
      "Max diff:\n",
      " tensor([6.3949e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[9.9920e-16, 1.7764e-15, 3.1086e-15, 3.9968e-15, 1.2212e-15, 8.8818e-16,\n",
      "         1.2212e-15, 2.6645e-15, 7.7716e-16, 6.2172e-15, 1.1102e-15, 2.3315e-15,\n",
      "         1.1102e-15, 3.9968e-15, 9.9920e-16, 6.6613e-16, 2.2204e-15, 3.9968e-15,\n",
      "         1.3323e-15, 1.5543e-15, 4.4409e-15, 4.4409e-15, 1.7764e-15, 8.8818e-15,\n",
      "         3.5527e-15, 6.2172e-15, 7.7716e-16, 8.8818e-16, 2.2204e-15, 1.4433e-15,\n",
      "         1.4433e-15, 8.8818e-16, 1.3323e-15, 8.8818e-16, 8.3267e-16, 1.1102e-15,\n",
      "         8.8818e-15, 2.4425e-15, 2.6645e-15, 1.3323e-15, 9.9920e-16, 1.1102e-15,\n",
      "         4.8850e-15, 1.5543e-15, 1.3323e-15, 1.5543e-15, 6.2172e-15, 1.5543e-15,\n",
      "         1.5543e-15, 1.5543e-15, 1.3323e-15, 1.9984e-15, 1.2434e-14, 2.2204e-15,\n",
      "         7.9936e-15, 7.7716e-16, 3.5527e-15, 1.1102e-15, 1.1102e-15, 7.7716e-16,\n",
      "         1.7764e-15, 1.1102e-15, 1.3323e-15, 1.9984e-15, 3.5527e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.5543e-15, 2.2204e-15, 3.9968e-15, 3.1086e-15, 1.7764e-15,\n",
      "         2.6645e-15, 8.8818e-16, 4.8850e-15, 3.1086e-15, 3.1086e-15, 5.3291e-15,\n",
      "         2.2204e-15, 3.5527e-15, 1.3323e-15, 1.9984e-15, 3.1086e-15, 3.1086e-15,\n",
      "         2.6645e-15, 7.9936e-15, 2.4425e-15, 1.9984e-15, 6.2172e-15, 7.9936e-15,\n",
      "         3.1086e-15, 1.2434e-14, 7.1054e-15, 1.9984e-15, 5.3291e-15, 1.5543e-15,\n",
      "         1.5543e-15, 7.9936e-15, 3.3307e-15, 3.9968e-15, 2.6645e-15, 2.6645e-15,\n",
      "         2.1316e-14, 7.1054e-15, 2.2204e-15, 8.8818e-15, 8.8818e-16, 2.4425e-15,\n",
      "         1.9540e-14, 8.8818e-15, 1.7764e-15, 2.6645e-15, 1.5543e-15, 1.7764e-15,\n",
      "         1.1102e-15, 2.6645e-15, 1.2434e-14, 1.3323e-15, 6.2172e-15, 1.4211e-14,\n",
      "         7.9936e-15, 1.3323e-15, 6.2172e-15, 1.2434e-14, 7.9936e-15, 1.2434e-14,\n",
      "         3.5527e-15, 9.7700e-15, 6.2172e-15, 6.2172e-15, 2.2204e-15, 6.2172e-15,\n",
      "         1.3323e-14, 1.9984e-15, 2.2204e-15, 1.9984e-15, 2.6645e-15, 1.9984e-15,\n",
      "         1.2434e-14, 3.9968e-15, 3.1086e-15, 5.7732e-15, 5.7732e-15, 2.1316e-14,\n",
      "         5.3291e-15, 1.7764e-15, 8.8818e-15, 4.8850e-15, 1.7764e-14, 4.4409e-15,\n",
      "         1.9984e-15, 5.3291e-15, 3.5527e-15, 6.2172e-15, 6.2172e-15, 2.2204e-15,\n",
      "         1.2212e-15, 8.8818e-15, 6.2172e-15, 1.7764e-15, 3.1086e-15, 7.1054e-15,\n",
      "         7.1054e-15, 2.4869e-14, 5.3291e-15, 7.1054e-15, 7.9936e-15, 1.7764e-14,\n",
      "         1.1102e-15, 5.3291e-15, 1.0658e-14, 3.9968e-15, 1.4211e-14, 8.8818e-15,\n",
      "         1.1102e-15, 4.4409e-15, 3.1086e-15, 1.0658e-14, 2.6645e-15, 7.1054e-15,\n",
      "         1.7764e-15, 9.9920e-16, 2.6645e-15, 7.1054e-15, 3.1086e-15, 4.8850e-15,\n",
      "         4.4409e-15, 1.7764e-15, 1.3323e-15, 8.8818e-15, 1.7764e-15, 6.6613e-15,\n",
      "         1.5987e-14, 1.7764e-14, 3.5527e-14, 3.5527e-14, 7.9936e-15, 1.9540e-14,\n",
      "         4.9738e-14, 1.2434e-14, 2.4869e-14, 1.7764e-14, 2.4869e-14, 3.5527e-14,\n",
      "         1.4211e-14, 2.1316e-14, 1.9540e-14, 1.7764e-14, 2.4869e-14, 3.5527e-14,\n",
      "         2.8422e-14, 2.1316e-14, 2.8422e-14, 2.1316e-14, 1.9540e-14, 1.0658e-14,\n",
      "         2.6645e-14, 1.7764e-14, 2.8422e-14, 2.1316e-14, 1.9540e-14, 4.6185e-14,\n",
      "         1.2434e-14, 1.4211e-14, 2.3093e-14, 4.9738e-14, 8.8818e-15, 1.5987e-14,\n",
      "         6.3949e-14, 8.8818e-15, 1.4211e-14, 2.1316e-14, 7.9936e-15, 7.1054e-15,\n",
      "         1.7764e-14, 4.2633e-14, 4.2633e-14, 2.8422e-14, 8.8818e-15, 1.5099e-14,\n",
      "         9.7700e-15, 1.2434e-14, 1.7764e-14, 3.1974e-14, 2.1316e-14, 2.8422e-14,\n",
      "         2.4869e-14, 2.3093e-14, 1.7764e-14, 1.7764e-14, 9.7700e-15, 1.4655e-14,\n",
      "         3.5527e-14, 1.9540e-14, 1.7764e-14, 6.2172e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 157: layer3.14.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 157\n",
      "Max diff:\n",
      " tensor([1.4655e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1593e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6629e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.3323e-15, 5.3291e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.6653e-15, 0.0000e+00, 4.4409e-15, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 7.8687e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2466e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.3993e-15, 0.0000e+00, 0.0000e+00, 1.4655e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([143, 189, 196, 199, 200, 204, 206, 209, 211, 214, 231, 248, 251])\n",
      "\n",
      "failing Cout = tensor([143, 189, 196, 199, 200, 204, 206, 209, 211, 214, 231, 248, 251])  (len = 13)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 158: layer3.14.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 158\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 158\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 158\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  3,  4,  6,  7,  9, 10, 11, 12, 13, 14, 18, 20, 22, 25, 27, 31, 37,\n",
      "        39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 65,  67,  69,  71,  73,  80,  82,  83,  84,  85,  93,  94,  98,  99,\n",
      "        101, 104, 105, 106, 107, 108, 109, 111, 112, 114, 115, 116, 117, 119,\n",
      "        123, 124, 125]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 194, 195, 196, 199, 200, 204, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229,\n",
      "        232, 233, 234, 235, 237, 238, 239, 240, 242, 243, 244, 245, 246, 248,\n",
      "        249, 250, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 158\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 158\n",
      "Max diff:\n",
      " tensor([1.1546e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.5511e-15, 4.9960e-16, 3.7748e-15, 7.2164e-16, 5.7732e-15, 1.3323e-15,\n",
      "         4.5519e-15, 7.3275e-15, 5.5511e-17, 3.7748e-15, 4.5797e-15, 4.4409e-15,\n",
      "         1.8457e-15, 1.4433e-15, 1.3323e-15, 3.3307e-15, 6.2172e-15, 5.5511e-15,\n",
      "         5.6621e-15, 1.3323e-15, 9.2287e-16, 4.5519e-15, 1.2212e-15, 5.1070e-15,\n",
      "         4.6629e-15, 2.3176e-15, 1.7764e-15, 4.4409e-15, 2.6645e-15, 2.9976e-15,\n",
      "         3.0531e-15, 3.2196e-15, 1.7208e-15, 2.9976e-15, 1.0547e-15, 3.2474e-15,\n",
      "         2.2204e-16, 1.0686e-15, 4.1078e-15, 5.1070e-15, 3.1086e-15, 1.8319e-15,\n",
      "         3.4417e-15, 2.2204e-15, 1.2212e-15, 1.7764e-15, 1.5543e-15, 2.4425e-15,\n",
      "         1.7764e-15, 3.2752e-15, 3.5805e-15, 2.3315e-15, 3.7470e-15, 4.7740e-15,\n",
      "         4.1078e-15, 6.6613e-16, 1.7764e-15, 3.3862e-15, 3.0809e-15, 1.7764e-15,\n",
      "         3.0115e-15, 9.9920e-16, 6.1062e-16, 2.4425e-15, 3.2196e-15, 1.3323e-15,\n",
      "         3.1919e-15, 3.7748e-15, 6.4393e-15, 4.8850e-15, 2.7109e-15, 1.2768e-15,\n",
      "         2.9143e-15, 2.5535e-15, 2.9976e-15, 1.3323e-15, 2.1094e-15, 4.4409e-15,\n",
      "         7.2164e-16, 4.8850e-15, 4.4409e-15, 1.0547e-15, 1.9706e-15, 3.7748e-15,\n",
      "         2.4425e-15, 6.1409e-16, 2.2204e-15, 1.7764e-15, 1.2768e-15, 4.7740e-15,\n",
      "         3.6637e-15, 1.8041e-15, 9.5479e-15, 1.4710e-15, 1.8319e-15, 5.4956e-15,\n",
      "         6.2172e-15, 7.1054e-15, 5.7732e-15, 5.1070e-15, 4.1356e-15, 1.3323e-15,\n",
      "         7.5495e-15, 3.9968e-15, 7.2164e-16, 4.7740e-15, 3.7192e-15, 4.6074e-15,\n",
      "         1.2768e-15, 3.2196e-15, 4.1078e-15, 2.1094e-15, 5.7732e-15, 2.5674e-15,\n",
      "         4.4409e-15, 1.4433e-15, 2.1094e-15, 2.0539e-15, 3.3168e-15, 1.5543e-15,\n",
      "         3.2196e-15, 3.3307e-15, 5.5511e-15, 2.0817e-16, 6.3838e-16, 6.6613e-15,\n",
      "         6.2172e-15, 2.2204e-15, 4.4409e-15, 2.9421e-15, 1.7764e-15, 6.2172e-15,\n",
      "         2.4147e-15, 2.5535e-15, 2.2343e-15, 2.1649e-15, 4.4409e-15, 4.4409e-15,\n",
      "         6.4393e-15, 6.6613e-15, 4.2188e-15, 3.9118e-15, 2.4425e-15, 6.8834e-15,\n",
      "         1.9984e-15, 3.9968e-15, 4.5519e-15, 1.2212e-15, 2.1649e-15, 3.1850e-15,\n",
      "         2.3315e-15, 6.4393e-15, 2.6645e-15, 4.1078e-15, 3.5527e-15, 1.4433e-15,\n",
      "         2.6645e-15, 3.7192e-15, 1.1241e-15, 9.9920e-16, 3.3584e-15, 1.6653e-15,\n",
      "         5.7732e-15, 3.1086e-15, 2.9976e-15, 1.4988e-15, 8.0491e-16, 1.6376e-15,\n",
      "         1.2559e-15, 1.5543e-15, 5.7732e-15, 5.5511e-16, 6.6613e-16, 4.4409e-16,\n",
      "         2.8866e-15, 6.8834e-15, 4.1633e-15, 4.8850e-15, 3.8303e-15, 6.6058e-15,\n",
      "         4.4409e-15, 1.3323e-15, 2.8866e-15, 4.3299e-15, 6.2172e-15, 3.8858e-15,\n",
      "         5.9952e-15, 2.4702e-15, 4.3299e-15, 2.5639e-15, 3.6637e-15, 8.8818e-16,\n",
      "         3.1364e-15, 4.5519e-15, 4.8850e-15, 2.8866e-15, 4.6629e-15, 5.9952e-15,\n",
      "         7.7716e-15, 6.2172e-15, 4.7184e-15, 3.7748e-15, 7.9936e-15, 1.0658e-14,\n",
      "         5.6621e-15, 8.6597e-15, 6.6613e-15, 3.8858e-15, 5.3846e-15, 3.3307e-15,\n",
      "         5.9952e-15, 6.8834e-15, 5.6621e-15, 6.0507e-15, 8.1046e-15, 6.2172e-15,\n",
      "         5.6621e-15, 4.6629e-15, 5.6621e-15, 3.7748e-15, 9.3259e-15, 6.2172e-15,\n",
      "         1.1546e-14, 6.2172e-15, 7.5495e-15, 7.1054e-15, 5.3291e-15, 7.1054e-15,\n",
      "         7.9936e-15, 4.4409e-15, 7.4385e-15, 6.7724e-15, 4.4409e-15, 5.7732e-15,\n",
      "         7.9936e-15, 3.8858e-15, 3.7192e-15, 7.5495e-15, 3.6637e-15, 3.9968e-15,\n",
      "         3.7054e-15, 4.3299e-15, 8.2157e-15, 3.2196e-15, 7.3275e-15, 4.4409e-15,\n",
      "         6.2172e-15, 5.9952e-15, 4.4409e-15, 5.7732e-15, 8.6597e-15, 4.7740e-15,\n",
      "         4.8850e-15, 7.9936e-15, 4.7184e-15, 5.1070e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 159: layer3.14.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 159\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 159\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 159\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 159\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 159\n",
      "Max diff:\n",
      " tensor([3.9968e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.2212e-15, 5.5511e-17, 1.3878e-15, 1.9429e-16, 3.2196e-15, 1.1102e-16,\n",
      "         1.8874e-15, 2.1094e-15, 2.7756e-17, 9.4369e-16, 1.2768e-15, 4.9960e-16,\n",
      "         5.0654e-16, 6.6613e-16, 3.8858e-16, 3.7990e-16, 2.0817e-15, 1.6653e-15,\n",
      "         3.4417e-15, 4.4409e-16, 1.8041e-16, 1.8319e-15, 4.9006e-16, 2.1094e-15,\n",
      "         1.8874e-15, 9.4369e-16, 8.8818e-16, 2.2204e-15, 1.0825e-15, 2.5674e-16,\n",
      "         1.2074e-15, 1.4433e-15, 9.1593e-16, 8.3267e-16, 5.5511e-17, 1.4710e-15,\n",
      "         6.9389e-18, 3.1919e-16, 1.4988e-15, 1.7208e-15, 3.9812e-16, 7.2164e-16,\n",
      "         2.0817e-16, 4.4409e-16, 2.4980e-16, 5.1348e-16, 6.1062e-16, 7.4940e-16,\n",
      "         9.9920e-16, 9.9920e-16, 3.8858e-16, 9.9920e-16, 1.0547e-15, 1.5543e-15,\n",
      "         4.7184e-16, 3.8858e-16, 6.6613e-16, 1.0825e-15, 7.4246e-16, 6.6613e-16,\n",
      "         1.7998e-16, 2.7756e-16, 1.2490e-16, 4.9960e-16, 2.0817e-16, 4.4409e-16,\n",
      "         1.1033e-15, 7.8410e-16, 8.1185e-16, 9.9920e-16, 5.9674e-16, 2.2898e-16,\n",
      "         4.1633e-16, 6.8001e-16, 1.3323e-15, 2.2204e-16, 3.1919e-16, 1.5266e-15,\n",
      "         1.3878e-16, 2.2204e-15, 3.8858e-16, 3.4694e-16, 5.5511e-16, 7.7716e-16,\n",
      "         5.8287e-16, 1.1362e-16, 6.1062e-16, 7.2164e-16, 8.6736e-17, 1.3878e-15,\n",
      "         3.1086e-15, 7.4940e-16, 1.1657e-15, 6.1062e-16, 3.6603e-16, 6.6613e-16,\n",
      "         2.2204e-15, 3.9968e-15, 2.2760e-15, 1.8874e-15, 1.2490e-15, 3.3307e-16,\n",
      "         2.1094e-15, 7.6328e-16, 2.4980e-16, 1.9429e-15, 1.5266e-15, 8.8818e-16,\n",
      "         2.7756e-16, 1.4051e-16, 1.5543e-15, 7.2164e-16, 1.1102e-15, 5.9674e-16,\n",
      "         2.3315e-15, 4.3021e-16, 5.2736e-16, 4.6491e-16, 1.1033e-15, 3.8858e-16,\n",
      "         6.2450e-16, 9.9920e-16, 8.8818e-16, 2.7756e-17, 1.2490e-16, 2.7756e-15,\n",
      "         2.3315e-15, 7.7716e-16, 1.9984e-15, 1.0686e-15, 4.9960e-16, 2.3870e-15,\n",
      "         4.3715e-16, 1.4433e-15, 9.8532e-16, 5.5511e-16, 1.9984e-15, 1.1519e-15,\n",
      "         1.3878e-15, 2.7756e-15, 7.4940e-16, 1.7764e-15, 1.2212e-15, 1.5543e-15,\n",
      "         4.9960e-16, 4.9960e-16, 1.1380e-15, 5.4123e-16, 5.1348e-16, 6.5226e-16,\n",
      "         6.1062e-16, 2.0539e-15, 1.1241e-15, 1.3323e-15, 8.8818e-16, 2.3592e-16,\n",
      "         1.2212e-15, 2.0817e-15, 4.0246e-16, 2.2204e-16, 1.0825e-15, 5.2736e-16,\n",
      "         8.8818e-16, 2.2204e-15, 9.2981e-16, 3.3307e-16, 3.0358e-16, 7.9103e-16,\n",
      "         5.1348e-16, 3.6082e-16, 2.3315e-15, 2.4980e-16, 2.2204e-16, 1.6653e-16,\n",
      "         1.3878e-15, 2.3315e-15, 1.4294e-15, 1.9984e-15, 2.0817e-16, 2.8311e-15,\n",
      "         9.9920e-16, 2.2204e-16, 1.4433e-15, 8.5869e-16, 2.2204e-15, 8.4655e-16,\n",
      "         3.4417e-15, 6.8695e-16, 1.2490e-15, 4.5797e-16, 1.3878e-15, 2.2204e-16,\n",
      "         8.1185e-16, 1.2768e-15, 1.8874e-15, 2.7756e-16, 1.3045e-15, 9.4369e-16,\n",
      "         2.7756e-15, 2.6645e-15, 1.3613e-15, 8.3267e-16, 1.4433e-15, 1.7764e-15,\n",
      "         1.2594e-15, 3.6637e-15, 1.8319e-15, 9.7145e-16, 2.0678e-15, 1.1449e-15,\n",
      "         2.2204e-15, 2.0539e-15, 1.7347e-15, 1.7764e-15, 3.0254e-15, 1.6653e-15,\n",
      "         1.8319e-15, 1.4849e-15, 1.3600e-15, 1.1657e-15, 2.2204e-15, 1.9984e-15,\n",
      "         3.8858e-15, 1.5543e-15, 3.9968e-15, 3.5527e-15, 2.2204e-15, 2.6645e-15,\n",
      "         2.8866e-15, 1.4988e-15, 1.6792e-15, 2.6645e-15, 1.2212e-15, 2.6090e-15,\n",
      "         1.4572e-15, 8.3267e-16, 8.5348e-16, 2.8866e-15, 1.0825e-15, 1.5543e-15,\n",
      "         1.6653e-15, 8.3267e-16, 3.6082e-15, 7.7716e-16, 2.3037e-15, 1.7764e-15,\n",
      "         1.5543e-15, 2.1094e-15, 1.6653e-15, 1.5543e-15, 2.8866e-15, 1.7208e-15,\n",
      "         1.8874e-15, 1.8319e-15, 1.3600e-15, 2.2204e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 160: layer3.14.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 160\n",
      "Max diff:\n",
      " tensor([3.1086e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.2212e-15, 4.3299e-15, 1.5404e-15, 3.9968e-15, 3.2196e-15, 1.1102e-16,\n",
      "         1.8874e-15, 5.7732e-15, 4.9960e-16, 1.6098e-15, 1.2768e-15, 9.9920e-16,\n",
      "         1.3323e-15, 5.7732e-15, 1.9984e-15, 6.3838e-16, 3.5527e-15, 1.6653e-15,\n",
      "         3.4417e-15, 5.8287e-16, 5.5511e-16, 1.8319e-15, 4.9006e-16, 3.3307e-15,\n",
      "         3.6360e-15, 9.4369e-16, 1.3323e-15, 2.2204e-15, 1.0825e-15, 2.6645e-15,\n",
      "         1.6931e-15, 1.9984e-15, 3.1086e-15, 5.5511e-15, 9.9920e-16, 1.4710e-15,\n",
      "         1.1102e-15, 3.3307e-16, 1.8319e-15, 3.1086e-15, 7.1054e-15, 1.6653e-15,\n",
      "         1.6653e-15, 3.1086e-15, 5.5511e-15, 5.1348e-16, 2.1094e-15, 1.1102e-15,\n",
      "         9.9920e-16, 1.4988e-15, 4.2188e-15, 9.9920e-16, 2.7200e-15, 3.6637e-15,\n",
      "         7.4940e-16, 1.9984e-15, 7.7716e-16, 1.0825e-15, 2.3315e-15, 1.9013e-15,\n",
      "         3.3307e-15, 1.9429e-15, 5.7732e-15, 7.7716e-16, 5.7732e-15, 1.8041e-15,\n",
      "         6.5781e-15, 6.4393e-15, 1.7764e-15, 5.4956e-15, 1.1546e-14, 1.8874e-15,\n",
      "         3.6637e-15, 5.5511e-15, 3.3307e-15, 6.2172e-15, 7.9936e-15, 8.5487e-15,\n",
      "         1.7764e-15, 2.2204e-15, 4.6629e-15, 7.9936e-15, 5.5511e-16, 1.1546e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7716e-15, 8.8818e-16, 8.4377e-15, 2.1094e-15,\n",
      "         3.1086e-15, 3.6637e-15, 1.5543e-15, 6.1062e-16, 2.4425e-15, 2.4147e-15,\n",
      "         4.4409e-15, 3.9968e-15, 3.9968e-15, 7.1054e-15, 2.2204e-15, 1.4710e-15,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 1.5266e-15, 1.3878e-15,\n",
      "         3.8858e-15, 2.4425e-15, 5.3291e-15, 6.6613e-15, 1.3323e-15, 3.9968e-15,\n",
      "         4.1633e-15, 7.9936e-15, 5.9952e-15, 9.4369e-16, 5.5511e-15, 5.3291e-15,\n",
      "         1.0825e-15, 1.9429e-15, 4.3299e-15, 4.4409e-15, 2.6645e-15, 4.2188e-15,\n",
      "         2.8588e-15, 2.7200e-15, 1.9984e-15, 6.2172e-15, 1.7764e-15, 4.1633e-15,\n",
      "         5.3291e-15, 5.1070e-15, 1.0658e-14, 4.8850e-15, 2.4425e-15, 1.1519e-15,\n",
      "         1.0658e-14, 2.7756e-15, 4.8850e-15, 4.2188e-15, 2.7756e-15, 1.0658e-14,\n",
      "         7.9936e-15, 4.9960e-16, 1.2212e-15, 4.5519e-15, 1.7764e-14, 6.5226e-16,\n",
      "         1.1546e-14, 3.9968e-15, 5.3291e-15, 1.3323e-15, 1.9984e-15, 6.6613e-15,\n",
      "         6.3283e-15, 5.1625e-15, 9.7700e-15, 7.7716e-16, 1.9984e-15, 5.9952e-15,\n",
      "         3.9968e-15, 2.2204e-15, 2.6645e-15, 1.2212e-15, 1.4599e-14, 4.2188e-15,\n",
      "         2.1316e-14, 8.8818e-16, 1.7764e-15, 1.0658e-14, 3.5527e-15, 1.0436e-14,\n",
      "         1.7764e-15, 1.2879e-14, 5.7732e-15, 1.9984e-15, 7.9936e-15, 4.4409e-15,\n",
      "         3.3307e-15, 2.6645e-15, 1.4433e-15, 1.5543e-15, 3.3307e-15, 4.8850e-15,\n",
      "         1.4877e-14, 4.7184e-15, 1.4211e-14, 9.7700e-15, 1.3878e-15, 2.4425e-15,\n",
      "         1.0658e-14, 2.4869e-14, 1.2434e-14, 1.2768e-15, 1.8319e-15, 8.8818e-15,\n",
      "         4.8850e-15, 1.5987e-14, 8.8818e-15, 6.3283e-15, 1.1990e-14, 3.1086e-15,\n",
      "         9.7700e-15, 1.4211e-14, 3.5527e-15, 1.6154e-14, 4.4409e-15, 3.1086e-15,\n",
      "         3.4833e-15, 3.1086e-14, 1.7764e-14, 5.4401e-15, 7.3275e-15, 5.7732e-15,\n",
      "         8.8818e-15, 1.0658e-14, 5.6621e-15, 4.3854e-15, 7.5495e-15, 1.9540e-14,\n",
      "         7.1054e-15, 8.8818e-15, 6.3283e-15, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.5099e-14, 9.7700e-15, 5.3291e-15, 1.4433e-14, 2.6645e-14, 9.1038e-15,\n",
      "         8.8818e-15, 1.9984e-15, 4.4409e-15, 1.4211e-14, 3.2196e-15, 7.1054e-15,\n",
      "         1.9984e-15, 7.1054e-15, 4.4409e-15, 5.9952e-15, 5.9952e-15, 1.4211e-14,\n",
      "         8.4377e-15, 8.6597e-15, 6.9944e-15, 9.3259e-15, 1.4211e-14, 7.9936e-15,\n",
      "         2.6645e-15, 3.9968e-15, 5.7732e-15, 1.1102e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 161: layer3.14.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 161\n",
      "Max diff:\n",
      " tensor([3.1086e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 4.3299e-15, 1.5404e-15, 3.9968e-15, 2.2204e-15, 0.0000e+00,\n",
      "         1.8874e-15, 5.7732e-15, 4.9960e-16, 1.6098e-15, 1.1102e-15, 9.9920e-16,\n",
      "         1.3323e-15, 5.7732e-15, 1.9984e-15, 0.0000e+00, 3.5527e-15, 3.3307e-16,\n",
      "         3.4417e-15, 0.0000e+00, 5.5511e-16, 1.8319e-15, 3.0531e-16, 6.6613e-16,\n",
      "         3.1086e-15, 4.4409e-16, 8.8818e-16, 1.8735e-15, 6.3838e-16, 2.6645e-15,\n",
      "         1.6931e-15, 1.9984e-15, 3.1086e-15, 5.5511e-15, 9.9920e-16, 1.6653e-16,\n",
      "         1.1102e-15, 3.3307e-16, 1.8319e-15, 3.1086e-15, 7.1054e-15, 1.6653e-15,\n",
      "         1.6653e-15, 3.1086e-15, 5.5511e-15, 3.8858e-16, 2.1094e-15, 7.4940e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.2188e-15, 7.7716e-16, 2.7200e-15, 1.3600e-15,\n",
      "         7.4940e-16, 1.9984e-15, 6.6613e-16, 1.0825e-15, 2.3315e-15, 1.6653e-15,\n",
      "         3.3307e-15, 0.0000e+00, 5.7732e-15, 3.8858e-16, 5.7732e-15, 8.0491e-16,\n",
      "         6.5781e-15, 6.4393e-15, 1.7764e-15, 5.4956e-15, 1.1546e-14, 1.8874e-15,\n",
      "         3.6637e-15, 5.5511e-15, 3.3307e-15, 6.2172e-15, 7.9936e-15, 8.5487e-15,\n",
      "         1.7764e-15, 5.4817e-16, 4.6629e-15, 7.9936e-15, 5.5511e-16, 1.1546e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7716e-15, 8.8818e-16, 8.4377e-15, 0.0000e+00,\n",
      "         2.2204e-15, 3.6637e-15, 1.2768e-15, 0.0000e+00, 2.4425e-15, 2.4147e-15,\n",
      "         4.4409e-15, 1.2490e-15, 3.9968e-15, 7.1054e-15, 2.2204e-15, 1.4710e-15,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 1.5266e-15, 1.3878e-15,\n",
      "         3.8858e-15, 2.4425e-15, 5.3291e-15, 6.6613e-15, 1.3323e-15, 3.9968e-15,\n",
      "         4.1633e-15, 7.9936e-15, 5.9952e-15, 9.4369e-16, 5.5511e-15, 5.3291e-15,\n",
      "         8.8818e-16, 9.0206e-16, 4.3299e-15, 4.4409e-15, 2.6645e-15, 4.2188e-15,\n",
      "         2.6645e-15, 2.4425e-15, 1.9984e-15, 6.2172e-15, 1.7764e-15, 4.1633e-15,\n",
      "         5.3291e-15, 5.1070e-15, 1.0658e-14, 4.8850e-15, 2.0539e-15, 6.1062e-16,\n",
      "         1.0658e-14, 2.0539e-15, 4.8850e-15, 2.9421e-15, 2.7756e-15, 1.0658e-14,\n",
      "         7.9936e-15, 1.0408e-16, 1.2212e-15, 4.5519e-15, 1.7764e-14, 2.9837e-16,\n",
      "         1.1546e-14, 3.9968e-15, 5.3291e-15, 0.0000e+00, 8.8818e-16, 6.6613e-15,\n",
      "         6.3283e-15, 5.1625e-15, 9.7700e-15, 0.0000e+00, 1.9984e-15, 5.9952e-15,\n",
      "         3.9968e-15, 8.6042e-16, 2.6645e-15, 1.2212e-15, 1.4599e-14, 4.2188e-15,\n",
      "         2.1316e-14, 8.8818e-16, 1.7764e-15, 1.0658e-14, 3.5527e-15, 1.0436e-14,\n",
      "         1.7764e-15, 1.2879e-14, 5.7732e-15, 8.4308e-16, 7.9936e-15, 4.4409e-15,\n",
      "         3.3307e-15, 2.6645e-15, 1.4433e-15, 1.5543e-15, 3.3307e-15, 4.8850e-15,\n",
      "         1.4877e-14, 4.7184e-15, 1.4211e-14, 9.7700e-15, 1.2282e-15, 2.4425e-15,\n",
      "         1.0658e-14, 2.4869e-14, 1.2434e-14, 1.2768e-15, 1.8319e-15, 8.8818e-15,\n",
      "         4.8850e-15, 1.5987e-14, 8.8818e-15, 6.3283e-15, 1.1990e-14, 3.1086e-15,\n",
      "         9.7700e-15, 1.4211e-14, 3.5527e-15, 1.6154e-14, 4.4409e-15, 3.1086e-15,\n",
      "         3.4833e-15, 3.1086e-14, 1.7764e-14, 5.4401e-15, 7.3275e-15, 5.7732e-15,\n",
      "         8.8818e-15, 1.0658e-14, 5.6621e-15, 8.3267e-16, 7.5495e-15, 1.9540e-14,\n",
      "         7.1054e-15, 8.8818e-15, 5.3291e-15, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.5099e-14, 9.7700e-15, 5.3291e-15, 1.0658e-14, 2.6645e-14, 9.1038e-15,\n",
      "         8.8818e-15, 1.9984e-15, 4.4409e-15, 1.4211e-14, 3.2196e-15, 7.1054e-15,\n",
      "         1.9984e-15, 7.1054e-15, 4.4409e-15, 5.9952e-15, 5.9952e-15, 1.4211e-14,\n",
      "         8.4377e-15, 8.6597e-15, 6.9944e-15, 9.3259e-15, 1.4211e-14, 7.9936e-15,\n",
      "         2.6645e-15, 3.9968e-15, 5.7732e-15, 1.1102e-14]], dtype=torch.float64)\n",
      " tensor([  1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,  16,\n",
      "         17,  18,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
      "         32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "         46,  47,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  62,\n",
      "         63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
      "         77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  90,  91,\n",
      "         92,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "        149, 150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,  16,\n",
      "         17,  18,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
      "         32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "         46,  47,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  62,\n",
      "         63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
      "         77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  90,  91,\n",
      "         92,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
      "        135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "        149, 150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
      "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "        249, 250, 251, 252, 253, 254, 255])  (len = 245)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 162: layer3.15.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 162\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 162\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 162\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 162\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 162\n",
      "Max diff:\n",
      " tensor([3.1264e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.1316e-14, 3.9968e-15, 6.2172e-15, 5.3291e-15, 1.4211e-14, 1.0658e-14,\n",
      "         8.8818e-15, 2.4869e-14, 1.7764e-14, 2.4869e-14, 5.3291e-15, 7.1054e-15,\n",
      "         5.3291e-15, 7.1054e-15, 3.5527e-15, 7.1054e-15, 9.7700e-15, 8.8818e-15,\n",
      "         8.8818e-15, 6.2172e-15, 1.7764e-14, 8.8818e-15, 7.1054e-15, 2.8422e-14,\n",
      "         1.4211e-14, 8.8818e-15, 4.4409e-15, 1.0658e-14, 1.0658e-14, 1.0658e-14,\n",
      "         5.3291e-15, 2.8422e-14, 1.0658e-14, 1.7764e-14, 4.4409e-15, 6.2172e-15,\n",
      "         3.9968e-15, 3.9968e-15, 1.7764e-14, 3.5527e-14, 1.0658e-14, 5.3291e-15,\n",
      "         6.2172e-15, 7.9936e-15, 2.8422e-14, 1.2434e-14, 1.0658e-14, 1.7764e-14,\n",
      "         9.9476e-14, 7.1054e-15, 7.1054e-15, 6.2172e-15, 1.0658e-14, 2.1316e-14,\n",
      "         1.4211e-14, 6.2172e-15, 3.5527e-15, 1.4211e-14, 4.4409e-15, 4.4409e-15,\n",
      "         1.2434e-14, 2.4869e-14, 6.2172e-15, 4.4409e-15, 2.1316e-14, 9.7700e-15,\n",
      "         6.2172e-15, 1.1546e-14, 1.2434e-14, 4.2633e-14, 1.5987e-14, 3.1974e-14,\n",
      "         1.2434e-14, 3.9968e-15, 9.7700e-15, 1.7764e-14, 8.8818e-15, 4.4409e-15,\n",
      "         1.7764e-14, 1.5987e-14, 1.0658e-14, 6.3949e-14, 2.8422e-14, 7.1054e-15,\n",
      "         4.2633e-14, 1.2434e-14, 1.4211e-14, 4.9738e-14, 3.1974e-14, 4.9738e-14,\n",
      "         7.9936e-15, 1.5987e-14, 8.8818e-15, 6.2172e-15, 1.0658e-14, 3.5527e-14,\n",
      "         3.5527e-14, 6.2172e-15, 2.1316e-14, 7.1054e-14, 7.9936e-15, 9.7700e-15,\n",
      "         1.4211e-14, 3.1974e-14, 1.2434e-14, 4.4409e-15, 5.3291e-15, 3.5527e-14,\n",
      "         1.2434e-14, 2.8422e-14, 1.1546e-14, 7.9936e-15, 1.0658e-14, 7.1054e-15,\n",
      "         1.2434e-14, 2.8422e-14, 6.3949e-14, 7.9936e-15, 4.9738e-14, 4.2633e-14,\n",
      "         2.8422e-14, 2.8422e-14, 8.5265e-14, 2.4869e-14, 7.9936e-15, 1.7764e-14,\n",
      "         3.5527e-14, 8.8818e-15, 7.8160e-14, 2.8422e-14, 4.2633e-14, 2.1316e-14,\n",
      "         2.1316e-14, 2.1316e-14, 3.3751e-14, 5.6843e-14, 1.0658e-14, 7.8160e-14,\n",
      "         2.4869e-14, 2.8422e-14, 1.4211e-14, 7.8160e-14, 2.8422e-14, 1.5987e-14,\n",
      "         5.6843e-14, 4.2633e-14, 1.0658e-14, 1.4211e-14, 4.9738e-14, 4.2633e-14,\n",
      "         6.3949e-14, 8.5265e-14, 8.8818e-15, 7.1054e-14, 3.1974e-14, 4.2633e-14,\n",
      "         6.3949e-14, 9.7700e-15, 2.4869e-14, 8.5265e-14, 5.6843e-14, 3.1974e-14,\n",
      "         6.3949e-14, 1.5987e-14, 9.9476e-14, 7.9936e-15, 1.2434e-14, 1.0658e-14,\n",
      "         4.2633e-14, 7.1054e-14, 1.4211e-14, 7.1054e-14, 2.3093e-14, 7.1054e-15,\n",
      "         7.1054e-14, 1.9540e-14, 1.4211e-14, 1.5099e-14, 4.9738e-14, 2.4869e-14,\n",
      "         1.5987e-14, 4.2633e-14, 7.8160e-14, 5.6843e-14, 7.1054e-14, 9.9476e-14,\n",
      "         4.2633e-14, 4.2633e-14, 4.2633e-14, 2.4869e-14, 4.2633e-14, 1.7764e-14,\n",
      "         1.2790e-13, 3.5527e-14, 1.2790e-13, 9.9476e-14, 7.1054e-14, 9.9476e-14,\n",
      "         4.2633e-14, 9.9476e-14, 1.5632e-13, 4.2633e-14, 8.5265e-14, 5.6843e-14,\n",
      "         7.1054e-14, 4.4409e-14, 8.5265e-14, 3.5527e-14, 1.7053e-13, 1.7053e-13,\n",
      "         8.5265e-14, 3.1264e-13, 1.7053e-13, 5.3291e-14, 7.1054e-14, 9.9476e-14,\n",
      "         1.1369e-13, 1.7053e-13, 1.7053e-13, 9.9476e-14, 1.1369e-13, 2.8422e-14,\n",
      "         3.5527e-14, 1.1369e-13, 5.6843e-14, 1.1369e-13, 7.1054e-14, 2.1316e-14,\n",
      "         5.3291e-14, 6.3949e-14, 8.1712e-14, 7.1054e-14, 1.4211e-13, 7.1054e-14,\n",
      "         2.8422e-14, 7.8160e-14, 1.2790e-13, 1.1369e-13, 8.5265e-14, 2.8422e-14,\n",
      "         1.0658e-13, 8.5265e-14, 5.6843e-14, 9.9476e-14, 1.9895e-13, 8.5265e-14,\n",
      "         9.9476e-14, 2.2737e-13, 1.9895e-13, 2.4869e-14, 8.5265e-14, 5.6843e-14,\n",
      "         9.9476e-14, 7.8160e-14, 1.7053e-13, 2.8422e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 163: layer3.15.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 163\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 163\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 163\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 163\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 163\n",
      "Max diff:\n",
      " tensor([8.5265e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 8.8818e-16, 9.9920e-16, 8.8818e-16, 3.1086e-15, 2.2204e-15,\n",
      "         1.5543e-15, 3.9968e-15, 3.1086e-15, 3.1086e-15, 1.3323e-15, 1.7764e-15,\n",
      "         1.1102e-15, 1.4433e-15, 7.7716e-16, 1.3323e-15, 1.9984e-15, 1.7764e-15,\n",
      "         1.5543e-15, 1.3323e-15, 2.2204e-15, 1.7764e-15, 9.9920e-16, 5.3291e-15,\n",
      "         2.6645e-15, 1.5543e-15, 9.9920e-16, 1.5543e-15, 1.7764e-15, 2.2204e-15,\n",
      "         7.7716e-16, 4.4409e-15, 1.8874e-15, 2.2204e-15, 9.9920e-16, 1.1102e-15,\n",
      "         8.8818e-16, 9.9920e-16, 2.4425e-15, 6.2172e-15, 2.2204e-15, 1.3323e-15,\n",
      "         9.9920e-16, 1.4433e-15, 4.4409e-15, 1.5543e-15, 2.2204e-15, 3.1086e-15,\n",
      "         1.4211e-14, 1.5543e-15, 1.3323e-15, 1.1102e-15, 1.3323e-15, 3.9968e-15,\n",
      "         2.6645e-15, 1.1102e-15, 6.6613e-16, 2.2204e-15, 1.1102e-15, 1.1102e-15,\n",
      "         2.2204e-15, 4.8850e-15, 1.5543e-15, 6.6613e-16, 4.4409e-15, 1.9984e-15,\n",
      "         1.3323e-15, 2.2204e-15, 2.6645e-15, 5.3291e-15, 2.8866e-15, 6.2172e-15,\n",
      "         1.9984e-15, 8.8818e-16, 1.9984e-15, 3.9968e-15, 1.3323e-15, 7.7716e-16,\n",
      "         4.4409e-15, 2.6645e-15, 2.2204e-15, 1.0658e-14, 3.9968e-15, 1.3323e-15,\n",
      "         7.9936e-15, 2.2204e-15, 3.1086e-15, 8.8818e-15, 4.4409e-15, 6.2172e-15,\n",
      "         1.7764e-15, 3.9968e-15, 2.2204e-15, 1.3323e-15, 2.6645e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.7764e-15, 4.4409e-15, 1.0658e-14, 1.9984e-15, 1.6653e-15,\n",
      "         3.1086e-15, 7.1054e-15, 2.2204e-15, 1.1102e-15, 9.9920e-16, 5.3291e-15,\n",
      "         1.9984e-15, 6.2172e-15, 2.4425e-15, 1.5543e-15, 2.4425e-15, 1.1102e-15,\n",
      "         2.6645e-15, 5.3291e-15, 7.9936e-15, 1.7764e-15, 6.2172e-15, 6.2172e-15,\n",
      "         5.3291e-15, 4.8850e-15, 2.1316e-14, 3.5527e-15, 1.5543e-15, 2.6645e-15,\n",
      "         7.1054e-15, 1.9984e-15, 1.5987e-14, 5.3291e-15, 7.1054e-15, 3.9968e-15,\n",
      "         3.5527e-15, 4.4409e-15, 6.6613e-15, 1.0658e-14, 2.2204e-15, 7.9936e-15,\n",
      "         3.1086e-15, 6.2172e-15, 2.6645e-15, 1.2434e-14, 3.1086e-15, 3.9968e-15,\n",
      "         1.2434e-14, 5.3291e-15, 1.9984e-15, 2.6645e-15, 1.2434e-14, 7.1054e-15,\n",
      "         1.5987e-14, 2.1316e-14, 1.7764e-15, 1.4211e-14, 7.1054e-15, 8.8818e-15,\n",
      "         1.0658e-14, 2.4425e-15, 3.9968e-15, 1.0658e-14, 1.0658e-14, 6.2172e-15,\n",
      "         1.1546e-14, 2.6645e-15, 1.0658e-14, 1.7764e-15, 1.7764e-15, 1.7764e-15,\n",
      "         8.8818e-15, 1.5987e-14, 3.1086e-15, 1.5987e-14, 4.8850e-15, 1.5543e-15,\n",
      "         7.1054e-15, 4.4409e-15, 2.6645e-15, 2.4425e-15, 7.1054e-15, 4.8850e-15,\n",
      "         2.6645e-15, 7.9936e-15, 1.1546e-14, 7.1054e-15, 1.5987e-14, 2.1316e-14,\n",
      "         8.8818e-15, 7.9936e-15, 7.1054e-15, 3.9968e-15, 7.1054e-15, 2.2204e-15,\n",
      "         2.8422e-14, 7.9936e-15, 4.2633e-14, 2.1316e-14, 9.7700e-15, 2.1316e-14,\n",
      "         7.1054e-15, 2.8422e-14, 3.5527e-14, 1.0658e-14, 1.7764e-14, 1.2434e-14,\n",
      "         1.4211e-14, 8.8818e-15, 1.7764e-14, 7.9936e-15, 3.0198e-14, 2.8422e-14,\n",
      "         2.4869e-14, 7.8160e-14, 2.1316e-14, 5.7732e-15, 1.2434e-14, 1.8652e-14,\n",
      "         2.8422e-14, 4.2633e-14, 3.1974e-14, 2.8422e-14, 2.1316e-14, 7.1054e-15,\n",
      "         7.1054e-15, 1.7764e-14, 1.0658e-14, 3.5527e-14, 1.1102e-14, 3.5527e-15,\n",
      "         8.8818e-15, 1.0658e-14, 2.3093e-14, 7.1054e-15, 3.1974e-14, 1.2434e-14,\n",
      "         6.2172e-15, 1.7764e-14, 2.4869e-14, 2.1316e-14, 1.5987e-14, 8.8818e-15,\n",
      "         1.8652e-14, 1.0658e-14, 7.1054e-15, 1.9540e-14, 8.5265e-14, 2.1316e-14,\n",
      "         1.4211e-14, 3.9080e-14, 8.5265e-14, 7.1054e-15, 1.9540e-14, 1.0658e-14,\n",
      "         2.1316e-14, 1.9540e-14, 2.8422e-14, 8.8818e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 164: layer3.15.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 164\n",
      "Max diff:\n",
      " tensor([1.1324e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7732e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.4393e-15, 0.0000e+00, 1.4988e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.7748e-15, 0.0000e+00, 7.1054e-15, 0.0000e+00, 0.0000e+00, 1.1324e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-15, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([187, 205, 213, 224, 226, 230, 240, 242, 245, 253])\n",
      "\n",
      "failing Cout = tensor([187, 205, 213, 224, 226, 230, 240, 242, 245, 253])  (len = 10)\n",
      "passing Cout = tensor([235])  (len = 1)\n",
      "\n",
      "Executing module 165: layer3.15.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 165\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 165\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 165\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  3,  4,  6,  7, 10, 17, 19, 23, 24, 25, 28, 30, 31, 32, 33, 35, 37,\n",
      "        41, 43, 44, 45, 55, 58, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  67,  72,  73,  83,  84,  87,  89,  93,  95,  97,  98, 103,\n",
      "        105, 108, 109, 111, 112, 121]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([193, 194, 195, 197, 199, 201, 202, 207, 211, 217, 218, 222, 225, 227,\n",
      "        230, 231, 232, 233, 234, 235, 239, 244, 245, 247, 248, 250, 251, 252,\n",
      "        253, 254]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 165\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37,\n",
      "        38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
      "        56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 165\n",
      "Max diff:\n",
      " tensor([7.9936e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.1657e-15, 0.0000e+00, 6.6613e-16, 6.6613e-16, 1.1102e-15, 4.2188e-15,\n",
      "         1.1657e-15, 1.0270e-15, 1.3323e-15, 3.3307e-15, 3.9968e-15, 2.6645e-15,\n",
      "         1.1102e-15, 4.4409e-16, 2.0539e-15, 4.2188e-15, 5.3291e-15, 2.9421e-15,\n",
      "         5.3291e-15, 3.1086e-15, 4.4409e-15, 5.7766e-16, 1.7208e-15, 4.4409e-16,\n",
      "         3.5527e-15, 6.8001e-16, 3.1086e-15, 2.4980e-15, 2.6645e-15, 8.8818e-16,\n",
      "         1.3323e-15, 3.2196e-15, 4.4409e-16, 4.8225e-15, 3.5527e-15, 3.9968e-15,\n",
      "         2.4425e-15, 4.8850e-15, 3.9968e-15, 2.6645e-15, 4.4409e-16, 5.1070e-15,\n",
      "         2.7148e-16, 5.3291e-15, 6.6613e-16, 4.5519e-15, 4.3299e-15, 2.9976e-15,\n",
      "         1.6653e-15, 3.9968e-15, 3.2196e-15, 3.7748e-15, 5.9987e-15, 2.3870e-15,\n",
      "         2.3245e-15, 6.6058e-15, 2.4980e-15, 4.4409e-15, 1.3947e-15, 8.8818e-16,\n",
      "         2.3870e-15, 2.6645e-15, 3.9968e-15, 4.4062e-15, 3.6082e-16, 6.3838e-16,\n",
      "         2.6645e-15, 2.5535e-15, 3.5527e-15, 2.2204e-15, 2.8311e-15, 1.6653e-15,\n",
      "         1.0825e-15, 3.1086e-15, 2.2204e-15, 1.8874e-15, 2.1094e-15, 4.4409e-15,\n",
      "         1.6653e-15, 5.6899e-16, 3.1086e-15, 2.3037e-15, 8.0491e-16, 3.9968e-15,\n",
      "         3.2162e-15, 1.5543e-15, 2.3315e-15, 2.2204e-15, 3.1919e-15, 2.6645e-15,\n",
      "         2.4425e-15, 4.9960e-16, 1.1380e-15, 1.9984e-15, 0.0000e+00, 2.6090e-15,\n",
      "         4.1911e-15, 3.7886e-15, 3.9968e-15, 2.3315e-15, 1.5543e-15, 3.1086e-15,\n",
      "         5.1070e-15, 3.9968e-15, 1.6376e-15, 1.1657e-15, 6.6613e-15, 3.6082e-15,\n",
      "         1.7764e-15, 2.3315e-15, 4.8850e-15, 1.5543e-15, 3.5527e-15, 3.3307e-15,\n",
      "         4.2188e-15, 2.9976e-15, 3.5527e-15, 6.2172e-15, 1.4433e-15, 2.9976e-15,\n",
      "         2.7756e-15, 2.6645e-15, 2.2204e-15, 2.6090e-15, 3.1086e-15, 8.8818e-16,\n",
      "         5.3291e-15, 3.5527e-15, 9.9920e-16, 4.4409e-15, 3.9968e-15, 3.1086e-15,\n",
      "         2.7200e-15, 1.0270e-15, 3.1086e-15, 4.9891e-15, 4.8850e-15, 1.9984e-15,\n",
      "         3.2196e-15, 3.1086e-15, 3.7748e-15, 3.5527e-15, 2.8311e-15, 1.9984e-15,\n",
      "         4.6629e-15, 3.9968e-15, 3.3307e-15, 3.1086e-15, 1.6098e-15, 3.1780e-15,\n",
      "         2.1649e-15, 4.4409e-15, 3.5527e-15, 2.4980e-15, 7.1054e-15, 2.6645e-15,\n",
      "         3.7748e-15, 8.8818e-16, 3.3307e-15, 2.2204e-15, 3.4417e-15, 9.4369e-16,\n",
      "         7.7716e-16, 5.3291e-15, 4.2744e-15, 4.1078e-15, 1.8319e-15, 2.6645e-15,\n",
      "         5.4401e-15, 1.1102e-15, 6.2172e-15, 3.9968e-15, 1.6653e-15, 3.8858e-15,\n",
      "         3.3307e-15, 3.5527e-15, 4.8850e-15, 6.2728e-15, 4.2188e-15, 6.2172e-15,\n",
      "         2.1094e-15, 2.1372e-15, 2.2204e-15, 2.4425e-15, 1.2768e-15, 4.8850e-15,\n",
      "         3.7748e-15, 3.6637e-15, 4.1078e-15, 2.4425e-15, 1.7764e-15, 2.5535e-15,\n",
      "         5.1070e-15, 6.2172e-15, 4.4409e-15, 4.7184e-15, 3.1086e-15, 5.5511e-15,\n",
      "         4.9960e-15, 7.9936e-15, 5.3013e-15, 4.8850e-15, 3.1086e-15, 3.8858e-15,\n",
      "         3.1086e-15, 3.3307e-15, 4.4131e-15, 4.4409e-15, 4.6629e-15, 4.3576e-15,\n",
      "         5.3291e-15, 4.8850e-15, 2.9976e-15, 6.8834e-15, 3.9968e-15, 3.5527e-15,\n",
      "         3.6637e-15, 4.8850e-15, 3.5527e-15, 2.6645e-15, 3.9968e-15, 2.7756e-15,\n",
      "         3.7748e-15, 2.8866e-15, 4.9960e-15, 5.6899e-15, 6.2172e-15, 4.2188e-15,\n",
      "         3.4139e-15, 4.6629e-15, 5.9952e-15, 3.6637e-15, 5.3291e-15, 3.7748e-15,\n",
      "         6.1062e-15, 3.5527e-15, 3.7192e-15, 3.9968e-15, 3.9968e-15, 6.0507e-15,\n",
      "         5.5511e-15, 3.3307e-15, 4.1217e-15, 5.3291e-15, 5.3291e-15, 5.1070e-15,\n",
      "         3.9413e-15, 3.8858e-15, 3.9968e-15, 4.8850e-15, 5.5511e-15, 4.8850e-15,\n",
      "         4.6629e-15, 5.6621e-15, 5.8842e-15, 6.2172e-15]], dtype=torch.float64)\n",
      " tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])  (len = 254)\n",
      "passing Cout = tensor([94])  (len = 1)\n",
      "\n",
      "Executing module 166: layer3.15.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 166\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 166\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 166\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 166\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 166\n",
      "Max diff:\n",
      " tensor([4.4409e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.5511e-16, 0.0000e+00, 1.1102e-16, 4.1633e-17, 4.4409e-16, 1.5543e-15,\n",
      "         2.7756e-16, 3.3307e-16, 1.9429e-16, 8.3267e-16, 2.3870e-15, 5.5511e-16,\n",
      "         6.8001e-16, 1.7347e-16, 3.6082e-16, 1.7764e-15, 1.5543e-15, 8.8818e-16,\n",
      "         2.2204e-15, 8.8818e-16, 1.7764e-15, 2.2204e-16, 2.7756e-16, 1.6653e-16,\n",
      "         5.5511e-16, 2.7756e-16, 8.8818e-16, 9.5757e-16, 1.2212e-15, 1.6653e-16,\n",
      "         4.9960e-16, 6.3838e-16, 1.4572e-16, 1.1519e-15, 1.9984e-15, 3.8858e-16,\n",
      "         9.4369e-16, 9.9920e-16, 7.2164e-16, 6.1062e-16, 6.9389e-17, 1.2212e-15,\n",
      "         3.9248e-17, 2.6645e-15, 1.6653e-16, 1.4433e-15, 2.1094e-15, 4.4409e-16,\n",
      "         3.7470e-16, 1.7764e-15, 1.1102e-15, 1.1102e-15, 3.0809e-15, 1.0096e-15,\n",
      "         1.0165e-15, 3.4694e-15, 1.2490e-15, 1.8874e-15, 1.6306e-16, 5.5511e-17,\n",
      "         4.6491e-16, 3.3307e-16, 1.9984e-15, 7.2164e-16, 4.1633e-17, 2.2898e-16,\n",
      "         9.4369e-16, 5.2736e-16, 7.7716e-16, 4.9960e-16, 3.2960e-16, 2.8189e-16,\n",
      "         4.4409e-16, 8.8818e-16, 5.5511e-16, 8.3267e-16, 4.7184e-16, 5.5511e-16,\n",
      "         3.3307e-16, 2.7756e-17, 8.0491e-16, 7.3552e-16, 3.3307e-16, 7.7716e-16,\n",
      "         1.0547e-15, 1.7347e-16, 4.1633e-16, 5.5511e-16, 4.8572e-16, 7.1644e-16,\n",
      "         1.0547e-15, 4.8572e-17, 3.6950e-16, 4.4409e-16, 0.0000e+00, 6.1062e-16,\n",
      "         1.1380e-15, 2.0539e-15, 6.7134e-16, 3.1919e-16, 6.9389e-16, 3.2960e-16,\n",
      "         1.3323e-15, 2.6368e-16, 1.8041e-16, 7.6328e-17, 3.1086e-15, 1.6098e-15,\n",
      "         5.1348e-16, 4.2045e-16, 8.0491e-16, 4.9960e-16, 7.2164e-16, 7.0083e-16,\n",
      "         2.5535e-15, 2.2204e-16, 6.1062e-16, 2.2204e-15, 3.0531e-16, 1.0547e-15,\n",
      "         6.1062e-16, 1.2212e-15, 2.6021e-17, 7.2164e-16, 6.6613e-16, 1.9429e-16,\n",
      "         1.3323e-15, 6.1062e-16, 4.8572e-16, 1.6653e-15, 1.9984e-15, 8.1879e-16,\n",
      "         3.7817e-16, 4.8572e-16, 7.7716e-16, 1.6376e-15, 1.7764e-15, 2.7756e-16,\n",
      "         8.6042e-16, 1.4433e-15, 8.8818e-16, 1.5543e-15, 1.5751e-15, 4.4409e-16,\n",
      "         9.9920e-16, 2.2204e-15, 1.3323e-15, 1.5543e-15, 3.1398e-16, 9.4369e-16,\n",
      "         7.2164e-16, 2.2204e-15, 1.4433e-15, 9.7145e-16, 2.6645e-15, 2.7756e-16,\n",
      "         1.4433e-15, 2.4980e-16, 6.3838e-16, 1.3323e-15, 1.1657e-15, 2.3592e-16,\n",
      "         9.4976e-17, 1.4433e-15, 1.2182e-15, 6.6613e-16, 3.0531e-16, 8.8818e-16,\n",
      "         1.0131e-15, 3.3307e-16, 1.8874e-15, 1.2212e-15, 1.1102e-15, 7.4940e-16,\n",
      "         6.6613e-16, 9.9920e-16, 1.6653e-15, 2.8588e-15, 4.4409e-16, 1.7764e-15,\n",
      "         4.8572e-16, 1.6653e-16, 6.6613e-16, 8.3267e-16, 2.4807e-16, 1.4433e-15,\n",
      "         1.4294e-15, 2.8449e-16, 9.9920e-16, 3.8858e-16, 4.4409e-16, 1.3878e-16,\n",
      "         2.5535e-15, 1.7764e-15, 2.2204e-15, 7.4940e-16, 1.0547e-15, 2.3315e-15,\n",
      "         9.7145e-16, 4.4409e-15, 1.2768e-15, 1.7764e-15, 9.9920e-16, 1.3323e-15,\n",
      "         1.1102e-15, 1.1657e-15, 1.1102e-15, 9.9920e-16, 1.3323e-15, 1.4710e-15,\n",
      "         2.4147e-15, 9.9920e-16, 1.0131e-15, 2.3870e-15, 1.6653e-15, 4.7184e-16,\n",
      "         7.8410e-16, 1.4433e-15, 8.8818e-16, 4.1633e-16, 1.4433e-15, 8.3267e-16,\n",
      "         1.1657e-15, 1.3323e-15, 1.7486e-15, 2.1094e-15, 2.4425e-15, 1.5682e-15,\n",
      "         1.7486e-15, 1.6098e-15, 9.1593e-16, 9.7145e-16, 1.2212e-15, 1.1102e-15,\n",
      "         7.6328e-16, 5.5511e-16, 7.2164e-16, 4.9960e-16, 7.7716e-16, 1.5682e-15,\n",
      "         1.9984e-15, 1.1935e-15, 2.1094e-15, 1.2212e-15, 2.5535e-15, 1.8874e-15,\n",
      "         1.0825e-15, 6.1062e-16, 1.0677e-15, 1.5543e-15, 1.8874e-15, 1.4433e-15,\n",
      "         9.4369e-16, 1.3045e-15, 1.5543e-15, 3.3307e-15]], dtype=torch.float64)\n",
      " tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])  (len = 254)\n",
      "passing Cout = tensor([ 1, 94])  (len = 2)\n",
      "\n",
      "Executing module 167: layer3.15.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 167\n",
      "Max diff:\n",
      " tensor([3.1086e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.5511e-16, 4.3299e-15, 1.5266e-15, 3.9968e-15, 1.7764e-15, 1.5543e-15,\n",
      "         1.9706e-15, 5.7732e-15, 4.9960e-16, 1.6098e-15, 2.4425e-15, 1.2212e-15,\n",
      "         1.3323e-15, 5.7732e-15, 1.9984e-15, 1.7764e-15, 3.5527e-15, 8.8818e-16,\n",
      "         3.6637e-15, 8.8818e-16, 1.7764e-15, 1.8319e-15, 3.0531e-16, 6.6613e-16,\n",
      "         3.1086e-15, 3.3307e-16, 8.8818e-16, 1.8735e-15, 1.2212e-15, 2.6645e-15,\n",
      "         1.6653e-15, 1.8874e-15, 3.1086e-15, 5.3568e-15, 1.9984e-15, 3.8858e-16,\n",
      "         1.1380e-15, 9.9920e-16, 1.8319e-15, 3.1364e-15, 7.1054e-15, 1.3878e-15,\n",
      "         1.6653e-15, 4.2188e-15, 5.5511e-15, 1.4433e-15, 2.1094e-15, 9.1593e-16,\n",
      "         3.7470e-16, 1.7764e-15, 4.2188e-15, 1.1102e-15, 3.0809e-15, 1.3600e-15,\n",
      "         1.0165e-15, 3.5527e-15, 1.2490e-15, 1.8874e-15, 2.3453e-15, 1.6653e-15,\n",
      "         3.3307e-15, 3.3307e-16, 7.5495e-15, 7.2164e-16, 5.7732e-15, 8.0491e-16,\n",
      "         6.4393e-15, 6.4393e-15, 1.7764e-15, 5.4956e-15, 1.1546e-14, 1.7764e-15,\n",
      "         3.6637e-15, 5.7870e-15, 2.8311e-15, 7.1054e-15, 7.9936e-15, 8.4377e-15,\n",
      "         1.7764e-15, 5.4123e-16, 4.6629e-15, 7.9936e-15, 5.5511e-16, 1.1990e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7716e-15, 9.9920e-16, 8.4377e-15, 7.1644e-16,\n",
      "         2.7756e-15, 3.6637e-15, 1.2768e-15, 4.4409e-16, 2.4425e-15, 2.4702e-15,\n",
      "         5.3291e-15, 2.6090e-15, 3.9968e-15, 7.1054e-15, 2.2204e-15, 1.3600e-15,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 3.1086e-15, 1.9984e-15,\n",
      "         3.8858e-15, 2.4425e-15, 5.7732e-15, 6.2172e-15, 1.3323e-15, 4.4409e-15,\n",
      "         4.0523e-15, 7.9936e-15, 5.4401e-15, 2.4425e-15, 5.5511e-15, 5.3291e-15,\n",
      "         9.9920e-16, 1.2212e-15, 4.3299e-15, 3.9968e-15, 2.6645e-15, 4.3299e-15,\n",
      "         3.5527e-15, 2.8311e-15, 2.1649e-15, 6.2172e-15, 1.9984e-15, 4.3576e-15,\n",
      "         5.3291e-15, 5.1070e-15, 1.0658e-14, 4.8850e-15, 2.1372e-15, 5.5511e-16,\n",
      "         1.0658e-14, 3.4972e-15, 4.4409e-15, 2.2621e-15, 2.2204e-15, 1.0658e-14,\n",
      "         7.9936e-15, 2.2204e-15, 1.7764e-15, 4.4409e-15, 1.7764e-14, 9.4369e-16,\n",
      "         1.1546e-14, 4.2188e-15, 5.3291e-15, 9.7145e-16, 2.6645e-15, 7.1054e-15,\n",
      "         6.4393e-15, 5.1625e-15, 9.3259e-15, 1.3323e-15, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 1.4433e-15, 2.6645e-15, 1.6653e-15, 1.4433e-14, 3.5527e-15,\n",
      "         2.1316e-14, 8.8818e-16, 3.1086e-15, 1.1546e-14, 3.6637e-15, 1.0436e-14,\n",
      "         2.2204e-15, 1.2990e-14, 5.5511e-15, 2.8588e-15, 7.9936e-15, 4.4964e-15,\n",
      "         3.7748e-15, 2.6645e-15, 1.7208e-15, 1.5543e-15, 3.3307e-15, 4.4409e-15,\n",
      "         1.3767e-14, 4.6074e-15, 1.4211e-14, 9.7700e-15, 1.2768e-15, 2.2204e-15,\n",
      "         1.0658e-14, 2.4869e-14, 1.2434e-14, 1.4710e-15, 2.6645e-15, 8.8818e-15,\n",
      "         4.4409e-15, 1.5099e-14, 9.7700e-15, 6.3283e-15, 1.1324e-14, 3.3307e-15,\n",
      "         1.0658e-14, 1.4211e-14, 3.5527e-15, 1.6209e-14, 3.9968e-15, 3.1641e-15,\n",
      "         3.4972e-15, 3.1086e-14, 1.7764e-14, 5.5511e-15, 7.7716e-15, 5.7732e-15,\n",
      "         8.8818e-15, 1.0214e-14, 5.7732e-15, 1.0270e-15, 7.9936e-15, 1.9540e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.9968e-15, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.5099e-14, 9.3259e-15, 5.3291e-15, 1.1102e-14, 2.6645e-14, 8.6597e-15,\n",
      "         1.0658e-14, 1.9984e-15, 4.4409e-15, 1.4211e-14, 3.9968e-15, 7.1054e-15,\n",
      "         1.9984e-15, 8.4377e-15, 4.4409e-15, 5.5511e-15, 7.1054e-15, 1.5543e-14,\n",
      "         8.8818e-15, 8.8818e-15, 7.9936e-15, 9.1038e-15, 1.4211e-14, 9.7700e-15,\n",
      "         2.4425e-15, 3.5527e-15, 6.2172e-15, 1.1990e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 168: layer3.15.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 168\n",
      "Max diff:\n",
      " tensor([3.1086e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 4.3299e-15, 1.3878e-15, 3.9968e-15, 1.7764e-15, 0.0000e+00,\n",
      "         1.9706e-15, 5.7732e-15, 0.0000e+00, 1.6098e-15, 1.7764e-15, 4.4409e-16,\n",
      "         1.3323e-15, 5.7732e-15, 1.9984e-15, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         3.6637e-15, 0.0000e+00, 0.0000e+00, 1.6653e-15, 2.2204e-16, 6.6613e-16,\n",
      "         3.1086e-15, 3.3307e-16, 6.6613e-16, 1.8735e-15, 4.4409e-16, 2.6645e-15,\n",
      "         1.6653e-15, 1.8874e-15, 3.1086e-15, 5.3568e-15, 7.2164e-16, 0.0000e+00,\n",
      "         1.1380e-15, 2.7756e-16, 1.8319e-15, 1.3600e-15, 7.1054e-15, 1.2768e-15,\n",
      "         1.6653e-15, 4.2188e-15, 5.5511e-15, 0.0000e+00, 2.1094e-15, 9.1593e-16,\n",
      "         2.7756e-17, 1.7764e-15, 4.2188e-15, 7.2164e-16, 2.8866e-15, 1.3600e-15,\n",
      "         7.4940e-16, 3.4694e-15, 1.2490e-15, 1.9429e-16, 2.3453e-15, 1.6653e-15,\n",
      "         3.3307e-15, 0.0000e+00, 7.5495e-15, 5.1348e-16, 5.7732e-15, 8.0491e-16,\n",
      "         6.4393e-15, 6.4393e-15, 1.7764e-15, 5.4956e-15, 1.1546e-14, 1.7764e-15,\n",
      "         3.6637e-15, 5.7870e-15, 2.8311e-15, 7.1054e-15, 7.9936e-15, 8.4377e-15,\n",
      "         1.7764e-15, 3.3307e-16, 4.6629e-15, 7.9936e-15, 5.5511e-16, 1.1990e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7716e-15, 4.9960e-16, 8.4377e-15, 7.1644e-16,\n",
      "         2.7756e-15, 3.6637e-15, 8.8818e-16, 0.0000e+00, 2.4425e-15, 3.6082e-16,\n",
      "         5.3291e-15, 2.6090e-15, 3.9968e-15, 7.1054e-15, 2.2204e-15, 8.8818e-16,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 7.3552e-16, 1.9984e-15,\n",
      "         3.8858e-15, 2.4425e-15, 5.7732e-15, 6.2172e-15, 1.3323e-15, 4.4409e-15,\n",
      "         4.0523e-15, 7.9936e-15, 5.4401e-15, 6.6613e-16, 5.5511e-15, 5.3291e-15,\n",
      "         9.9920e-16, 1.1380e-15, 4.3299e-15, 3.9968e-15, 2.6645e-15, 4.3299e-15,\n",
      "         2.3315e-15, 2.7200e-15, 2.1649e-15, 6.2172e-15, 5.5511e-16, 4.3576e-15,\n",
      "         5.3291e-15, 5.1070e-15, 1.0658e-14, 4.8850e-15, 1.7208e-15, 5.5511e-16,\n",
      "         1.0658e-14, 1.8874e-15, 4.4409e-15, 2.2204e-15, 2.2204e-15, 1.0658e-14,\n",
      "         7.9936e-15, 1.6515e-15, 1.6653e-15, 4.4409e-15, 1.7764e-14, 3.3307e-16,\n",
      "         1.1546e-14, 4.2188e-15, 5.3291e-15, 6.6613e-16, 1.3323e-15, 7.1054e-15,\n",
      "         6.4393e-15, 5.1625e-15, 9.3259e-15, 5.5511e-16, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 6.3838e-16, 2.6645e-15, 1.6653e-15, 1.4433e-14, 3.5527e-15,\n",
      "         2.1316e-14, 8.8818e-16, 0.0000e+00, 1.1546e-14, 3.4139e-15, 1.0436e-14,\n",
      "         2.2204e-15, 1.2990e-14, 5.5511e-15, 3.1919e-16, 7.9936e-15, 4.4964e-15,\n",
      "         3.7748e-15, 2.6645e-15, 1.7208e-15, 1.5543e-15, 3.3307e-15, 4.4409e-15,\n",
      "         1.3767e-14, 4.6074e-15, 1.4211e-14, 9.7700e-15, 0.0000e+00, 2.2204e-15,\n",
      "         1.0658e-14, 2.4869e-14, 1.2434e-14, 1.4710e-15, 2.6645e-15, 8.8818e-15,\n",
      "         4.4409e-15, 1.5099e-14, 9.7700e-15, 6.3283e-15, 1.1324e-14, 3.3307e-15,\n",
      "         1.0658e-14, 1.4211e-14, 3.5527e-15, 1.4211e-14, 3.9968e-15, 3.1641e-15,\n",
      "         3.4972e-15, 3.1086e-14, 1.7764e-14, 5.5511e-15, 7.7716e-15, 5.7732e-15,\n",
      "         8.8818e-15, 1.0214e-14, 5.7732e-15, 1.0270e-15, 7.9936e-15, 1.9540e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.9968e-15, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.5099e-14, 9.3259e-15, 5.3291e-15, 1.1102e-14, 2.6645e-14, 8.6597e-15,\n",
      "         1.0658e-14, 1.9984e-15, 4.4409e-15, 1.4211e-14, 3.9968e-15, 7.1054e-15,\n",
      "         1.7764e-15, 8.4377e-15, 4.4409e-15, 5.5511e-15, 7.1054e-15, 1.5543e-14,\n",
      "         8.8818e-15, 8.8818e-15, 7.9936e-15, 9.1038e-15, 1.4211e-14, 9.7700e-15,\n",
      "         2.4425e-15, 3.5527e-15, 6.2172e-15, 1.1990e-14]], dtype=torch.float64)\n",
      " tensor([  1,   2,   3,   4,   6,   7,   9,  10,  11,  12,  13,  14,  16,  18,\n",
      "         21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  44,  46,  47,  48,  49,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  94,\n",
      "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   4,   6,   7,   9,  10,  11,  12,  13,  14,  16,  18,\n",
      "         21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,\n",
      "         36,  37,  38,  39,  40,  41,  42,  43,  44,  46,  47,  48,  49,  50,\n",
      "         51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  94,\n",
      "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])  (len = 243)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 169: layer3.16.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 169\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 169\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 169\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 169\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 169\n",
      "Max diff:\n",
      " tensor([2.2737e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-15, 7.1054e-15, 7.8160e-14, 7.1054e-14, 4.9738e-14, 5.7732e-15,\n",
      "         1.4211e-14, 2.4869e-14, 5.3291e-15, 2.6645e-15, 2.4869e-14, 1.2434e-14,\n",
      "         4.9738e-14, 1.4211e-14, 1.5987e-14, 1.0658e-14, 1.2434e-14, 1.7764e-14,\n",
      "         7.1054e-15, 5.3291e-15, 5.3291e-15, 2.1316e-14, 1.4211e-14, 5.3291e-15,\n",
      "         7.1054e-15, 5.3291e-15, 3.1974e-14, 1.4211e-14, 7.1054e-15, 7.9936e-15,\n",
      "         1.0658e-14, 3.9080e-14, 2.8422e-14, 1.5987e-14, 2.4869e-14, 1.4211e-14,\n",
      "         6.2172e-15, 1.4211e-14, 1.0658e-14, 3.1086e-15, 4.2633e-14, 7.8160e-14,\n",
      "         7.1054e-15, 4.2633e-14, 6.2172e-15, 2.8422e-14, 5.3291e-15, 6.2172e-15,\n",
      "         1.7764e-14, 3.1974e-14, 5.3291e-15, 3.1974e-14, 5.3291e-15, 5.6843e-14,\n",
      "         1.5987e-14, 2.1316e-14, 7.1054e-15, 1.0658e-14, 3.1974e-14, 4.4409e-15,\n",
      "         2.4869e-14, 3.5527e-14, 2.1316e-14, 2.8422e-14, 1.7764e-14, 1.7764e-14,\n",
      "         2.8422e-14, 7.9936e-15, 2.8422e-14, 4.2633e-14, 9.9476e-14, 9.7700e-15,\n",
      "         1.5987e-14, 7.1054e-15, 3.1974e-14, 4.9738e-14, 3.1974e-14, 7.9936e-15,\n",
      "         2.8422e-14, 3.1974e-14, 5.6843e-14, 3.9968e-15, 2.1316e-14, 4.9738e-14,\n",
      "         2.6645e-15, 1.7764e-14, 9.7700e-15, 2.4869e-14, 2.4869e-14, 6.3949e-14,\n",
      "         6.2172e-15, 5.6843e-14, 2.1316e-14, 4.9738e-14, 5.6843e-14, 4.4409e-15,\n",
      "         5.3291e-15, 4.2633e-14, 1.4211e-14, 9.9476e-14, 6.2172e-15, 2.1316e-14,\n",
      "         3.5527e-14, 1.7764e-14, 1.0658e-14, 9.7700e-15, 1.0658e-14, 7.1054e-15,\n",
      "         5.6843e-14, 1.0658e-14, 7.1054e-14, 2.1316e-14, 1.2434e-14, 1.7764e-14,\n",
      "         1.7764e-14, 1.2434e-14, 1.7764e-14, 1.0658e-14, 4.2633e-14, 9.7700e-15,\n",
      "         3.5527e-14, 2.4869e-14, 5.6843e-14, 7.1054e-15, 2.1316e-14, 6.2172e-15,\n",
      "         2.1316e-14, 6.3949e-14, 5.6843e-14, 3.5527e-14, 2.8422e-14, 7.9936e-15,\n",
      "         4.2633e-14, 2.4869e-14, 4.7962e-14, 4.2633e-14, 6.2172e-15, 2.1316e-14,\n",
      "         1.4211e-14, 3.9080e-14, 3.5527e-14, 2.1316e-14, 1.7764e-14, 4.9738e-14,\n",
      "         5.6843e-14, 5.3291e-15, 1.7764e-14, 2.4869e-14, 5.6843e-14, 2.8422e-14,\n",
      "         1.0658e-14, 2.4869e-14, 2.1316e-14, 2.1316e-14, 7.9936e-15, 3.9080e-14,\n",
      "         3.9080e-14, 2.1316e-14, 7.1054e-15, 1.4211e-14, 7.1054e-15, 2.8422e-14,\n",
      "         7.9936e-15, 4.2633e-14, 3.1974e-14, 4.6185e-14, 4.9738e-14, 1.2434e-14,\n",
      "         2.8422e-14, 1.2790e-13, 1.7764e-14, 6.3949e-14, 2.4869e-14, 7.8160e-14,\n",
      "         1.4211e-14, 8.8818e-15, 8.8818e-15, 8.5265e-14, 4.9738e-14, 5.6843e-14,\n",
      "         1.9540e-14, 6.3949e-14, 4.6185e-14, 7.1054e-14, 4.2633e-14, 7.1054e-14,\n",
      "         1.2434e-14, 3.1974e-14, 1.4211e-14, 4.9738e-14, 6.3949e-14, 4.9738e-14,\n",
      "         9.9476e-14, 4.2633e-14, 1.9895e-13, 1.1369e-13, 1.1369e-13, 1.4211e-13,\n",
      "         2.1316e-14, 1.1369e-13, 1.1369e-13, 5.6843e-14, 9.9476e-14, 1.1369e-13,\n",
      "         1.4211e-13, 1.5632e-13, 8.5265e-14, 1.5632e-13, 1.7053e-13, 2.8422e-14,\n",
      "         7.1054e-14, 2.8422e-14, 8.5265e-14, 8.5265e-14, 1.4211e-13, 7.8160e-14,\n",
      "         1.1369e-13, 8.5265e-14, 9.9476e-14, 4.9738e-14, 7.1054e-14, 6.0396e-14,\n",
      "         1.7053e-13, 1.1369e-13, 7.1054e-14, 6.3949e-14, 2.4869e-14, 3.5527e-14,\n",
      "         1.7053e-13, 9.9476e-14, 1.2790e-13, 1.1369e-13, 1.5987e-14, 4.6185e-14,\n",
      "         4.2633e-14, 6.3949e-14, 8.5265e-14, 4.9738e-14, 1.1369e-13, 1.2790e-13,\n",
      "         9.2371e-14, 2.2737e-13, 3.8192e-14, 4.2633e-14, 1.2790e-13, 1.1369e-13,\n",
      "         1.2790e-13, 4.9738e-14, 1.8474e-13, 4.2633e-14, 1.9895e-13, 5.6843e-14,\n",
      "         5.6843e-14, 7.1054e-14, 1.4211e-13, 9.9476e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 170: layer3.16.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 170\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 170\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 170\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 170\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 170\n",
      "Max diff:\n",
      " tensor([4.9738e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.7716e-16, 1.2212e-15, 1.2434e-14, 1.2434e-14, 7.1054e-15, 9.9920e-16,\n",
      "         2.6645e-15, 3.1086e-15, 9.9920e-16, 4.4409e-16, 4.4409e-15, 1.2212e-15,\n",
      "         6.2172e-15, 1.7764e-15, 3.9968e-15, 1.5543e-15, 1.5543e-15, 3.1086e-15,\n",
      "         1.1102e-15, 8.8818e-16, 9.9920e-16, 3.5527e-15, 1.5543e-15, 8.8818e-16,\n",
      "         1.4433e-15, 1.1102e-15, 4.8850e-15, 3.5527e-15, 1.7764e-15, 9.9920e-16,\n",
      "         2.2204e-15, 8.8818e-15, 3.9968e-15, 1.9984e-15, 3.9968e-15, 2.2204e-15,\n",
      "         8.8818e-16, 3.1086e-15, 1.6653e-15, 6.6613e-16, 5.3291e-15, 1.0658e-14,\n",
      "         1.3323e-15, 5.3291e-15, 8.8818e-16, 5.3291e-15, 8.8818e-16, 1.3323e-15,\n",
      "         3.1086e-15, 4.4409e-15, 7.7716e-16, 6.2172e-15, 8.8818e-16, 5.3291e-15,\n",
      "         2.6645e-15, 3.1086e-15, 1.5543e-15, 2.6645e-15, 3.9968e-15, 7.7716e-16,\n",
      "         2.2204e-15, 4.8850e-15, 3.5527e-15, 5.3291e-15, 3.1086e-15, 2.8866e-15,\n",
      "         2.6645e-15, 1.5543e-15, 6.2172e-15, 8.8818e-15, 8.8818e-15, 1.7764e-15,\n",
      "         2.6645e-15, 1.3323e-15, 7.1054e-15, 7.1054e-15, 6.2172e-15, 1.4433e-15,\n",
      "         4.4409e-15, 4.4409e-15, 8.8818e-15, 6.6613e-16, 3.9968e-15, 9.7700e-15,\n",
      "         6.6613e-16, 1.9984e-15, 2.2204e-15, 4.4409e-15, 3.1086e-15, 8.8818e-15,\n",
      "         1.3323e-15, 7.1054e-15, 3.5527e-15, 7.1054e-15, 1.2434e-14, 9.9920e-16,\n",
      "         9.9920e-16, 8.8818e-15, 2.6645e-15, 2.4869e-14, 1.1102e-15, 3.9968e-15,\n",
      "         4.8850e-15, 3.1086e-15, 1.7764e-15, 1.9984e-15, 2.2204e-15, 1.3323e-15,\n",
      "         7.1054e-15, 1.9984e-15, 1.4211e-14, 3.5527e-15, 2.2204e-15, 2.8866e-15,\n",
      "         3.1086e-15, 2.8866e-15, 4.4409e-15, 1.7764e-15, 7.9936e-15, 1.8874e-15,\n",
      "         5.3291e-15, 4.4409e-15, 1.2434e-14, 1.5543e-15, 3.5527e-15, 1.1102e-15,\n",
      "         2.2204e-15, 8.8818e-15, 1.4211e-14, 6.2172e-15, 5.7732e-15, 1.1102e-15,\n",
      "         3.1086e-15, 5.3291e-15, 7.9936e-15, 7.1054e-15, 9.9920e-16, 4.4409e-15,\n",
      "         2.4425e-15, 9.7700e-15, 5.3291e-15, 4.4409e-15, 3.1086e-15, 5.7732e-15,\n",
      "         6.2172e-15, 1.1102e-15, 3.5527e-15, 3.1086e-15, 7.1054e-15, 4.4409e-15,\n",
      "         1.9984e-15, 3.1086e-15, 3.5527e-15, 3.1086e-15, 1.3323e-15, 6.2172e-15,\n",
      "         5.3291e-15, 4.4409e-15, 1.3323e-15, 2.2204e-15, 1.5543e-15, 6.2172e-15,\n",
      "         1.7764e-15, 8.8818e-15, 6.2172e-15, 6.2172e-15, 7.9936e-15, 2.2204e-15,\n",
      "         5.3291e-15, 1.5987e-14, 4.4409e-15, 3.9968e-15, 5.1070e-15, 1.5987e-14,\n",
      "         3.1086e-15, 1.7764e-15, 1.7764e-15, 3.1974e-14, 8.8818e-15, 1.1546e-14,\n",
      "         4.4409e-15, 1.2434e-14, 7.1054e-15, 1.2434e-14, 8.4377e-15, 1.0658e-14,\n",
      "         2.4425e-15, 5.3291e-15, 2.2204e-15, 1.2434e-14, 7.9936e-15, 7.9936e-15,\n",
      "         2.1316e-14, 7.9936e-15, 2.3093e-14, 2.4869e-14, 2.8422e-14, 4.2633e-14,\n",
      "         6.2172e-15, 2.4869e-14, 2.8422e-14, 1.2434e-14, 1.9540e-14, 1.5987e-14,\n",
      "         3.1974e-14, 4.2633e-14, 1.7764e-14, 2.8422e-14, 3.9080e-14, 6.2172e-15,\n",
      "         1.1546e-14, 6.2172e-15, 2.1316e-14, 1.0658e-14, 2.8422e-14, 1.6875e-14,\n",
      "         2.1316e-14, 1.4211e-14, 2.1316e-14, 1.2434e-14, 1.0658e-14, 1.0658e-14,\n",
      "         4.9738e-14, 2.4869e-14, 1.2434e-14, 1.5987e-14, 6.2172e-15, 7.1054e-15,\n",
      "         4.2633e-14, 2.1316e-14, 3.5527e-14, 1.9540e-14, 2.4425e-15, 1.4211e-14,\n",
      "         1.1546e-14, 1.2434e-14, 1.7764e-14, 1.7764e-14, 2.4869e-14, 2.4869e-14,\n",
      "         1.9540e-14, 2.4869e-14, 8.8818e-15, 8.8818e-15, 1.4211e-14, 1.7764e-14,\n",
      "         2.1316e-14, 1.0658e-14, 3.1974e-14, 1.2434e-14, 4.6185e-14, 1.0658e-14,\n",
      "         8.8818e-15, 1.5987e-14, 2.4869e-14, 2.4869e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 171: layer3.16.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 171\n",
      "Max diff:\n",
      " tensor([7.9936e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.3267e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5821e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9968e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8850e-15,\n",
      "         3.8580e-15, 1.3323e-15, 6.7914e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.1609e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1070e-15, 0.0000e+00, 7.3275e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.6984e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7724e-15, 8.8818e-16,\n",
      "         0.0000e+00, 7.9936e-15, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([  2, 126, 134, 147, 155, 179, 180, 181, 182, 205, 210, 214, 219, 221,\n",
      "        242, 250, 251, 253])\n",
      "\n",
      "failing Cout = tensor([  2, 126, 134, 147, 155, 179, 180, 181, 182, 205, 210, 214, 219, 221,\n",
      "        242, 250, 251, 253])  (len = 18)\n",
      "passing Cout = tensor([230])  (len = 1)\n",
      "\n",
      "Executing module 172: layer3.16.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 172\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 70,  71,  72,  76,  80,  82,  93,  97, 104, 108, 112, 117, 123, 126]) to machine 1\n",
      "\t\t sending C_out tensor([128, 133, 136, 138, 139, 148, 155, 156, 164, 181, 182, 183, 188]) to machine 2\n",
      "\t\t sending C_out tensor([198, 199, 206, 207, 209, 210, 220, 225, 226, 227, 232, 233, 235, 238,\n",
      "        243]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 172\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  4,  6,  7,  8,  9, 10, 12, 13, 14, 16, 18, 22, 29, 30, 33, 35,\n",
      "        39, 42, 43, 45, 48, 50, 52, 54, 56, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([130, 136, 137, 141, 143, 144, 154, 157, 164, 169, 172, 173, 174, 179,\n",
      "        182, 186, 189, 190]) to machine 2\n",
      "\t\t sending C_out tensor([193, 195, 199, 203, 205, 211, 214, 215, 216, 222, 226, 228, 232, 234,\n",
      "        235, 237, 238, 241, 242, 244, 245, 246, 248, 251]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 172\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  86,  88,  89,  90,  91,  92,  93,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206,\n",
      "        207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 172\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38,\n",
      "        39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
      "        57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,  91,  92,  93,\n",
      "         94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 172\n",
      "Max diff:\n",
      " tensor([6.6613e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.8866e-15, 2.2204e-15, 5.1070e-15, 6.2172e-15, 1.9984e-15, 1.3323e-15,\n",
      "         2.1094e-15, 1.4433e-15, 1.3323e-15, 2.2482e-15, 1.1380e-15, 1.4988e-15,\n",
      "         3.9968e-15, 2.8866e-15, 9.4369e-16, 2.6645e-15, 3.1086e-15, 4.2188e-15,\n",
      "         1.5543e-15, 3.1086e-15, 1.1657e-15, 3.9968e-15, 3.0254e-15, 2.4425e-15,\n",
      "         4.2188e-15, 4.1078e-15, 1.5543e-15, 2.6645e-15, 3.6082e-16, 2.2204e-15,\n",
      "         2.2204e-15, 4.4409e-15, 1.1102e-15, 1.7764e-15, 5.7732e-15, 2.9698e-15,\n",
      "         3.5527e-15, 5.7732e-15, 4.4409e-16, 1.9706e-15, 8.2573e-16, 2.8588e-15,\n",
      "         3.5527e-15, 1.9429e-15, 1.5543e-15, 1.0547e-15, 4.4409e-15, 3.2196e-15,\n",
      "         1.1241e-15, 1.7902e-15, 1.7764e-15, 9.3675e-16, 2.5258e-15, 1.8874e-15,\n",
      "         4.3195e-16, 1.7764e-15, 7.2164e-16, 4.4409e-15, 2.6645e-15, 1.9013e-15,\n",
      "         3.4070e-15, 4.2188e-15, 1.5543e-15, 1.2212e-15, 2.4425e-15, 2.8866e-15,\n",
      "         8.0491e-16, 1.2212e-15, 7.7716e-16, 1.0547e-15, 1.7764e-15, 2.6645e-15,\n",
      "         1.1102e-15, 2.4425e-15, 1.2629e-15, 3.1086e-15, 1.4017e-15, 2.1927e-15,\n",
      "         1.7764e-15, 2.9976e-15, 1.4988e-15, 4.8850e-15, 1.8596e-15, 1.8180e-15,\n",
      "         4.6629e-15, 4.1633e-17, 1.1102e-15, 1.5266e-15, 1.3323e-15, 1.9984e-15,\n",
      "         2.6645e-15, 2.2204e-15, 2.2204e-15, 2.4980e-15, 1.9984e-15, 1.2212e-15,\n",
      "         3.7748e-15, 3.3307e-15, 4.8850e-15, 2.8866e-15, 2.2204e-15, 7.5634e-16,\n",
      "         1.8319e-15, 1.7764e-15, 2.2204e-15, 2.6645e-15, 2.4980e-15, 1.5543e-15,\n",
      "         2.7756e-15, 1.1380e-15, 2.7756e-16, 4.4409e-15, 2.1094e-15, 2.2204e-15,\n",
      "         5.7732e-15, 2.7756e-15, 8.8818e-16, 3.6082e-15, 2.2760e-15, 3.5527e-15,\n",
      "         1.8319e-15, 1.5127e-15, 2.2204e-15, 1.1102e-15, 2.1233e-15, 2.3037e-15,\n",
      "         1.9984e-15, 3.3307e-15, 1.3045e-15, 3.1086e-15, 2.6645e-15, 3.1086e-15,\n",
      "         2.4425e-15, 1.7764e-15, 3.7192e-15, 1.5543e-15, 4.6395e-15, 1.3739e-15,\n",
      "         3.1086e-15, 3.1086e-15, 1.9429e-15, 2.4425e-15, 3.9968e-15, 6.6613e-15,\n",
      "         2.4425e-15, 4.4409e-15, 1.8319e-15, 2.3315e-15, 2.4425e-15, 3.5527e-15,\n",
      "         3.7748e-15, 3.7748e-15, 4.4409e-15, 2.2621e-15, 1.9984e-15, 3.1086e-15,\n",
      "         3.6082e-15, 1.6653e-15, 1.7156e-15, 2.3870e-15, 3.1086e-15, 1.3323e-15,\n",
      "         2.2204e-15, 4.4409e-15, 2.2204e-15, 1.7764e-15, 2.4425e-15, 2.6645e-15,\n",
      "         3.3307e-15, 2.8866e-15, 9.9920e-16, 4.2188e-15, 4.4409e-15, 3.9968e-15,\n",
      "         1.5543e-15, 2.6645e-15, 2.2204e-15, 2.9976e-15, 2.9976e-15, 2.4425e-15,\n",
      "         2.6645e-15, 3.1086e-15, 2.8866e-15, 5.9952e-15, 2.2204e-15, 5.7732e-15,\n",
      "         2.6645e-15, 1.6098e-15, 1.7764e-15, 3.1086e-15, 2.6090e-15, 4.8850e-15,\n",
      "         5.3291e-15, 3.5527e-15, 3.5527e-15, 4.2188e-15, 4.4409e-15, 4.8850e-15,\n",
      "         2.6645e-15, 2.8866e-15, 3.9968e-15, 2.4425e-15, 3.1086e-15, 3.7748e-15,\n",
      "         3.3307e-15, 5.7732e-15, 3.1086e-15, 6.6613e-15, 6.4393e-15, 3.1086e-15,\n",
      "         4.8850e-15, 2.7756e-15, 5.4401e-15, 4.8850e-15, 4.2188e-15, 2.6645e-15,\n",
      "         4.4409e-15, 3.1086e-15, 2.1094e-15, 3.6637e-15, 3.5527e-15, 2.3315e-15,\n",
      "         3.7748e-15, 5.9570e-15, 3.5527e-15, 3.3307e-15, 2.6923e-15, 2.4425e-15,\n",
      "         3.8858e-15, 3.1086e-15, 2.2204e-15, 2.8866e-15, 3.5527e-15, 3.1086e-15,\n",
      "         3.1086e-15, 5.7732e-15, 4.4409e-15, 6.2172e-15, 3.5527e-15, 3.8858e-15,\n",
      "         2.1649e-15, 5.7732e-15, 2.4425e-15, 3.7192e-15, 2.5535e-15, 3.9968e-15,\n",
      "         2.3453e-15, 2.6645e-15, 2.7756e-15, 4.2466e-15, 4.6629e-15, 3.7748e-15,\n",
      "         3.1086e-15, 3.5527e-15, 3.5527e-15, 4.5519e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 173: layer3.16.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 173\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 173\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 173\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 173\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 173\n",
      "Max diff:\n",
      " tensor([2.9976e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3878e-15, 8.8818e-16, 2.4425e-15, 1.6098e-15, 2.4980e-16, 4.4409e-16,\n",
      "         9.9920e-16, 1.1102e-16, 3.8858e-16, 9.4369e-16, 3.3307e-16, 2.7756e-17,\n",
      "         1.1102e-15, 5.2736e-16, 2.2204e-16, 1.1102e-15, 6.6613e-16, 1.2212e-15,\n",
      "         6.1062e-16, 8.8818e-16, 3.9552e-16, 1.7764e-15, 1.4433e-15, 1.1102e-15,\n",
      "         1.3323e-15, 2.5535e-15, 5.2736e-16, 1.2212e-15, 1.3878e-16, 2.7756e-16,\n",
      "         7.7716e-16, 2.2204e-15, 3.3307e-16, 5.5511e-16, 2.4425e-15, 3.8858e-16,\n",
      "         8.8818e-16, 2.9976e-15, 1.6653e-16, 6.8001e-16, 1.0235e-16, 8.3267e-16,\n",
      "         8.8818e-16, 3.6776e-16, 2.9143e-16, 1.5266e-16, 6.1062e-16, 7.7716e-16,\n",
      "         3.3307e-16, 4.7184e-16, 1.1102e-16, 2.7756e-16, 4.7184e-16, 7.7716e-16,\n",
      "         1.7000e-16, 4.0939e-16, 2.4980e-16, 1.1102e-15, 6.6613e-16, 6.1062e-16,\n",
      "         8.0491e-16, 1.2212e-15, 7.2164e-16, 4.4409e-16, 5.5511e-16, 7.2164e-16,\n",
      "         1.9429e-16, 4.4409e-16, 2.9143e-16, 4.0246e-16, 4.1633e-16, 4.4409e-16,\n",
      "         2.7756e-16, 5.8287e-16, 2.3961e-16, 7.2164e-16, 1.8041e-16, 4.2327e-16,\n",
      "         4.4409e-16, 7.4940e-16, 2.9837e-16, 1.1657e-15, 6.3838e-16, 2.9143e-16,\n",
      "         7.4940e-16, 6.0715e-18, 9.7145e-17, 4.1633e-16, 2.3592e-16, 1.9429e-16,\n",
      "         8.8818e-16, 6.6613e-16, 6.1062e-16, 7.2164e-16, 6.6613e-16, 3.8858e-16,\n",
      "         8.3267e-16, 9.4369e-16, 1.9984e-15, 6.1062e-16, 6.6613e-16, 6.2450e-17,\n",
      "         4.7965e-16, 2.7756e-16, 3.0531e-16, 7.2164e-16, 1.3184e-15, 5.5511e-16,\n",
      "         6.6960e-16, 2.5674e-16, 5.5511e-17, 1.0547e-15, 4.3021e-16, 3.8858e-16,\n",
      "         1.7764e-15, 7.7889e-16, 1.1102e-16, 6.8001e-16, 7.7716e-16, 1.5543e-15,\n",
      "         2.2204e-16, 5.6205e-16, 1.1102e-15, 1.6653e-16, 5.4123e-16, 5.0134e-16,\n",
      "         6.1062e-16, 1.6653e-16, 9.7145e-17, 4.5797e-16, 2.4980e-16, 7.7716e-16,\n",
      "         6.1062e-16, 7.7716e-16, 7.0777e-16, 3.6082e-16, 1.6237e-15, 4.7184e-16,\n",
      "         1.4017e-15, 1.3323e-15, 4.9873e-16, 2.7756e-16, 1.3323e-15, 2.2204e-15,\n",
      "         9.9920e-16, 1.9984e-15, 2.7756e-16, 5.5511e-16, 3.3307e-16, 6.6613e-16,\n",
      "         1.3878e-15, 1.1102e-15, 8.8818e-16, 6.6613e-16, 1.0547e-15, 2.2204e-16,\n",
      "         1.3323e-15, 7.7716e-16, 2.2898e-16, 1.0270e-15, 8.8818e-16, 6.9389e-18,\n",
      "         3.1919e-16, 1.1102e-15, 5.8634e-16, 6.6613e-16, 7.2164e-16, 9.9920e-16,\n",
      "         1.0547e-15, 9.4369e-16, 1.6653e-16, 1.2768e-15, 2.2204e-15, 1.9984e-15,\n",
      "         4.1633e-17, 9.4369e-16, 1.3878e-16, 1.0547e-15, 3.3307e-16, 4.8572e-16,\n",
      "         5.8287e-16, 9.9920e-16, 6.1062e-16, 2.8866e-15, 2.7756e-16, 2.3315e-15,\n",
      "         1.1102e-15, 3.4694e-16, 3.0184e-16, 4.9960e-16, 4.7184e-16, 2.8866e-15,\n",
      "         1.4433e-15, 4.6491e-16, 1.3323e-15, 7.7716e-16, 1.5543e-15, 1.4433e-15,\n",
      "         7.2164e-16, 1.5543e-15, 1.5543e-15, 1.1102e-15, 5.2736e-16, 9.4369e-16,\n",
      "         1.0547e-15, 1.8874e-15, 1.1102e-15, 1.7764e-15, 1.5543e-15, 9.9920e-16,\n",
      "         1.7764e-15, 9.9920e-16, 2.5535e-15, 1.1102e-15, 1.4988e-15, 5.8287e-16,\n",
      "         1.1657e-15, 1.3323e-15, 5.9674e-16, 8.3267e-16, 1.2212e-15, 6.7437e-16,\n",
      "         1.5543e-15, 1.3184e-15, 1.4433e-15, 1.3045e-15, 9.9920e-16, 8.3267e-16,\n",
      "         1.6653e-15, 6.1062e-16, 3.8858e-16, 8.8818e-16, 7.2164e-16, 8.8818e-16,\n",
      "         6.6613e-16, 6.6613e-16, 1.1102e-15, 1.4433e-15, 8.8818e-16, 9.4369e-16,\n",
      "         5.6899e-16, 2.2204e-15, 9.9920e-16, 7.7716e-16, 8.3267e-16, 1.5543e-15,\n",
      "         3.3307e-16, 8.3267e-16, 6.9389e-16, 1.3278e-15, 1.7764e-15, 1.1102e-15,\n",
      "         8.8818e-16, 9.9920e-16, 6.6613e-16, 1.9984e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 174: layer3.16.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 174\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3878e-15, 4.4409e-15, 2.4425e-15, 4.4409e-15, 1.7764e-15, 4.4409e-16,\n",
      "         2.3315e-15, 5.7732e-15, 3.8858e-16, 1.6653e-15, 1.7764e-15, 4.4409e-16,\n",
      "         1.9984e-15, 5.7732e-15, 1.9151e-15, 1.1102e-15, 3.5527e-15, 1.2212e-15,\n",
      "         3.6637e-15, 8.8818e-16, 3.9552e-16, 1.6653e-15, 1.4433e-15, 8.8818e-16,\n",
      "         3.1086e-15, 2.5535e-15, 6.1062e-16, 1.4433e-15, 4.4409e-16, 2.6645e-15,\n",
      "         1.7208e-15, 2.3315e-15, 3.1086e-15, 5.4817e-15, 2.4425e-15, 3.8858e-16,\n",
      "         8.8818e-16, 2.9976e-15, 1.8319e-15, 1.3184e-15, 7.1054e-15, 8.8818e-16,\n",
      "         1.8874e-15, 4.1911e-15, 5.5511e-15, 1.5266e-16, 2.1094e-15, 9.1593e-16,\n",
      "         3.3307e-16, 1.6653e-15, 4.2188e-15, 7.2164e-16, 2.8866e-15, 1.4988e-15,\n",
      "         7.4940e-16, 3.7470e-15, 1.2768e-15, 1.1102e-15, 2.4980e-15, 1.7764e-15,\n",
      "         3.2196e-15, 1.2212e-15, 7.7716e-15, 4.5797e-16, 5.7732e-15, 7.3552e-16,\n",
      "         6.4393e-15, 6.2172e-15, 1.7208e-15, 5.4956e-15, 1.1546e-14, 1.9429e-15,\n",
      "         3.6637e-15, 5.1903e-15, 2.8449e-15, 7.1054e-15, 7.9936e-15, 8.2157e-15,\n",
      "         1.7764e-15, 7.4940e-16, 4.8850e-15, 7.9936e-15, 6.3838e-16, 1.1990e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7161e-15, 4.9960e-16, 8.4377e-15, 6.7307e-16,\n",
      "         2.6645e-15, 3.6637e-15, 8.8818e-16, 7.2164e-16, 2.4425e-15, 3.8858e-16,\n",
      "         4.4409e-15, 3.2196e-15, 3.9968e-15, 7.1054e-15, 2.2204e-15, 8.6042e-16,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 1.3184e-15, 2.1302e-15,\n",
      "         3.9968e-15, 2.4425e-15, 5.8842e-15, 6.2172e-15, 1.3323e-15, 4.4409e-15,\n",
      "         4.4548e-15, 7.9936e-15, 5.3291e-15, 7.4940e-16, 5.5511e-15, 5.5511e-15,\n",
      "         9.9920e-16, 1.4433e-15, 4.3299e-15, 3.9968e-15, 2.6645e-15, 4.4409e-15,\n",
      "         2.3315e-15, 2.7200e-15, 2.1233e-15, 7.1054e-15, 5.9674e-16, 3.9690e-15,\n",
      "         5.3291e-15, 5.3291e-15, 1.0658e-14, 4.8850e-15, 1.6237e-15, 6.9389e-16,\n",
      "         1.1546e-14, 1.8874e-15, 4.4409e-15, 2.2204e-15, 2.6645e-15, 1.0658e-14,\n",
      "         7.5495e-15, 1.7764e-15, 1.4433e-15, 4.5519e-15, 1.7764e-14, 6.6613e-16,\n",
      "         1.1546e-14, 4.6629e-15, 5.3291e-15, 6.9389e-16, 1.5821e-15, 7.1054e-15,\n",
      "         5.9952e-15, 4.9578e-15, 9.3259e-15, 1.0270e-15, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 1.1102e-15, 2.6645e-15, 1.7764e-15, 1.4433e-14, 3.4417e-15,\n",
      "         2.1316e-14, 9.4369e-16, 1.6653e-16, 1.1546e-14, 3.7748e-15, 1.0214e-14,\n",
      "         2.2204e-15, 1.2546e-14, 5.5511e-15, 1.0547e-15, 7.9936e-15, 4.4686e-15,\n",
      "         3.9968e-15, 2.2204e-15, 1.6098e-15, 3.2474e-15, 3.5527e-15, 4.4409e-15,\n",
      "         1.4211e-14, 4.6629e-15, 1.4211e-14, 9.3259e-15, 4.7184e-16, 2.8866e-15,\n",
      "         1.0658e-14, 2.5757e-14, 1.2434e-14, 1.4294e-15, 2.7756e-15, 8.8818e-15,\n",
      "         4.7740e-15, 1.4211e-14, 8.8818e-15, 5.9952e-15, 1.1546e-14, 3.3307e-15,\n",
      "         1.0658e-14, 1.4211e-14, 3.5527e-15, 1.4211e-14, 3.7748e-15, 2.6645e-15,\n",
      "         3.6637e-15, 3.1974e-14, 1.7764e-14, 6.4393e-15, 7.9936e-15, 5.7732e-15,\n",
      "         8.8818e-15, 1.1102e-14, 5.5511e-15, 9.9920e-16, 7.9936e-15, 1.9540e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.5527e-15, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.5099e-14, 8.8818e-15, 5.3291e-15, 1.1546e-14, 2.5757e-14, 9.1038e-15,\n",
      "         1.0658e-14, 2.2204e-15, 5.3291e-15, 1.4877e-14, 4.3299e-15, 7.1054e-15,\n",
      "         1.3878e-15, 8.8818e-15, 5.1070e-15, 5.5511e-15, 7.1054e-15, 1.5099e-14,\n",
      "         8.8818e-15, 8.7708e-15, 7.8826e-15, 8.8818e-15, 1.4211e-14, 1.0658e-14,\n",
      "         2.4425e-15, 3.5527e-15, 6.6613e-15, 1.1768e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 175: layer3.16.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 175\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-16, 8.8818e-16, 2.4425e-15, 4.4409e-15, 1.7764e-15, 0.0000e+00,\n",
      "         1.0547e-15, 5.7732e-15, 3.8858e-16, 0.0000e+00, 1.7764e-15, 4.4409e-16,\n",
      "         1.3323e-15, 5.7732e-15, 1.8874e-15, 0.0000e+00, 3.5527e-15, 6.3838e-16,\n",
      "         0.0000e+00, 3.8858e-16, 3.6299e-16, 0.0000e+00, 9.4369e-16, 8.8818e-16,\n",
      "         1.6098e-15, 1.8319e-15, 5.5511e-16, 1.4433e-15, 4.4409e-16, 2.6645e-15,\n",
      "         1.7208e-15, 2.3315e-15, 3.1086e-15, 5.4817e-15, 5.2736e-16, 0.0000e+00,\n",
      "         8.3267e-16, 1.3878e-16, 1.8319e-15, 1.1657e-15, 7.1054e-15, 0.0000e+00,\n",
      "         1.8874e-15, 4.1911e-15, 5.5511e-15, 3.1225e-17, 6.6613e-16, 0.0000e+00,\n",
      "         0.0000e+00, 1.6653e-15, 4.2188e-15, 0.0000e+00, 2.8866e-15, 0.0000e+00,\n",
      "         7.4940e-16, 3.7470e-15, 1.2768e-15, 7.4940e-16, 2.4980e-15, 1.7764e-15,\n",
      "         3.2196e-15, 2.6368e-16, 7.7716e-15, 0.0000e+00, 5.7732e-15, 7.2164e-16,\n",
      "         6.4393e-15, 6.2172e-15, 1.7208e-15, 5.4956e-15, 1.1546e-14, 1.9429e-15,\n",
      "         3.6637e-15, 3.7748e-15, 2.8449e-15, 7.1054e-15, 7.9936e-15, 8.2157e-15,\n",
      "         1.7764e-15, 3.3307e-16, 4.8850e-15, 7.9936e-15, 4.9960e-16, 1.1990e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7161e-15, 4.9960e-16, 8.4377e-15, 6.6613e-16,\n",
      "         2.6645e-15, 3.6637e-15, 6.1062e-16, 0.0000e+00, 2.4425e-15, 3.6082e-16,\n",
      "         4.4409e-15, 3.2196e-15, 3.9968e-15, 7.1054e-15, 2.2204e-15, 8.6042e-16,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 7.3552e-16, 2.1302e-15,\n",
      "         3.9968e-15, 2.4425e-15, 5.8842e-15, 6.2172e-15, 1.3323e-15, 4.4409e-15,\n",
      "         4.4548e-15, 7.9936e-15, 5.3291e-15, 7.4940e-16, 5.5511e-15, 5.5511e-15,\n",
      "         9.9920e-16, 1.4433e-15, 4.3299e-15, 3.9968e-15, 2.6645e-15, 4.4409e-15,\n",
      "         2.3315e-15, 2.0539e-15, 2.1233e-15, 7.1054e-15, 5.5511e-16, 2.9976e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.0658e-14, 4.8850e-15, 1.0270e-15, 2.7756e-16,\n",
      "         1.1546e-14, 1.8874e-15, 4.4409e-15, 2.2204e-15, 2.6645e-15, 1.0658e-14,\n",
      "         7.5495e-15, 1.7764e-15, 1.4433e-15, 4.5519e-15, 1.7764e-14, 0.0000e+00,\n",
      "         1.1546e-14, 4.6629e-15, 5.3291e-15, 6.3838e-16, 1.5821e-15, 7.1054e-15,\n",
      "         5.9952e-15, 4.9578e-15, 9.3259e-15, 8.6042e-16, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 1.1102e-15, 2.6645e-15, 0.0000e+00, 1.4433e-14, 3.4417e-15,\n",
      "         2.1316e-14, 9.4369e-16, 0.0000e+00, 1.1546e-14, 3.7748e-15, 1.0214e-14,\n",
      "         2.2204e-15, 1.2546e-14, 5.5511e-15, 8.8818e-16, 7.9936e-15, 1.1102e-15,\n",
      "         3.9968e-15, 2.2204e-15, 1.6098e-15, 1.6653e-15, 3.5527e-15, 4.4409e-15,\n",
      "         1.4211e-14, 4.6629e-15, 1.4211e-14, 9.3259e-15, 0.0000e+00, 2.2204e-15,\n",
      "         1.0658e-14, 2.5757e-14, 1.2434e-14, 1.0131e-15, 2.7756e-15, 8.8818e-15,\n",
      "         4.7740e-15, 1.4211e-14, 8.8818e-15, 5.9952e-15, 1.1546e-14, 3.3307e-15,\n",
      "         1.0658e-14, 1.4211e-14, 3.5527e-15, 1.4211e-14, 3.7748e-15, 2.6645e-15,\n",
      "         3.6637e-15, 3.1974e-14, 1.7764e-14, 6.4393e-15, 7.9936e-15, 5.7732e-15,\n",
      "         8.8818e-15, 1.1102e-14, 5.5511e-15, 7.7716e-16, 7.9936e-15, 1.9540e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.5527e-15, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.5099e-14, 8.8818e-15, 5.3291e-15, 1.1546e-14, 2.5757e-14, 9.1038e-15,\n",
      "         1.0658e-14, 2.2204e-15, 5.3291e-15, 1.4877e-14, 4.3299e-15, 7.1054e-15,\n",
      "         1.3878e-15, 8.8818e-15, 5.1070e-15, 5.5511e-15, 7.1054e-15, 1.5099e-14,\n",
      "         8.8818e-15, 8.7708e-15, 7.8826e-15, 8.8818e-15, 1.4211e-14, 1.0658e-14,\n",
      "         2.4425e-15, 3.5527e-15, 6.6613e-15, 1.1768e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   6,   7,   8,  10,  11,  12,  13,  14,  16,\n",
      "         17,  19,  20,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
      "         33,  34,  36,  37,  38,  39,  40,  42,  43,  44,  45,  46,  49,  50,\n",
      "         52,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "         82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  94,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168,\n",
      "        169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "        227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   6,   7,   8,  10,  11,  12,  13,  14,  16,\n",
      "         17,  19,  20,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
      "         33,  34,  36,  37,  38,  39,  40,  42,  43,  44,  45,  46,  49,  50,\n",
      "         52,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "         82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  94,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "        125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168,\n",
      "        169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "        227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255])  (len = 239)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 176: layer3.17.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 176\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 176\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 176\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 176\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 176\n",
      "Max diff:\n",
      " tensor([2.1316e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5987e-14, 1.2434e-14, 3.9968e-15, 4.9738e-14, 8.8818e-15, 7.1054e-15,\n",
      "         3.1974e-14, 2.4869e-14, 8.5265e-14, 2.1316e-14, 8.8818e-15, 5.3291e-15,\n",
      "         3.9080e-14, 3.5527e-14, 5.3291e-15, 3.5527e-14, 7.1054e-15, 2.4869e-14,\n",
      "         1.7764e-14, 4.4409e-15, 3.1086e-15, 5.3291e-15, 2.8422e-14, 1.0658e-14,\n",
      "         6.2172e-15, 2.8422e-14, 5.6843e-14, 5.6843e-14, 3.9968e-15, 7.1054e-15,\n",
      "         2.1316e-14, 7.9936e-15, 7.1054e-15, 5.3291e-15, 3.5527e-14, 1.9540e-14,\n",
      "         2.4869e-14, 7.9936e-15, 2.1316e-14, 1.4211e-14, 3.5527e-15, 5.3291e-15,\n",
      "         2.3093e-14, 4.4409e-15, 2.8422e-14, 8.8818e-15, 6.2172e-15, 2.1316e-14,\n",
      "         7.9936e-15, 1.2434e-14, 1.4211e-14, 4.2633e-14, 1.1546e-14, 5.3291e-15,\n",
      "         7.1054e-15, 4.4409e-15, 7.1054e-15, 3.5527e-14, 7.1054e-15, 2.1316e-14,\n",
      "         7.1054e-15, 4.9738e-14, 2.6645e-14, 7.1054e-15, 2.1316e-14, 9.7700e-15,\n",
      "         5.3291e-15, 4.9738e-14, 2.8422e-14, 8.8818e-15, 2.2204e-15, 7.8160e-14,\n",
      "         3.5527e-14, 3.1974e-14, 2.8422e-14, 2.1316e-14, 2.3093e-14, 7.9936e-15,\n",
      "         2.1316e-14, 2.4869e-14, 6.2172e-15, 1.0658e-14, 7.1054e-14, 4.2633e-14,\n",
      "         7.9936e-15, 1.4211e-14, 5.6843e-14, 6.3949e-14, 2.8422e-14, 1.4211e-14,\n",
      "         3.5527e-15, 6.3949e-14, 7.1054e-15, 7.8160e-14, 2.8422e-14, 5.6843e-14,\n",
      "         2.8422e-14, 2.1316e-14, 1.4211e-14, 3.1974e-14, 7.9936e-15, 1.0658e-14,\n",
      "         4.2633e-14, 8.8818e-15, 6.3949e-14, 1.2434e-14, 5.3291e-15, 3.1974e-14,\n",
      "         2.4869e-14, 1.2434e-14, 1.4211e-14, 2.8422e-14, 1.4211e-14, 2.4869e-14,\n",
      "         5.6843e-14, 9.7700e-15, 7.1054e-14, 1.7764e-14, 1.7764e-14, 7.9936e-15,\n",
      "         1.0658e-14, 5.6843e-14, 4.6185e-14, 8.5265e-14, 1.9540e-14, 1.0658e-14,\n",
      "         7.1054e-15, 2.4869e-14, 4.2633e-14, 2.8422e-14, 1.7764e-14, 8.8818e-15,\n",
      "         2.8422e-14, 1.2434e-14, 3.9080e-14, 1.7764e-14, 3.5527e-14, 3.1974e-14,\n",
      "         5.6843e-14, 1.4211e-14, 3.1974e-14, 3.1974e-14, 4.9738e-14, 2.1316e-14,\n",
      "         7.1054e-14, 3.1974e-14, 8.8818e-15, 1.4211e-14, 1.4211e-14, 2.1316e-14,\n",
      "         6.3949e-14, 3.1974e-14, 9.9476e-14, 7.9936e-15, 7.9936e-15, 1.2434e-14,\n",
      "         9.7700e-15, 4.2633e-14, 2.2871e-14, 1.7764e-14, 7.9936e-15, 4.9738e-14,\n",
      "         1.4211e-14, 3.5527e-14, 6.3949e-14, 6.3949e-14, 7.1054e-14, 5.6843e-14,\n",
      "         2.1316e-14, 7.8160e-14, 1.0658e-14, 1.7764e-14, 3.5527e-14, 1.4211e-14,\n",
      "         1.7764e-14, 1.2434e-14, 1.4211e-14, 1.4211e-14, 8.8818e-15, 4.9738e-14,\n",
      "         2.8422e-14, 1.2434e-14, 1.4211e-14, 1.8474e-13, 8.5265e-14, 8.5265e-14,\n",
      "         1.4211e-13, 4.9738e-14, 1.2434e-14, 2.1316e-14, 4.2633e-14, 2.3093e-14,\n",
      "         1.9895e-13, 5.6843e-14, 3.1974e-14, 1.1369e-13, 1.1369e-13, 6.3949e-14,\n",
      "         1.7764e-14, 1.5632e-13, 9.9476e-14, 8.5265e-14, 8.5265e-14, 9.9476e-14,\n",
      "         9.9476e-14, 1.2790e-13, 9.9476e-14, 7.1054e-14, 4.2633e-14, 1.1369e-13,\n",
      "         1.7053e-13, 4.6185e-14, 1.1369e-13, 1.4211e-13, 1.2790e-13, 2.8422e-14,\n",
      "         5.6843e-14, 4.9738e-14, 1.4211e-13, 4.2633e-14, 9.2371e-14, 3.9080e-14,\n",
      "         3.5527e-14, 7.1054e-14, 7.8160e-14, 1.5632e-13, 4.9738e-14, 1.1369e-13,\n",
      "         1.7053e-13, 3.5527e-14, 8.5265e-14, 1.1369e-13, 9.9476e-14, 2.1316e-13,\n",
      "         7.8160e-14, 6.3949e-14, 6.3949e-14, 3.1974e-14, 5.3291e-14, 6.3949e-14,\n",
      "         7.8160e-14, 9.9476e-14, 8.5265e-14, 1.4211e-13, 6.3949e-14, 8.5265e-14,\n",
      "         1.1369e-13, 8.5265e-14, 8.5265e-14, 4.9738e-14, 1.4211e-13, 7.1054e-14,\n",
      "         9.2371e-14, 7.8160e-14, 1.5632e-13, 1.5632e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 177: layer3.17.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 177\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 177\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 177\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 177\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 177\n",
      "Max diff:\n",
      " tensor([4.6185e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.2204e-15, 2.4425e-15, 6.6613e-16, 4.8850e-15, 1.5543e-15, 1.3323e-15,\n",
      "         3.5527e-15, 3.9968e-15, 1.5987e-14, 3.5527e-15, 2.1094e-15, 7.7716e-16,\n",
      "         4.4409e-15, 3.5527e-15, 9.9920e-16, 4.4409e-15, 1.4433e-15, 3.5527e-15,\n",
      "         3.1086e-15, 7.7716e-16, 5.5511e-16, 1.1102e-15, 3.5527e-15, 2.2204e-15,\n",
      "         8.8818e-16, 3.1086e-15, 9.7700e-15, 7.1054e-15, 8.8818e-16, 1.3323e-15,\n",
      "         3.5527e-15, 1.6653e-15, 1.2212e-15, 9.9920e-16, 4.4409e-15, 3.1086e-15,\n",
      "         5.3291e-15, 1.2212e-15, 3.9968e-15, 3.1086e-15, 6.6613e-16, 8.8818e-16,\n",
      "         3.5527e-15, 6.6613e-16, 3.9968e-15, 1.5543e-15, 1.3323e-15, 2.2204e-15,\n",
      "         1.3323e-15, 2.6645e-15, 2.4425e-15, 8.8818e-15, 1.6653e-15, 8.8818e-16,\n",
      "         1.3323e-15, 8.8818e-16, 1.5543e-15, 5.7732e-15, 1.2212e-15, 3.5527e-15,\n",
      "         1.1102e-15, 6.2172e-15, 4.8850e-15, 9.9920e-16, 3.1086e-15, 1.5543e-15,\n",
      "         1.2212e-15, 6.2172e-15, 3.5527e-15, 1.9984e-15, 4.4409e-16, 1.3323e-14,\n",
      "         4.4409e-15, 3.5527e-15, 5.7732e-15, 3.1086e-15, 5.3291e-15, 1.7764e-15,\n",
      "         3.5527e-15, 3.9968e-15, 1.3323e-15, 2.2204e-15, 8.8818e-15, 7.1054e-15,\n",
      "         1.2212e-15, 1.7764e-15, 1.0658e-14, 7.9936e-15, 5.3291e-15, 2.6645e-15,\n",
      "         6.6613e-16, 1.0658e-14, 1.5543e-15, 1.7764e-14, 5.3291e-15, 8.8818e-15,\n",
      "         5.3291e-15, 2.8866e-15, 2.6645e-15, 4.8850e-15, 1.3323e-15, 1.2212e-15,\n",
      "         6.2172e-15, 1.5543e-15, 1.2434e-14, 1.1102e-15, 9.9920e-16, 4.4409e-15,\n",
      "         2.6645e-15, 2.4425e-15, 1.7764e-15, 4.4409e-15, 2.4425e-15, 4.4409e-15,\n",
      "         8.8818e-15, 1.7764e-15, 7.9936e-15, 2.6645e-15, 2.8866e-15, 1.4433e-15,\n",
      "         1.7764e-15, 8.8818e-15, 6.6613e-15, 1.5987e-14, 3.3307e-15, 1.6653e-15,\n",
      "         1.4433e-15, 3.9968e-15, 7.9936e-15, 3.9968e-15, 3.5527e-15, 1.3323e-15,\n",
      "         6.2172e-15, 1.7764e-15, 5.3291e-15, 3.1086e-15, 5.3291e-15, 5.3291e-15,\n",
      "         8.8818e-15, 1.9984e-15, 5.3291e-15, 5.3291e-15, 7.9936e-15, 2.4425e-15,\n",
      "         9.7700e-15, 5.3291e-15, 1.4433e-15, 2.2204e-15, 3.1086e-15, 3.5527e-15,\n",
      "         1.2434e-14, 5.3291e-15, 1.7764e-14, 1.3323e-15, 1.3323e-15, 1.6653e-15,\n",
      "         1.7764e-15, 5.3291e-15, 4.8295e-15, 2.6645e-15, 1.3323e-15, 6.2172e-15,\n",
      "         2.6645e-15, 5.3291e-15, 1.0658e-14, 8.8818e-15, 1.2434e-14, 7.1054e-15,\n",
      "         3.1086e-15, 9.7700e-15, 1.9984e-15, 3.1086e-15, 6.2172e-15, 3.1086e-15,\n",
      "         3.1086e-15, 2.2204e-15, 3.1086e-15, 2.6645e-15, 1.9984e-15, 1.4211e-14,\n",
      "         5.7732e-15, 3.1086e-15, 2.6645e-15, 4.2633e-14, 1.5987e-14, 6.2172e-15,\n",
      "         3.1974e-14, 5.3291e-15, 1.9984e-15, 2.6645e-15, 7.9936e-15, 3.7748e-15,\n",
      "         3.1974e-14, 1.4211e-14, 6.2172e-15, 3.1974e-14, 3.5527e-14, 1.1546e-14,\n",
      "         2.6645e-15, 1.7764e-14, 1.2434e-14, 1.4211e-14, 2.1316e-14, 2.1316e-14,\n",
      "         1.5987e-14, 3.5527e-14, 1.5987e-14, 1.0658e-14, 7.1054e-15, 1.5987e-14,\n",
      "         3.5527e-14, 1.1546e-14, 2.8422e-14, 2.3093e-14, 1.9540e-14, 6.2172e-15,\n",
      "         1.4211e-14, 8.8818e-15, 3.5527e-14, 1.2434e-14, 1.5987e-14, 1.0658e-14,\n",
      "         5.3291e-15, 1.0658e-14, 2.1316e-14, 1.9540e-14, 6.2172e-15, 2.8422e-14,\n",
      "         3.9080e-14, 6.2172e-15, 1.2434e-14, 2.1316e-14, 2.4869e-14, 4.6185e-14,\n",
      "         2.1316e-14, 1.2434e-14, 1.4211e-14, 7.9936e-15, 1.4211e-14, 1.7764e-14,\n",
      "         1.5987e-14, 2.1316e-14, 1.7764e-14, 3.3751e-14, 7.9936e-15, 2.3093e-14,\n",
      "         2.4869e-14, 1.7764e-14, 1.7764e-14, 7.1054e-15, 2.8422e-14, 1.2434e-14,\n",
      "         1.5099e-14, 1.1546e-14, 3.1974e-14, 4.2633e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 178: layer3.17.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 178\n",
      "Max diff:\n",
      " tensor([1.1990e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2821e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.8295e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1990e-14, 2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.1054e-15, 0.0000e+00, 7.1054e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 69,  94,  99, 158, 205, 206, 226, 236, 238])\n",
      "\n",
      "failing Cout = tensor([ 69,  94,  99, 158, 205, 206, 226, 236, 238])  (len = 9)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 179: layer3.17.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 179\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 179\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 1,  2,  5,  6,  7,  9, 10, 11, 12, 16, 17, 19, 21, 24, 27, 28, 29, 30,\n",
      "        32, 33, 35, 36, 38, 40, 41, 42, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55,\n",
      "        56, 58, 59, 60, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
      "        147, 148, 149, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163,\n",
      "        164, 165, 166, 167, 169, 170, 172, 173, 174, 175, 176, 178, 180, 181,\n",
      "        182, 183, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 195, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 229, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 179\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 2,  4,  7, 19, 24, 25, 26, 31, 33, 34, 37, 47, 49, 51, 52, 54, 55, 62]) to machine 0\n",
      "\t\t sending C_out tensor([ 67,  68,  70,  72,  73,  79,  83,  84,  88,  91,  95,  97,  99, 101,\n",
      "        104, 107, 108, 113, 114, 115, 117, 120]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([195, 202, 203, 209, 210, 212, 220, 223, 224, 227, 228, 231, 234, 236,\n",
      "        239, 242, 245, 247, 248, 252, 253, 254]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 179\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 16, 18, 19, 20,\n",
      "        21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
      "        41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59,\n",
      "        60, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  67,  68,  69,  70,  72,  73,  74,  75,  76,  79,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 114,\n",
      "        115, 116, 117, 118, 120, 121, 122, 123, 125, 126]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        158, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "        174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188,\n",
      "        189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 179\n",
      "Max diff:\n",
      " tensor([9.7700e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.7732e-15, 3.6637e-15, 3.7748e-15, 2.6645e-15, 3.5527e-15, 5.7732e-15,\n",
      "         7.7716e-16, 1.7764e-15, 1.1102e-16, 2.2204e-15, 2.2204e-15, 2.7756e-17,\n",
      "         4.0801e-15, 3.5527e-15, 2.6645e-15, 0.0000e+00, 4.4409e-16, 2.9816e-19,\n",
      "         2.7756e-15, 1.0547e-15, 1.3323e-15, 1.1102e-16, 5.7732e-15, 0.0000e+00,\n",
      "         9.9920e-16, 2.1094e-15, 5.7732e-15, 1.6098e-15, 4.4409e-15, 2.7756e-15,\n",
      "         2.7617e-15, 2.8866e-15, 1.7764e-15, 7.1054e-15, 2.2204e-15, 1.1796e-15,\n",
      "         6.2172e-15, 5.3291e-15, 1.9984e-15, 1.1102e-16, 1.2490e-15, 8.3267e-17,\n",
      "         3.5388e-16, 8.8818e-16, 9.9920e-16, 5.7732e-15, 2.8866e-15, 3.1086e-15,\n",
      "         5.5511e-16, 3.5527e-15, 2.2204e-15, 1.2768e-15, 3.1086e-15, 9.7700e-15,\n",
      "         2.6645e-15, 4.8850e-15, 3.5527e-15, 4.4409e-16, 3.5527e-15, 1.1657e-15,\n",
      "         6.3838e-16, 1.5543e-15, 2.3315e-15, 5.7732e-15, 2.2204e-15, 4.4409e-15,\n",
      "         2.4980e-15, 3.0809e-15, 2.5813e-15, 1.6653e-15, 1.9984e-15, 1.4017e-15,\n",
      "         3.3307e-15, 3.2196e-15, 1.1796e-15, 1.2590e-15, 3.1086e-15, 1.4433e-15,\n",
      "         5.5511e-16, 4.4409e-15, 7.7716e-16, 9.4369e-16, 1.0547e-15, 2.6645e-15,\n",
      "         2.6645e-15, 2.3315e-15, 3.9968e-15, 1.9984e-15, 3.3307e-15, 3.1086e-15,\n",
      "         2.2760e-15, 2.5674e-15, 1.5821e-15, 1.3323e-15, 3.5527e-15, 1.9429e-15,\n",
      "         3.2196e-15, 5.3291e-15, 6.2172e-15, 1.5543e-15, 5.5511e-15, 2.6645e-15,\n",
      "         3.1641e-15, 1.5543e-15, 2.6645e-15, 1.7764e-15, 3.9968e-15, 6.2172e-15,\n",
      "         3.5527e-15, 3.3307e-15, 3.9968e-15, 2.3870e-15, 1.8111e-15, 2.7200e-15,\n",
      "         4.4409e-15, 7.1054e-15, 2.6645e-15, 4.4409e-15, 5.3291e-15, 2.0331e-15,\n",
      "         2.4425e-15, 9.9920e-16, 2.6645e-15, 2.8866e-15, 1.9984e-15, 3.3307e-15,\n",
      "         5.9952e-15, 2.1094e-15, 3.3931e-15, 1.9984e-15, 3.3307e-15, 3.5527e-15,\n",
      "         3.5527e-15, 1.6098e-15, 1.8874e-15, 3.3307e-15, 2.8866e-15, 1.7208e-15,\n",
      "         5.7732e-15, 2.6645e-15, 2.1094e-15, 4.6629e-15, 2.8866e-15, 3.9968e-15,\n",
      "         3.9968e-15, 1.7764e-15, 4.4409e-15, 3.5527e-15, 3.5527e-15, 3.1086e-15,\n",
      "         3.5527e-15, 1.8596e-15, 2.2204e-15, 5.7732e-15, 2.7756e-15, 2.2204e-15,\n",
      "         2.8727e-15, 1.2768e-15, 3.6637e-15, 8.0491e-16, 2.2204e-15, 3.1086e-15,\n",
      "         2.6645e-15, 2.8866e-15, 6.2172e-15, 2.6645e-15, 3.2196e-15, 3.9968e-15,\n",
      "         2.4425e-15, 5.1070e-15, 3.5527e-15, 1.7764e-15, 2.4425e-15, 4.4409e-15,\n",
      "         4.2188e-15, 3.1086e-15, 1.7764e-15, 2.6645e-15, 2.4425e-15, 1.2768e-15,\n",
      "         5.3291e-15, 1.9984e-15, 3.7748e-15, 1.8319e-15, 2.8866e-15, 1.5543e-15,\n",
      "         1.6653e-15, 1.3323e-15, 2.6645e-15, 1.8874e-15, 2.8866e-15, 3.7748e-15,\n",
      "         4.6629e-15, 3.1086e-15, 5.3291e-15, 2.6645e-15, 2.4425e-15, 4.2188e-15,\n",
      "         2.6645e-15, 7.5495e-15, 2.6645e-15, 3.7748e-15, 2.6645e-15, 3.5527e-15,\n",
      "         2.2204e-15, 2.7756e-15, 4.4409e-15, 2.0262e-15, 4.4409e-15, 7.9936e-15,\n",
      "         3.9968e-15, 2.6645e-15, 2.2204e-15, 2.8866e-15, 3.5527e-15, 7.9936e-15,\n",
      "         3.9968e-15, 2.4425e-15, 6.2172e-15, 2.6645e-15, 7.1054e-15, 4.4409e-15,\n",
      "         6.2172e-15, 3.5527e-15, 5.1070e-15, 3.1086e-15, 3.7748e-15, 6.6613e-15,\n",
      "         5.7732e-15, 4.8850e-15, 3.1086e-15, 4.4409e-15, 3.9968e-15, 2.8866e-15,\n",
      "         5.3291e-15, 3.3307e-15, 3.7748e-15, 6.6613e-15, 4.4409e-15, 4.4409e-15,\n",
      "         4.1078e-15, 4.4409e-15, 3.7748e-15, 5.3291e-15, 3.1086e-15, 6.2172e-15,\n",
      "         4.4409e-15, 2.6645e-15, 2.8866e-15, 2.2204e-15, 5.3291e-15, 3.5527e-15,\n",
      "         2.4425e-15, 2.8866e-15, 6.2172e-15, 3.5527e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
      "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])  (len = 254)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 180: layer3.17.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 180\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 180\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 180\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 180\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 180\n",
      "Max diff:\n",
      " tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5543e-15, 1.8319e-15, 1.6653e-15, 3.8858e-16, 1.5543e-15, 1.4433e-15,\n",
      "         2.4980e-16, 5.5511e-16, 8.3267e-17, 1.1102e-15, 1.2212e-15, 2.7756e-17,\n",
      "         5.5511e-16, 1.6098e-15, 1.1102e-15, 0.0000e+00, 2.2204e-16, 0.0000e+00,\n",
      "         7.2164e-16, 3.6082e-16, 6.6613e-16, 2.7756e-17, 1.4433e-15, 0.0000e+00,\n",
      "         2.2204e-16, 2.2204e-16, 1.7764e-15, 7.7716e-16, 2.2204e-16, 5.1348e-16,\n",
      "         6.9389e-16, 1.1102e-15, 6.6613e-16, 2.4425e-15, 1.2750e-16, 4.4409e-16,\n",
      "         2.4425e-15, 9.4369e-16, 8.8818e-16, 2.7756e-17, 1.3184e-16, 5.5511e-17,\n",
      "         2.7756e-17, 1.3878e-16, 6.2450e-17, 3.3307e-15, 8.3267e-16, 9.9920e-16,\n",
      "         5.5511e-17, 1.3323e-15, 1.3323e-15, 4.9960e-16, 2.3592e-16, 3.3307e-15,\n",
      "         9.9920e-16, 9.9920e-16, 1.2212e-15, 2.2204e-16, 1.1102e-15, 3.8858e-16,\n",
      "         5.5511e-17, 2.8449e-16, 4.6838e-16, 3.5527e-15, 6.9389e-16, 8.8818e-16,\n",
      "         1.1102e-15, 8.5695e-16, 7.4940e-16, 4.5797e-16, 3.0531e-16, 2.7409e-16,\n",
      "         7.2164e-16, 1.3600e-15, 2.3592e-16, 2.2204e-16, 8.3267e-16, 6.3838e-16,\n",
      "         5.5511e-17, 1.1657e-15, 7.9797e-17, 1.3184e-16, 2.7756e-16, 4.9960e-16,\n",
      "         7.2164e-16, 2.6368e-16, 8.3267e-16, 7.7716e-16, 8.8818e-16, 6.6613e-16,\n",
      "         4.1633e-16, 5.1348e-16, 9.7145e-17, 6.6613e-16, 6.6613e-16, 6.1062e-16,\n",
      "         1.4433e-15, 1.1102e-15, 8.8818e-16, 4.4409e-16, 2.1094e-15, 1.9429e-16,\n",
      "         1.8735e-16, 2.2204e-16, 4.4409e-16, 3.0531e-16, 1.4433e-15, 2.1094e-15,\n",
      "         1.2212e-15, 8.3267e-16, 1.9984e-15, 9.1593e-16, 3.8858e-16, 6.3838e-16,\n",
      "         1.3323e-15, 2.6645e-15, 5.5511e-16, 1.3323e-15, 2.2204e-15, 1.0547e-15,\n",
      "         3.8858e-16, 4.4409e-16, 4.8572e-16, 6.1062e-16, 5.8287e-16, 1.0131e-15,\n",
      "         1.3323e-15, 2.2898e-16, 1.8319e-15, 6.1062e-16, 7.7716e-16, 1.9984e-15,\n",
      "         8.8818e-16, 4.7184e-16, 6.6613e-16, 2.4980e-16, 7.7716e-16, 8.1879e-16,\n",
      "         2.2204e-15, 3.6082e-16, 6.6613e-16, 4.4409e-16, 1.6653e-15, 5.5511e-16,\n",
      "         1.3323e-15, 5.5511e-16, 4.9960e-16, 1.5543e-15, 1.1380e-15, 1.6653e-15,\n",
      "         8.8818e-16, 1.0131e-15, 8.3267e-16, 3.1086e-15, 8.3267e-16, 6.6613e-16,\n",
      "         9.3675e-16, 1.1102e-16, 1.3878e-15, 2.7756e-16, 7.2164e-16, 6.3838e-16,\n",
      "         3.6082e-16, 1.1102e-15, 1.1102e-15, 1.5543e-15, 8.8818e-16, 1.1102e-15,\n",
      "         7.7716e-16, 8.8818e-16, 1.3323e-15, 7.7716e-16, 4.7184e-16, 1.7764e-15,\n",
      "         1.9984e-15, 1.3323e-15, 2.4980e-16, 1.4433e-15, 6.1062e-16, 2.7756e-17,\n",
      "         1.1102e-15, 6.1062e-16, 2.3592e-16, 8.7083e-16, 6.6613e-16, 5.5511e-16,\n",
      "         7.7716e-16, 3.9899e-17, 6.6613e-16, 2.0817e-17, 7.7716e-16, 1.5543e-15,\n",
      "         1.1657e-15, 8.8818e-16, 2.2204e-15, 2.2204e-16, 4.4409e-16, 1.1657e-15,\n",
      "         1.0547e-15, 2.6645e-15, 7.7716e-16, 2.0539e-15, 7.7716e-16, 1.3323e-15,\n",
      "         7.2164e-16, 1.4017e-15, 8.8818e-16, 6.6613e-16, 1.7764e-15, 2.6645e-15,\n",
      "         1.3323e-15, 1.1102e-15, 7.7716e-16, 8.8818e-16, 1.7764e-15, 7.7716e-16,\n",
      "         7.2164e-16, 3.8858e-16, 1.9984e-15, 7.2164e-16, 1.9984e-15, 9.9920e-16,\n",
      "         1.6653e-15, 7.7716e-16, 2.1094e-15, 6.6613e-16, 1.2212e-15, 1.8874e-15,\n",
      "         1.7208e-15, 8.8818e-16, 9.4369e-16, 1.3323e-15, 1.3323e-15, 5.5511e-16,\n",
      "         1.3323e-15, 3.8858e-16, 6.6613e-16, 2.4425e-15, 1.1102e-15, 1.7764e-15,\n",
      "         1.2490e-15, 1.2212e-15, 1.1102e-15, 8.3267e-16, 9.9920e-16, 2.8866e-15,\n",
      "         9.9920e-16, 5.5511e-16, 7.2164e-16, 4.9960e-16, 1.6653e-15, 1.4433e-15,\n",
      "         1.1102e-15, 9.9920e-16, 1.2212e-15, 1.9984e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  30,\n",
      "         31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,\n",
      "         45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
      "         59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
      "         73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
      "         87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
      "        101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
      "        129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "        227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  30,\n",
      "         31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,\n",
      "         45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
      "         59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
      "         73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
      "         87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
      "        101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
      "        129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "        227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255])  (len = 253)\n",
      "passing Cout = tensor([15, 17, 23])  (len = 3)\n",
      "\n",
      "Executing module 181: layer3.17.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 181\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5543e-15, 1.8319e-15, 2.4425e-15, 4.4409e-15, 1.9151e-15, 1.4433e-15,\n",
      "         1.0547e-15, 5.3291e-15, 3.8858e-16, 1.1102e-15, 1.9984e-15, 4.4409e-16,\n",
      "         1.3878e-15, 5.8287e-15, 1.9706e-15, 0.0000e+00, 3.5527e-15, 6.3838e-16,\n",
      "         7.2164e-16, 3.8858e-16, 6.6613e-16, 2.7756e-17, 1.4433e-15, 8.8818e-16,\n",
      "         1.6098e-15, 1.8596e-15, 1.6653e-15, 1.6653e-15, 4.4409e-16, 2.6645e-15,\n",
      "         1.7486e-15, 2.6645e-15, 3.1641e-15, 5.7176e-15, 5.8287e-16, 4.4409e-16,\n",
      "         2.2204e-15, 9.4369e-16, 1.8319e-15, 1.2212e-15, 7.1054e-15, 5.5511e-17,\n",
      "         1.7764e-15, 4.1633e-15, 5.5511e-15, 3.3307e-15, 8.3267e-16, 9.9920e-16,\n",
      "         5.5511e-17, 2.4425e-15, 4.3854e-15, 4.9960e-16, 2.8866e-15, 3.3307e-15,\n",
      "         1.6376e-15, 3.6360e-15, 1.4433e-15, 7.2164e-16, 2.6645e-15, 1.9151e-15,\n",
      "         3.2196e-15, 2.8449e-16, 7.7716e-15, 3.5527e-15, 6.6613e-15, 1.1657e-15,\n",
      "         6.6058e-15, 7.1054e-15, 1.9151e-15, 5.4956e-15, 1.1546e-14, 2.2204e-15,\n",
      "         3.6637e-15, 3.5527e-15, 2.9282e-15, 7.3275e-15, 7.9936e-15, 8.2157e-15,\n",
      "         1.7764e-15, 1.1657e-15, 4.8850e-15, 7.9936e-15, 4.9960e-16, 1.1990e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7161e-15, 7.7716e-16, 8.8818e-15, 7.7716e-16,\n",
      "         2.6645e-15, 3.6637e-15, 6.1062e-16, 6.6613e-16, 2.6645e-15, 6.1062e-16,\n",
      "         4.6629e-15, 3.1086e-15, 4.2188e-15, 7.1054e-15, 2.6645e-15, 8.3267e-16,\n",
      "         5.3291e-15, 1.1657e-15, 1.1102e-15, 1.0658e-14, 1.4433e-15, 2.1927e-15,\n",
      "         3.4417e-15, 2.2204e-15, 5.7732e-15, 6.6613e-15, 1.3323e-15, 4.6629e-15,\n",
      "         3.3307e-15, 9.9920e-15, 5.2180e-15, 1.3323e-15, 5.6066e-15, 5.5511e-15,\n",
      "         9.9920e-16, 1.5543e-15, 4.4409e-15, 4.4409e-15, 2.6645e-15, 3.9968e-15,\n",
      "         2.3315e-15, 2.2204e-15, 2.3315e-15, 7.9936e-15, 8.3267e-16, 3.8303e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.0658e-14, 4.8850e-15, 1.2212e-15, 8.1879e-16,\n",
      "         1.1546e-14, 1.9984e-15, 4.8850e-15, 2.2204e-15, 3.4417e-15, 1.0658e-14,\n",
      "         7.3275e-15, 1.7764e-15, 1.4433e-15, 5.5511e-15, 1.7764e-14, 1.6653e-15,\n",
      "         1.1990e-14, 4.6629e-15, 5.3291e-15, 3.1086e-15, 1.1102e-15, 7.1054e-15,\n",
      "         5.8842e-15, 4.9405e-15, 9.3259e-15, 8.3267e-16, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 9.9920e-16, 2.6645e-15, 1.5543e-15, 1.5155e-14, 3.4972e-15,\n",
      "         2.1316e-14, 9.4369e-16, 1.3323e-15, 1.1546e-14, 3.7748e-15, 9.9920e-15,\n",
      "         1.9984e-15, 1.2712e-14, 5.5511e-15, 1.5543e-15, 7.9936e-15, 1.1102e-15,\n",
      "         3.5805e-15, 2.2204e-15, 1.6653e-15, 1.5266e-15, 3.3307e-15, 4.4409e-15,\n",
      "         1.4211e-14, 4.6629e-15, 1.4211e-14, 9.3259e-15, 7.7716e-16, 2.2204e-15,\n",
      "         1.2434e-14, 2.5757e-14, 1.0658e-14, 9.8532e-16, 2.7756e-15, 8.8818e-15,\n",
      "         4.7740e-15, 1.4211e-14, 8.8818e-15, 5.7732e-15, 1.1324e-14, 3.7748e-15,\n",
      "         1.0658e-14, 1.4655e-14, 3.5527e-15, 1.4211e-14, 4.2188e-15, 2.6645e-15,\n",
      "         3.8303e-15, 3.1974e-14, 2.1316e-14, 6.4393e-15, 7.1054e-15, 6.4393e-15,\n",
      "         9.3259e-15, 1.1269e-14, 5.7732e-15, 9.9920e-16, 7.9936e-15, 1.9540e-14,\n",
      "         7.9936e-15, 8.8818e-15, 3.1086e-15, 1.4211e-14, 1.4211e-14, 1.3323e-14,\n",
      "         1.5321e-14, 8.8818e-15, 5.3291e-15, 1.1546e-14, 2.5757e-14, 9.3259e-15,\n",
      "         1.0658e-14, 2.3315e-15, 5.3291e-15, 1.4877e-14, 4.0523e-15, 7.1054e-15,\n",
      "         1.2490e-15, 8.8818e-15, 4.8850e-15, 5.3291e-15, 7.2164e-15, 1.7764e-14,\n",
      "         8.8818e-15, 8.9928e-15, 8.2157e-15, 8.6597e-15, 1.4211e-14, 1.0658e-14,\n",
      "         2.6645e-15, 3.5527e-15, 6.6613e-15, 1.1768e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 255)\n",
      "passing Cout = tensor([15])  (len = 1)\n",
      "\n",
      "Executing module 182: layer3.17.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 182\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.5511e-17, 8.8818e-16, 2.4425e-15, 4.4409e-15, 1.9151e-15, 4.0246e-16,\n",
      "         1.0547e-15, 5.3291e-15, 3.8858e-16, 1.0547e-15, 6.6613e-16, 4.4409e-16,\n",
      "         1.3878e-15, 5.8287e-15, 5.5511e-16, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         3.2266e-16, 3.8858e-16, 0.0000e+00, 0.0000e+00, 1.4433e-15, 8.8818e-16,\n",
      "         1.6098e-15, 9.7145e-16, 1.6653e-15, 1.6653e-15, 0.0000e+00, 2.6645e-15,\n",
      "         1.7486e-15, 2.6645e-15, 3.1641e-15, 5.7176e-15, 5.8287e-16, 0.0000e+00,\n",
      "         2.2204e-15, 8.3267e-17, 1.1102e-15, 1.2212e-15, 7.1054e-15, 0.0000e+00,\n",
      "         1.7764e-15, 4.1633e-15, 5.5511e-15, 3.3307e-15, 6.1062e-16, 5.5511e-16,\n",
      "         0.0000e+00, 2.4425e-15, 4.3854e-15, 0.0000e+00, 2.8866e-15, 0.0000e+00,\n",
      "         1.6376e-15, 3.2752e-15, 6.1062e-16, 7.2164e-16, 2.6645e-15, 1.9151e-15,\n",
      "         3.2196e-15, 2.8449e-16, 7.7716e-15, 3.5527e-15, 6.6613e-15, 2.7756e-16,\n",
      "         6.1062e-15, 7.1054e-15, 1.9151e-15, 5.4956e-15, 1.1546e-14, 2.2204e-15,\n",
      "         3.6637e-15, 3.5527e-15, 2.9282e-15, 7.3275e-15, 7.9936e-15, 8.2157e-15,\n",
      "         1.7764e-15, 1.1657e-15, 4.8850e-15, 7.9936e-15, 4.9960e-16, 1.1990e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.7161e-15, 0.0000e+00, 8.8818e-15, 1.9429e-16,\n",
      "         2.6645e-15, 3.6637e-15, 6.1062e-16, 3.3307e-16, 2.6645e-15, 5.5511e-17,\n",
      "         4.6629e-15, 3.1086e-15, 4.2188e-15, 7.1054e-15, 2.6645e-15, 8.3267e-16,\n",
      "         5.3291e-15, 1.1657e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.1927e-15,\n",
      "         3.4417e-15, 2.2204e-15, 5.7732e-15, 6.6613e-15, 1.3323e-15, 4.6629e-15,\n",
      "         2.4425e-15, 9.9920e-15, 5.2180e-15, 1.3323e-15, 5.6066e-15, 5.5511e-15,\n",
      "         9.9920e-16, 1.5543e-15, 4.4409e-15, 4.4409e-15, 2.6645e-15, 3.9968e-15,\n",
      "         2.3315e-15, 2.2204e-15, 2.2204e-15, 7.9936e-15, 8.3267e-16, 3.8303e-15,\n",
      "         5.3291e-15, 3.5527e-15, 1.0658e-14, 4.8850e-15, 1.0547e-15, 3.6082e-16,\n",
      "         1.1546e-14, 1.9984e-15, 4.8850e-15, 2.2204e-15, 2.5535e-15, 1.0658e-14,\n",
      "         7.3275e-15, 1.7764e-15, 1.4433e-15, 3.3307e-15, 1.7764e-14, 5.8287e-16,\n",
      "         1.1990e-14, 4.6629e-15, 5.3291e-15, 3.1086e-15, 1.1102e-15, 7.1054e-15,\n",
      "         5.8842e-15, 9.9920e-16, 9.3259e-15, 2.2204e-16, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 9.9920e-16, 2.6645e-15, 9.8532e-16, 1.5155e-14, 3.4972e-15,\n",
      "         2.1316e-14, 9.4369e-16, 1.2837e-16, 1.1546e-14, 3.7748e-15, 9.9920e-15,\n",
      "         1.9984e-15, 1.2712e-14, 5.5511e-15, 8.8818e-16, 7.9936e-15, 1.1102e-15,\n",
      "         3.5805e-15, 2.2204e-15, 0.0000e+00, 1.4433e-15, 3.3307e-15, 4.4409e-15,\n",
      "         1.4211e-14, 4.6629e-15, 1.4211e-14, 9.3259e-15, 0.0000e+00, 2.2204e-15,\n",
      "         1.2434e-14, 2.5757e-14, 1.0658e-14, 9.8532e-16, 2.7756e-15, 8.8818e-15,\n",
      "         4.7740e-15, 1.4211e-14, 8.8818e-15, 5.7732e-15, 1.1324e-14, 3.7748e-15,\n",
      "         1.0658e-14, 1.4655e-14, 3.5527e-15, 1.4211e-14, 4.2188e-15, 2.6645e-15,\n",
      "         3.8303e-15, 3.1974e-14, 2.1316e-14, 6.4393e-15, 7.1054e-15, 6.4393e-15,\n",
      "         9.3259e-15, 1.1269e-14, 5.7732e-15, 7.7716e-16, 7.9936e-15, 1.9540e-14,\n",
      "         7.9936e-15, 8.8818e-15, 3.1086e-15, 1.4211e-14, 1.4211e-14, 1.3323e-14,\n",
      "         1.5321e-14, 8.8818e-15, 5.3291e-15, 1.1546e-14, 2.5757e-14, 9.3259e-15,\n",
      "         1.0658e-14, 2.3315e-15, 5.3291e-15, 1.4877e-14, 4.0523e-15, 7.1054e-15,\n",
      "         1.2212e-15, 8.8818e-15, 4.8850e-15, 5.3291e-15, 7.2164e-15, 1.7764e-14,\n",
      "         8.8818e-15, 8.9928e-15, 8.2157e-15, 8.6597e-15, 1.4211e-14, 1.0658e-14,\n",
      "         2.6645e-15, 3.5527e-15, 6.6613e-15, 1.1768e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  18,  19,  22,  23,  24,  25,  26,  27,  29,  30,  31,  32,\n",
      "         33,  34,  36,  37,  38,  39,  40,  42,  43,  44,  45,  46,  47,  49,\n",
      "         50,  52,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  82,  83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,\n",
      "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  18,  19,  22,  23,  24,  25,  26,  27,  29,  30,  31,  32,\n",
      "         33,  34,  36,  37,  38,  39,  40,  42,  43,  44,  45,  46,  47,  49,\n",
      "         50,  52,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  82,  83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,\n",
      "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])  (len = 243)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 183: layer3.18.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 183\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 183\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 183\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 183\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 183\n",
      "Max diff:\n",
      " tensor([2.4158e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5987e-14, 6.2172e-15, 4.4409e-15, 4.9738e-14, 6.2172e-15, 3.5527e-14,\n",
      "         8.8818e-15, 6.2172e-15, 2.4869e-14, 3.9080e-14, 1.0658e-14, 6.2172e-15,\n",
      "         6.3949e-14, 3.1974e-14, 7.9936e-15, 3.5527e-14, 1.2434e-14, 7.9936e-15,\n",
      "         1.9540e-14, 7.1054e-15, 5.3291e-15, 3.9080e-14, 5.3291e-15, 3.5527e-14,\n",
      "         7.8160e-14, 5.3291e-15, 8.8818e-15, 9.7700e-15, 2.1316e-14, 5.3291e-15,\n",
      "         3.1974e-14, 7.1054e-14, 4.4409e-15, 6.2172e-15, 6.2172e-15, 3.5527e-14,\n",
      "         7.1054e-15, 6.2172e-15, 5.3291e-15, 1.2434e-14, 2.8422e-14, 3.1974e-14,\n",
      "         5.3291e-15, 6.2172e-15, 1.0658e-14, 5.3291e-15, 1.4211e-14, 6.2172e-15,\n",
      "         7.1054e-15, 2.4869e-14, 7.1054e-15, 7.1054e-15, 6.2172e-15, 4.4409e-15,\n",
      "         7.1054e-15, 3.1974e-14, 5.3291e-15, 4.4409e-15, 6.2172e-15, 3.1086e-15,\n",
      "         6.2172e-15, 1.4211e-14, 5.3291e-15, 1.2434e-14, 4.8850e-15, 8.8818e-15,\n",
      "         2.1316e-14, 1.2434e-14, 6.2172e-15, 7.9936e-15, 1.2434e-14, 3.9080e-14,\n",
      "         3.9080e-14, 6.3949e-14, 1.2434e-14, 7.9936e-15, 7.1054e-15, 3.1974e-14,\n",
      "         6.3949e-14, 1.2434e-14, 7.1054e-15, 6.2172e-15, 9.7700e-15, 6.3949e-14,\n",
      "         2.8422e-14, 1.5987e-14, 1.4211e-14, 1.4211e-14, 8.5265e-14, 8.5265e-14,\n",
      "         3.5527e-14, 6.3949e-14, 5.3291e-15, 7.8160e-14, 3.9080e-14, 4.9738e-14,\n",
      "         1.4211e-14, 1.7053e-13, 4.2633e-14, 5.6843e-14, 8.8818e-15, 2.4869e-14,\n",
      "         7.1054e-15, 5.6843e-14, 8.8818e-15, 2.1316e-14, 1.4211e-14, 7.1054e-15,\n",
      "         8.8818e-15, 4.9738e-14, 1.5987e-14, 1.7764e-14, 5.6843e-14, 3.9968e-15,\n",
      "         1.4211e-14, 8.8818e-15, 3.5527e-14, 4.4409e-15, 2.4869e-14, 5.6843e-14,\n",
      "         2.8422e-14, 4.2633e-14, 4.2633e-14, 8.5265e-14, 4.8850e-15, 1.5987e-14,\n",
      "         2.1316e-14, 4.4409e-15, 1.0658e-14, 2.1316e-14, 1.4211e-14, 1.4211e-14,\n",
      "         8.8818e-15, 4.2633e-14, 2.8422e-14, 1.5987e-14, 5.6843e-14, 3.9080e-14,\n",
      "         9.9476e-14, 4.6185e-14, 2.1316e-14, 1.1546e-14, 5.6843e-14, 3.9080e-14,\n",
      "         4.9738e-14, 7.8160e-14, 1.5987e-14, 1.4211e-14, 2.1316e-14, 2.4869e-14,\n",
      "         4.2633e-14, 3.1974e-14, 5.6843e-14, 4.9738e-14, 1.0658e-14, 5.6843e-14,\n",
      "         3.5527e-14, 3.9080e-14, 3.1974e-14, 1.1369e-13, 3.7303e-14, 2.4869e-14,\n",
      "         9.9476e-14, 8.8818e-15, 4.4409e-15, 2.8422e-14, 2.4869e-14, 3.1974e-14,\n",
      "         9.7700e-15, 5.6843e-14, 2.1316e-14, 4.2633e-14, 1.7764e-14, 4.9738e-14,\n",
      "         3.5527e-14, 8.8818e-15, 5.6843e-14, 3.1974e-14, 2.1316e-14, 6.2172e-15,\n",
      "         1.7764e-14, 1.7764e-14, 8.8818e-15, 1.1369e-13, 2.1316e-14, 2.4869e-14,\n",
      "         1.4921e-13, 2.4869e-14, 5.6843e-14, 1.5987e-14, 1.7764e-14, 1.0658e-14,\n",
      "         6.3949e-14, 7.1054e-14, 8.5265e-14, 4.2633e-14, 9.9476e-14, 1.1369e-13,\n",
      "         9.9476e-14, 2.4869e-14, 2.4158e-13, 1.1369e-13, 8.5265e-14, 4.2633e-14,\n",
      "         2.8422e-14, 2.4869e-14, 1.5632e-13, 5.6843e-14, 1.7764e-14, 6.3949e-14,\n",
      "         1.4211e-14, 2.1316e-14, 1.7053e-13, 4.9738e-14, 1.2790e-13, 3.1974e-14,\n",
      "         1.7053e-13, 7.1054e-14, 2.8422e-14, 1.2790e-13, 1.4211e-13, 4.9738e-14,\n",
      "         4.9738e-14, 1.1369e-13, 5.6843e-14, 9.9476e-14, 5.6843e-14, 2.1316e-14,\n",
      "         7.6383e-14, 1.8474e-13, 1.1369e-13, 9.9476e-14, 5.6843e-14, 2.4869e-14,\n",
      "         3.5527e-14, 3.1974e-14, 1.1369e-13, 2.8422e-14, 2.8422e-14, 2.1316e-14,\n",
      "         1.2790e-13, 1.1369e-13, 7.1054e-14, 1.9895e-13, 1.1369e-13, 7.8160e-14,\n",
      "         7.1054e-14, 6.3949e-14, 3.5527e-14, 8.5265e-14, 1.2790e-13, 1.5632e-13,\n",
      "         9.9476e-14, 7.1054e-14, 1.1369e-13, 7.1054e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 184: layer3.18.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 184\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 184\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 184\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 184\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 184\n",
      "Max diff:\n",
      " tensor([7.4607e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 1.1102e-15, 8.8818e-16, 5.3291e-15, 9.9920e-16, 6.6613e-15,\n",
      "         1.6653e-15, 8.8818e-16, 3.1086e-15, 6.2172e-15, 1.5543e-15, 7.7716e-16,\n",
      "         4.4409e-15, 5.3291e-15, 1.1102e-15, 6.2172e-15, 1.9984e-15, 1.3323e-15,\n",
      "         2.6645e-15, 1.3323e-15, 1.1102e-15, 5.3291e-15, 8.8818e-16, 7.1054e-15,\n",
      "         1.1546e-14, 8.8818e-16, 1.2212e-15, 1.5543e-15, 3.1086e-15, 7.2164e-16,\n",
      "         3.5527e-15, 8.8818e-15, 1.1102e-15, 8.8818e-16, 1.2212e-15, 5.3291e-15,\n",
      "         1.1102e-15, 7.7716e-16, 7.7716e-16, 1.5543e-15, 4.4409e-15, 3.9968e-15,\n",
      "         1.2212e-15, 1.5543e-15, 1.1102e-15, 1.1102e-15, 1.4433e-15, 1.3323e-15,\n",
      "         1.1102e-15, 3.5527e-15, 1.2212e-15, 1.7764e-15, 8.8818e-16, 7.7716e-16,\n",
      "         1.2212e-15, 3.5527e-15, 9.9920e-16, 7.7716e-16, 1.1102e-15, 6.1062e-16,\n",
      "         1.2212e-15, 2.4425e-15, 7.7716e-16, 1.9984e-15, 9.9920e-16, 1.3323e-15,\n",
      "         1.9984e-15, 1.3323e-15, 9.9920e-16, 1.7764e-15, 2.2204e-15, 6.2172e-15,\n",
      "         6.2172e-15, 7.9936e-15, 2.2204e-15, 1.7764e-15, 9.9920e-16, 4.8850e-15,\n",
      "         1.0658e-14, 2.2204e-15, 1.5543e-15, 1.3323e-15, 1.9984e-15, 7.9936e-15,\n",
      "         5.7732e-15, 2.6645e-15, 2.4425e-15, 2.2204e-15, 7.9936e-15, 1.0658e-14,\n",
      "         4.4409e-15, 7.1054e-15, 9.9920e-16, 1.4211e-14, 4.8850e-15, 5.3291e-15,\n",
      "         2.4425e-15, 1.9540e-14, 6.2172e-15, 8.8818e-15, 2.2204e-15, 3.9968e-15,\n",
      "         1.3323e-15, 8.8818e-15, 1.5543e-15, 3.1086e-15, 1.5543e-15, 8.8818e-16,\n",
      "         2.2204e-15, 5.3291e-15, 1.9984e-15, 3.1086e-15, 1.2434e-14, 9.9920e-16,\n",
      "         2.6645e-15, 1.5543e-15, 8.8818e-15, 7.7716e-16, 3.9968e-15, 7.9936e-15,\n",
      "         3.5527e-15, 7.1054e-15, 6.2172e-15, 1.0658e-14, 1.1102e-15, 2.4425e-15,\n",
      "         3.1086e-15, 8.8818e-16, 2.2204e-15, 3.5527e-15, 2.6645e-15, 3.1086e-15,\n",
      "         1.7764e-15, 7.1054e-15, 4.4409e-15, 1.9984e-15, 1.0658e-14, 4.8850e-15,\n",
      "         8.8818e-15, 7.1054e-15, 3.1086e-15, 1.1102e-15, 8.8818e-15, 7.9936e-15,\n",
      "         5.3291e-15, 1.0658e-14, 2.6645e-15, 3.3307e-15, 3.9968e-15, 4.4409e-15,\n",
      "         6.2172e-15, 3.5527e-15, 1.1546e-14, 5.3291e-15, 1.5543e-15, 1.2434e-14,\n",
      "         4.8850e-15, 3.7748e-15, 6.2172e-15, 8.8818e-15, 6.2172e-15, 5.3291e-15,\n",
      "         1.5987e-14, 1.2212e-15, 9.9920e-16, 5.3291e-15, 3.5527e-15, 6.2172e-15,\n",
      "         1.6653e-15, 7.9936e-15, 3.5527e-15, 7.9936e-15, 2.4425e-15, 4.4409e-15,\n",
      "         3.5527e-15, 1.5543e-15, 8.8818e-15, 4.4409e-15, 2.6645e-15, 1.1102e-15,\n",
      "         2.2204e-15, 2.8866e-15, 1.5543e-15, 1.7764e-14, 3.1086e-15, 4.4409e-15,\n",
      "         3.7303e-14, 3.5527e-15, 1.4211e-14, 3.1086e-15, 2.8866e-15, 1.9984e-15,\n",
      "         1.2434e-14, 1.7764e-14, 1.5099e-14, 7.9936e-15, 2.8422e-14, 2.3093e-14,\n",
      "         1.4211e-14, 5.3291e-15, 7.4607e-14, 1.4211e-14, 1.2434e-14, 7.1054e-15,\n",
      "         3.5527e-15, 5.3291e-15, 4.6185e-14, 1.2434e-14, 2.6645e-15, 7.9936e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.0198e-14, 7.1054e-15, 4.2633e-14, 4.8850e-15,\n",
      "         3.5527e-14, 1.4211e-14, 4.8850e-15, 2.4869e-14, 2.3093e-14, 1.0658e-14,\n",
      "         1.0658e-14, 2.4869e-14, 1.0658e-14, 1.5987e-14, 7.9936e-15, 1.3323e-15,\n",
      "         1.3767e-14, 3.0198e-14, 3.1974e-14, 7.9936e-15, 1.0658e-14, 3.5527e-15,\n",
      "         5.3291e-15, 4.8850e-15, 1.7764e-14, 7.1054e-15, 3.9968e-15, 3.9968e-15,\n",
      "         2.1316e-14, 3.5527e-14, 6.2172e-15, 2.1316e-14, 1.5987e-14, 1.7764e-14,\n",
      "         8.8818e-15, 8.8818e-15, 3.9968e-15, 1.7764e-14, 1.4211e-14, 3.5527e-14,\n",
      "         1.5987e-14, 1.2434e-14, 2.4869e-14, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 185: layer3.18.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 185\n",
      "Max diff:\n",
      " tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1935e-15, 3.9968e-15, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3307e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-15, 3.9413e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 6.1617e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "         4.6074e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.2172e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([157, 158, 160, 176, 188, 196, 197, 220, 221, 225, 228, 242, 247])\n",
      "\n",
      "failing Cout = tensor([157, 158, 160, 176, 188, 196, 197, 220, 221, 225, 228, 242, 247])  (len = 13)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 186: layer3.18.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 186\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 186\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 186\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37,\n",
      "        38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
      "        58, 59, 60, 61, 62]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  80,  81,\n",
      "         83,  84,  85,  87,  88,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 122, 124, 126]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 186\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58,\n",
      "        59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "        121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157,\n",
      "        158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 186\n",
      "Max diff:\n",
      " tensor([8.8818e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.6653e-15, 1.1102e-15, 3.7470e-16, 1.4710e-15, 3.1086e-15, 1.0547e-15,\n",
      "         1.1241e-15, 1.1102e-15, 1.5543e-15, 3.5527e-15, 6.2172e-15, 6.3838e-16,\n",
      "         5.3291e-15, 2.4425e-15, 3.9968e-15, 4.4409e-15, 1.6098e-15, 2.2204e-15,\n",
      "         1.0270e-15, 1.2768e-15, 5.3291e-15, 2.2204e-15, 3.5527e-15, 1.6376e-15,\n",
      "         1.7764e-15, 2.8866e-15, 4.4409e-16, 1.8041e-15, 1.0547e-15, 1.7764e-15,\n",
      "         8.3267e-16, 6.3838e-16, 1.3323e-15, 7.9936e-15, 4.4409e-15, 3.5527e-15,\n",
      "         2.2204e-15, 6.9389e-16, 4.7184e-16, 1.3323e-15, 3.5527e-15, 3.5527e-15,\n",
      "         3.1086e-15, 1.1102e-15, 1.9984e-15, 1.3323e-15, 0.0000e+00, 2.3315e-15,\n",
      "         1.2906e-15, 2.5535e-15, 1.0547e-15, 1.2490e-15, 3.5527e-15, 1.2768e-15,\n",
      "         2.2204e-15, 1.6653e-16, 3.1086e-15, 5.5511e-16, 5.3291e-15, 1.9984e-15,\n",
      "         1.5543e-15, 3.1086e-15, 1.4433e-15, 3.5527e-15, 1.8735e-15, 1.9706e-15,\n",
      "         3.9968e-15, 3.5527e-15, 2.5535e-15, 1.7764e-15, 8.3267e-17, 1.7764e-15,\n",
      "         5.2736e-16, 2.4980e-15, 3.5527e-15, 1.0547e-15, 1.9984e-15, 2.2204e-15,\n",
      "         1.3878e-15, 4.8850e-15, 9.8532e-16, 1.1519e-15, 1.6237e-15, 4.4409e-15,\n",
      "         1.3323e-15, 1.0825e-15, 1.1657e-15, 3.9968e-15, 3.9968e-15, 2.8866e-15,\n",
      "         8.5348e-16, 3.9968e-15, 3.2196e-15, 7.1054e-15, 4.4409e-15, 4.6629e-15,\n",
      "         2.6645e-15, 2.5535e-15, 5.7732e-15, 1.4988e-15, 3.5527e-15, 3.1086e-15,\n",
      "         3.9968e-15, 9.4369e-16, 1.2629e-15, 9.2981e-16, 6.6613e-16, 2.2204e-15,\n",
      "         3.5527e-15, 7.1054e-15, 1.1102e-15, 3.5527e-15, 2.2204e-15, 3.1086e-15,\n",
      "         4.2188e-15, 2.8866e-15, 3.1086e-15, 1.8874e-15, 8.8818e-15, 6.2172e-15,\n",
      "         2.5258e-15, 5.3291e-15, 4.4409e-15, 1.3323e-15, 3.8858e-16, 5.3291e-15,\n",
      "         3.2752e-15, 4.4409e-16, 1.4710e-15, 3.5527e-15, 4.8850e-15, 2.1788e-15,\n",
      "         2.2204e-15, 4.4409e-15, 2.1094e-15, 5.3291e-15, 2.4425e-15, 4.4409e-15,\n",
      "         4.8850e-15, 2.6645e-15, 3.3307e-15, 6.6613e-16, 7.1054e-15, 2.1094e-15,\n",
      "         1.9568e-15, 3.3307e-15, 2.4425e-15, 5.3291e-15, 7.1054e-15, 3.5527e-15,\n",
      "         1.3184e-15, 6.2172e-15, 4.4409e-15, 3.9968e-15, 4.4409e-15, 1.3878e-15,\n",
      "         1.9984e-15, 1.6653e-15, 1.1102e-15, 1.3323e-15, 9.7145e-16, 1.4849e-15,\n",
      "         4.4409e-15, 4.7740e-15, 3.1086e-15, 2.6645e-15, 3.1086e-15, 2.2760e-15,\n",
      "         6.2172e-15, 1.5543e-15, 2.0539e-15, 4.3299e-15, 2.6645e-15, 7.1054e-15,\n",
      "         3.1086e-15, 2.6645e-15, 8.8818e-15, 3.1086e-15, 1.7764e-15, 1.5543e-15,\n",
      "         1.9429e-15, 1.5543e-15, 3.5527e-15, 1.7208e-15, 3.3307e-15, 1.4988e-15,\n",
      "         7.1054e-15, 3.9968e-15, 6.2172e-15, 3.1086e-15, 2.1094e-15, 1.0131e-15,\n",
      "         3.9968e-15, 8.8818e-15, 3.5527e-15, 5.7732e-15, 5.2180e-15, 3.5527e-15,\n",
      "         4.4409e-15, 1.9984e-15, 3.3584e-15, 5.3291e-15, 3.9968e-15, 4.8850e-15,\n",
      "         2.6645e-15, 4.4409e-15, 8.8818e-15, 2.8866e-15, 7.1054e-15, 4.4409e-15,\n",
      "         4.7740e-15, 3.5527e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15, 2.6645e-15,\n",
      "         5.3291e-15, 8.8818e-15, 5.3291e-15, 8.8818e-15, 4.4409e-15, 3.9968e-15,\n",
      "         3.1086e-15, 3.3307e-15, 5.3291e-15, 6.2172e-15, 3.2543e-15, 4.4409e-15,\n",
      "         5.3291e-15, 2.8866e-15, 3.9968e-15, 7.9936e-15, 3.9968e-15, 6.3283e-15,\n",
      "         3.9968e-15, 4.6629e-15, 3.3307e-15, 6.2172e-15, 4.8850e-15, 4.4409e-15,\n",
      "         2.7756e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15, 5.3291e-15, 3.5527e-15,\n",
      "         4.4409e-15, 5.3291e-15, 5.3291e-15, 6.6613e-15, 4.8850e-15, 6.2172e-15,\n",
      "         3.9968e-15, 5.6621e-15, 3.4694e-15, 4.8850e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 255)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 187: layer3.18.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 187\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 187\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 187\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 187\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 187\n",
      "Max diff:\n",
      " tensor([4.4409e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.2204e-16, 5.5511e-16, 1.3878e-16, 1.2902e-16, 1.3323e-15, 2.6368e-16,\n",
      "         2.9143e-16, 1.0408e-16, 4.4409e-16, 3.3307e-16, 1.5543e-15, 5.5511e-17,\n",
      "         1.7764e-15, 9.9920e-16, 7.7716e-16, 2.6645e-15, 7.2164e-16, 6.6613e-16,\n",
      "         8.3267e-17, 2.2204e-16, 1.3323e-15, 9.4369e-16, 2.2204e-15, 7.6328e-16,\n",
      "         1.1102e-16, 3.3307e-16, 1.1102e-16, 5.1348e-16, 1.1102e-16, 4.7184e-16,\n",
      "         2.6368e-16, 1.5613e-16, 3.3307e-16, 2.6645e-15, 2.2204e-15, 1.1102e-15,\n",
      "         4.9960e-16, 1.6653e-16, 1.9429e-16, 3.8858e-16, 1.6653e-16, 1.2212e-15,\n",
      "         9.9920e-16, 5.2042e-16, 1.6653e-16, 6.9389e-18, 0.0000e+00, 7.7716e-16,\n",
      "         8.0491e-16, 4.9960e-16, 3.4694e-16, 6.1062e-16, 1.6653e-15, 1.6653e-16,\n",
      "         1.5543e-15, 6.2450e-17, 1.6653e-15, 1.3878e-16, 2.2204e-15, 9.9920e-16,\n",
      "         1.1796e-16, 5.5511e-16, 7.2164e-16, 8.8818e-16, 4.3021e-16, 5.2736e-16,\n",
      "         4.9960e-16, 6.6613e-16, 7.9103e-16, 5.5511e-16, 2.0817e-17, 3.8858e-16,\n",
      "         2.2204e-16, 9.1593e-16, 1.3323e-15, 2.6368e-16, 4.9960e-16, 6.6613e-16,\n",
      "         4.7531e-16, 6.1062e-16, 3.6776e-16, 1.8041e-16, 5.9674e-16, 1.5543e-15,\n",
      "         4.4409e-16, 1.2490e-16, 2.0817e-16, 4.4409e-16, 1.1102e-15, 1.1102e-15,\n",
      "         4.1633e-16, 1.2212e-15, 6.9389e-16, 2.4425e-15, 1.5543e-15, 1.3323e-15,\n",
      "         4.7184e-16, 1.6653e-15, 2.2204e-15, 4.3021e-16, 1.1102e-15, 1.9429e-16,\n",
      "         8.8818e-16, 3.0531e-16, 2.6368e-16, 2.7495e-16, 3.3307e-16, 5.5511e-16,\n",
      "         7.7716e-16, 1.7764e-15, 4.1633e-16, 1.3323e-15, 3.3307e-16, 5.5511e-16,\n",
      "         1.4433e-15, 5.5511e-16, 4.4409e-16, 6.1062e-16, 2.6645e-15, 2.6645e-15,\n",
      "         6.1062e-16, 1.9984e-15, 1.1102e-15, 2.4980e-16, 5.8981e-17, 1.7764e-15,\n",
      "         1.9429e-16, 1.6653e-16, 4.9266e-16, 1.5543e-15, 6.1062e-16, 6.3144e-16,\n",
      "         6.6613e-16, 5.5511e-16, 5.5511e-16, 1.6653e-15, 9.9920e-16, 2.2204e-15,\n",
      "         7.7716e-16, 9.4369e-16, 3.3307e-16, 1.1102e-16, 2.6645e-15, 6.1756e-16,\n",
      "         3.8858e-16, 6.1062e-16, 6.6613e-16, 4.9960e-16, 1.5543e-15, 1.5543e-15,\n",
      "         3.6082e-16, 2.6645e-15, 1.3323e-15, 2.4425e-15, 1.3323e-15, 3.8858e-16,\n",
      "         8.3267e-16, 7.4940e-16, 9.7145e-17, 3.3307e-16, 1.8735e-16, 2.4847e-16,\n",
      "         6.6613e-16, 2.4425e-15, 1.5543e-15, 1.1102e-15, 8.8818e-16, 8.8818e-16,\n",
      "         3.1086e-15, 8.3267e-17, 4.1633e-16, 1.2212e-15, 7.7716e-16, 2.2204e-15,\n",
      "         7.7716e-16, 1.2212e-15, 4.4409e-15, 1.9984e-15, 3.6082e-16, 6.9389e-16,\n",
      "         3.8511e-16, 4.7184e-16, 3.1086e-15, 7.2164e-16, 1.1102e-15, 4.8572e-16,\n",
      "         3.1086e-15, 8.8818e-16, 3.1086e-15, 6.6613e-16, 6.1062e-16, 4.1633e-16,\n",
      "         1.1102e-15, 2.2204e-15, 1.3323e-15, 9.4369e-16, 1.8874e-15, 1.2212e-15,\n",
      "         1.4433e-15, 8.8818e-16, 9.9226e-16, 8.8818e-16, 9.9920e-16, 1.5543e-15,\n",
      "         1.3323e-15, 1.2212e-15, 3.5527e-15, 7.4940e-16, 1.9984e-15, 1.7764e-15,\n",
      "         2.3037e-15, 1.5543e-15, 1.5543e-15, 1.2212e-15, 2.2204e-15, 1.0547e-15,\n",
      "         4.4409e-16, 2.6645e-15, 1.1102e-15, 2.2204e-15, 7.7716e-16, 1.3323e-15,\n",
      "         1.1102e-15, 8.8818e-16, 2.6645e-15, 1.9984e-15, 8.3267e-16, 1.3323e-15,\n",
      "         1.7764e-15, 4.7184e-16, 1.1102e-15, 3.1086e-15, 1.4433e-15, 2.6645e-15,\n",
      "         3.3307e-16, 1.3323e-15, 5.5511e-16, 1.9984e-15, 8.8818e-16, 8.8818e-16,\n",
      "         9.4369e-16, 1.7764e-15, 1.7764e-15, 9.9920e-16, 1.3323e-15, 1.1102e-15,\n",
      "         6.6613e-16, 1.3323e-15, 1.1102e-15, 4.6491e-16, 1.9984e-15, 3.1086e-15,\n",
      "         1.3323e-15, 1.9429e-15, 1.2048e-15, 2.2204e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255])  (len = 255)\n",
      "passing Cout = tensor([46])  (len = 1)\n",
      "\n",
      "Executing module 188: layer3.18.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 188\n",
      "Max diff:\n",
      " tensor([3.2863e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.2204e-16, 1.2212e-15, 2.4425e-15, 4.4409e-15, 3.3307e-15, 4.0246e-16,\n",
      "         1.0547e-15, 5.3291e-15, 4.4409e-16, 9.9920e-16, 1.5543e-15, 4.1633e-16,\n",
      "         2.4425e-15, 6.1062e-15, 7.7716e-16, 2.6645e-15, 3.5527e-15, 6.6613e-16,\n",
      "         3.0531e-16, 4.4409e-16, 1.3323e-15, 9.4369e-16, 3.1086e-15, 7.7716e-16,\n",
      "         1.5543e-15, 7.2164e-16, 1.6653e-15, 1.7764e-15, 1.1102e-16, 2.2204e-15,\n",
      "         1.7764e-15, 2.6645e-15, 3.2196e-15, 7.1054e-15, 2.2204e-15, 1.1102e-15,\n",
      "         2.2204e-15, 1.6653e-16, 1.1102e-15, 1.2212e-15, 6.9944e-15, 1.2212e-15,\n",
      "         1.3323e-15, 4.1633e-15, 5.3291e-15, 3.3307e-15, 6.1062e-16, 9.4369e-16,\n",
      "         8.0491e-16, 2.3870e-15, 4.3854e-15, 6.1062e-16, 3.9968e-15, 1.6653e-16,\n",
      "         2.5813e-15, 3.2752e-15, 1.6653e-15, 7.2164e-16, 4.4409e-15, 1.6653e-15,\n",
      "         3.1086e-15, 5.5511e-16, 7.7716e-15, 3.9968e-15, 7.1054e-15, 5.2736e-16,\n",
      "         6.2172e-15, 7.1054e-15, 1.9984e-15, 5.4401e-15, 1.1546e-14, 2.2760e-15,\n",
      "         3.6637e-15, 3.9968e-15, 3.7748e-15, 7.3275e-15, 8.4377e-15, 8.2157e-15,\n",
      "         1.7764e-15, 9.9920e-16, 4.8850e-15, 7.9936e-15, 5.9674e-16, 1.0658e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.6605e-15, 4.4409e-16, 8.8818e-15, 1.1102e-15,\n",
      "         2.6645e-15, 3.6082e-15, 8.8818e-16, 2.4425e-15, 2.6645e-15, 1.3323e-15,\n",
      "         4.6629e-15, 3.3307e-15, 3.5527e-15, 7.9936e-15, 2.4425e-15, 9.1593e-16,\n",
      "         5.3291e-15, 1.1657e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.4564e-15,\n",
      "         3.5527e-15, 2.2204e-15, 5.7732e-15, 7.2164e-15, 1.3323e-15, 4.8850e-15,\n",
      "         2.9976e-15, 9.9920e-15, 5.3291e-15, 1.7764e-15, 5.6066e-15, 6.6613e-15,\n",
      "         9.9920e-16, 2.2204e-15, 4.4409e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         2.5535e-15, 2.2204e-15, 2.2204e-15, 7.1054e-15, 6.1062e-16, 3.6637e-15,\n",
      "         4.4409e-15, 3.5527e-15, 8.8818e-15, 4.8850e-15, 1.1935e-15, 2.2204e-15,\n",
      "         1.1546e-14, 1.8874e-15, 4.8850e-15, 2.2204e-15, 2.6645e-15, 1.0658e-14,\n",
      "         7.3275e-15, 1.7764e-15, 1.6653e-15, 3.3307e-15, 1.8652e-14, 2.1094e-15,\n",
      "         1.1990e-14, 4.8850e-15, 4.8850e-15, 2.4425e-15, 1.9984e-15, 7.1054e-15,\n",
      "         6.3283e-15, 9.9920e-16, 9.3259e-15, 4.1633e-16, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 2.2204e-15, 3.5527e-15, 1.1102e-15, 1.4932e-14, 3.6637e-15,\n",
      "         2.1316e-14, 9.1593e-16, 4.1633e-16, 1.0658e-14, 4.4409e-15, 9.9920e-15,\n",
      "         1.9984e-15, 1.3545e-14, 6.4393e-15, 1.9984e-15, 7.9936e-15, 8.3267e-16,\n",
      "         3.5527e-15, 2.2204e-15, 3.1086e-15, 2.0817e-15, 3.5527e-15, 4.4409e-15,\n",
      "         1.5099e-14, 4.2744e-15, 1.2434e-14, 9.3259e-15, 6.1062e-16, 2.3315e-15,\n",
      "         1.2434e-14, 2.6201e-14, 1.1546e-14, 1.3878e-15, 2.1094e-15, 9.3259e-15,\n",
      "         5.8842e-15, 1.4211e-14, 9.3259e-15, 6.2172e-15, 1.0880e-14, 3.5527e-15,\n",
      "         9.7700e-15, 1.4211e-14, 3.5527e-15, 1.4211e-14, 4.6629e-15, 3.5527e-15,\n",
      "         4.4409e-15, 3.2863e-14, 2.1316e-14, 6.3283e-15, 8.8818e-15, 5.3291e-15,\n",
      "         9.7700e-15, 9.7700e-15, 5.5511e-15, 2.2204e-15, 7.9936e-15, 1.7764e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.5527e-15, 1.5987e-14, 1.4655e-14, 1.3323e-14,\n",
      "         1.5987e-14, 8.8818e-15, 5.7732e-15, 1.2434e-14, 2.5757e-14, 1.1324e-14,\n",
      "         1.2434e-14, 1.7764e-15, 5.3291e-15, 1.5099e-14, 4.6629e-15, 7.1054e-15,\n",
      "         1.5404e-15, 9.1038e-15, 5.3291e-15, 4.4409e-15, 7.5495e-15, 1.7764e-14,\n",
      "         8.8818e-15, 7.7716e-15, 8.3267e-15, 8.6597e-15, 1.2434e-14, 1.0658e-14,\n",
      "         2.3315e-15, 4.6629e-15, 7.1054e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 189: layer3.18.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 189\n",
      "Max diff:\n",
      " tensor([3.2863e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 4.4409e-16, 2.4425e-15, 4.4409e-15, 3.3307e-15, 4.0246e-16,\n",
      "         1.0547e-15, 5.3291e-15, 0.0000e+00, 9.9920e-16, 6.4879e-16, 0.0000e+00,\n",
      "         9.4369e-16, 1.3878e-15, 4.4409e-16, 6.2146e-16, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 9.4369e-16, 3.1086e-15, 7.7716e-16,\n",
      "         1.3323e-15, 0.0000e+00, 1.6653e-15, 1.7764e-15, 0.0000e+00, 2.2204e-15,\n",
      "         1.7764e-15, 2.6645e-15, 3.2196e-15, 4.8850e-15, 2.2204e-15, 1.1102e-15,\n",
      "         2.2204e-15, 0.0000e+00, 1.1102e-15, 1.2212e-15, 6.9944e-15, 1.2212e-15,\n",
      "         1.3323e-15, 4.1633e-15, 5.3291e-15, 3.3307e-15, 0.0000e+00, 9.4369e-16,\n",
      "         8.0491e-16, 2.3870e-15, 4.3854e-15, 0.0000e+00, 3.9968e-15, 4.1633e-17,\n",
      "         6.1062e-16, 2.2204e-15, 4.1633e-16, 7.2164e-16, 1.7764e-15, 6.6613e-16,\n",
      "         3.1086e-15, 0.0000e+00, 7.7716e-15, 3.9968e-15, 7.1054e-15, 4.9960e-16,\n",
      "         6.2172e-15, 7.1054e-15, 1.9984e-15, 5.4401e-15, 1.1546e-14, 2.2760e-15,\n",
      "         3.6637e-15, 3.9968e-15, 1.9984e-15, 7.3275e-15, 8.4377e-15, 8.2157e-15,\n",
      "         1.7764e-15, 9.9920e-16, 4.8850e-15, 7.9936e-15, 0.0000e+00, 1.0658e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.6605e-15, 0.0000e+00, 8.8818e-15, 0.0000e+00,\n",
      "         2.6645e-15, 3.6082e-15, 8.8818e-16, 2.4425e-15, 2.6645e-15, 1.3323e-15,\n",
      "         4.6629e-15, 1.1380e-15, 3.5527e-15, 7.9936e-15, 2.4425e-15, 9.1593e-16,\n",
      "         5.3291e-15, 1.1657e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.4564e-15,\n",
      "         3.5527e-15, 2.2204e-15, 5.7732e-15, 7.2164e-15, 1.3323e-15, 4.8850e-15,\n",
      "         2.9976e-15, 9.9920e-15, 5.3291e-15, 1.7764e-15, 2.7756e-15, 6.6613e-15,\n",
      "         9.9920e-16, 6.9389e-17, 4.4409e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         2.5535e-15, 2.2204e-15, 2.2204e-15, 7.1054e-15, 3.3307e-16, 3.6637e-15,\n",
      "         4.4409e-15, 3.5527e-15, 8.8818e-15, 4.8850e-15, 1.1935e-15, 0.0000e+00,\n",
      "         1.1546e-14, 1.8874e-15, 4.8850e-15, 2.2204e-15, 0.0000e+00, 1.0658e-14,\n",
      "         7.3275e-15, 1.7764e-15, 1.0547e-15, 3.3307e-15, 1.8652e-14, 6.6613e-16,\n",
      "         1.1990e-14, 4.8850e-15, 4.8850e-15, 2.4425e-15, 1.9984e-15, 7.1054e-15,\n",
      "         6.3283e-15, 9.9920e-16, 9.3259e-15, 4.1633e-16, 2.4425e-15, 5.9952e-15,\n",
      "         3.9968e-15, 2.2204e-15, 3.5527e-15, 6.1062e-16, 1.4932e-14, 3.6637e-15,\n",
      "         2.1316e-14, 2.4980e-16, 0.0000e+00, 1.0658e-14, 4.4409e-15, 9.9920e-15,\n",
      "         1.9984e-15, 1.1102e-14, 1.1102e-15, 1.9984e-15, 7.9936e-15, 8.3267e-16,\n",
      "         3.5527e-15, 2.2204e-15, 3.1086e-15, 2.0817e-15, 3.5527e-15, 4.4409e-15,\n",
      "         1.5099e-14, 4.2744e-15, 1.2434e-14, 9.3259e-15, 0.0000e+00, 2.3315e-15,\n",
      "         1.2434e-14, 2.6201e-14, 1.1546e-14, 1.3878e-15, 2.1094e-15, 9.3259e-15,\n",
      "         2.4425e-15, 1.4211e-14, 9.3259e-15, 6.2172e-15, 1.0880e-14, 3.5527e-15,\n",
      "         9.7700e-15, 1.4211e-14, 3.5527e-15, 1.4211e-14, 3.7748e-15, 3.1086e-15,\n",
      "         4.4409e-15, 3.2863e-14, 2.1316e-14, 6.3283e-15, 8.8818e-15, 5.3291e-15,\n",
      "         9.7700e-15, 9.7700e-15, 5.5511e-15, 1.3045e-15, 7.9936e-15, 1.7764e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.5527e-15, 1.5987e-14, 1.4655e-14, 1.3323e-14,\n",
      "         1.5987e-14, 8.8818e-15, 5.7732e-15, 9.3259e-15, 2.5757e-14, 1.1324e-14,\n",
      "         1.2434e-14, 1.7764e-15, 5.3291e-15, 1.5099e-14, 1.6653e-15, 7.1054e-15,\n",
      "         1.5404e-15, 9.1038e-15, 5.3291e-15, 4.4409e-15, 7.5495e-15, 1.7764e-14,\n",
      "         8.8818e-15, 6.2172e-15, 8.3267e-15, 8.6597e-15, 1.2434e-14, 1.0658e-14,\n",
      "         2.2204e-15, 4.6629e-15, 7.1054e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  1,   2,   3,   4,   5,   6,   7,   9,  10,  12,  13,  14,  15,  16,\n",
      "         19,  21,  22,  23,  24,  26,  27,  29,  30,  31,  32,  33,  34,  35,\n",
      "         36,  38,  39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  50,  52,\n",
      "         53,  54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "         83,  84,  85,  86,  88,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171,\n",
      "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "        201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "        215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   4,   5,   6,   7,   9,  10,  12,  13,  14,  15,  16,\n",
      "         19,  21,  22,  23,  24,  26,  27,  29,  30,  31,  32,  33,  34,  35,\n",
      "         36,  38,  39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  50,  52,\n",
      "         53,  54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "         83,  84,  85,  86,  88,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171,\n",
      "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "        201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "        215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 237)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 190: layer3.19.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 190\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 190\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 190\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 190\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 190\n",
      "Max diff:\n",
      " tensor([2.4158e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.2172e-15, 3.9968e-15, 7.9936e-15, 2.1316e-14, 1.4211e-14, 3.9968e-15,\n",
      "         2.8422e-14, 4.2633e-14, 2.4869e-14, 1.2434e-14, 2.4869e-14, 4.9738e-14,\n",
      "         1.2434e-14, 8.8818e-15, 1.2790e-13, 2.4869e-14, 6.2172e-15, 3.9968e-15,\n",
      "         1.7764e-14, 8.8818e-15, 3.5527e-14, 3.1974e-14, 6.2172e-15, 2.4869e-14,\n",
      "         7.9936e-15, 4.9738e-14, 2.1316e-14, 8.8818e-15, 1.7764e-14, 5.3291e-15,\n",
      "         1.9540e-14, 5.3291e-15, 1.2434e-14, 3.5527e-14, 1.5987e-14, 4.9738e-14,\n",
      "         2.2204e-15, 1.7764e-14, 2.1316e-14, 3.5527e-15, 7.1054e-15, 1.4211e-14,\n",
      "         8.8818e-15, 5.3291e-15, 2.4869e-14, 2.1316e-14, 6.2172e-15, 2.1316e-14,\n",
      "         1.4211e-14, 1.2434e-14, 2.1316e-14, 3.9968e-15, 5.3291e-15, 1.4211e-14,\n",
      "         3.5527e-15, 4.4409e-15, 2.1316e-14, 4.8850e-15, 4.4409e-15, 1.0658e-14,\n",
      "         5.6843e-14, 7.9936e-15, 8.8818e-15, 4.4409e-15, 3.5527e-14, 7.9936e-15,\n",
      "         1.7764e-14, 7.1054e-14, 5.6843e-14, 4.9738e-14, 6.2172e-15, 3.5527e-14,\n",
      "         7.1054e-15, 2.1316e-14, 2.8422e-14, 3.5527e-14, 7.1054e-15, 3.5527e-14,\n",
      "         4.9738e-14, 5.3291e-15, 5.6843e-14, 4.2633e-14, 1.0658e-14, 3.1974e-14,\n",
      "         2.8422e-14, 4.4409e-15, 3.5527e-15, 8.8818e-15, 1.0658e-14, 5.3291e-15,\n",
      "         6.3949e-14, 1.7764e-14, 4.2633e-14, 4.6185e-14, 2.4869e-14, 1.5987e-14,\n",
      "         5.6843e-14, 3.9080e-14, 3.1974e-14, 2.8422e-14, 7.1054e-14, 5.6843e-14,\n",
      "         2.4869e-14, 6.3949e-14, 1.1546e-14, 3.1974e-14, 3.5527e-14, 1.0658e-14,\n",
      "         4.9738e-14, 1.2434e-14, 8.8818e-15, 2.4869e-14, 1.5987e-14, 3.5527e-14,\n",
      "         2.6645e-15, 6.2172e-15, 3.5527e-14, 2.4869e-14, 4.2633e-14, 2.4869e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.1316e-14, 9.7700e-15, 5.3291e-15, 1.5987e-14,\n",
      "         2.1316e-14, 1.7764e-14, 2.8422e-14, 3.5527e-14, 4.2633e-14, 5.6843e-14,\n",
      "         1.2434e-14, 1.4211e-14, 2.1316e-14, 7.1054e-14, 5.6843e-14, 4.2633e-14,\n",
      "         1.7764e-14, 1.7764e-14, 4.9738e-14, 1.4211e-14, 4.9738e-14, 1.2434e-14,\n",
      "         1.7764e-14, 5.6843e-14, 1.5987e-14, 1.4211e-14, 1.4211e-14, 8.8818e-15,\n",
      "         3.9080e-14, 5.6843e-14, 1.4211e-14, 4.2633e-14, 6.2172e-15, 5.6843e-14,\n",
      "         7.1054e-15, 4.2633e-14, 1.2434e-14, 8.8818e-15, 3.5527e-14, 7.1054e-15,\n",
      "         4.9738e-14, 3.5527e-14, 8.8818e-15, 2.4869e-14, 1.2434e-14, 1.4211e-14,\n",
      "         1.0658e-14, 1.4211e-14, 3.5527e-14, 1.0658e-14, 1.7764e-14, 2.4869e-14,\n",
      "         3.5527e-14, 2.8422e-14, 4.9738e-14, 2.4869e-14, 7.1054e-14, 1.4211e-14,\n",
      "         1.2434e-14, 1.7764e-14, 4.9738e-14, 6.3949e-14, 1.2434e-14, 7.1054e-14,\n",
      "         8.8818e-15, 3.1974e-14, 3.5527e-14, 8.5265e-14, 1.4211e-14, 1.5987e-14,\n",
      "         6.3949e-14, 3.5527e-14, 1.1369e-13, 3.9080e-14, 6.3949e-14, 2.4158e-13,\n",
      "         6.3949e-14, 1.4211e-13, 5.6843e-14, 7.8160e-14, 1.1369e-13, 1.2790e-13,\n",
      "         7.1054e-14, 7.8160e-14, 9.9476e-14, 1.4211e-13, 4.9738e-14, 1.4211e-13,\n",
      "         3.5527e-14, 1.1369e-13, 1.2790e-13, 7.1054e-14, 7.1054e-14, 4.2633e-14,\n",
      "         2.1316e-14, 1.9895e-13, 1.0658e-13, 1.2790e-13, 9.9476e-14, 8.5265e-14,\n",
      "         5.6843e-14, 2.8422e-14, 4.9738e-14, 2.8422e-14, 1.2790e-13, 8.5265e-14,\n",
      "         7.1054e-14, 5.6843e-14, 6.0396e-14, 9.9476e-14, 1.2434e-14, 7.1054e-14,\n",
      "         8.5265e-14, 3.5527e-14, 4.9738e-14, 1.9895e-13, 3.5527e-14, 4.9738e-14,\n",
      "         5.3291e-14, 3.1974e-14, 1.4211e-14, 9.9476e-14, 4.9738e-14, 2.2737e-13,\n",
      "         2.4869e-14, 5.6843e-14, 2.1316e-14, 8.5265e-14, 1.1369e-13, 7.1054e-14,\n",
      "         8.5265e-14, 8.5265e-14, 4.9738e-14, 5.6843e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 191: layer3.19.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 191\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 191\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 191\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 191\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 191\n",
      "Max diff:\n",
      " tensor([6.3949e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.8818e-16, 8.8818e-16, 1.3323e-15, 2.6645e-15, 1.7764e-15, 7.7716e-16,\n",
      "         3.9968e-15, 6.2172e-15, 3.1086e-15, 2.2204e-15, 2.4425e-15, 8.8818e-15,\n",
      "         1.7764e-15, 1.3323e-15, 1.1546e-14, 3.9968e-15, 1.2212e-15, 7.7716e-16,\n",
      "         3.1086e-15, 1.3323e-15, 3.5527e-15, 3.5527e-15, 1.3323e-15, 3.5527e-15,\n",
      "         1.3323e-15, 9.7700e-15, 3.1086e-15, 1.3323e-15, 2.6645e-15, 9.9920e-16,\n",
      "         3.1086e-15, 1.1102e-15, 1.7764e-15, 5.3291e-15, 2.2204e-15, 6.2172e-15,\n",
      "         5.5511e-16, 2.6645e-15, 2.2204e-15, 6.1062e-16, 1.1102e-15, 2.2204e-15,\n",
      "         1.1102e-15, 8.8818e-16, 2.6645e-15, 3.1086e-15, 8.8818e-16, 3.1086e-15,\n",
      "         2.2204e-15, 1.3323e-15, 2.2204e-15, 6.6613e-16, 7.7716e-16, 2.2204e-15,\n",
      "         7.7716e-16, 8.8818e-16, 2.6645e-15, 9.9920e-16, 8.8818e-16, 2.2204e-15,\n",
      "         4.4409e-15, 1.3323e-15, 1.5543e-15, 1.1102e-15, 3.5527e-15, 1.5543e-15,\n",
      "         3.1086e-15, 1.0658e-14, 1.0658e-14, 6.2172e-15, 1.1102e-15, 4.8850e-15,\n",
      "         1.3323e-15, 1.9984e-15, 2.6645e-15, 5.3291e-15, 1.3323e-15, 7.1054e-15,\n",
      "         6.2172e-15, 1.1102e-15, 7.1054e-15, 1.0658e-14, 1.9984e-15, 4.4409e-15,\n",
      "         3.9968e-15, 7.7716e-16, 8.8818e-16, 1.5543e-15, 2.4425e-15, 8.8818e-16,\n",
      "         1.0658e-14, 1.7764e-15, 4.4409e-15, 4.4409e-15, 4.8850e-15, 2.2204e-15,\n",
      "         5.3291e-15, 4.4409e-15, 5.3291e-15, 3.9968e-15, 1.1546e-14, 1.0658e-14,\n",
      "         3.5527e-15, 7.9936e-15, 2.2204e-15, 4.8850e-15, 3.9968e-15, 2.2204e-15,\n",
      "         7.5495e-15, 1.9984e-15, 1.3323e-15, 3.5527e-15, 2.2204e-15, 3.5527e-15,\n",
      "         3.8858e-16, 9.9920e-16, 4.4409e-15, 5.3291e-15, 4.8850e-15, 3.1086e-15,\n",
      "         4.4409e-15, 3.1086e-15, 3.5527e-15, 1.9984e-15, 1.1102e-15, 2.6645e-15,\n",
      "         3.5527e-15, 2.4425e-15, 4.4409e-15, 3.9968e-15, 1.2434e-14, 3.1086e-15,\n",
      "         1.3323e-15, 1.9984e-15, 4.4409e-15, 1.0658e-14, 1.1546e-14, 5.3291e-15,\n",
      "         3.5527e-15, 2.8866e-15, 1.0658e-14, 2.4425e-15, 3.1086e-15, 1.5543e-15,\n",
      "         3.1086e-15, 5.3291e-15, 2.6645e-15, 1.6653e-15, 2.6645e-15, 1.4433e-15,\n",
      "         5.3291e-15, 1.2434e-14, 1.7764e-15, 2.2204e-15, 1.3323e-15, 7.1054e-15,\n",
      "         1.3323e-15, 3.9968e-15, 1.9984e-15, 1.9984e-15, 7.1054e-15, 1.3323e-15,\n",
      "         7.9936e-15, 3.5527e-15, 1.3323e-15, 3.5527e-15, 1.9984e-15, 1.9984e-15,\n",
      "         1.7764e-15, 1.7764e-15, 3.9968e-15, 1.7764e-15, 3.9968e-15, 2.6645e-15,\n",
      "         5.3291e-15, 3.5527e-15, 7.9936e-15, 3.1086e-15, 8.8818e-15, 2.6645e-15,\n",
      "         1.9984e-15, 3.7748e-15, 7.1054e-15, 9.7700e-15, 1.5543e-15, 1.7764e-14,\n",
      "         1.3323e-15, 4.8850e-15, 4.8850e-15, 1.2434e-14, 1.9984e-15, 1.9984e-15,\n",
      "         1.4211e-14, 6.2172e-15, 1.2434e-14, 9.7700e-15, 6.6613e-15, 4.6185e-14,\n",
      "         1.0658e-14, 2.1316e-14, 8.8818e-15, 1.2434e-14, 1.2434e-14, 3.1974e-14,\n",
      "         1.0658e-14, 1.1546e-14, 8.8818e-15, 2.1316e-14, 7.1054e-15, 2.4869e-14,\n",
      "         7.9936e-15, 2.4869e-14, 2.8422e-14, 1.2434e-14, 1.2434e-14, 5.3291e-15,\n",
      "         2.6645e-15, 6.3949e-14, 1.9540e-14, 2.1316e-14, 1.4211e-14, 1.0658e-14,\n",
      "         1.2434e-14, 6.2172e-15, 8.8818e-15, 4.8850e-15, 1.9540e-14, 1.6875e-14,\n",
      "         7.1054e-15, 8.8818e-15, 1.6875e-14, 1.5987e-14, 1.9984e-15, 1.2434e-14,\n",
      "         9.7700e-15, 4.4409e-15, 1.3323e-14, 5.3291e-14, 6.2172e-15, 7.1054e-15,\n",
      "         5.7732e-15, 4.4409e-15, 3.1086e-15, 1.5987e-14, 5.3291e-15, 4.2633e-14,\n",
      "         6.2172e-15, 7.1054e-15, 3.9968e-15, 1.2434e-14, 2.4869e-14, 1.2434e-14,\n",
      "         1.3323e-14, 1.2434e-14, 1.1546e-14, 5.7732e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 192: layer3.19.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 192\n",
      "Max diff:\n",
      " tensor([6.8834e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8311e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9429e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.8842e-15, 0.0000e+00, 0.0000e+00, 4.8850e-15,\n",
      "         0.0000e+00, 4.4409e-15, 6.8834e-15, 7.4940e-16, 0.0000e+00, 0.0000e+00,\n",
      "         3.9135e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4433e-15,\n",
      "         5.7732e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7748e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.4393e-15, 0.0000e+00, 0.0000e+00, 1.1102e-16]], dtype=torch.float64)\n",
      " tensor([ 94, 130, 170, 218, 224, 227, 229, 230, 231, 234, 239, 240, 245, 252,\n",
      "        255])\n",
      "\n",
      "failing Cout = tensor([ 94, 130, 170, 218, 224, 227, 229, 230, 231, 234, 239, 240, 245, 252,\n",
      "        255])  (len = 15)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 193: layer3.19.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 193\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 193\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 3,  4,  5,  6,  8,  9, 11, 12, 13, 15, 16, 21, 27, 31, 33, 34, 35, 36,\n",
      "        37, 40, 41, 43, 46, 48, 54, 57, 58, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([131, 135, 138, 148, 151, 153, 156, 159, 162, 166, 167, 171, 172, 173,\n",
      "        174, 176, 183, 184, 185, 186, 188, 189]) to machine 2\n",
      "\t\t sending C_out tensor([196, 198, 200, 201, 202, 204, 205, 208, 209, 211, 214, 216, 221, 222,\n",
      "        223, 225, 226, 227, 229, 237, 238, 239, 240, 241, 242, 243, 245, 254,\n",
      "        255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 193\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  3,  4,  6,  8, 10, 11, 13, 15, 16, 17, 19, 23, 27, 29, 30, 32,\n",
      "        33, 37, 38, 39, 40, 41, 45, 46, 47, 49, 51, 52, 54, 55, 56, 58, 59, 61,\n",
      "        62]) to machine 0\n",
      "\t\t sending C_out tensor([ 69,  71,  73,  75,  76,  80,  82,  83,  86,  96,  97,  98, 101, 103,\n",
      "        104, 105, 107, 108, 113, 114, 117, 119, 124, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([194, 196, 198, 199, 202, 204, 207, 209, 211, 212, 213, 214, 215, 217,\n",
      "        218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 233,\n",
      "        234, 235, 236, 237, 239, 241, 242, 244, 245, 248, 251, 252, 253, 254,\n",
      "        255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 193\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 193\n",
      "Max diff:\n",
      " tensor([7.9936e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.7756e-15, 3.5527e-15, 2.5535e-15, 4.4409e-15, 2.1094e-15, 1.5543e-15,\n",
      "         1.3878e-15, 2.2482e-15, 3.1086e-15, 2.7756e-15, 2.3315e-15, 1.9429e-15,\n",
      "         2.1094e-15, 4.2466e-15, 1.8596e-15, 6.1062e-16, 6.2172e-15, 4.2188e-15,\n",
      "         2.1094e-15, 1.5474e-15, 2.2204e-15, 3.4417e-15, 1.5543e-15, 3.1086e-15,\n",
      "         3.7748e-15, 1.7764e-15, 2.1649e-15, 3.1086e-15, 4.4409e-15, 1.1102e-15,\n",
      "         5.5511e-16, 2.2204e-15, 1.6653e-15, 2.4425e-15, 4.1078e-15, 1.1102e-15,\n",
      "         1.1102e-15, 2.2760e-15, 7.7716e-16, 1.8874e-15, 2.0262e-15, 3.2196e-15,\n",
      "         2.6090e-15, 3.1086e-15, 1.6376e-15, 2.2204e-15, 1.7764e-15, 2.8866e-15,\n",
      "         2.3315e-15, 1.3323e-15, 4.4409e-15, 5.7732e-15, 2.2204e-15, 2.6645e-15,\n",
      "         1.6653e-15, 4.8850e-15, 4.4409e-15, 1.6098e-15, 1.9984e-15, 2.2204e-15,\n",
      "         9.1593e-16, 3.5527e-15, 1.7417e-15, 3.1086e-15, 2.6090e-15, 2.6645e-15,\n",
      "         9.1593e-16, 3.5527e-15, 2.1094e-15, 2.2760e-15, 2.8311e-15, 1.3323e-15,\n",
      "         2.2204e-15, 2.2204e-15, 2.4425e-15, 2.0539e-15, 2.4425e-15, 2.2204e-15,\n",
      "         1.1102e-15, 4.4409e-15, 1.5543e-15, 2.4425e-15, 2.1094e-15, 3.5527e-15,\n",
      "         2.4356e-15, 1.1519e-15, 2.6645e-15, 1.9984e-15, 2.2204e-15, 1.7208e-15,\n",
      "         2.6645e-15, 2.6368e-15, 3.5527e-15, 3.1086e-15, 2.6645e-15, 1.5543e-15,\n",
      "         2.0539e-15, 1.9984e-15, 4.8850e-15, 2.5535e-15, 3.0531e-15, 3.9968e-15,\n",
      "         2.1649e-15, 1.2768e-15, 2.8866e-15, 3.2899e-15, 1.7139e-15, 2.4425e-15,\n",
      "         2.8866e-15, 2.6645e-15, 1.0686e-15, 1.5543e-15, 2.7756e-15, 2.0539e-15,\n",
      "         2.9698e-15, 4.4409e-15, 3.7192e-15, 1.9845e-15, 1.4433e-15, 3.7748e-15,\n",
      "         2.6645e-15, 1.5543e-15, 3.2196e-15, 8.8818e-16, 1.4433e-15, 1.5370e-15,\n",
      "         4.4409e-15, 1.8874e-15, 3.1086e-15, 3.7748e-15, 2.6645e-15, 2.3315e-15,\n",
      "         3.1086e-15, 4.8850e-15, 3.1086e-15, 1.5543e-15, 1.4433e-15, 2.8866e-15,\n",
      "         1.9238e-15, 2.4425e-15, 5.3291e-15, 1.6376e-15, 3.5527e-15, 2.1094e-15,\n",
      "         2.2204e-15, 2.2760e-15, 2.8311e-15, 2.7756e-15, 2.6645e-15, 3.5527e-15,\n",
      "         3.2196e-15, 5.8842e-15, 5.3291e-15, 2.1094e-15, 4.4409e-15, 1.3323e-15,\n",
      "         3.7748e-15, 2.4425e-15, 2.8866e-15, 4.5519e-15, 3.1086e-15, 2.6645e-15,\n",
      "         3.1086e-15, 3.6637e-15, 2.8866e-15, 3.1086e-15, 3.9413e-15, 1.2212e-15,\n",
      "         3.0531e-15, 7.7716e-16, 3.1086e-15, 1.7764e-15, 2.2760e-15, 3.5527e-15,\n",
      "         3.5527e-15, 2.7200e-15, 7.9936e-15, 2.6645e-15, 1.1935e-15, 1.5543e-15,\n",
      "         1.6653e-15, 4.2744e-15, 3.1086e-15, 2.3037e-15, 3.8997e-15, 2.7756e-15,\n",
      "         3.5527e-15, 1.1657e-15, 2.4425e-15, 3.7748e-15, 1.3045e-15, 3.3307e-15,\n",
      "         3.7470e-15, 3.3307e-15, 5.4401e-15, 2.3315e-15, 6.6613e-15, 4.3125e-15,\n",
      "         2.6645e-15, 3.3307e-15, 3.8858e-15, 4.2188e-15, 3.5527e-15, 3.7748e-15,\n",
      "         3.7748e-15, 3.7748e-15, 3.0531e-15, 2.4425e-15, 2.6645e-15, 3.2752e-15,\n",
      "         3.7748e-15, 4.3299e-15, 3.5527e-15, 7.1054e-15, 6.2172e-15, 5.3291e-15,\n",
      "         3.1086e-15, 3.4972e-15, 3.6637e-15, 3.2196e-15, 4.5519e-15, 3.9968e-15,\n",
      "         4.1633e-15, 6.8834e-15, 4.4409e-15, 2.7200e-15, 5.3291e-15, 3.4972e-15,\n",
      "         3.3307e-15, 2.8866e-15, 3.9968e-15, 3.5527e-15, 2.6645e-15, 3.5527e-15,\n",
      "         5.3291e-15, 4.2744e-15, 5.7732e-15, 3.2196e-15, 2.2482e-15, 3.4417e-15,\n",
      "         3.5527e-15, 2.8866e-15, 4.4409e-15, 4.6629e-15, 4.4409e-15, 4.8850e-15,\n",
      "         2.2204e-15, 3.5527e-15, 2.7478e-15, 3.5527e-15, 4.4409e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.5527e-15, 3.3307e-15, 3.9968e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 194: layer3.19.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 194\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 194\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 194\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 194\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 194\n",
      "Max diff:\n",
      " tensor([3.5527e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.3267e-16, 4.4409e-16, 7.7716e-16, 1.1102e-15, 7.4940e-16, 4.4409e-16,\n",
      "         4.9960e-16, 8.3267e-16, 1.4433e-15, 1.1102e-15, 7.7716e-16, 5.9674e-16,\n",
      "         4.3021e-16, 1.0547e-15, 6.9389e-16, 2.7756e-17, 2.2204e-15, 9.9920e-16,\n",
      "         8.8818e-16, 1.2490e-16, 3.3307e-16, 2.2204e-15, 3.0531e-16, 9.1593e-16,\n",
      "         1.2768e-15, 6.5226e-16, 7.6328e-16, 8.8818e-16, 7.7716e-16, 1.1796e-16,\n",
      "         2.0817e-17, 1.1102e-15, 1.3878e-16, 5.5511e-16, 1.9429e-15, 5.2736e-16,\n",
      "         3.8858e-16, 3.8858e-16, 5.5511e-17, 4.9960e-16, 4.6491e-16, 9.9920e-16,\n",
      "         1.6653e-16, 1.4433e-15, 2.9837e-16, 7.2164e-16, 3.3307e-16, 1.7764e-15,\n",
      "         6.9389e-17, 3.8858e-16, 1.8874e-15, 3.5527e-15, 8.3267e-16, 6.6613e-16,\n",
      "         5.2736e-16, 9.9920e-16, 2.2204e-15, 9.4369e-16, 3.4694e-16, 6.1062e-16,\n",
      "         3.4694e-17, 8.3267e-16, 3.7470e-16, 9.9920e-16, 8.5001e-16, 2.5847e-16,\n",
      "         2.7062e-16, 9.9920e-16, 2.7929e-16, 7.7716e-16, 9.4369e-16, 2.6715e-16,\n",
      "         4.4409e-16, 6.6613e-16, 3.6082e-16, 6.9389e-17, 4.7878e-16, 7.2164e-16,\n",
      "         2.4980e-16, 8.8818e-16, 4.4409e-16, 6.1062e-16, 1.1657e-15, 7.2164e-16,\n",
      "         5.5511e-16, 1.8735e-16, 4.9960e-16, 4.4409e-16, 4.4409e-16, 4.3715e-16,\n",
      "         1.2212e-15, 6.1062e-16, 8.3267e-16, 9.4369e-16, 4.4409e-16, 4.4409e-16,\n",
      "         3.1919e-16, 4.9960e-16, 1.7764e-15, 8.0491e-16, 1.3323e-15, 6.6613e-16,\n",
      "         6.6613e-16, 1.5266e-16, 6.6613e-16, 7.6328e-16, 7.2164e-16, 7.4940e-16,\n",
      "         3.6950e-16, 1.9429e-16, 2.2204e-16, 1.1102e-16, 3.6082e-16, 7.7716e-16,\n",
      "         9.2287e-16, 1.2212e-15, 9.9920e-16, 4.5797e-16, 5.5511e-16, 8.8818e-16,\n",
      "         7.7716e-16, 6.3838e-16, 8.3267e-16, 8.3267e-17, 2.2204e-16, 4.1633e-16,\n",
      "         1.5543e-15, 5.2736e-16, 6.6613e-16, 6.1062e-16, 1.5266e-15, 2.4980e-16,\n",
      "         9.9920e-16, 4.9960e-16, 1.2212e-15, 4.9960e-16, 3.8858e-16, 1.1102e-15,\n",
      "         7.1818e-16, 8.8818e-16, 1.3323e-15, 7.5634e-16, 1.4988e-15, 7.4940e-16,\n",
      "         3.3307e-16, 1.1102e-16, 9.9920e-16, 8.6042e-16, 4.9960e-16, 7.7716e-16,\n",
      "         8.3267e-16, 3.2752e-15, 2.2204e-15, 7.7716e-16, 2.8866e-15, 4.1633e-16,\n",
      "         1.2212e-15, 1.3323e-15, 6.6613e-16, 5.5511e-16, 1.5543e-15, 4.7184e-16,\n",
      "         4.4409e-16, 8.3267e-16, 6.3838e-16, 9.7145e-16, 1.8319e-15, 1.1102e-16,\n",
      "         9.6104e-16, 2.7756e-17, 6.6613e-16, 2.7756e-16, 8.3267e-16, 1.1102e-15,\n",
      "         7.7716e-16, 8.0491e-16, 3.5527e-15, 1.9429e-16, 2.2204e-16, 2.4980e-16,\n",
      "         7.2164e-16, 1.0681e-15, 5.5511e-16, 1.0998e-15, 1.0963e-15, 8.6042e-16,\n",
      "         1.3323e-15, 3.5041e-16, 7.4940e-16, 6.9389e-16, 1.3878e-16, 2.4980e-16,\n",
      "         7.3552e-16, 9.4369e-16, 3.5527e-15, 2.9143e-16, 9.9920e-16, 1.2351e-15,\n",
      "         3.3307e-16, 1.3323e-15, 1.5266e-15, 1.2768e-15, 7.7716e-16, 5.5511e-16,\n",
      "         1.4433e-15, 1.4433e-15, 7.7022e-16, 5.5511e-16, 7.7716e-16, 9.7145e-16,\n",
      "         1.8874e-15, 1.4988e-15, 1.4433e-15, 2.2204e-15, 2.2204e-15, 1.1657e-15,\n",
      "         7.7716e-16, 1.0408e-15, 8.3961e-16, 9.1767e-16, 1.5821e-15, 1.2768e-15,\n",
      "         1.6653e-15, 1.8319e-15, 1.7764e-15, 5.9674e-16, 1.5543e-15, 5.9674e-16,\n",
      "         1.5543e-15, 6.6613e-16, 9.9920e-16, 2.2204e-15, 6.6613e-16, 9.9920e-16,\n",
      "         1.7764e-15, 8.0491e-16, 1.6653e-15, 1.1102e-15, 1.5613e-16, 1.7208e-15,\n",
      "         1.7764e-15, 8.6042e-16, 1.9984e-15, 1.2212e-15, 1.7764e-15, 2.2204e-15,\n",
      "         5.5511e-16, 9.1593e-16, 8.0491e-16, 1.2212e-15, 1.9984e-15, 2.3315e-15,\n",
      "         1.3323e-15, 1.3323e-15, 1.2212e-15, 1.4433e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 195: layer3.19.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 195\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.3267e-16, 4.4409e-16, 2.3870e-15, 4.6629e-15, 3.1086e-15, 4.4409e-16,\n",
      "         1.0547e-15, 4.4409e-15, 1.4433e-15, 1.1102e-15, 7.7716e-16, 5.9674e-16,\n",
      "         7.2164e-16, 1.2768e-15, 6.9389e-16, 6.3838e-16, 4.4409e-15, 9.9920e-16,\n",
      "         8.8818e-16, 4.3021e-16, 3.3307e-16, 2.2204e-15, 3.1086e-15, 9.9920e-16,\n",
      "         1.3323e-15, 6.5226e-16, 1.6653e-15, 1.8874e-15, 7.7716e-16, 2.2204e-15,\n",
      "         1.7764e-15, 2.8866e-15, 3.2196e-15, 4.6629e-15, 2.2204e-15, 1.1102e-15,\n",
      "         1.7764e-15, 3.8858e-16, 1.1102e-15, 1.5543e-15, 6.9944e-15, 9.9920e-16,\n",
      "         1.3600e-15, 5.3291e-15, 5.3291e-15, 4.1078e-15, 3.3307e-16, 1.7764e-15,\n",
      "         8.0491e-16, 2.3870e-15, 4.4409e-15, 3.5527e-15, 3.9968e-15, 6.6613e-16,\n",
      "         5.8287e-16, 2.1094e-15, 2.2204e-15, 1.1102e-15, 1.7764e-15, 8.8818e-16,\n",
      "         3.1086e-15, 8.3267e-16, 7.9936e-15, 4.2188e-15, 7.1054e-15, 4.9960e-16,\n",
      "         6.1062e-15, 7.1054e-15, 1.9706e-15, 5.4401e-15, 1.0658e-14, 2.3315e-15,\n",
      "         3.6637e-15, 3.9968e-15, 1.9984e-15, 7.5495e-15, 8.4377e-15, 7.5495e-15,\n",
      "         1.6653e-15, 1.6653e-15, 4.8850e-15, 7.9936e-15, 1.1657e-15, 1.0658e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.6605e-15, 4.4409e-16, 8.8818e-15, 4.3715e-16,\n",
      "         3.1086e-15, 3.6221e-15, 8.3267e-16, 2.8866e-15, 2.6645e-15, 1.4433e-15,\n",
      "         4.6629e-15, 1.6098e-15, 3.1086e-15, 7.9936e-15, 2.4425e-15, 1.0408e-15,\n",
      "         5.3291e-15, 1.1657e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.2204e-15,\n",
      "         3.7748e-15, 2.2204e-15, 5.8842e-15, 7.2164e-15, 1.3323e-15, 5.1070e-15,\n",
      "         2.7756e-15, 9.9920e-15, 5.0515e-15, 1.9984e-15, 3.3307e-15, 6.6613e-15,\n",
      "         1.1380e-15, 6.3838e-16, 3.9968e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         3.1086e-15, 2.0539e-15, 1.8874e-15, 7.1054e-15, 1.5266e-15, 3.6915e-15,\n",
      "         4.4409e-15, 3.5527e-15, 8.8818e-15, 4.8850e-15, 1.1796e-15, 1.1102e-15,\n",
      "         1.1546e-14, 1.5543e-15, 5.3291e-15, 2.6645e-15, 1.4988e-15, 1.0658e-14,\n",
      "         6.8834e-15, 1.7764e-15, 1.2768e-15, 3.3307e-15, 1.8652e-14, 7.7716e-16,\n",
      "         1.2434e-14, 6.6613e-15, 5.3291e-15, 2.8311e-15, 2.8866e-15, 6.6613e-15,\n",
      "         6.3283e-15, 1.5543e-15, 9.3259e-15, 5.5511e-16, 2.7756e-15, 5.5511e-15,\n",
      "         4.4409e-15, 2.5535e-15, 3.5527e-15, 9.7145e-16, 1.4821e-14, 3.6915e-15,\n",
      "         2.1316e-14, 2.4980e-16, 6.6613e-16, 1.0658e-14, 4.4409e-15, 1.0436e-14,\n",
      "         2.1094e-15, 1.1324e-14, 3.5527e-15, 1.9984e-15, 7.9936e-15, 8.0491e-16,\n",
      "         4.1078e-15, 2.2204e-15, 2.8866e-15, 2.5813e-15, 3.5527e-15, 4.8850e-15,\n",
      "         1.4932e-14, 4.5519e-15, 1.2434e-14, 9.5479e-15, 1.3878e-16, 2.2760e-15,\n",
      "         1.2434e-14, 2.6201e-14, 1.1546e-14, 1.4988e-15, 2.3037e-15, 8.8818e-15,\n",
      "         2.4425e-15, 1.4211e-14, 8.8818e-15, 6.4393e-15, 1.0658e-14, 3.3307e-15,\n",
      "         1.1546e-14, 1.4211e-14, 3.5527e-15, 1.4211e-14, 3.7748e-15, 2.6645e-15,\n",
      "         3.9413e-15, 3.1974e-14, 2.1316e-14, 6.2172e-15, 8.8818e-15, 5.3846e-15,\n",
      "         9.7700e-15, 9.7700e-15, 5.9952e-15, 1.1657e-15, 7.5495e-15, 1.7764e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.4417e-15, 1.7764e-14, 1.4655e-14, 1.3323e-14,\n",
      "         1.6209e-14, 8.8818e-15, 6.2172e-15, 1.0436e-14, 2.5757e-14, 1.1768e-14,\n",
      "         1.2434e-14, 1.9984e-15, 5.3291e-15, 1.4655e-14, 1.5266e-15, 7.1054e-15,\n",
      "         1.9429e-15, 9.3259e-15, 4.5519e-15, 4.4409e-15, 7.1054e-15, 1.8652e-14,\n",
      "         8.8818e-15, 6.2172e-15, 8.3267e-15, 9.5479e-15, 1.2434e-14, 1.0214e-14,\n",
      "         2.4425e-15, 5.3291e-15, 7.1054e-15, 1.1768e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 196: layer3.19.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 196\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 3.8858e-16, 2.3870e-15, 4.6629e-15, 3.1086e-15, 0.0000e+00,\n",
      "         1.0547e-15, 4.4409e-15, 1.9429e-16, 0.0000e+00, 1.3878e-16, 5.1348e-16,\n",
      "         7.2164e-16, 0.0000e+00, 5.7983e-16, 3.0531e-16, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 4.3021e-16, 0.0000e+00, 1.6098e-15, 3.1086e-15, 9.9920e-16,\n",
      "         1.3323e-15, 0.0000e+00, 1.6653e-15, 1.8874e-15, 0.0000e+00, 2.2204e-15,\n",
      "         1.7764e-15, 2.8866e-15, 3.2196e-15, 4.6629e-15, 2.2204e-15, 1.1102e-15,\n",
      "         1.7764e-15, 0.0000e+00, 1.1102e-15, 1.5543e-15, 6.9944e-15, 5.5511e-16,\n",
      "         1.3600e-15, 4.7740e-15, 5.3291e-15, 4.1078e-15, 0.0000e+00, 9.9920e-16,\n",
      "         8.0491e-16, 1.1102e-15, 0.0000e+00, 3.5527e-15, 3.9968e-15, 0.0000e+00,\n",
      "         5.8287e-16, 2.1094e-15, 3.3307e-16, 4.0246e-16, 1.7764e-15, 8.8818e-16,\n",
      "         3.1086e-15, 1.5266e-16, 7.9936e-15, 4.2188e-15, 7.1054e-15, 4.9960e-16,\n",
      "         6.1062e-15, 7.1054e-15, 1.9706e-15, 5.4401e-15, 1.0658e-14, 2.3315e-15,\n",
      "         3.6637e-15, 3.9968e-15, 1.9984e-15, 7.5495e-15, 8.4377e-15, 7.5495e-15,\n",
      "         1.6653e-15, 3.8858e-16, 4.8850e-15, 7.9936e-15, 1.1657e-15, 1.0658e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.6605e-15, 0.0000e+00, 8.8818e-15, 3.3307e-16,\n",
      "         3.1086e-15, 3.6221e-15, 4.4409e-16, 2.8866e-15, 2.6645e-15, 8.8818e-16,\n",
      "         4.6629e-15, 9.4369e-16, 3.1086e-15, 7.9936e-15, 2.4425e-15, 1.0408e-15,\n",
      "         5.3291e-15, 1.1657e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.1094e-15,\n",
      "         3.7748e-15, 2.2204e-15, 5.8842e-15, 7.2164e-15, 1.3323e-15, 5.1070e-15,\n",
      "         2.7756e-15, 9.9920e-15, 5.0515e-15, 1.9984e-15, 3.3307e-15, 6.6613e-15,\n",
      "         1.1380e-15, 2.1337e-16, 3.9968e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         1.9984e-15, 2.0539e-15, 1.1796e-16, 7.1054e-15, 1.5266e-15, 3.6915e-15,\n",
      "         4.4409e-15, 3.5527e-15, 8.8818e-15, 4.8850e-15, 9.7145e-16, 3.8858e-16,\n",
      "         1.1546e-14, 1.5543e-15, 5.3291e-15, 2.6645e-15, 9.4369e-16, 1.0658e-14,\n",
      "         6.8834e-15, 1.7764e-15, 1.2768e-15, 3.3307e-15, 1.8652e-14, 7.7716e-16,\n",
      "         1.2434e-14, 6.6613e-15, 5.3291e-15, 2.8311e-15, 2.2204e-16, 6.6613e-15,\n",
      "         6.3283e-15, 1.5543e-15, 9.3259e-15, 3.4694e-16, 2.7756e-15, 5.5511e-15,\n",
      "         4.4409e-15, 2.5535e-15, 3.5527e-15, 6.3838e-16, 1.2879e-14, 3.6915e-15,\n",
      "         2.1316e-14, 2.4980e-16, 0.0000e+00, 1.0658e-14, 4.4409e-15, 1.0436e-14,\n",
      "         2.1094e-15, 1.1324e-14, 1.2212e-15, 1.9984e-15, 7.9936e-15, 8.0491e-16,\n",
      "         4.1078e-15, 2.2204e-15, 2.8866e-15, 2.5813e-15, 3.5527e-15, 4.8850e-15,\n",
      "         1.4932e-14, 3.5527e-15, 1.2434e-14, 9.5479e-15, 0.0000e+00, 2.2760e-15,\n",
      "         1.2434e-14, 2.6201e-14, 1.1546e-14, 1.4988e-15, 2.3037e-15, 8.8818e-15,\n",
      "         2.4425e-15, 1.4211e-14, 8.8818e-15, 6.4393e-15, 1.0658e-14, 3.3307e-15,\n",
      "         1.1546e-14, 1.4211e-14, 3.5527e-15, 1.4211e-14, 3.7748e-15, 2.6645e-15,\n",
      "         3.7748e-15, 3.1974e-14, 2.1316e-14, 6.2172e-15, 8.8818e-15, 5.3846e-15,\n",
      "         9.7700e-15, 9.7700e-15, 5.9952e-15, 1.1657e-15, 7.5495e-15, 1.7764e-14,\n",
      "         7.1054e-15, 8.8818e-15, 3.4417e-15, 1.7764e-14, 1.4655e-14, 1.3323e-14,\n",
      "         1.4211e-14, 8.8818e-15, 6.2172e-15, 1.0436e-14, 2.5757e-14, 1.1768e-14,\n",
      "         1.2434e-14, 1.9984e-15, 5.3291e-15, 1.4655e-14, 1.5266e-15, 7.1054e-15,\n",
      "         1.9429e-15, 9.3259e-15, 4.5519e-15, 4.4409e-15, 7.1054e-15, 1.8652e-14,\n",
      "         8.8818e-15, 6.2172e-15, 8.3267e-15, 9.5479e-15, 1.2434e-14, 1.0214e-14,\n",
      "         2.4425e-15, 5.3291e-15, 7.1054e-15, 1.1768e-14]], dtype=torch.float64)\n",
      " tensor([  1,   2,   3,   4,   6,   7,   8,  10,  11,  12,  14,  15,  16,  19,\n",
      "         21,  22,  23,  24,  26,  27,  29,  30,  31,  32,  33,  34,  35,  36,\n",
      "         38,  39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  51,  52,  54,\n",
      "         55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   4,   6,   7,   8,  10,  11,  12,  14,  15,  16,  19,\n",
      "         21,  22,  23,  24,  26,  27,  29,  30,  31,  32,  33,  34,  35,  36,\n",
      "         38,  39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  51,  52,  54,\n",
      "         55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255])  (len = 240)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 197: layer3.20.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 197\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 197\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 197\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 197\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 197\n",
      "Max diff:\n",
      " tensor([1.5632e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.8422e-14, 9.7700e-15, 8.8818e-15, 7.9936e-15, 6.2172e-15, 3.5527e-14,\n",
      "         7.1054e-15, 3.1086e-15, 8.8818e-15, 7.9936e-15, 1.0658e-14, 8.8818e-15,\n",
      "         9.7700e-15, 6.2172e-15, 3.5527e-15, 2.6645e-15, 2.8422e-14, 1.5987e-14,\n",
      "         5.3291e-15, 4.4409e-15, 6.2172e-15, 2.4869e-14, 3.5527e-14, 3.1974e-14,\n",
      "         3.5527e-14, 1.4211e-14, 2.4869e-14, 3.1086e-15, 2.3093e-14, 1.5987e-14,\n",
      "         3.1974e-14, 4.4409e-15, 7.9936e-15, 3.5527e-14, 6.3949e-14, 7.9936e-15,\n",
      "         9.2371e-14, 3.5527e-15, 3.5527e-15, 3.1974e-14, 1.5987e-14, 3.5527e-15,\n",
      "         2.1316e-14, 7.1054e-15, 5.3291e-15, 6.2172e-15, 3.1974e-14, 3.1086e-15,\n",
      "         1.0658e-14, 6.2172e-15, 3.1974e-14, 1.0658e-14, 4.4409e-15, 3.5527e-15,\n",
      "         2.4869e-14, 1.7764e-14, 7.9936e-15, 7.1054e-15, 1.0658e-14, 1.1369e-13,\n",
      "         1.2434e-14, 1.0658e-14, 4.2633e-14, 1.4211e-14, 4.9738e-14, 4.9738e-14,\n",
      "         2.8422e-14, 7.1054e-15, 1.0658e-14, 2.8422e-14, 1.2434e-14, 1.4211e-14,\n",
      "         1.2434e-14, 3.1086e-15, 8.5265e-14, 7.1054e-15, 2.4869e-14, 2.8422e-14,\n",
      "         5.3291e-15, 2.8422e-14, 3.1974e-14, 6.3949e-14, 2.1316e-14, 2.1316e-14,\n",
      "         2.1316e-14, 7.1054e-15, 2.8422e-14, 1.7764e-14, 5.6843e-14, 7.9936e-15,\n",
      "         6.2172e-15, 6.2172e-15, 3.5527e-14, 4.9738e-14, 2.1316e-14, 8.8818e-15,\n",
      "         2.8422e-14, 2.6645e-15, 2.8422e-14, 3.1974e-14, 6.2172e-15, 2.1316e-14,\n",
      "         4.2633e-14, 9.7700e-15, 6.2172e-15, 1.7764e-14, 1.4211e-14, 2.1316e-14,\n",
      "         3.5527e-14, 3.9080e-14, 2.3093e-14, 4.9738e-14, 3.1974e-14, 8.5265e-14,\n",
      "         6.3949e-14, 7.9936e-15, 2.4869e-14, 1.0658e-14, 1.5987e-14, 5.6843e-14,\n",
      "         1.2434e-14, 1.2434e-14, 9.9476e-14, 8.5265e-14, 3.1974e-14, 4.2633e-14,\n",
      "         3.1308e-14, 2.4869e-14, 1.0658e-14, 7.1054e-14, 2.8422e-14, 7.8160e-14,\n",
      "         2.1316e-14, 2.8422e-14, 3.5527e-14, 2.4869e-14, 2.8422e-14, 1.5987e-14,\n",
      "         2.8422e-14, 1.4211e-14, 6.2172e-15, 2.8422e-14, 2.8422e-14, 3.9080e-14,\n",
      "         2.1316e-14, 2.8422e-14, 2.4869e-14, 2.8422e-14, 4.2633e-14, 7.8160e-14,\n",
      "         3.1974e-14, 8.8818e-15, 4.2633e-14, 8.5265e-14, 1.9540e-14, 6.3949e-14,\n",
      "         2.8422e-14, 3.5527e-14, 9.7700e-15, 5.6843e-14, 7.8160e-14, 4.9738e-14,\n",
      "         1.4211e-14, 3.5527e-14, 4.2633e-14, 7.1054e-14, 4.2633e-14, 5.6843e-14,\n",
      "         3.1974e-14, 1.7764e-14, 7.9936e-15, 4.9738e-14, 4.9738e-14, 1.0658e-14,\n",
      "         3.5527e-14, 2.3093e-14, 2.8422e-14, 1.0658e-14, 6.3949e-14, 9.9476e-14,\n",
      "         3.9080e-14, 1.4211e-14, 4.2633e-14, 1.7764e-14, 1.4211e-14, 2.8422e-14,\n",
      "         1.2434e-14, 4.9738e-14, 2.4869e-14, 7.8160e-14, 7.1054e-14, 5.6843e-14,\n",
      "         1.1369e-13, 4.2633e-14, 1.7764e-14, 4.9738e-14, 4.2633e-14, 1.4211e-13,\n",
      "         1.1369e-13, 1.0658e-14, 1.2790e-13, 1.2790e-13, 8.5265e-14, 2.4869e-14,\n",
      "         4.9738e-14, 1.4211e-14, 7.8160e-14, 8.5265e-14, 4.9738e-14, 9.2371e-14,\n",
      "         5.6843e-14, 4.2633e-14, 6.3949e-14, 1.1369e-13, 1.5632e-13, 1.1369e-13,\n",
      "         8.5265e-14, 7.1054e-14, 3.1974e-14, 7.8160e-14, 3.1974e-14, 7.1054e-14,\n",
      "         4.9738e-14, 4.9738e-14, 9.9476e-14, 1.2790e-13, 1.1369e-13, 9.9476e-14,\n",
      "         4.2633e-14, 6.3949e-14, 2.4869e-14, 2.1316e-14, 1.3500e-13, 8.5265e-14,\n",
      "         2.1316e-14, 1.1369e-13, 1.1369e-13, 7.1054e-14, 3.1974e-14, 8.5265e-14,\n",
      "         7.1054e-14, 1.4211e-13, 7.1054e-14, 7.1054e-14, 7.1054e-14, 9.9476e-14,\n",
      "         1.4211e-13, 2.1316e-14, 1.2790e-13, 1.1369e-13, 9.9476e-14, 1.2790e-13,\n",
      "         8.5265e-14, 3.1974e-14, 9.9476e-14, 8.5265e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 198: layer3.20.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 198\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 198\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 198\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 198\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 198\n",
      "Max diff:\n",
      " tensor([4.2633e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[5.3291e-15, 1.7764e-15, 1.1102e-15, 1.3323e-15, 1.1102e-15, 2.2204e-15,\n",
      "         1.1102e-15, 4.4409e-16, 1.5543e-15, 9.9920e-16, 1.3323e-15, 1.3323e-15,\n",
      "         1.2212e-15, 8.8818e-16, 6.6613e-16, 4.9960e-16, 3.1086e-15, 2.6645e-15,\n",
      "         5.5511e-16, 5.5511e-16, 1.1102e-15, 3.9968e-15, 4.8850e-15, 4.8850e-15,\n",
      "         1.2212e-15, 2.2204e-15, 3.9968e-15, 6.1062e-16, 3.1086e-15, 3.1086e-15,\n",
      "         3.5527e-15, 4.4409e-16, 1.4433e-15, 4.4409e-15, 7.1054e-15, 1.3323e-15,\n",
      "         1.5099e-14, 6.6613e-16, 6.6613e-16, 3.1086e-15, 2.2204e-15, 7.7716e-16,\n",
      "         3.1086e-15, 1.3323e-15, 7.7716e-16, 8.8818e-16, 3.1086e-15, 4.9960e-16,\n",
      "         9.9920e-16, 9.9920e-16, 3.1086e-15, 1.3323e-15, 7.7716e-16, 6.6613e-16,\n",
      "         2.6645e-15, 2.2204e-15, 1.4433e-15, 7.7716e-16, 1.6653e-15, 1.9540e-14,\n",
      "         1.9984e-15, 1.5543e-15, 3.5527e-15, 1.7764e-15, 7.9936e-15, 7.1054e-15,\n",
      "         5.7732e-15, 1.3323e-15, 2.2204e-15, 3.1086e-15, 1.9984e-15, 1.5543e-15,\n",
      "         2.4425e-15, 5.5511e-16, 1.5987e-14, 1.3323e-15, 3.1086e-15, 4.4409e-15,\n",
      "         1.1102e-15, 3.1086e-15, 3.9968e-15, 6.2172e-15, 3.5527e-15, 3.1086e-15,\n",
      "         3.3307e-15, 1.7764e-15, 3.9968e-15, 2.2204e-15, 3.5527e-15, 1.3323e-15,\n",
      "         8.8818e-16, 8.8818e-16, 4.4409e-15, 8.8818e-15, 2.6645e-15, 1.7764e-15,\n",
      "         6.2172e-15, 6.6613e-16, 3.1086e-15, 5.3291e-15, 1.3323e-15, 3.5527e-15,\n",
      "         7.1054e-15, 1.1102e-15, 1.1102e-15, 3.1086e-15, 1.9984e-15, 2.2204e-15,\n",
      "         3.9968e-15, 6.2172e-15, 4.4409e-15, 4.4409e-15, 4.4409e-15, 8.8818e-15,\n",
      "         1.0658e-14, 9.9920e-16, 3.1086e-15, 1.5543e-15, 3.1086e-15, 7.1054e-15,\n",
      "         2.2204e-15, 1.5543e-15, 4.2633e-14, 7.1054e-15, 4.4409e-15, 7.1054e-15,\n",
      "         4.0176e-15, 6.2172e-15, 1.7764e-15, 1.2434e-14, 4.4409e-15, 7.9936e-15,\n",
      "         4.8850e-15, 5.3291e-15, 7.1054e-15, 2.6645e-15, 3.5527e-15, 3.1086e-15,\n",
      "         4.4409e-15, 2.2204e-15, 8.8818e-16, 4.4409e-15, 3.5527e-15, 7.9936e-15,\n",
      "         2.6645e-15, 4.4409e-15, 3.5527e-15, 2.6645e-15, 6.2172e-15, 1.1546e-14,\n",
      "         4.4409e-15, 1.7764e-15, 4.4409e-15, 1.4211e-14, 2.6645e-15, 6.2172e-15,\n",
      "         4.4409e-15, 4.8850e-15, 1.7764e-15, 1.0658e-14, 1.5987e-14, 6.2172e-15,\n",
      "         2.2204e-15, 5.3291e-15, 1.1102e-15, 1.4211e-14, 6.6613e-15, 7.5495e-15,\n",
      "         3.9968e-15, 1.7764e-15, 1.7764e-15, 6.2172e-15, 6.2172e-15, 1.7764e-15,\n",
      "         3.9968e-15, 5.7732e-15, 3.1086e-15, 1.5543e-15, 2.4425e-15, 1.0658e-14,\n",
      "         6.2172e-15, 2.6645e-15, 3.5527e-15, 3.3307e-15, 1.9984e-15, 4.4409e-15,\n",
      "         1.9984e-15, 7.9936e-15, 2.8866e-15, 9.7700e-15, 1.2434e-14, 7.9936e-15,\n",
      "         2.3093e-14, 7.9936e-15, 2.2204e-15, 1.1546e-14, 5.3291e-15, 1.5099e-14,\n",
      "         2.4869e-14, 2.2204e-15, 3.5527e-14, 2.4869e-14, 3.5527e-15, 3.1086e-15,\n",
      "         1.0658e-14, 2.2204e-15, 1.0658e-14, 9.7700e-15, 6.2172e-15, 1.4211e-14,\n",
      "         8.8818e-15, 5.3291e-15, 9.7700e-15, 1.7764e-14, 3.1974e-14, 2.4869e-14,\n",
      "         2.4869e-14, 1.3323e-14, 4.4409e-15, 1.4211e-14, 7.1054e-15, 7.1054e-15,\n",
      "         7.1054e-15, 6.8834e-15, 1.7764e-14, 1.9540e-14, 1.9540e-14, 1.4211e-14,\n",
      "         5.3291e-15, 9.7700e-15, 3.1086e-15, 3.9968e-15, 1.7764e-14, 2.1316e-14,\n",
      "         3.1086e-15, 1.7764e-14, 2.1316e-14, 1.5987e-14, 4.4409e-15, 1.9540e-14,\n",
      "         1.0658e-14, 2.6645e-14, 8.8818e-15, 7.1054e-15, 1.0658e-14, 1.5987e-14,\n",
      "         3.5527e-14, 3.9968e-15, 2.1316e-14, 2.4869e-14, 2.1316e-14, 3.1974e-14,\n",
      "         1.9540e-14, 6.6613e-15, 2.1316e-14, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 199: layer3.20.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 199\n",
      "Max diff:\n",
      " tensor([6.8834e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.9960e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.6931e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9984e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0539e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.7748e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5805e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.8834e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 36,  92, 126, 134, 142, 150, 165, 206, 210, 223])\n",
      "\n",
      "failing Cout = tensor([ 36,  92, 126, 134, 142, 150, 165, 206, 210, 223])  (len = 10)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 200: layer3.20.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 200\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 65,  68,  70,  71,  75,  83,  84,  85,  89,  92,  97, 100, 102, 108,\n",
      "        111, 112, 115, 117, 125, 126]) to machine 1\n",
      "\t\t sending C_out tensor([130, 131, 133, 135, 149, 151, 152, 161, 164, 168, 169, 172, 181, 183,\n",
      "        187, 188]) to machine 2\n",
      "\t\t sending C_out tensor([193, 203, 204, 217, 218, 219, 221, 226, 228, 229, 232, 234, 240, 241,\n",
      "        243, 248, 250]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 200\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  2,  5,  6,  8,  9, 10, 11, 16, 17, 22, 26, 27, 29, 30, 33, 37, 38,\n",
      "        39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 55, 56, 58, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 134, 135, 136, 138, 140, 142, 144, 149, 151, 153,\n",
      "        155, 159, 160, 161, 162, 164, 165, 167, 168, 170, 173, 175, 176, 178,\n",
      "        179, 182, 183, 185, 186, 187, 188, 189, 191]) to machine 2\n",
      "\t\t sending C_out tensor([193, 194, 195, 196, 199, 200, 201, 203, 204, 205, 206, 207, 209, 210,\n",
      "        211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 227, 228,\n",
      "        230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 242, 244, 245, 247,\n",
      "        248, 249, 250, 251, 252, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 200\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39,\n",
      "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
      "        58, 59, 60, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 65,  66,  67,  69,  70,  72,  73,  74,  76,  77,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86,  87,  88,  93,  94,  95,  96,  98,  99, 100, 102,\n",
      "        103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 119, 120, 121,\n",
      "        122, 123, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        208, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 224, 225,\n",
      "        228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 242, 244,\n",
      "        246, 247, 248, 249, 250, 251, 252, 254]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 200\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  2,  3,  4,  5,  6,  8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 23,\n",
      "        24, 25, 28, 29, 30, 35, 37, 38, 39, 43, 44, 45, 46, 47, 48, 51, 52, 53,\n",
      "        58, 59, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 65,  66,  67,  68,  69,  70,  75,  76,  77,  79,  81,  84,  85,  86,\n",
      "         88,  89,  91,  92,  93,  95,  96,  97,  98, 100, 102, 103, 104, 105,\n",
      "        106, 107, 109, 110, 111, 112, 114, 115, 118, 119, 120, 121, 124, 125,\n",
      "        126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 143,\n",
      "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
      "        158, 159, 160, 161, 163, 166, 167, 169, 171, 172, 173, 174, 176, 177,\n",
      "        178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 200\n",
      "Max diff:\n",
      " tensor([6.6613e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.5527e-15, 5.5511e-17, 1.2212e-15, 3.1086e-15, 2.3315e-15, 3.9968e-15,\n",
      "         1.6098e-15, 1.4988e-15, 8.8634e-16, 1.7764e-15, 2.6645e-15, 1.7764e-15,\n",
      "         2.0539e-15, 1.5821e-15, 3.7748e-15, 2.8866e-15, 4.4409e-15, 1.7764e-15,\n",
      "         1.0547e-15, 4.4409e-15, 5.8287e-16, 3.7748e-15, 1.1657e-15, 1.1102e-15,\n",
      "         1.9429e-15, 1.9984e-15, 2.5535e-15, 3.3307e-15, 1.3323e-15, 1.0270e-15,\n",
      "         5.3291e-15, 1.2212e-15, 7.7716e-16, 1.0825e-15, 1.2768e-15, 1.4988e-15,\n",
      "         1.3323e-15, 3.8858e-16, 1.8874e-15, 4.1633e-15, 7.7716e-16, 1.1380e-15,\n",
      "         1.2490e-15, 1.3045e-15, 1.4988e-15, 2.2204e-15, 9.4369e-16, 1.4988e-15,\n",
      "         2.1233e-15, 3.7470e-16, 7.2164e-16, 3.4417e-15, 1.9984e-15, 1.4433e-15,\n",
      "         1.5543e-15, 1.2212e-15, 1.1657e-15, 9.7145e-16, 3.3307e-15, 2.8087e-15,\n",
      "         2.3315e-15, 6.2172e-15, 2.6645e-15, 2.4425e-15, 4.3021e-16, 2.3315e-15,\n",
      "         1.1519e-15, 5.2180e-15, 1.4433e-15, 2.8311e-15, 7.7716e-16, 4.7184e-16,\n",
      "         8.7430e-16, 1.3461e-15, 1.5543e-15, 9.7145e-16, 5.7732e-15, 1.0200e-15,\n",
      "         4.2327e-16, 2.2204e-15, 1.1657e-15, 1.7764e-15, 8.4655e-16, 2.1094e-15,\n",
      "         7.7716e-16, 1.4433e-15, 1.4988e-15, 2.2760e-15, 2.2204e-15, 1.8319e-15,\n",
      "         5.7593e-16, 5.3291e-15, 6.3838e-16, 1.6653e-15, 2.3315e-15, 1.8666e-15,\n",
      "         3.3307e-15, 1.8041e-15, 2.5535e-15, 6.6613e-16, 2.1649e-15, 1.7347e-16,\n",
      "         4.4409e-16, 1.0270e-15, 8.3267e-16, 2.6645e-15, 3.2196e-15, 4.4409e-15,\n",
      "         1.6653e-15, 2.2204e-15, 1.9984e-15, 4.7184e-16, 1.6376e-15, 6.3838e-16,\n",
      "         1.9984e-15, 2.8866e-15, 5.1348e-16, 9.1593e-16, 9.4369e-16, 3.2752e-15,\n",
      "         1.7833e-15, 2.2204e-15, 5.7593e-16, 6.6613e-16, 6.3838e-16, 1.0270e-15,\n",
      "         3.1086e-15, 6.6613e-16, 2.5535e-15, 2.7478e-15, 3.1086e-15, 3.2994e-15,\n",
      "         2.7756e-15, 2.6368e-15, 2.6645e-15, 1.4433e-15, 4.4409e-15, 1.7694e-15,\n",
      "         1.8874e-15, 2.3870e-15, 1.9984e-15, 2.6645e-15, 2.3315e-15, 1.7829e-15,\n",
      "         3.6637e-15, 6.2172e-15, 4.5519e-15, 1.4988e-15, 2.2760e-15, 1.6653e-15,\n",
      "         1.8076e-15, 2.2204e-15, 5.1070e-15, 1.8874e-15, 2.9976e-15, 1.9151e-15,\n",
      "         2.2204e-15, 3.7748e-15, 1.6376e-15, 6.6613e-15, 4.4409e-15, 2.5535e-15,\n",
      "         2.2204e-15, 4.4409e-15, 3.1086e-15, 3.3307e-15, 2.2204e-15, 6.6613e-15,\n",
      "         3.1086e-15, 1.1935e-15, 1.4433e-15, 2.4425e-15, 3.1086e-15, 2.8866e-15,\n",
      "         4.2188e-15, 2.5535e-15, 6.2172e-15, 2.6645e-15, 1.4988e-15, 1.8874e-15,\n",
      "         1.6098e-15, 2.2204e-15, 3.5527e-15, 3.9968e-15, 2.6645e-15, 2.6090e-15,\n",
      "         4.4409e-15, 2.2204e-15, 4.1078e-15, 2.3315e-15, 6.2172e-15, 1.5543e-15,\n",
      "         3.6637e-15, 5.7732e-15, 4.6629e-15, 3.6082e-15, 3.2196e-15, 2.3315e-15,\n",
      "         3.5527e-15, 1.6653e-15, 3.9413e-15, 2.6090e-15, 3.5527e-15, 2.4425e-15,\n",
      "         2.2204e-15, 2.1927e-15, 1.3323e-15, 5.5511e-15, 2.6645e-15, 1.7764e-15,\n",
      "         2.7756e-15, 3.7748e-15, 2.0539e-15, 5.3291e-15, 1.4710e-15, 3.2196e-15,\n",
      "         5.7732e-15, 2.5535e-15, 2.7756e-15, 2.2204e-15, 3.1086e-15, 2.3315e-15,\n",
      "         2.1094e-15, 2.4425e-15, 2.2204e-15, 3.3307e-15, 1.8874e-15, 1.9429e-15,\n",
      "         2.7756e-15, 2.4425e-15, 3.5527e-15, 3.1086e-15, 1.7764e-15, 1.9984e-15,\n",
      "         1.7764e-15, 2.9421e-15, 1.2698e-15, 3.5527e-15, 3.3307e-15, 3.3307e-15,\n",
      "         3.7748e-15, 1.9984e-15, 2.9560e-15, 1.9984e-15, 2.7756e-15, 2.6645e-15,\n",
      "         3.3862e-15, 2.0539e-15, 2.8866e-15, 2.4425e-15, 2.4425e-15, 3.9968e-15,\n",
      "         2.9976e-15, 3.4417e-15, 2.4425e-15, 1.1102e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 201: layer3.20.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 201\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 201\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 201\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 201\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 201\n",
      "Max diff:\n",
      " tensor([3.3307e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5543e-15, 2.7756e-17, 5.5511e-16, 2.6368e-16, 1.2212e-15, 6.6613e-16,\n",
      "         7.2164e-16, 4.2674e-16, 1.9429e-16, 3.8858e-16, 1.3323e-15, 7.7716e-16,\n",
      "         3.3307e-16, 6.6613e-16, 1.7764e-15, 1.0547e-15, 4.7184e-16, 4.1633e-16,\n",
      "         4.7184e-16, 1.4433e-15, 6.9389e-17, 8.8818e-16, 3.6082e-16, 7.2164e-16,\n",
      "         1.6653e-16, 5.5511e-16, 5.2736e-16, 7.7716e-16, 5.4123e-16, 1.5266e-16,\n",
      "         2.2204e-15, 2.2204e-16, 5.5511e-17, 3.9552e-16, 7.7716e-16, 5.6899e-16,\n",
      "         5.9674e-16, 1.1102e-16, 6.6613e-16, 2.1684e-15, 2.6368e-16, 4.4409e-16,\n",
      "         3.8858e-16, 3.3307e-16, 5.5511e-16, 5.5511e-16, 3.6082e-16, 4.9960e-16,\n",
      "         5.6899e-16, 8.3267e-17, 3.3307e-16, 9.4369e-16, 1.3878e-16, 2.2204e-16,\n",
      "         3.6082e-16, 3.8858e-16, 4.7184e-16, 4.9960e-16, 1.0547e-15, 1.1623e-15,\n",
      "         6.1062e-16, 2.6645e-15, 6.9389e-16, 6.9389e-16, 1.1102e-16, 8.3267e-16,\n",
      "         2.4980e-16, 1.8319e-15, 4.9960e-16, 3.5150e-16, 2.4980e-16, 1.3878e-16,\n",
      "         2.0817e-16, 4.0939e-16, 5.5511e-17, 2.4286e-16, 1.6653e-15, 2.4286e-16,\n",
      "         5.5511e-17, 4.8572e-16, 2.0817e-16, 5.5511e-16, 5.2736e-16, 5.5511e-16,\n",
      "         2.2204e-16, 5.2736e-16, 3.8164e-16, 1.1102e-15, 6.1062e-16, 6.1062e-16,\n",
      "         2.4980e-16, 1.9984e-15, 2.2204e-16, 7.2164e-16, 1.1380e-15, 4.0246e-16,\n",
      "         1.2212e-15, 7.4246e-16, 9.9920e-16, 2.6021e-16, 3.8858e-16, 1.3878e-17,\n",
      "         1.8735e-16, 2.2204e-16, 1.1102e-16, 1.1102e-15, 1.1102e-15, 1.9984e-15,\n",
      "         6.6613e-16, 4.9960e-16, 6.6613e-16, 8.3267e-17, 4.7878e-16, 1.6653e-16,\n",
      "         7.5634e-16, 5.5511e-16, 1.3878e-16, 5.5511e-17, 2.0817e-16, 1.0547e-15,\n",
      "         6.6613e-16, 7.7716e-16, 2.0817e-16, 1.1102e-16, 8.3267e-17, 2.7756e-16,\n",
      "         7.7716e-16, 2.4633e-16, 8.3267e-16, 8.6042e-16, 2.2204e-16, 9.8532e-16,\n",
      "         8.3267e-16, 1.1657e-15, 5.5511e-16, 3.8858e-16, 1.5543e-15, 4.1633e-16,\n",
      "         7.2164e-16, 5.4817e-16, 6.6613e-16, 8.8818e-16, 8.3267e-16, 8.1879e-16,\n",
      "         6.1062e-16, 2.2204e-15, 2.0539e-15, 1.6653e-16, 1.2490e-16, 4.9960e-16,\n",
      "         4.4409e-16, 7.7716e-16, 1.5543e-15, 4.2327e-16, 1.7764e-15, 1.3878e-17,\n",
      "         7.2164e-16, 1.5023e-15, 3.4694e-16, 3.3307e-15, 1.9984e-15, 4.3021e-16,\n",
      "         1.2143e-16, 2.2204e-15, 9.9920e-16, 1.2768e-15, 8.0491e-16, 3.1086e-15,\n",
      "         1.3323e-15, 2.2204e-16, 4.9960e-16, 7.2164e-16, 1.3600e-15, 9.9920e-16,\n",
      "         2.0539e-15, 9.9920e-16, 1.5543e-15, 1.2212e-15, 1.6306e-16, 5.2736e-16,\n",
      "         3.8858e-16, 9.9920e-16, 1.4988e-15, 1.7764e-15, 1.1102e-15, 1.2351e-15,\n",
      "         1.6653e-15, 3.4001e-16, 8.8818e-16, 2.6368e-16, 2.2204e-15, 6.9389e-17,\n",
      "         1.3323e-15, 1.5543e-15, 2.1094e-15, 4.7705e-16, 6.9389e-16, 4.9960e-16,\n",
      "         9.4369e-16, 6.3838e-16, 1.3878e-15, 9.1593e-16, 8.8818e-16, 3.3307e-16,\n",
      "         1.1102e-15, 4.5797e-16, 2.4980e-16, 1.9984e-15, 8.8818e-16, 4.4409e-16,\n",
      "         1.3323e-15, 1.8874e-15, 6.5919e-16, 1.1102e-15, 5.9328e-16, 1.0270e-15,\n",
      "         1.4433e-15, 6.3838e-16, 8.8818e-16, 6.6613e-16, 1.1657e-15, 9.9920e-16,\n",
      "         4.1633e-16, 4.7184e-16, 8.8818e-16, 8.3267e-16, 6.1062e-16, 2.3592e-16,\n",
      "         1.2212e-15, 4.9960e-16, 1.1102e-15, 4.4409e-16, 3.8858e-16, 6.1062e-16,\n",
      "         2.0990e-16, 6.1062e-16, 3.1919e-16, 9.9920e-16, 1.2212e-15, 1.2212e-15,\n",
      "         1.7764e-15, 3.3307e-16, 1.3756e-15, 6.6613e-16, 9.2981e-16, 6.6613e-16,\n",
      "         5.2736e-16, 4.8572e-16, 1.1102e-15, 7.7716e-16, 7.1124e-16, 1.5543e-15,\n",
      "         6.9389e-16, 1.2212e-15, 6.6613e-16, 4.9960e-16]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 202: layer3.20.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 202\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.5543e-15, 3.8858e-16, 2.7756e-15, 4.6629e-15, 2.9976e-15, 6.6613e-16,\n",
      "         1.0478e-15, 4.8850e-15, 1.9429e-16, 3.8858e-16, 1.3323e-15, 7.2164e-16,\n",
      "         7.7716e-16, 6.6613e-16, 2.2204e-15, 1.0547e-15, 3.1086e-15, 4.1633e-16,\n",
      "         4.7184e-16, 1.4433e-15, 6.9389e-17, 1.9984e-15, 3.1086e-15, 9.9920e-16,\n",
      "         1.3045e-15, 5.5511e-16, 1.8596e-15, 1.9845e-15, 5.4123e-16, 2.2204e-15,\n",
      "         3.0531e-15, 2.9143e-15, 3.2196e-15, 4.6629e-15, 2.2204e-15, 8.8818e-16,\n",
      "         1.9984e-15, 1.1102e-16, 1.4988e-15, 2.2204e-15, 6.9944e-15, 5.5511e-16,\n",
      "         1.3323e-15, 4.7740e-15, 5.3291e-15, 4.1078e-15, 3.6082e-16, 1.3878e-15,\n",
      "         6.0021e-16, 1.1102e-15, 3.3307e-16, 4.4409e-15, 4.1078e-15, 2.2204e-16,\n",
      "         6.1062e-16, 2.1372e-15, 4.7184e-16, 4.9960e-16, 1.7764e-15, 1.2768e-15,\n",
      "         2.7756e-15, 2.6645e-15, 7.3275e-15, 4.4409e-15, 7.1054e-15, 8.3267e-16,\n",
      "         6.0507e-15, 7.9936e-15, 1.8735e-15, 5.3291e-15, 1.0658e-14, 2.3315e-15,\n",
      "         3.8025e-15, 4.2188e-15, 1.9706e-15, 7.3275e-15, 8.4377e-15, 7.5495e-15,\n",
      "         1.6653e-15, 4.8572e-16, 4.8850e-15, 7.9936e-15, 1.1657e-15, 1.1102e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.8826e-15, 1.1102e-15, 8.8818e-15, 4.9960e-16,\n",
      "         3.1086e-15, 3.5388e-15, 4.4409e-16, 3.1086e-15, 2.2204e-15, 7.2164e-16,\n",
      "         4.8850e-15, 9.9920e-16, 3.1086e-15, 7.9936e-15, 2.4425e-15, 1.0408e-15,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 1.7764e-15, 2.3592e-15,\n",
      "         3.7748e-15, 2.2204e-15, 5.7732e-15, 7.2164e-15, 1.3323e-15, 4.8850e-15,\n",
      "         2.8866e-15, 1.0214e-14, 5.0515e-15, 1.9984e-15, 3.4417e-15, 7.1054e-15,\n",
      "         1.2212e-15, 7.7716e-16, 3.9968e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         1.9984e-15, 2.0539e-15, 8.3267e-16, 7.1054e-15, 1.6931e-15, 3.7886e-15,\n",
      "         3.9968e-15, 3.7748e-15, 9.3259e-15, 4.8850e-15, 1.5543e-15, 4.1633e-16,\n",
      "         1.1546e-14, 1.6653e-15, 5.7732e-15, 2.5535e-15, 9.4369e-16, 7.1054e-15,\n",
      "         6.8834e-15, 2.4425e-15, 2.0539e-15, 3.3307e-15, 1.8652e-14, 7.7716e-16,\n",
      "         1.2434e-14, 6.4393e-15, 6.2172e-15, 2.9976e-15, 1.7764e-15, 6.6613e-15,\n",
      "         6.3283e-15, 1.5543e-15, 9.3259e-15, 3.3307e-15, 2.4425e-15, 5.3291e-15,\n",
      "         4.4409e-15, 2.8866e-15, 3.9968e-15, 1.2768e-15, 1.2434e-14, 3.1086e-15,\n",
      "         2.1316e-14, 3.3307e-16, 4.9960e-16, 1.0214e-14, 4.4409e-15, 1.0214e-14,\n",
      "         2.2204e-15, 1.1324e-14, 1.5543e-15, 1.9984e-15, 7.9936e-15, 6.9389e-16,\n",
      "         4.1078e-15, 2.2204e-15, 3.5527e-15, 2.3315e-15, 4.2188e-15, 4.8850e-15,\n",
      "         1.4988e-14, 3.6637e-15, 1.2434e-14, 9.5479e-15, 2.2204e-15, 2.3315e-15,\n",
      "         1.2434e-14, 2.5757e-14, 1.1102e-14, 1.5266e-15, 2.2204e-15, 8.8818e-15,\n",
      "         2.8866e-15, 1.5099e-14, 9.7700e-15, 6.4393e-15, 1.1546e-14, 3.3862e-15,\n",
      "         1.2434e-14, 1.4211e-14, 3.5527e-15, 1.4877e-14, 3.8858e-15, 3.1086e-15,\n",
      "         3.7470e-15, 3.1974e-14, 2.1316e-14, 5.8842e-15, 8.8818e-15, 5.7176e-15,\n",
      "         9.7700e-15, 9.9920e-15, 5.7732e-15, 8.8818e-16, 7.3275e-15, 1.7764e-14,\n",
      "         7.1054e-15, 8.8818e-15, 2.8866e-15, 1.7764e-14, 1.4655e-14, 1.3323e-14,\n",
      "         1.4211e-14, 8.8818e-15, 6.2172e-15, 1.0325e-14, 2.5757e-14, 1.1546e-14,\n",
      "         1.2434e-14, 1.9984e-15, 5.3291e-15, 1.4655e-14, 2.4147e-15, 7.1054e-15,\n",
      "         2.1094e-15, 9.5479e-15, 4.7740e-15, 4.4409e-15, 7.3275e-15, 1.8652e-14,\n",
      "         8.8818e-15, 7.1054e-15, 7.9936e-15, 9.3259e-15, 1.2434e-14, 1.0769e-14,\n",
      "         2.6645e-15, 5.3291e-15, 6.6613e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 203: layer3.20.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 203\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-16, 0.0000e+00, 2.7756e-15, 4.6629e-15, 2.9976e-15, 0.0000e+00,\n",
      "         8.3267e-16, 4.8850e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.1062e-16, 0.0000e+00, 1.6653e-16, 1.0547e-15, 3.1086e-15, 0.0000e+00,\n",
      "         4.8572e-17, 1.4433e-15, 0.0000e+00, 4.7184e-16, 3.1086e-15, 9.9920e-16,\n",
      "         1.2490e-15, 0.0000e+00, 1.8596e-15, 1.1102e-15, 5.4123e-16, 2.2204e-15,\n",
      "         1.6931e-15, 2.9143e-15, 1.9984e-15, 4.6629e-15, 2.2204e-15, 8.8818e-16,\n",
      "         1.9984e-15, 0.0000e+00, 0.0000e+00, 2.2204e-15, 6.9944e-15, 0.0000e+00,\n",
      "         1.3323e-15, 4.7740e-15, 5.3291e-15, 4.1078e-15, 0.0000e+00, 8.8818e-16,\n",
      "         6.0021e-16, 0.0000e+00, 0.0000e+00, 4.4409e-15, 4.1078e-15, 0.0000e+00,\n",
      "         6.1062e-16, 2.1372e-15, 3.3307e-16, 4.0246e-16, 1.7764e-15, 8.8818e-16,\n",
      "         2.7756e-15, 0.0000e+00, 7.3275e-15, 4.4409e-15, 7.1054e-15, 0.0000e+00,\n",
      "         6.0507e-15, 7.9936e-15, 1.1102e-15, 5.3291e-15, 1.0658e-14, 2.3315e-15,\n",
      "         3.8025e-15, 4.2188e-15, 1.1172e-15, 7.3275e-15, 8.4377e-15, 7.5495e-15,\n",
      "         1.6653e-15, 1.6653e-16, 4.8850e-15, 7.9936e-15, 1.1657e-15, 1.1102e-14,\n",
      "         8.8818e-15, 1.5543e-15, 7.8826e-15, 0.0000e+00, 8.8818e-15, 3.8858e-16,\n",
      "         3.1086e-15, 3.5388e-15, 4.4409e-16, 3.1086e-15, 2.2204e-15, 7.2164e-16,\n",
      "         4.8850e-15, 9.9920e-16, 3.1086e-15, 7.9936e-15, 2.4425e-15, 1.0408e-15,\n",
      "         5.3291e-15, 1.2212e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.1094e-15,\n",
      "         3.7748e-15, 2.2204e-15, 5.7732e-15, 7.2164e-15, 1.3323e-15, 4.8850e-15,\n",
      "         2.8866e-15, 1.0214e-14, 5.0515e-15, 1.9984e-15, 3.4417e-15, 7.1054e-15,\n",
      "         1.1935e-15, 3.4694e-16, 3.9968e-15, 4.4409e-15, 2.6645e-15, 5.3291e-15,\n",
      "         1.9984e-15, 2.0539e-15, 0.0000e+00, 7.1054e-15, 6.6613e-16, 3.7886e-15,\n",
      "         3.9968e-15, 3.7748e-15, 9.3259e-15, 4.8850e-15, 1.1102e-16, 3.3307e-16,\n",
      "         1.1546e-14, 1.6653e-15, 5.7732e-15, 2.5535e-15, 9.4369e-16, 7.1054e-15,\n",
      "         6.8834e-15, 1.9984e-15, 0.0000e+00, 3.3307e-15, 1.8652e-14, 7.7716e-16,\n",
      "         1.2434e-14, 6.4393e-15, 6.2172e-15, 2.9976e-15, 1.7764e-15, 6.6613e-15,\n",
      "         2.6645e-15, 1.5543e-15, 9.3259e-15, 3.3307e-15, 2.4425e-15, 5.3291e-15,\n",
      "         4.4409e-15, 2.8866e-15, 3.9968e-15, 1.2768e-15, 1.2434e-14, 1.7764e-15,\n",
      "         2.1316e-14, 0.0000e+00, 0.0000e+00, 1.0214e-14, 4.4409e-15, 1.0214e-14,\n",
      "         2.2204e-15, 1.1324e-14, 0.0000e+00, 1.9984e-15, 7.9936e-15, 1.1796e-16,\n",
      "         4.1078e-15, 2.2204e-15, 3.5527e-15, 1.9984e-15, 4.2188e-15, 4.8850e-15,\n",
      "         1.1546e-14, 3.6637e-15, 1.2434e-14, 9.5479e-15, 0.0000e+00, 2.3315e-15,\n",
      "         1.2434e-14, 2.5757e-14, 1.1102e-14, 1.5266e-15, 2.1094e-15, 8.8818e-15,\n",
      "         2.8866e-15, 1.5099e-14, 9.7700e-15, 6.4393e-15, 1.1546e-14, 3.3862e-15,\n",
      "         1.2434e-14, 1.4211e-14, 3.5527e-15, 1.4877e-14, 3.8858e-15, 3.1086e-15,\n",
      "         3.7470e-15, 3.1974e-14, 2.1316e-14, 4.4409e-15, 8.8818e-15, 5.1070e-15,\n",
      "         9.7700e-15, 9.9920e-15, 5.7732e-15, 7.2164e-16, 7.3275e-15, 1.7764e-14,\n",
      "         7.1054e-15, 8.8818e-15, 2.8866e-15, 1.7764e-14, 1.4655e-14, 1.3323e-14,\n",
      "         8.8818e-15, 8.8818e-15, 6.2172e-15, 1.0325e-14, 2.5757e-14, 1.1546e-14,\n",
      "         1.2434e-14, 1.9984e-15, 5.3291e-15, 1.4655e-14, 6.1062e-16, 7.1054e-15,\n",
      "         2.1094e-15, 9.5479e-15, 4.7740e-15, 4.4409e-15, 7.3275e-15, 1.8652e-14,\n",
      "         8.8818e-15, 7.1054e-15, 7.9936e-15, 9.3259e-15, 1.2434e-14, 7.5079e-15,\n",
      "         2.6645e-15, 5.3291e-15, 6.6613e-15, 1.1546e-14]], dtype=torch.float64)\n",
      " tensor([  0,   2,   3,   4,   6,   7,  12,  14,  15,  16,  18,  19,  21,  22,\n",
      "         23,  24,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  39,\n",
      "         40,  42,  43,  44,  45,  47,  48,  51,  52,  54,  55,  56,  57,  58,\n",
      "         59,  60,  62,  63,  64,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  88,  89,\n",
      "         90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132,\n",
      "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147,\n",
      "        148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "        162, 163, 164, 165, 166, 167, 168, 171, 172, 173, 174, 175, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   2,   3,   4,   6,   7,  12,  14,  15,  16,  18,  19,  21,  22,\n",
      "         23,  24,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  39,\n",
      "         40,  42,  43,  44,  45,  47,  48,  51,  52,  54,  55,  56,  57,  58,\n",
      "         59,  60,  62,  63,  64,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  88,  89,\n",
      "         90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132,\n",
      "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147,\n",
      "        148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "        162, 163, 164, 165, 166, 167, 168, 171, 172, 173, 174, 175, 177, 178,\n",
      "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "        250, 251, 252, 253, 254, 255])  (len = 230)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 204: layer3.21.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 204\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 204\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 204\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 204\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 204\n",
      "Max diff:\n",
      " tensor([1.5632e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.8422e-14, 5.6843e-14, 7.1054e-15, 6.2172e-15, 4.4409e-15, 1.7764e-14,\n",
      "         6.2172e-15, 3.1086e-15, 2.8422e-14, 5.3291e-14, 3.5527e-15, 3.5527e-14,\n",
      "         5.3291e-15, 3.9968e-15, 8.8818e-15, 2.1316e-14, 3.5527e-14, 6.2172e-15,\n",
      "         2.4869e-14, 2.8422e-14, 2.4869e-14, 5.3291e-15, 9.7700e-15, 2.8422e-14,\n",
      "         2.8422e-14, 3.9968e-15, 6.2172e-15, 2.1316e-14, 7.1054e-15, 3.5527e-14,\n",
      "         2.1316e-14, 1.0658e-14, 1.0658e-14, 7.1054e-15, 5.3291e-15, 7.1054e-15,\n",
      "         4.9738e-14, 9.7700e-15, 2.8422e-14, 5.3291e-15, 3.1974e-14, 3.5527e-15,\n",
      "         4.9738e-14, 4.4409e-15, 3.5527e-14, 4.9738e-14, 2.8422e-14, 1.9540e-14,\n",
      "         1.5987e-14, 8.8818e-15, 4.9738e-14, 5.3291e-15, 7.1054e-15, 4.4409e-15,\n",
      "         3.1086e-15, 3.5527e-15, 5.3291e-15, 2.8422e-14, 3.5527e-14, 1.2434e-14,\n",
      "         3.9080e-14, 3.5527e-14, 4.2633e-14, 9.7700e-15, 2.8422e-14, 5.6843e-14,\n",
      "         2.8422e-14, 5.6843e-14, 4.9738e-14, 2.4869e-14, 7.9936e-15, 2.8422e-14,\n",
      "         7.1054e-15, 8.5265e-14, 8.5265e-14, 1.7764e-14, 3.5527e-14, 9.9476e-14,\n",
      "         4.2633e-14, 4.2633e-14, 1.9540e-14, 6.3949e-14, 1.1546e-14, 4.2633e-14,\n",
      "         4.6185e-14, 2.1316e-14, 1.7764e-14, 1.0658e-14, 3.9080e-14, 3.1974e-14,\n",
      "         9.7700e-15, 2.4869e-14, 5.3291e-15, 4.2633e-14, 3.5527e-14, 3.5527e-14,\n",
      "         4.2633e-14, 3.9080e-14, 4.9738e-14, 5.6843e-14, 4.9738e-14, 3.9080e-14,\n",
      "         2.8422e-14, 4.2633e-14, 2.2204e-15, 5.6843e-14, 8.8818e-15, 6.2172e-15,\n",
      "         7.9936e-15, 1.4211e-14, 1.4211e-14, 2.8422e-14, 7.1054e-14, 4.9738e-14,\n",
      "         2.8422e-14, 2.4869e-14, 2.4869e-14, 4.2633e-14, 7.1054e-14, 3.9968e-15,\n",
      "         1.7764e-14, 3.5527e-14, 1.0658e-14, 3.5527e-14, 8.5265e-14, 2.4869e-14,\n",
      "         6.3949e-14, 7.8160e-14, 3.5527e-14, 7.9936e-15, 9.9476e-14, 3.1974e-14,\n",
      "         3.1974e-14, 1.0658e-14, 5.6843e-14, 4.2633e-14, 4.9738e-14, 5.6843e-14,\n",
      "         4.9738e-14, 5.6843e-14, 1.2434e-14, 4.9738e-14, 2.6645e-15, 3.5527e-14,\n",
      "         4.2633e-14, 4.2633e-14, 6.3949e-14, 6.2172e-15, 1.2434e-14, 7.1054e-14,\n",
      "         8.5265e-14, 3.1974e-14, 2.1316e-14, 5.6843e-14, 5.6843e-14, 7.1054e-14,\n",
      "         2.1316e-14, 1.7764e-14, 4.2633e-14, 8.8818e-15, 1.2434e-14, 2.1316e-14,\n",
      "         8.8818e-15, 7.1054e-15, 6.3949e-14, 1.9540e-14, 4.2633e-14, 1.5987e-14,\n",
      "         6.3949e-14, 4.6185e-14, 2.1316e-14, 2.4869e-14, 2.1316e-14, 7.1054e-14,\n",
      "         5.6843e-14, 4.9738e-14, 2.1316e-14, 1.4211e-14, 1.0658e-13, 4.2633e-14,\n",
      "         4.2633e-14, 5.6843e-14, 2.8422e-14, 2.8422e-14, 5.6843e-14, 4.9738e-14,\n",
      "         3.5527e-14, 2.8422e-14, 1.5987e-14, 7.1054e-14, 2.8422e-14, 2.1316e-14,\n",
      "         1.4211e-14, 1.1369e-13, 3.1974e-14, 1.2790e-13, 8.5265e-14, 4.9738e-14,\n",
      "         7.8160e-14, 1.2790e-13, 6.3949e-14, 4.2633e-14, 1.1369e-13, 4.9738e-14,\n",
      "         4.9738e-14, 5.3291e-14, 7.1054e-14, 9.9476e-14, 2.6645e-14, 8.5265e-14,\n",
      "         7.1054e-14, 4.2633e-14, 2.1316e-14, 9.9476e-14, 9.9476e-14, 7.1054e-14,\n",
      "         3.5527e-14, 1.5632e-13, 5.6843e-14, 7.8160e-14, 5.6843e-14, 2.8422e-14,\n",
      "         9.2371e-14, 1.1369e-13, 1.2790e-13, 3.5527e-14, 2.4869e-14, 6.3949e-14,\n",
      "         3.9080e-14, 5.6843e-14, 5.6843e-14, 9.9476e-14, 9.9476e-14, 7.1054e-14,\n",
      "         9.9476e-14, 4.9738e-14, 6.3949e-14, 7.1054e-14, 7.4607e-14, 1.1369e-13,\n",
      "         4.2633e-14, 1.1369e-13, 1.1369e-13, 8.5265e-14, 8.5265e-14, 4.2633e-14,\n",
      "         6.4837e-14, 7.1054e-14, 6.3949e-14, 6.3949e-14, 7.1054e-14, 7.8160e-14,\n",
      "         7.1054e-14, 8.5265e-14, 4.9738e-14, 6.3949e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 205: layer3.21.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 205\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 205\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 205\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 205\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 205\n",
      "Max diff:\n",
      " tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.8850e-15, 4.4409e-15, 1.2212e-15, 1.1102e-15, 7.7716e-16, 1.9984e-15,\n",
      "         8.8818e-16, 6.6613e-16, 3.5527e-15, 7.5495e-15, 5.5511e-16, 3.9968e-15,\n",
      "         5.5511e-16, 7.7716e-16, 1.1102e-15, 3.9968e-15, 3.5527e-15, 9.9920e-16,\n",
      "         2.6645e-15, 3.1086e-15, 3.1086e-15, 6.6613e-16, 1.5543e-15, 2.2204e-15,\n",
      "         5.3291e-15, 7.7716e-16, 8.8818e-16, 2.6645e-15, 1.1102e-15, 5.3291e-15,\n",
      "         2.2204e-15, 1.3323e-15, 1.3323e-15, 9.9920e-16, 6.6613e-16, 8.8818e-16,\n",
      "         4.8850e-15, 1.5543e-15, 3.9968e-15, 8.8818e-16, 4.4409e-15, 4.4409e-16,\n",
      "         4.4409e-15, 7.7716e-16, 6.2172e-15, 6.2172e-15, 3.1086e-15, 1.9984e-15,\n",
      "         1.9984e-15, 1.3323e-15, 5.3291e-15, 8.8818e-16, 7.7716e-16, 5.5511e-16,\n",
      "         6.6613e-16, 6.6613e-16, 8.8818e-16, 3.5527e-15, 3.5527e-15, 1.7764e-15,\n",
      "         3.5527e-15, 7.1054e-15, 5.7732e-15, 1.5543e-15, 3.1086e-15, 1.2434e-14,\n",
      "         3.1086e-15, 6.2172e-15, 6.2172e-15, 3.1086e-15, 9.4369e-16, 3.1086e-15,\n",
      "         8.8818e-16, 1.7764e-14, 6.2172e-15, 2.6645e-15, 4.4409e-15, 2.1316e-14,\n",
      "         4.4409e-15, 3.9968e-15, 3.1086e-15, 8.8818e-15, 7.7716e-16, 5.3291e-15,\n",
      "         5.7732e-15, 2.6645e-15, 2.2204e-15, 1.5543e-15, 1.5543e-15, 4.8850e-15,\n",
      "         2.4425e-15, 3.5527e-15, 8.8818e-16, 1.0658e-14, 3.5527e-15, 6.2172e-15,\n",
      "         7.1054e-15, 6.2172e-15, 3.5527e-15, 4.8850e-15, 3.1086e-15, 4.8850e-15,\n",
      "         4.4409e-15, 2.4425e-15, 6.6613e-16, 1.4211e-14, 1.5543e-15, 8.8818e-16,\n",
      "         1.3323e-15, 2.4425e-15, 2.2204e-15, 3.5527e-15, 1.1546e-14, 3.9968e-15,\n",
      "         3.5527e-15, 3.5527e-15, 3.5527e-15, 7.9936e-15, 6.2172e-15, 7.7716e-16,\n",
      "         2.6645e-15, 6.2172e-15, 1.6653e-15, 2.6645e-15, 8.8818e-15, 3.5527e-15,\n",
      "         8.8818e-15, 1.4211e-14, 2.6645e-15, 7.7716e-16, 1.5987e-14, 4.4409e-15,\n",
      "         3.1086e-15, 1.7764e-15, 1.2434e-14, 7.1054e-15, 6.2172e-15, 9.7700e-15,\n",
      "         7.1054e-15, 1.2434e-14, 1.5543e-15, 4.4409e-15, 6.6613e-16, 5.3291e-15,\n",
      "         5.3291e-15, 7.5495e-15, 8.8818e-15, 1.1102e-15, 1.9984e-15, 1.7764e-14,\n",
      "         5.7732e-15, 1.5543e-15, 2.2204e-15, 8.8818e-15, 6.2172e-15, 1.2434e-14,\n",
      "         2.6645e-15, 3.5527e-15, 6.2172e-15, 1.3323e-15, 1.7764e-15, 3.5527e-15,\n",
      "         1.2212e-15, 8.8818e-16, 8.8818e-15, 3.5527e-15, 6.2172e-15, 2.6645e-15,\n",
      "         1.4211e-14, 4.8850e-15, 2.6645e-15, 2.2204e-15, 1.9984e-15, 3.5527e-15,\n",
      "         7.1054e-15, 8.8818e-15, 2.6645e-15, 1.7764e-15, 1.7764e-14, 4.4409e-15,\n",
      "         6.2172e-15, 1.0658e-14, 5.3291e-15, 3.5527e-15, 1.0658e-14, 6.2172e-15,\n",
      "         4.4409e-15, 4.4409e-15, 2.2204e-15, 7.1054e-15, 3.1086e-15, 2.4425e-15,\n",
      "         1.9984e-15, 1.9540e-14, 3.9968e-15, 2.3093e-14, 7.9936e-15, 7.1054e-15,\n",
      "         6.2172e-15, 2.8422e-14, 7.9936e-15, 5.3291e-15, 1.9540e-14, 6.2172e-15,\n",
      "         6.2172e-15, 6.6613e-15, 9.7700e-15, 1.5987e-14, 4.4409e-15, 7.9936e-15,\n",
      "         1.0658e-14, 4.4409e-15, 3.5527e-15, 1.0658e-14, 2.3093e-14, 1.5987e-14,\n",
      "         5.3291e-15, 1.7764e-14, 7.9936e-15, 1.4211e-14, 1.0658e-14, 5.7732e-15,\n",
      "         1.2434e-14, 1.7764e-14, 2.8422e-14, 5.3291e-15, 3.9968e-15, 1.1546e-14,\n",
      "         9.7700e-15, 1.2434e-14, 1.2434e-14, 1.7764e-14, 1.2434e-14, 2.1316e-14,\n",
      "         8.8818e-15, 6.2172e-15, 1.2434e-14, 1.2434e-14, 1.1102e-14, 1.7764e-14,\n",
      "         3.5527e-15, 1.9540e-14, 1.2434e-14, 1.4211e-14, 8.8818e-15, 8.8818e-15,\n",
      "         7.9936e-15, 1.2434e-14, 1.0658e-14, 1.0658e-14, 1.1546e-14, 1.4211e-14,\n",
      "         1.4211e-14, 1.2434e-14, 8.8818e-15, 1.7764e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 206: layer3.21.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 206\n",
      "Max diff:\n",
      " tensor([7.9936e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5543e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0491e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3607e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.7716e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0582e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.9143e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.7716e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 1.7764e-15,\n",
      "         0.0000e+00, 6.6613e-15, 2.2204e-16, 1.6653e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.9936e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.7732e-15, 6.8834e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6915e-15,\n",
      "         0.0000e+00, 0.0000e+00, 6.4393e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 15,  50,  62, 114, 139, 145, 164, 169, 201, 203, 205, 206, 207, 211,\n",
      "        220, 230, 238, 246, 247, 251, 254])\n",
      "\n",
      "failing Cout = tensor([ 15,  50,  62, 114, 139, 145, 164, 169, 201, 203, 205, 206, 207, 211,\n",
      "        220, 230, 238, 246, 247, 251, 254])  (len = 21)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 207: layer3.21.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 207\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 66,  67,  68,  71,  73,  76,  80,  83,  85,  86,  91,  93,  94,  98,\n",
      "         99, 100, 103, 104, 108, 110, 111, 112, 118, 119, 121, 122, 124, 127]) to machine 1\n",
      "\t\t sending C_out tensor([129, 131, 132, 133, 134, 135, 136, 137, 139, 141, 143, 144, 145, 146,\n",
      "        149, 150, 154, 159, 164, 165, 167, 169, 170, 171, 173, 174, 175, 177,\n",
      "        179, 181, 182, 184, 185, 186, 187]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 196, 197, 198, 199, 201, 202, 204, 206, 210, 211, 212, 214,\n",
      "        216, 219, 220, 221, 225, 230, 234, 235, 236, 237, 238, 240, 241, 245,\n",
      "        246, 250, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 207\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 2,  7,  9, 10, 12, 13, 14, 20, 21, 22, 30, 31, 32, 41, 43, 44, 45, 48,\n",
      "        54, 56, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 130, 135, 139, 141, 143, 144, 148, 150, 151, 152, 156, 157, 159,\n",
      "        160, 162, 164, 165, 171, 179, 181, 182, 183, 185, 186, 188, 189]) to machine 2\n",
      "\t\t sending C_out tensor([197, 199, 200, 202, 203, 204, 207, 210, 211, 212, 215, 218, 221, 222,\n",
      "        223, 226, 227, 228, 229, 230, 232, 235, 238, 240, 241, 242, 243, 249,\n",
      "        250]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 207\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
      "        38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58,\n",
      "        59, 60, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  85,  86,  87,  88,  90,  91,  92,  94,  96,  97,  98,\n",
      "         99, 100, 102, 103, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        119, 122, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 199, 200, 202, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 244, 245, 246, 247, 249, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 207\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 207\n",
      "Max diff:\n",
      " tensor([1.5987e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.4425e-15, 3.1086e-15, 1.1102e-15, 9.9920e-16, 5.9952e-15, 5.7732e-15,\n",
      "         1.4433e-15, 2.9143e-15, 1.9984e-15, 7.1054e-15, 5.9952e-15, 1.9984e-15,\n",
      "         3.5527e-15, 5.9952e-15, 1.3878e-15, 2.4425e-15, 1.8874e-15, 3.3862e-15,\n",
      "         8.3267e-16, 3.3307e-15, 6.1062e-16, 1.0658e-14, 5.3291e-15, 4.8850e-15,\n",
      "         3.2752e-15, 4.5797e-15, 4.6629e-15, 9.5757e-16, 5.6552e-16, 4.4409e-15,\n",
      "         1.9984e-15, 1.0658e-14, 2.6645e-15, 3.2196e-15, 4.7184e-16, 2.5535e-15,\n",
      "         3.9968e-15, 1.4988e-15, 2.5535e-15, 4.2188e-15, 2.4980e-15, 2.2204e-15,\n",
      "         7.1054e-15, 4.4409e-15, 3.5527e-15, 1.0408e-15, 1.3600e-15, 7.5495e-15,\n",
      "         7.3275e-15, 1.6653e-15, 1.8874e-15, 1.2212e-15, 3.3307e-15, 2.3315e-15,\n",
      "         3.6637e-15, 5.3291e-15, 1.6098e-15, 1.5543e-15, 4.2188e-15, 3.9968e-15,\n",
      "         8.8818e-15, 2.9074e-15, 2.8866e-15, 1.1102e-15, 5.6205e-16, 3.5527e-15,\n",
      "         1.9984e-15, 1.8874e-15, 7.7716e-16, 1.5543e-15, 2.2204e-15, 3.9968e-15,\n",
      "         1.1102e-15, 1.6653e-15, 1.0547e-15, 1.2004e-15, 7.1054e-15, 1.8319e-15,\n",
      "         1.3323e-15, 1.9429e-15, 7.9936e-15, 2.7756e-15, 1.7486e-15, 1.6653e-15,\n",
      "         3.1086e-15, 4.0506e-16, 3.5527e-15, 4.4409e-16, 2.4425e-15, 1.6653e-15,\n",
      "         4.4409e-15, 1.5543e-15, 1.4710e-15, 4.8850e-15, 1.0963e-15, 5.3291e-15,\n",
      "         3.9968e-15, 1.4155e-15, 4.6629e-15, 5.1070e-15, 8.8818e-16, 3.1641e-15,\n",
      "         5.1070e-15, 3.2196e-15, 1.5543e-15, 3.1086e-15, 3.5527e-15, 6.6613e-15,\n",
      "         3.7748e-15, 2.9976e-15, 2.3870e-15, 4.1078e-15, 4.8850e-15, 4.7184e-16,\n",
      "         3.9968e-15, 4.4409e-15, 3.1086e-15, 3.9968e-15, 1.6653e-15, 9.4369e-16,\n",
      "         3.9968e-15, 5.7732e-15, 3.3307e-15, 1.2976e-15, 2.4425e-15, 5.7732e-15,\n",
      "         4.3299e-15, 5.7732e-15, 2.5258e-15, 1.8319e-15, 2.2204e-15, 2.5535e-15,\n",
      "         1.8874e-15, 4.8850e-15, 1.4433e-15, 1.8874e-15, 8.8818e-15, 3.7748e-15,\n",
      "         3.8858e-15, 3.1086e-15, 2.6645e-15, 3.7748e-15, 8.0491e-16, 1.7764e-15,\n",
      "         1.3323e-15, 3.9968e-15, 1.1102e-15, 8.3267e-16, 6.6613e-15, 1.7486e-15,\n",
      "         1.6653e-15, 4.6629e-15, 4.8850e-15, 5.3291e-15, 3.1086e-15, 5.3291e-15,\n",
      "         1.7764e-15, 4.6629e-15, 2.2204e-15, 1.9984e-15, 5.3291e-15, 3.5527e-15,\n",
      "         7.6328e-16, 2.6645e-15, 5.7732e-15, 1.3045e-15, 1.6098e-15, 2.3315e-15,\n",
      "         1.7208e-15, 4.8850e-15, 2.8866e-15, 3.1641e-15, 2.8866e-15, 3.7748e-15,\n",
      "         1.8041e-15, 2.7478e-15, 2.9976e-15, 1.9984e-15, 2.2204e-15, 3.9968e-15,\n",
      "         8.8818e-16, 4.6629e-15, 2.2204e-15, 6.2172e-15, 2.4425e-15, 1.7764e-15,\n",
      "         4.4409e-15, 7.1054e-15, 4.4409e-15, 2.6645e-15, 1.0658e-14, 1.9984e-15,\n",
      "         6.2728e-15, 7.9936e-15, 6.6613e-15, 5.5511e-15, 9.7700e-15, 7.6605e-15,\n",
      "         3.9968e-15, 9.7700e-15, 4.5519e-15, 4.4409e-15, 1.1546e-14, 6.8834e-15,\n",
      "         7.5495e-15, 1.0658e-14, 5.3291e-15, 5.3291e-15, 1.1546e-14, 7.1054e-15,\n",
      "         6.2172e-15, 4.2188e-15, 9.7700e-15, 9.7700e-15, 7.1054e-15, 4.4409e-15,\n",
      "         4.4409e-15, 5.3291e-15, 4.6074e-15, 1.5987e-14, 3.7748e-15, 6.6613e-15,\n",
      "         7.1054e-15, 3.9968e-15, 7.1054e-15, 5.3291e-15, 4.7393e-15, 6.6613e-15,\n",
      "         8.8818e-15, 8.8818e-15, 3.2196e-15, 5.3291e-15, 7.9936e-15, 5.5511e-15,\n",
      "         9.7700e-15, 5.3291e-15, 5.3291e-15, 8.8818e-15, 6.4393e-15, 4.1078e-15,\n",
      "         5.3291e-15, 3.5527e-15, 5.3291e-15, 4.8850e-15, 6.2728e-15, 5.7732e-15,\n",
      "         2.2204e-15, 4.8850e-15, 1.0214e-14, 3.2196e-15, 3.5527e-15, 8.8818e-15,\n",
      "         4.4409e-15, 4.8850e-15, 4.4409e-15, 5.3291e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 208: layer3.21.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 208\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 208\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 208\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 208\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 208\n",
      "Max diff:\n",
      " tensor([4.8850e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3843e-15, 1.1102e-15, 3.6082e-16, 1.9429e-16, 2.1094e-15, 1.9984e-15,\n",
      "         4.4409e-16, 6.9389e-16, 4.9960e-16, 1.7764e-15, 2.5396e-15, 5.5511e-17,\n",
      "         1.5543e-15, 2.9976e-15, 1.6653e-16, 9.9920e-16, 8.8818e-16, 8.8818e-16,\n",
      "         1.9429e-16, 7.7022e-16, 1.3878e-16, 2.2204e-15, 1.7764e-15, 1.5543e-15,\n",
      "         1.1380e-15, 1.0547e-15, 1.6098e-15, 1.9429e-16, 1.8041e-16, 1.3323e-15,\n",
      "         6.3838e-16, 2.8866e-15, 1.3323e-15, 1.5543e-15, 1.2490e-16, 5.5511e-16,\n",
      "         1.6376e-15, 7.7716e-16, 8.3267e-16, 2.1094e-15, 4.1633e-16, 6.6266e-16,\n",
      "         1.7764e-15, 2.2204e-15, 7.7716e-16, 2.7756e-16, 3.6082e-16, 3.9968e-15,\n",
      "         4.4409e-15, 1.1102e-15, 4.4409e-16, 1.9429e-16, 6.6613e-16, 4.4409e-16,\n",
      "         8.6042e-16, 1.5543e-15, 3.8858e-16, 9.9920e-16, 1.2768e-15, 1.2212e-15,\n",
      "         1.1102e-15, 1.4988e-15, 1.5543e-15, 1.1102e-16, 1.2490e-16, 1.5543e-15,\n",
      "         8.3267e-16, 4.9960e-16, 1.3878e-16, 2.7756e-16, 5.4123e-16, 7.2164e-16,\n",
      "         1.9429e-16, 6.1062e-16, 3.8511e-16, 2.0817e-16, 9.9920e-16, 5.9674e-16,\n",
      "         3.3307e-16, 2.2204e-16, 1.9984e-15, 2.7756e-16, 4.4409e-16, 4.1633e-16,\n",
      "         7.0777e-16, 6.9389e-17, 8.8818e-16, 1.9429e-16, 1.3878e-17, 7.7716e-16,\n",
      "         3.1086e-15, 3.0531e-16, 4.9960e-16, 1.6653e-15, 2.3592e-16, 1.2212e-15,\n",
      "         7.7716e-16, 3.4001e-16, 1.8874e-15, 1.8874e-15, 2.7756e-16, 9.7145e-17,\n",
      "         1.7208e-15, 5.6899e-16, 4.9787e-16, 3.3307e-16, 8.6042e-16, 2.8866e-15,\n",
      "         1.4433e-15, 8.0491e-16, 8.1879e-16, 1.4433e-15, 1.1102e-15, 1.6653e-16,\n",
      "         8.0491e-16, 6.6613e-16, 5.8981e-16, 5.8287e-16, 5.0654e-16, 3.0531e-16,\n",
      "         6.6613e-16, 2.2204e-15, 4.5797e-16, 1.3878e-16, 2.4980e-16, 2.1094e-15,\n",
      "         1.4155e-15, 1.8874e-15, 6.1756e-16, 3.3307e-16, 3.8858e-16, 4.5103e-16,\n",
      "         6.6613e-16, 6.6613e-16, 4.4409e-16, 4.0593e-16, 3.7748e-15, 1.0547e-15,\n",
      "         1.3323e-15, 2.7756e-16, 7.7716e-16, 6.1062e-16, 4.5797e-16, 5.5511e-16,\n",
      "         4.1633e-16, 7.7716e-16, 4.4409e-16, 1.9429e-16, 1.4433e-15, 2.4980e-16,\n",
      "         2.6368e-16, 1.3878e-15, 1.1102e-15, 1.1102e-15, 3.6429e-17, 1.5543e-15,\n",
      "         5.5511e-16, 1.6653e-15, 2.4980e-16, 2.2204e-16, 1.8041e-15, 6.9389e-16,\n",
      "         1.7347e-16, 6.7307e-16, 2.3315e-15, 3.8858e-16, 3.8858e-16, 6.6613e-16,\n",
      "         6.3838e-16, 8.8818e-16, 7.7716e-16, 9.1593e-16, 6.8001e-16, 1.5543e-15,\n",
      "         6.9389e-16, 7.9103e-16, 5.2736e-16, 6.6613e-16, 2.7062e-16, 4.9960e-16,\n",
      "         1.2490e-16, 1.3878e-15, 7.7716e-16, 3.1086e-15, 7.2164e-16, 6.9389e-16,\n",
      "         1.3323e-15, 9.9920e-16, 2.2204e-15, 2.7756e-16, 4.6629e-15, 6.6613e-16,\n",
      "         1.9013e-15, 1.5543e-15, 3.1086e-15, 8.3267e-16, 2.4425e-15, 1.8874e-15,\n",
      "         7.2164e-16, 4.8850e-15, 2.2204e-15, 1.7764e-15, 2.6645e-15, 1.2490e-15,\n",
      "         2.3870e-15, 3.5527e-15, 1.7208e-15, 1.9984e-15, 4.8850e-15, 1.9984e-15,\n",
      "         3.1086e-15, 1.4433e-15, 3.3307e-15, 2.4425e-15, 3.5527e-15, 9.9920e-16,\n",
      "         1.5543e-15, 2.2204e-15, 1.2490e-15, 3.5527e-15, 7.2164e-16, 9.9920e-16,\n",
      "         3.3307e-15, 1.1102e-15, 3.3307e-15, 1.9984e-15, 1.0825e-15, 2.1094e-15,\n",
      "         4.4409e-15, 2.6645e-15, 6.1062e-16, 1.7764e-15, 1.9984e-15, 1.3600e-15,\n",
      "         1.2212e-15, 8.8818e-16, 1.2212e-15, 3.5527e-15, 1.1657e-15, 1.6098e-15,\n",
      "         1.7764e-15, 1.3323e-15, 2.1094e-15, 1.0825e-15, 2.2621e-15, 1.4433e-15,\n",
      "         4.4409e-16, 1.1102e-15, 3.9968e-15, 1.3323e-15, 5.5511e-16, 3.4417e-15,\n",
      "         7.2164e-16, 9.9920e-16, 1.1102e-15, 2.6645e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 209: layer3.21.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 209\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3843e-15, 1.1102e-15, 2.7756e-15, 4.6629e-15, 4.2188e-15, 1.9984e-15,\n",
      "         8.3267e-16, 4.8850e-15, 4.9960e-16, 1.7764e-15, 2.5396e-15, 5.5511e-17,\n",
      "         1.5543e-15, 2.9976e-15, 1.6653e-16, 1.0270e-15, 3.1086e-15, 8.8818e-16,\n",
      "         1.9429e-16, 1.2768e-15, 1.3878e-16, 2.2204e-15, 3.7748e-15, 1.7208e-15,\n",
      "         1.2212e-15, 1.0547e-15, 1.7486e-15, 9.4369e-16, 5.4123e-16, 2.6645e-15,\n",
      "         1.7764e-15, 4.2744e-15, 2.2204e-15, 4.2188e-15, 2.2204e-15, 8.3267e-16,\n",
      "         2.2204e-15, 7.7716e-16, 8.3267e-16, 3.2196e-15, 6.9944e-15, 6.6266e-16,\n",
      "         1.7764e-15, 5.8842e-15, 5.7732e-15, 4.1078e-15, 3.6082e-16, 3.9968e-15,\n",
      "         4.4409e-15, 1.1102e-15, 4.4409e-16, 4.4409e-15, 4.1078e-15, 4.4409e-16,\n",
      "         8.6042e-16, 1.5821e-15, 3.8858e-16, 1.3323e-15, 1.5543e-15, 1.2212e-15,\n",
      "         2.9976e-15, 1.4988e-15, 7.7716e-15, 4.4409e-15, 7.1054e-15, 1.5543e-15,\n",
      "         5.5511e-15, 7.9936e-15, 1.1102e-15, 5.3291e-15, 1.0658e-14, 2.2482e-15,\n",
      "         3.6915e-15, 4.2188e-15, 1.0582e-15, 7.3275e-15, 8.8818e-15, 7.6605e-15,\n",
      "         1.6653e-15, 2.2204e-16, 5.9952e-15, 7.9936e-15, 1.2212e-15, 1.1102e-14,\n",
      "         9.3259e-15, 1.5543e-15, 7.8548e-15, 1.9429e-16, 8.8818e-15, 7.7716e-16,\n",
      "         3.5527e-15, 3.5527e-15, 4.9960e-16, 3.5527e-15, 2.2204e-15, 1.6653e-15,\n",
      "         4.8850e-15, 9.9920e-16, 3.9968e-15, 7.9936e-15, 2.4425e-15, 9.9920e-16,\n",
      "         7.1054e-15, 1.1102e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.8866e-15,\n",
      "         4.1078e-15, 2.2204e-15, 5.8842e-15, 7.5495e-15, 1.3323e-15, 4.8850e-15,\n",
      "         2.6645e-15, 1.0214e-14, 4.8850e-15, 2.2204e-15, 3.8858e-15, 7.5495e-15,\n",
      "         1.0547e-15, 2.2204e-15, 3.9968e-15, 4.4409e-15, 2.4425e-15, 5.8842e-15,\n",
      "         2.2760e-15, 3.6637e-15, 6.1756e-16, 7.1054e-15, 8.8818e-16, 3.7331e-15,\n",
      "         4.4409e-15, 3.9968e-15, 9.3259e-15, 4.8850e-15, 3.7748e-15, 1.0547e-15,\n",
      "         1.1546e-14, 1.7764e-15, 5.7732e-15, 2.6645e-15, 1.3323e-15, 7.1054e-15,\n",
      "         6.6613e-15, 1.8874e-15, 4.4409e-16, 3.3307e-15, 1.8652e-14, 7.7716e-16,\n",
      "         1.2434e-14, 6.1062e-15, 7.5495e-15, 3.5527e-15, 1.7764e-15, 6.2172e-15,\n",
      "         2.5535e-15, 2.8866e-15, 9.3259e-15, 3.3307e-15, 2.2482e-15, 5.3291e-15,\n",
      "         4.4409e-15, 2.5535e-15, 4.4409e-15, 1.2768e-15, 1.2434e-14, 1.2490e-15,\n",
      "         2.1316e-14, 8.8818e-16, 7.7716e-16, 1.0214e-14, 4.4409e-15, 1.1324e-14,\n",
      "         2.1094e-15, 1.1768e-14, 5.2736e-16, 1.5543e-15, 7.9936e-15, 4.9960e-16,\n",
      "         4.1078e-15, 1.7208e-15, 3.8858e-15, 3.1086e-15, 4.2188e-15, 4.8850e-15,\n",
      "         1.1546e-14, 3.3862e-15, 1.2434e-14, 9.5479e-15, 4.6629e-15, 2.3315e-15,\n",
      "         1.2434e-14, 2.4425e-14, 1.0658e-14, 1.3878e-15, 3.7748e-15, 8.8818e-15,\n",
      "         2.8866e-15, 1.4655e-14, 1.1768e-14, 6.8834e-15, 9.1038e-15, 3.5527e-15,\n",
      "         1.2434e-14, 1.6431e-14, 3.5527e-15, 1.3989e-14, 4.8850e-15, 2.6645e-15,\n",
      "         3.8858e-15, 3.1974e-14, 2.1316e-14, 4.8850e-15, 8.3267e-15, 4.8850e-15,\n",
      "         9.7700e-15, 8.6597e-15, 6.8834e-15, 3.5527e-15, 7.1054e-15, 1.7764e-14,\n",
      "         8.8818e-15, 8.8818e-15, 4.2188e-15, 1.7764e-14, 1.4877e-14, 1.3323e-14,\n",
      "         9.3259e-15, 8.4377e-15, 6.2172e-15, 1.0769e-14, 2.4869e-14, 1.2434e-14,\n",
      "         1.2434e-14, 2.2204e-15, 5.3291e-15, 1.7319e-14, 1.1657e-15, 7.1054e-15,\n",
      "         2.7756e-15, 8.8818e-15, 5.2180e-15, 4.4409e-15, 8.1046e-15, 1.9096e-14,\n",
      "         8.8818e-15, 8.8818e-15, 7.2164e-15, 9.2149e-15, 1.2434e-14, 7.6744e-15,\n",
      "         2.6645e-15, 5.3291e-15, 7.1054e-15, 1.3545e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 210: layer3.21.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 210\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3843e-15, 0.0000e+00, 2.7756e-15, 4.6629e-15, 4.2188e-15, 1.9984e-15,\n",
      "         8.3267e-16, 4.8850e-15, 1.0235e-16, 0.0000e+00, 2.5396e-15, 0.0000e+00,\n",
      "         2.2204e-16, 2.7200e-15, 0.0000e+00, 9.4369e-16, 3.1086e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.2768e-15, 0.0000e+00, 0.0000e+00, 3.7748e-15, 1.7208e-15,\n",
      "         1.2212e-15, 1.0408e-16, 1.3323e-15, 9.4369e-16, 2.6888e-17, 2.6645e-15,\n",
      "         1.7764e-15, 2.9490e-17, 2.2204e-15, 4.2188e-15, 2.2204e-15, 8.3267e-16,\n",
      "         2.2204e-15, 3.4694e-16, 0.0000e+00, 3.2196e-15, 6.9944e-15, 6.6266e-16,\n",
      "         8.3267e-16, 2.9421e-15, 5.7732e-15, 4.1078e-15, 0.0000e+00, 3.9968e-15,\n",
      "         1.3323e-15, 6.0368e-16, 1.6567e-16, 4.4409e-15, 4.1078e-15, 0.0000e+00,\n",
      "         6.1062e-16, 0.0000e+00, 3.3307e-16, 6.9389e-17, 1.5543e-15, 5.5511e-16,\n",
      "         2.9976e-15, 1.2351e-15, 5.2180e-15, 4.4409e-15, 7.1054e-15, 1.3323e-15,\n",
      "         5.5511e-15, 7.9936e-15, 1.1102e-15, 5.3291e-15, 1.0658e-14, 2.2482e-15,\n",
      "         2.3315e-15, 4.2188e-15, 1.0582e-15, 7.3275e-15, 8.8818e-15, 7.6605e-15,\n",
      "         1.6653e-15, 0.0000e+00, 5.9952e-15, 7.9936e-15, 1.2212e-15, 1.1102e-14,\n",
      "         9.3259e-15, 1.5543e-15, 7.8548e-15, 0.0000e+00, 8.8818e-15, 0.0000e+00,\n",
      "         3.5527e-15, 3.0531e-16, 4.4409e-16, 3.5527e-15, 2.2204e-15, 6.6613e-16,\n",
      "         4.8850e-15, 9.9920e-16, 2.6645e-15, 7.9936e-15, 2.4425e-15, 7.2858e-17,\n",
      "         7.1054e-15, 1.1102e-15, 1.1102e-15, 1.0658e-14, 1.1102e-15, 2.3870e-15,\n",
      "         4.1078e-15, 2.2204e-15, 5.8842e-15, 7.5495e-15, 1.3323e-15, 4.8850e-15,\n",
      "         2.6645e-15, 1.0214e-14, 4.8850e-15, 2.2204e-15, 3.8858e-15, 7.5495e-15,\n",
      "         8.8818e-16, 2.2204e-15, 3.9968e-15, 4.4409e-15, 2.4425e-15, 5.8842e-15,\n",
      "         2.2760e-15, 3.6637e-15, 3.8164e-16, 7.1054e-15, 8.8818e-16, 1.8319e-15,\n",
      "         4.4409e-15, 3.9968e-15, 9.3259e-15, 4.8850e-15, 3.7748e-15, 5.5511e-16,\n",
      "         1.1546e-14, 1.7764e-15, 5.7732e-15, 2.6645e-15, 1.3323e-15, 7.1054e-15,\n",
      "         6.6613e-15, 1.8874e-15, 1.1102e-16, 3.3307e-15, 1.8652e-14, 7.7716e-16,\n",
      "         1.2434e-14, 6.1062e-15, 7.5495e-15, 2.4425e-15, 1.7764e-15, 6.2172e-15,\n",
      "         2.5535e-15, 2.1094e-15, 9.3259e-15, 3.3307e-15, 2.2482e-15, 5.3291e-15,\n",
      "         4.4409e-15, 2.5535e-15, 4.4409e-15, 3.3307e-16, 1.2434e-14, 6.6613e-16,\n",
      "         2.1316e-14, 0.0000e+00, 0.0000e+00, 1.0214e-14, 4.4409e-15, 1.1324e-14,\n",
      "         2.1094e-15, 1.1768e-14, 5.2736e-16, 1.5543e-15, 7.9936e-15, 0.0000e+00,\n",
      "         4.1078e-15, 1.7208e-15, 3.8858e-15, 3.1086e-15, 4.2188e-15, 4.8850e-15,\n",
      "         1.1546e-14, 3.3862e-15, 1.2434e-14, 9.5479e-15, 4.6629e-15, 2.3315e-15,\n",
      "         1.2434e-14, 2.4425e-14, 1.0658e-14, 1.3878e-15, 8.8818e-16, 8.8818e-15,\n",
      "         2.8866e-15, 1.4655e-14, 1.1768e-14, 1.3323e-15, 6.2172e-15, 3.5527e-15,\n",
      "         1.2434e-14, 1.6431e-14, 3.5527e-15, 1.2879e-14, 1.7764e-15, 2.6645e-15,\n",
      "         2.6645e-15, 3.1974e-14, 2.1316e-14, 4.8850e-15, 8.3267e-15, 4.8850e-15,\n",
      "         9.7700e-15, 8.6597e-15, 6.8834e-15, 4.9960e-16, 7.1054e-15, 1.7764e-14,\n",
      "         8.8818e-15, 8.8818e-15, 4.2188e-15, 1.7764e-14, 1.4877e-14, 1.3323e-14,\n",
      "         9.3259e-15, 8.4377e-15, 6.2172e-15, 7.5495e-15, 2.4869e-14, 1.2434e-14,\n",
      "         1.2434e-14, 2.2204e-15, 5.3291e-15, 1.7319e-14, 7.2164e-16, 7.1054e-15,\n",
      "         1.7764e-15, 8.8818e-15, 5.2180e-15, 4.4409e-15, 8.1046e-15, 1.9096e-14,\n",
      "         8.8818e-15, 8.8818e-15, 7.2164e-15, 8.6597e-15, 1.2434e-14, 7.5495e-15,\n",
      "         2.6645e-15, 5.3291e-15, 7.1054e-15, 1.3545e-14]], dtype=torch.float64)\n",
      " tensor([  0,   2,   3,   4,   5,   6,   7,   8,  10,  12,  13,  15,  16,  19,\n",
      "         22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
      "         36,  37,  39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  50,  51,\n",
      "         52,  54,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  82,\n",
      "         83,  84,  85,  86,  88,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   2,   3,   4,   5,   6,   7,   8,  10,  12,  13,  15,  16,  19,\n",
      "         22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
      "         36,  37,  39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  50,  51,\n",
      "         52,  54,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  82,\n",
      "         83,  84,  85,  86,  88,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
      "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255])  (len = 238)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 211: layer3.22.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 211\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 211\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 211\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 211\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 211\n",
      "Max diff:\n",
      " tensor([1.5632e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-15, 3.1974e-14, 3.5527e-15, 2.1316e-14, 5.3291e-15, 7.1054e-15,\n",
      "         6.2172e-15, 6.2172e-15, 8.8818e-15, 2.8422e-14, 2.8422e-14, 3.5527e-15,\n",
      "         4.2633e-14, 3.1974e-14, 3.1086e-15, 5.6843e-14, 2.1316e-14, 5.3291e-15,\n",
      "         7.1054e-15, 6.0396e-14, 7.9936e-15, 1.7764e-14, 6.2172e-15, 3.1086e-15,\n",
      "         1.2434e-14, 4.2633e-14, 1.7764e-14, 2.4869e-14, 8.8818e-15, 1.5987e-14,\n",
      "         2.4869e-14, 1.5987e-14, 5.3291e-15, 3.7303e-14, 2.1316e-14, 8.8818e-15,\n",
      "         3.5527e-15, 7.1054e-15, 7.1054e-15, 2.1316e-14, 2.1316e-14, 2.4869e-14,\n",
      "         6.2172e-15, 2.1316e-14, 2.1316e-14, 5.3291e-15, 8.8818e-15, 7.1054e-15,\n",
      "         6.2172e-15, 1.2434e-14, 4.4409e-15, 2.1316e-14, 1.5987e-14, 5.6843e-14,\n",
      "         4.4409e-15, 1.0658e-14, 3.9968e-15, 7.1054e-15, 7.9936e-15, 2.4869e-14,\n",
      "         2.6645e-15, 1.0658e-14, 8.8818e-15, 5.3291e-15, 1.2434e-14, 8.8818e-15,\n",
      "         7.1054e-15, 1.2434e-14, 3.5527e-14, 4.2633e-14, 1.4211e-14, 6.3949e-14,\n",
      "         4.7962e-14, 1.4211e-14, 1.7764e-14, 1.5987e-14, 9.2371e-14, 2.8422e-14,\n",
      "         1.7764e-14, 7.8160e-14, 4.4409e-15, 7.9936e-15, 4.2633e-14, 9.9476e-14,\n",
      "         4.2633e-14, 1.5987e-14, 1.0658e-14, 1.5987e-14, 4.9738e-14, 2.8422e-14,\n",
      "         3.5527e-14, 3.5527e-14, 3.5527e-15, 4.2633e-14, 1.7764e-14, 3.1974e-14,\n",
      "         7.8160e-14, 4.9738e-14, 9.9476e-14, 4.9738e-14, 4.2633e-14, 4.2633e-14,\n",
      "         8.5265e-14, 3.5527e-14, 6.2172e-15, 2.8422e-14, 7.9936e-15, 9.2371e-14,\n",
      "         1.1369e-13, 1.2434e-14, 9.9476e-14, 3.5527e-14, 1.4211e-14, 8.5265e-14,\n",
      "         3.5527e-14, 4.2633e-14, 3.5527e-14, 1.7764e-14, 2.1316e-14, 5.6843e-14,\n",
      "         6.3949e-14, 7.1054e-15, 1.2434e-14, 4.9738e-14, 4.9738e-14, 4.2633e-14,\n",
      "         1.0658e-14, 2.1316e-14, 3.5527e-14, 2.8422e-14, 2.8422e-14, 2.8422e-14,\n",
      "         3.9080e-14, 8.8818e-15, 8.8818e-15, 2.5757e-14, 2.8422e-14, 4.9738e-14,\n",
      "         3.1974e-14, 3.1974e-14, 1.4211e-14, 3.5527e-14, 3.1974e-14, 2.3093e-14,\n",
      "         1.4211e-14, 7.1054e-14, 4.2633e-14, 1.5987e-14, 1.7764e-14, 5.6843e-14,\n",
      "         5.6843e-14, 6.3949e-14, 3.5527e-14, 7.1054e-14, 3.9080e-14, 7.9936e-15,\n",
      "         5.3291e-15, 4.2633e-14, 4.9738e-14, 7.9936e-15, 5.6843e-14, 6.3949e-14,\n",
      "         4.2633e-14, 3.1974e-14, 5.6843e-14, 7.1942e-14, 2.6645e-14, 9.2371e-14,\n",
      "         3.9080e-14, 8.8818e-15, 8.5265e-14, 2.4869e-14, 2.1316e-14, 4.2633e-14,\n",
      "         4.9738e-14, 2.4869e-14, 1.1369e-13, 2.4869e-14, 2.4869e-14, 3.5527e-14,\n",
      "         1.2434e-14, 1.0658e-14, 1.7764e-14, 5.6843e-14, 6.3949e-14, 6.3949e-14,\n",
      "         5.6843e-14, 4.2633e-14, 1.0658e-14, 4.7962e-14, 9.7700e-15, 3.5527e-14,\n",
      "         4.2633e-14, 7.8604e-14, 6.3949e-14, 2.1316e-14, 2.4869e-14, 5.6843e-14,\n",
      "         1.1369e-13, 2.8422e-14, 3.1974e-14, 8.5265e-14, 1.2790e-13, 4.8628e-14,\n",
      "         8.5265e-14, 3.5527e-14, 4.2633e-14, 5.6843e-14, 2.8422e-14, 8.5265e-14,\n",
      "         7.1054e-14, 6.2172e-14, 6.3949e-14, 1.1369e-13, 7.1054e-14, 3.5527e-14,\n",
      "         8.5265e-14, 7.1054e-14, 9.9476e-14, 3.5527e-14, 8.5265e-14, 4.2633e-14,\n",
      "         1.5632e-13, 8.5265e-14, 5.6843e-14, 4.9738e-14, 5.6843e-14, 9.9476e-14,\n",
      "         4.9738e-14, 8.5265e-14, 9.9476e-14, 2.1316e-14, 9.2371e-14, 7.1054e-14,\n",
      "         5.6843e-14, 1.0658e-13, 2.1316e-14, 3.5527e-14, 8.5265e-14, 8.5265e-14,\n",
      "         1.1369e-13, 3.5527e-14, 5.6843e-14, 4.6185e-14, 2.4869e-14, 6.3949e-14,\n",
      "         8.5265e-14, 1.2790e-13, 4.2633e-14, 6.3949e-14, 1.9540e-14, 1.4211e-13,\n",
      "         1.2790e-13, 5.6843e-14, 9.9476e-14, 1.1369e-13]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 212: layer3.22.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 212\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 212\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 212\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 212\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 212\n",
      "Max diff:\n",
      " tensor([2.3093e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.6613e-16, 3.5527e-15, 4.4409e-16, 2.4425e-15, 4.4409e-16, 8.8818e-16,\n",
      "         1.1102e-15, 8.8818e-16, 1.5543e-15, 2.2204e-15, 3.9968e-15, 5.5511e-16,\n",
      "         3.5527e-15, 2.4425e-15, 4.9960e-16, 2.6645e-15, 3.1086e-15, 7.7716e-16,\n",
      "         8.8818e-16, 6.6613e-15, 1.2212e-15, 2.2204e-15, 6.6613e-16, 3.8858e-16,\n",
      "         1.9984e-15, 5.3291e-15, 2.2204e-15, 3.9968e-15, 1.1102e-15, 1.5543e-15,\n",
      "         2.2204e-15, 2.2204e-15, 6.6613e-16, 5.7732e-15, 1.7764e-15, 1.3323e-15,\n",
      "         8.8818e-16, 1.2212e-15, 9.9920e-16, 1.9984e-15, 2.2204e-15, 2.2204e-15,\n",
      "         8.8818e-16, 2.6645e-15, 2.6645e-15, 5.5511e-16, 9.9920e-16, 1.1102e-15,\n",
      "         6.6613e-16, 9.9920e-16, 9.9920e-16, 2.6645e-15, 1.9984e-15, 3.1086e-15,\n",
      "         5.5511e-16, 1.1102e-15, 7.7716e-16, 1.1102e-15, 8.8818e-16, 2.6645e-15,\n",
      "         2.4980e-16, 1.3323e-15, 1.1102e-15, 9.9920e-16, 1.5543e-15, 1.1102e-15,\n",
      "         5.5511e-16, 1.9984e-15, 3.5527e-15, 6.2172e-15, 1.7764e-15, 1.9984e-15,\n",
      "         4.4409e-15, 1.7764e-15, 2.2204e-15, 2.4425e-15, 9.7700e-15, 3.5527e-15,\n",
      "         2.6645e-15, 1.7764e-14, 6.6613e-16, 9.9920e-16, 6.2172e-15, 1.5987e-14,\n",
      "         7.1054e-15, 1.9984e-15, 1.5543e-15, 2.4425e-15, 2.6645e-15, 2.2204e-15,\n",
      "         5.3291e-15, 3.1086e-15, 4.9960e-16, 4.4409e-15, 2.6645e-15, 2.2204e-15,\n",
      "         9.7700e-15, 1.0658e-14, 1.2434e-14, 3.9968e-15, 5.3291e-15, 4.4409e-15,\n",
      "         1.0658e-14, 5.7732e-15, 8.8818e-16, 2.4425e-15, 1.7764e-15, 7.5495e-15,\n",
      "         2.3093e-14, 1.1102e-15, 7.1054e-15, 4.4409e-15, 2.2204e-15, 1.0658e-14,\n",
      "         4.4409e-15, 3.5527e-15, 1.2212e-15, 2.6645e-15, 2.6645e-15, 4.4409e-15,\n",
      "         6.2172e-15, 1.3323e-15, 2.6645e-15, 7.1054e-15, 6.2172e-15, 4.4409e-15,\n",
      "         1.7764e-15, 2.6645e-15, 3.5527e-15, 1.7764e-15, 3.5527e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.4433e-15, 1.1102e-15, 4.1078e-15, 4.4409e-15, 7.1054e-15,\n",
      "         3.9968e-15, 3.9968e-15, 8.8818e-16, 3.5527e-15, 3.9968e-15, 4.8850e-15,\n",
      "         3.5527e-15, 7.1054e-15, 3.6143e-15, 2.2204e-15, 2.2204e-15, 1.0658e-14,\n",
      "         7.9936e-15, 9.7700e-15, 2.8866e-15, 7.9936e-15, 4.4409e-15, 1.5543e-15,\n",
      "         6.6613e-16, 5.3291e-15, 8.8818e-15, 1.2212e-15, 6.2172e-15, 5.3291e-15,\n",
      "         4.4409e-15, 2.4980e-15, 7.1054e-15, 7.2164e-15, 1.8874e-15, 1.1546e-14,\n",
      "         3.1086e-15, 9.9920e-16, 8.8818e-15, 4.4409e-15, 3.1086e-15, 4.4409e-15,\n",
      "         2.2204e-15, 2.2204e-15, 1.5987e-14, 2.6645e-15, 3.5527e-15, 4.8850e-15,\n",
      "         2.4425e-15, 1.7764e-15, 3.1086e-15, 7.1054e-15, 4.4409e-15, 5.3291e-15,\n",
      "         1.2434e-14, 8.8818e-15, 1.9984e-15, 4.2188e-15, 1.6653e-15, 3.9968e-15,\n",
      "         4.4409e-15, 1.1546e-14, 1.0658e-14, 3.1086e-15, 3.1086e-15, 4.8850e-15,\n",
      "         1.5987e-14, 3.5527e-15, 4.8850e-15, 1.9540e-14, 1.9540e-14, 4.0714e-15,\n",
      "         1.4211e-14, 5.3291e-15, 5.3291e-15, 7.1054e-15, 3.5527e-15, 1.7764e-14,\n",
      "         9.7700e-15, 7.1054e-15, 6.6613e-15, 1.4211e-14, 1.5987e-14, 5.3291e-15,\n",
      "         1.1546e-14, 6.2172e-15, 1.4211e-14, 5.3291e-15, 8.8818e-15, 7.1054e-15,\n",
      "         2.3093e-14, 2.1316e-14, 1.2434e-14, 7.1054e-15, 4.4409e-15, 1.4211e-14,\n",
      "         7.1054e-15, 1.7764e-14, 1.4211e-14, 3.1086e-15, 5.7732e-15, 1.2434e-14,\n",
      "         6.2172e-15, 1.5987e-14, 3.5527e-15, 2.2204e-15, 1.7764e-14, 1.4211e-14,\n",
      "         1.4211e-14, 4.4409e-15, 7.1054e-15, 5.7732e-15, 3.5527e-15, 7.1054e-15,\n",
      "         1.7764e-14, 1.4211e-14, 3.1086e-15, 7.5495e-15, 1.9984e-15, 2.3093e-14,\n",
      "         1.7764e-14, 7.1054e-15, 1.2434e-14, 1.7764e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 213: layer3.22.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 213\n",
      "Max diff:\n",
      " tensor([1.1546e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9429e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0547e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6653e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1078e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.8866e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5511e-16,\n",
      "         0.0000e+00, 2.4980e-15, 0.0000e+00, 0.0000e+00, 1.2212e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9920e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5535e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1546e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1094e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4417e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.1054e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7732e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.8866e-15, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([ 19,  72,  98, 118, 131, 135, 141, 146, 152, 161, 163, 166, 173, 179,\n",
      "        189, 193, 197, 203, 211, 232, 241, 242])\n",
      "\n",
      "failing Cout = tensor([ 19,  72,  98, 118, 131, 135, 141, 146, 152, 161, 163, 166, 173, 179,\n",
      "        189, 193, 197, 203, 211, 232, 241, 242])  (len = 22)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 214: layer3.22.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 214\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 68,  69,  70,  74,  79,  81,  85,  89,  93,  97, 109, 110, 116, 126]) to machine 1\n",
      "\t\t sending C_out tensor([129, 130, 137, 143, 148, 149, 159, 160, 166, 168, 169, 175, 177, 178,\n",
      "        181, 182, 184, 187]) to machine 2\n",
      "\t\t sending C_out tensor([210, 213, 216, 225, 231, 236, 244, 246, 249, 253]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 214\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 11, 13, 17, 18, 19, 20, 22, 23, 24,\n",
      "        25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42, 43, 44, 45, 46, 49,\n",
      "        51, 52, 54, 55, 57, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([129, 130, 131, 132, 134, 135, 141, 142, 143, 144, 145, 146, 148, 149,\n",
      "        150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 162, 163, 164, 165,\n",
      "        166, 168, 169, 171, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184,\n",
      "        185, 187, 188, 189, 190]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "        207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222,\n",
      "        224, 225, 226, 228, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 214\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,  91,  92,  93,\n",
      "         94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 214\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 16, 17, 18, 19,\n",
      "        20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
      "        39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59,\n",
      "        60, 61, 63]) to machine 0\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  73,  74,  76,  77,  78,  79,\n",
      "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 126, 127]) to machine 1\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171,\n",
      "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "        186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 214\n",
      "Max diff:\n",
      " tensor([1.5987e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 2.6645e-15, 3.7748e-15, 2.6645e-15, 4.4409e-15, 4.8850e-15,\n",
      "         4.4409e-15, 3.5527e-15, 7.6605e-15, 2.8866e-15, 3.5527e-15, 2.2204e-15,\n",
      "         7.5495e-15, 7.1054e-15, 7.9936e-15, 2.4980e-15, 3.5527e-15, 3.5527e-15,\n",
      "         2.2204e-15, 6.2172e-15, 3.5527e-15, 2.3315e-15, 6.1062e-15, 7.1054e-15,\n",
      "         4.4409e-15, 3.7748e-15, 7.1054e-15, 3.3307e-15, 5.3291e-15, 3.1086e-15,\n",
      "         4.4409e-15, 3.7748e-15, 3.9968e-15, 1.8874e-15, 7.9936e-15, 4.4409e-15,\n",
      "         3.9968e-15, 2.2204e-15, 9.7700e-15, 5.1070e-15, 2.2204e-15, 1.0214e-14,\n",
      "         3.1364e-15, 3.5527e-15, 6.8834e-15, 2.8866e-15, 2.7235e-16, 5.1070e-15,\n",
      "         3.7748e-15, 3.5527e-15, 5.3291e-15, 1.1102e-15, 3.8858e-15, 7.1054e-15,\n",
      "         5.7732e-15, 3.1086e-15, 3.9968e-15, 7.1054e-15, 2.2742e-15, 4.7740e-15,\n",
      "         3.5250e-15, 3.5527e-15, 2.2204e-15, 5.5511e-15, 1.7764e-15, 3.9968e-15,\n",
      "         2.6645e-15, 3.7748e-15, 3.1086e-15, 3.1086e-15, 1.7764e-15, 3.8025e-15,\n",
      "         2.3315e-15, 4.4409e-15, 9.1038e-15, 2.1094e-15, 3.3307e-15, 2.6645e-15,\n",
      "         3.1086e-15, 2.3315e-15, 1.4433e-15, 2.4425e-15, 7.1054e-15, 8.3822e-15,\n",
      "         7.5495e-15, 1.3323e-15, 2.4425e-15, 5.3291e-15, 2.9143e-15, 5.3291e-15,\n",
      "         6.2172e-15, 3.1086e-15, 3.9968e-15, 6.5503e-15, 2.7200e-15, 2.6645e-15,\n",
      "         4.8850e-15, 7.1054e-15, 4.8850e-15, 2.2204e-15, 6.2172e-15, 4.8850e-15,\n",
      "         6.2172e-15, 2.6645e-15, 2.7200e-15, 5.3291e-15, 6.2172e-15, 7.1054e-15,\n",
      "         6.2172e-15, 6.7724e-15, 3.0254e-15, 4.8850e-15, 2.2204e-15, 7.9936e-15,\n",
      "         7.1054e-15, 7.9936e-15, 2.8588e-15, 2.6645e-15, 3.1086e-15, 2.8866e-15,\n",
      "         1.7764e-15, 3.5527e-15, 5.6066e-15, 4.2188e-15, 1.2143e-15, 3.3307e-15,\n",
      "         7.9936e-15, 5.6621e-15, 1.5987e-14, 3.1086e-15, 3.5527e-15, 6.2172e-15,\n",
      "         3.9968e-15, 1.4211e-14, 5.3291e-15, 5.3291e-15, 4.4409e-15, 3.3307e-15,\n",
      "         3.5527e-15, 2.4425e-15, 7.1054e-15, 8.8818e-15, 6.2172e-15, 6.2172e-15,\n",
      "         2.4425e-15, 8.7708e-15, 7.1054e-15, 2.4980e-15, 3.7748e-15, 7.5495e-15,\n",
      "         4.9960e-15, 3.1086e-15, 8.8818e-15, 7.1054e-15, 4.4409e-15, 4.8850e-15,\n",
      "         6.6613e-15, 1.0658e-14, 7.8271e-15, 7.9936e-15, 7.1054e-15, 6.6613e-15,\n",
      "         4.4409e-15, 8.8818e-15, 1.0658e-14, 2.9976e-15, 9.7700e-15, 8.8818e-15,\n",
      "         1.1546e-14, 6.6613e-15, 5.3291e-15, 7.5495e-15, 4.4409e-15, 6.2172e-15,\n",
      "         3.5527e-15, 5.3291e-15, 1.0658e-14, 7.1054e-15, 2.4425e-15, 2.5535e-15,\n",
      "         7.1956e-15, 9.7700e-15, 3.9968e-15, 5.3291e-15, 5.3291e-15, 5.7732e-15,\n",
      "         7.1054e-15, 6.2172e-15, 7.1054e-15, 3.5527e-15, 4.7740e-15, 4.8850e-15,\n",
      "         6.1062e-15, 8.8818e-15, 8.4377e-15, 8.7708e-15, 6.6613e-15, 8.8818e-15,\n",
      "         6.6613e-15, 7.1054e-15, 3.1086e-15, 3.5527e-15, 7.5495e-15, 5.3291e-15,\n",
      "         6.2172e-15, 1.0658e-14, 9.8810e-15, 6.2172e-15, 7.1054e-15, 5.9952e-15,\n",
      "         7.9936e-15, 5.3291e-15, 5.3291e-15, 8.4377e-15, 5.7732e-15, 6.2172e-15,\n",
      "         4.8850e-15, 8.8818e-15, 7.3275e-15, 4.4409e-15, 5.3291e-15, 7.1054e-15,\n",
      "         5.7732e-15, 5.3291e-15, 4.4409e-15, 1.0658e-14, 1.2657e-14, 8.6042e-15,\n",
      "         8.8818e-15, 4.4409e-15, 6.2172e-15, 6.6613e-15, 6.2172e-15, 4.4409e-15,\n",
      "         5.7732e-15, 6.8001e-15, 5.1070e-15, 9.3259e-15, 4.8295e-15, 3.6637e-15,\n",
      "         6.7724e-15, 4.8850e-15, 4.8850e-15, 4.8850e-15, 7.9936e-15, 4.8850e-15,\n",
      "         4.8850e-15, 4.8850e-15, 4.4409e-15, 7.3275e-15, 5.7732e-15, 5.7454e-15,\n",
      "         4.8850e-15, 1.2434e-14, 8.6597e-15, 9.7700e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 215: layer3.22.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 215\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 215\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "        106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 215\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 215\n",
      "\t\t Output tensor shape : torch.Size([1, 256, 8, 8])\n",
      "\t\t sending C_out tensor([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 3\n",
      "Finished execution of layer 215\n",
      "Max diff:\n",
      " tensor([8.4377e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-16, 1.2212e-15, 9.9920e-16, 7.7022e-16, 2.6645e-15, 1.6653e-15,\n",
      "         1.7764e-15, 1.5543e-15, 1.3600e-15, 1.3323e-15, 1.3323e-15, 1.1102e-15,\n",
      "         5.3291e-15, 4.4409e-15, 3.5527e-15, 8.4655e-16, 1.5543e-15, 1.1102e-15,\n",
      "         4.4409e-16, 4.8850e-15, 1.1102e-15, 1.1935e-15, 2.4425e-15, 2.8866e-15,\n",
      "         2.2204e-15, 1.3323e-15, 4.8850e-15, 9.9920e-16, 2.2204e-15, 5.5511e-16,\n",
      "         1.9984e-15, 1.0547e-15, 1.3323e-15, 2.1511e-16, 3.1086e-15, 1.9984e-15,\n",
      "         1.7764e-15, 6.1062e-16, 2.6090e-15, 1.0547e-15, 3.6082e-16, 5.1070e-15,\n",
      "         1.2490e-16, 6.6613e-16, 1.0686e-15, 3.8858e-16, 8.3267e-17, 2.1094e-15,\n",
      "         3.8858e-16, 1.1102e-15, 1.9984e-15, 4.1633e-17, 1.2768e-15, 1.3323e-15,\n",
      "         3.3307e-15, 1.1102e-16, 3.1086e-15, 2.4425e-15, 1.9429e-16, 1.2768e-15,\n",
      "         1.2490e-16, 1.2212e-15, 4.4409e-16, 1.2212e-15, 3.8858e-16, 1.3323e-15,\n",
      "         6.6613e-16, 9.7145e-16, 4.4409e-16, 6.6613e-16, 2.7756e-16, 9.7145e-16,\n",
      "         5.5511e-16, 1.9984e-15, 4.2188e-15, 8.3267e-16, 6.1062e-16, 5.5511e-16,\n",
      "         7.7716e-16, 6.0368e-16, 3.6082e-16, 3.8858e-16, 3.1086e-15, 1.5821e-15,\n",
      "         1.3323e-15, 4.1633e-17, 6.1062e-16, 4.4409e-15, 2.2204e-16, 2.2204e-15,\n",
      "         2.6645e-15, 7.7716e-16, 1.5543e-15, 3.8858e-15, 6.1062e-16, 8.8818e-16,\n",
      "         1.5543e-15, 3.7748e-15, 1.9984e-15, 7.7716e-16, 2.2204e-15, 2.4980e-16,\n",
      "         1.5543e-15, 6.6613e-16, 4.4409e-16, 1.1102e-15, 1.8874e-15, 3.5527e-15,\n",
      "         3.1086e-15, 1.9429e-15, 5.5511e-16, 8.3267e-16, 2.7756e-16, 2.2204e-15,\n",
      "         3.9968e-15, 1.9984e-15, 3.8858e-16, 8.8818e-16, 7.7716e-16, 9.9920e-16,\n",
      "         2.2204e-16, 1.1102e-15, 1.8874e-15, 1.1102e-15, 8.3267e-17, 1.2212e-15,\n",
      "         1.6098e-15, 1.7208e-15, 5.3291e-15, 3.8858e-16, 5.5511e-16, 2.2204e-15,\n",
      "         1.3323e-15, 5.1070e-15, 2.2204e-15, 1.3323e-15, 9.9920e-16, 4.4409e-16,\n",
      "         1.7764e-15, 6.6613e-16, 3.3307e-15, 3.1086e-15, 3.9968e-15, 3.5527e-15,\n",
      "         2.7756e-17, 1.6098e-15, 3.5527e-15, 8.8818e-16, 4.5797e-16, 1.4433e-15,\n",
      "         1.2768e-15, 8.8818e-16, 5.3291e-15, 1.8874e-15, 1.8874e-15, 1.5543e-15,\n",
      "         2.6645e-15, 5.7732e-15, 1.6376e-15, 3.1086e-15, 4.8850e-15, 2.7756e-15,\n",
      "         5.5511e-16, 8.4377e-15, 4.4409e-15, 8.3267e-17, 4.4409e-15, 4.4409e-15,\n",
      "         4.8850e-15, 4.4409e-15, 1.5543e-15, 2.2204e-15, 1.7764e-15, 3.1086e-15,\n",
      "         8.8818e-16, 1.3323e-15, 4.3299e-15, 3.1086e-15, 4.4409e-16, 5.5511e-16,\n",
      "         8.0491e-16, 3.5527e-15, 1.5543e-15, 2.6645e-15, 1.5543e-15, 1.8319e-15,\n",
      "         3.1086e-15, 3.1086e-15, 3.9968e-15, 8.3267e-16, 1.4988e-15, 1.9984e-15,\n",
      "         1.9429e-15, 2.2204e-15, 3.9968e-15, 1.7208e-15, 1.7764e-15, 2.2760e-15,\n",
      "         1.7208e-15, 2.4425e-15, 1.3323e-15, 9.9920e-16, 2.1094e-15, 1.7764e-15,\n",
      "         2.6645e-15, 2.8866e-15, 3.4417e-15, 2.2204e-15, 2.4425e-15, 9.9920e-16,\n",
      "         2.8866e-15, 2.4425e-15, 2.2204e-15, 2.3315e-15, 1.9984e-15, 1.9984e-15,\n",
      "         1.1102e-15, 2.2204e-15, 2.0539e-15, 1.1102e-15, 1.5543e-15, 3.5527e-15,\n",
      "         1.9984e-15, 1.1102e-15, 1.5543e-15, 3.1086e-15, 4.9960e-15, 2.8588e-15,\n",
      "         3.7748e-15, 1.3323e-15, 7.7716e-16, 2.5535e-15, 1.9984e-15, 8.8818e-16,\n",
      "         5.5511e-16, 1.2212e-15, 1.2212e-15, 2.5535e-15, 6.6613e-16, 6.3838e-16,\n",
      "         2.6090e-15, 1.3323e-15, 1.3323e-15, 2.2204e-15, 2.6645e-15, 5.5511e-16,\n",
      "         8.3267e-16, 8.8818e-16, 9.9920e-16, 2.7200e-15, 2.4425e-15, 2.5258e-15,\n",
      "         1.5543e-15, 4.2188e-15, 1.8319e-15, 4.8850e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 216: layer3.22.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 216\n",
      "Max diff:\n",
      " tensor([3.2863e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.4988e-15, 1.2212e-15, 2.7756e-15, 4.5519e-15, 6.6613e-15, 2.2204e-15,\n",
      "         1.3323e-15, 5.3291e-15, 1.3600e-15, 1.3323e-15, 1.9984e-15, 1.1102e-15,\n",
      "         5.3291e-15, 4.8850e-15, 3.5527e-15, 1.6098e-15, 3.1086e-15, 1.1102e-15,\n",
      "         4.4409e-16, 5.7732e-15, 1.1102e-15, 1.1935e-15, 5.1070e-15, 2.8866e-15,\n",
      "         2.2204e-15, 1.3323e-15, 4.8850e-15, 1.1102e-15, 2.2204e-15, 2.6645e-15,\n",
      "         2.6645e-15, 1.0547e-15, 1.4710e-15, 4.1633e-15, 3.1086e-15, 1.9984e-15,\n",
      "         2.6645e-15, 6.1062e-16, 2.6090e-15, 3.5527e-15, 6.8834e-15, 5.1070e-15,\n",
      "         8.1879e-16, 2.7756e-15, 6.6613e-15, 4.2188e-15, 8.3267e-17, 4.2188e-15,\n",
      "         1.3323e-15, 1.1102e-15, 1.9984e-15, 4.6629e-15, 3.7748e-15, 1.3323e-15,\n",
      "         3.3307e-15, 1.1102e-16, 3.1086e-15, 2.4425e-15, 1.6653e-15, 1.3600e-15,\n",
      "         2.9698e-15, 1.2212e-15, 5.4401e-15, 4.6629e-15, 7.1054e-15, 1.3323e-15,\n",
      "         5.2180e-15, 7.9936e-15, 1.2768e-15, 5.3846e-15, 1.0658e-14, 2.4702e-15,\n",
      "         2.3315e-15, 4.4409e-15, 4.2188e-15, 7.3275e-15, 8.8818e-15, 7.1054e-15,\n",
      "         1.3323e-15, 6.0368e-16, 5.8842e-15, 7.9936e-15, 3.1086e-15, 1.1102e-14,\n",
      "         9.3259e-15, 1.5543e-15, 7.2442e-15, 4.4409e-15, 8.8818e-15, 2.2204e-15,\n",
      "         4.2188e-15, 7.7716e-16, 1.3323e-15, 7.3275e-15, 2.4425e-15, 8.8818e-16,\n",
      "         4.9960e-15, 3.7748e-15, 3.5527e-15, 7.9936e-15, 3.5527e-15, 2.4980e-16,\n",
      "         8.8818e-15, 1.0825e-15, 9.4369e-16, 1.0658e-14, 1.8874e-15, 3.9968e-15,\n",
      "         5.1070e-15, 3.1086e-15, 5.8842e-15, 7.9936e-15, 1.3323e-15, 5.7732e-15,\n",
      "         3.9968e-15, 1.1435e-14, 4.8850e-15, 2.2204e-15, 3.9968e-15, 7.3275e-15,\n",
      "         9.4369e-16, 2.2204e-15, 5.3291e-15, 3.9968e-15, 2.4425e-15, 5.6621e-15,\n",
      "         2.3315e-15, 2.8866e-15, 5.3291e-15, 7.1054e-15, 7.7716e-16, 2.2204e-15,\n",
      "         4.2188e-15, 8.2157e-15, 9.3259e-15, 5.1070e-15, 3.2196e-15, 6.9389e-16,\n",
      "         1.1546e-14, 2.3315e-15, 6.2172e-15, 3.3307e-15, 3.9968e-15, 6.6613e-15,\n",
      "         6.6613e-15, 2.1094e-15, 3.5527e-15, 3.3862e-15, 1.7764e-14, 1.4433e-15,\n",
      "         1.1990e-14, 5.8842e-15, 9.3259e-15, 3.1086e-15, 2.3315e-15, 5.3291e-15,\n",
      "         3.1086e-15, 5.7732e-15, 8.4377e-15, 5.7732e-15, 4.8850e-15, 6.6613e-15,\n",
      "         3.9968e-15, 8.4377e-15, 5.1070e-15, 3.3307e-16, 1.2434e-14, 4.8850e-15,\n",
      "         2.1316e-14, 4.4409e-15, 1.5543e-15, 9.3259e-15, 5.5511e-15, 1.0658e-14,\n",
      "         2.1094e-15, 1.1990e-14, 4.3299e-15, 3.1086e-15, 7.9936e-15, 5.5511e-16,\n",
      "         3.5527e-15, 3.9968e-15, 3.9968e-15, 4.6629e-15, 3.6637e-15, 6.6613e-15,\n",
      "         8.8818e-15, 3.1086e-15, 1.2434e-14, 9.7700e-15, 3.7748e-15, 2.4425e-15,\n",
      "         1.1546e-14, 2.4536e-14, 8.8818e-15, 2.8311e-15, 1.7764e-15, 8.8818e-15,\n",
      "         3.9968e-15, 1.4211e-14, 1.2212e-14, 1.4988e-15, 6.2172e-15, 2.8866e-15,\n",
      "         1.1990e-14, 1.4433e-14, 3.5527e-15, 1.3101e-14, 2.4425e-15, 2.6645e-15,\n",
      "         3.6637e-15, 3.2863e-14, 2.1316e-14, 3.5527e-15, 8.8818e-15, 4.2188e-15,\n",
      "         9.7700e-15, 9.3259e-15, 5.9952e-15, 1.1102e-15, 7.2164e-15, 2.1316e-14,\n",
      "         8.4377e-15, 8.8818e-15, 4.5519e-15, 1.7764e-14, 1.5210e-14, 1.2434e-14,\n",
      "         7.9936e-15, 8.2157e-15, 6.2172e-15, 7.5495e-15, 2.5757e-14, 1.2657e-14,\n",
      "         1.2434e-14, 2.2204e-15, 5.3291e-15, 1.7764e-14, 6.6613e-16, 7.1054e-15,\n",
      "         3.3307e-15, 9.3259e-15, 6.1062e-15, 3.7748e-15, 8.8818e-15, 1.9096e-14,\n",
      "         8.8818e-15, 8.4377e-15, 7.0777e-15, 8.4377e-15, 1.1990e-14, 7.7716e-15,\n",
      "         2.4425e-15, 5.7732e-15, 7.5495e-15, 1.3767e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])  (len = 256)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 217: layer3.22.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 217\n",
      "Max diff:\n",
      " tensor([3.2863e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 2.0817e-17, 2.7756e-15, 4.5519e-15, 0.0000e+00, 2.2204e-15,\n",
      "         0.0000e+00, 5.3291e-15, 5.8287e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.6629e-15, 0.0000e+00, 0.0000e+00, 9.4369e-16, 3.1086e-15, 0.0000e+00,\n",
      "         0.0000e+00, 3.1086e-15, 0.0000e+00, 1.1935e-15, 5.1070e-15, 1.0547e-15,\n",
      "         8.8818e-16, 0.0000e+00, 5.8287e-16, 1.1102e-15, 0.0000e+00, 2.6645e-15,\n",
      "         2.2204e-15, 0.0000e+00, 1.4710e-15, 4.1633e-15, 2.2204e-15, 0.0000e+00,\n",
      "         2.6645e-15, 1.8041e-16, 2.6090e-15, 3.5527e-15, 6.8834e-15, 9.4369e-16,\n",
      "         5.5511e-16, 1.5543e-15, 6.6613e-15, 4.2188e-15, 0.0000e+00, 4.2188e-15,\n",
      "         1.3323e-15, 1.5266e-16, 1.1562e-15, 4.6629e-15, 3.7748e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7221e-17, 1.6653e-15, 6.6613e-16,\n",
      "         2.9698e-15, 0.0000e+00, 3.5527e-15, 4.6629e-15, 7.1054e-15, 0.0000e+00,\n",
      "         4.5519e-15, 7.9936e-15, 1.2768e-15, 5.3846e-15, 1.0658e-14, 8.3267e-16,\n",
      "         2.3315e-15, 3.4417e-15, 0.0000e+00, 7.3275e-15, 8.8818e-15, 7.1054e-15,\n",
      "         1.3323e-15, 1.1449e-16, 5.8842e-15, 7.9936e-15, 0.0000e+00, 1.1102e-14,\n",
      "         9.3259e-15, 1.5543e-15, 5.9952e-15, 0.0000e+00, 8.8818e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.6613e-16, 7.3275e-15, 2.4425e-15, 0.0000e+00,\n",
      "         4.9960e-15, 0.0000e+00, 3.5527e-15, 7.9936e-15, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-15, 1.0825e-15, 0.0000e+00, 1.0658e-14, 7.7716e-16, 0.0000e+00,\n",
      "         1.5543e-15, 3.1086e-15, 5.8842e-15, 7.9936e-15, 1.3323e-15, 5.7732e-15,\n",
      "         9.9920e-16, 1.1435e-14, 4.8850e-15, 2.2204e-15, 3.9968e-15, 7.3275e-15,\n",
      "         9.4369e-16, 1.9984e-15, 5.3291e-15, 3.9968e-15, 2.4425e-15, 4.9960e-16,\n",
      "         2.3315e-15, 2.8866e-15, 4.4409e-16, 7.1054e-15, 7.7716e-16, 8.8818e-16,\n",
      "         4.2188e-15, 6.4393e-15, 9.3259e-15, 5.1070e-15, 3.2196e-15, 0.0000e+00,\n",
      "         1.1546e-14, 2.3315e-15, 6.2172e-15, 0.0000e+00, 1.3878e-16, 6.6613e-15,\n",
      "         6.6613e-15, 2.1094e-15, 0.0000e+00, 3.1086e-15, 1.7764e-14, 6.6613e-16,\n",
      "         1.1990e-14, 5.8842e-15, 5.1070e-15, 3.1086e-15, 9.9920e-16, 5.3291e-15,\n",
      "         1.4988e-15, 1.5543e-15, 8.4377e-15, 1.5543e-15, 1.7764e-15, 6.6613e-15,\n",
      "         3.9968e-15, 2.8866e-15, 4.6629e-15, 0.0000e+00, 1.2434e-14, 7.2164e-16,\n",
      "         2.1316e-14, 7.7716e-16, 0.0000e+00, 9.3259e-15, 5.5511e-15, 8.8818e-15,\n",
      "         2.1094e-15, 1.1990e-14, 8.3267e-16, 6.6613e-16, 7.9936e-15, 0.0000e+00,\n",
      "         3.5527e-15, 2.2204e-15, 1.8319e-15, 4.6629e-15, 3.6637e-15, 6.6613e-15,\n",
      "         8.8818e-15, 1.7764e-15, 1.2434e-14, 9.7700e-15, 3.7748e-15, 6.6613e-16,\n",
      "         1.1546e-14, 2.4536e-14, 8.8818e-15, 2.8311e-15, 9.4369e-16, 8.8818e-15,\n",
      "         3.9968e-15, 1.4211e-14, 1.0658e-14, 8.8818e-16, 6.2172e-15, 2.8866e-15,\n",
      "         1.1990e-14, 1.4433e-14, 3.5527e-15, 1.3101e-14, 2.1094e-15, 2.6645e-15,\n",
      "         1.0963e-15, 3.2863e-14, 2.1316e-14, 3.5527e-15, 7.9936e-15, 2.5535e-15,\n",
      "         9.7700e-15, 3.7748e-15, 5.9952e-15, 6.1062e-16, 7.2164e-15, 2.1316e-14,\n",
      "         8.4377e-15, 8.8818e-15, 4.5519e-15, 1.7764e-14, 1.5210e-14, 1.2434e-14,\n",
      "         7.9936e-15, 8.2157e-15, 6.2172e-15, 7.5495e-15, 2.5757e-14, 1.2657e-14,\n",
      "         1.2434e-14, 2.2204e-15, 5.3291e-15, 1.7764e-14, 6.6613e-16, 7.1054e-15,\n",
      "         1.9984e-15, 9.3259e-15, 0.0000e+00, 3.7748e-15, 8.8818e-15, 1.9096e-14,\n",
      "         8.8818e-15, 8.4377e-15, 3.9968e-15, 8.4377e-15, 1.1990e-14, 7.7716e-15,\n",
      "         2.4425e-15, 5.7732e-15, 7.5495e-15, 1.3767e-14]], dtype=torch.float64)\n",
      " tensor([  1,   2,   3,   5,   7,   8,  12,  15,  16,  19,  21,  22,  23,  24,\n",
      "         26,  27,  29,  30,  32,  33,  34,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  47,  48,  49,  50,  51,  52,  57,  58,  59,  60,  62,\n",
      "         63,  64,  66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,\n",
      "         79,  80,  81,  83,  84,  85,  86,  88,  92,  93,  94,  96,  98,  99,\n",
      "        102, 103, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
      "        132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145, 147, 148,\n",
      "        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "        163, 164, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])\n",
      "\n",
      "failing Cout = tensor([  1,   2,   3,   5,   7,   8,  12,  15,  16,  19,  21,  22,  23,  24,\n",
      "         26,  27,  29,  30,  32,  33,  34,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  47,  48,  49,  50,  51,  52,  57,  58,  59,  60,  62,\n",
      "         63,  64,  66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,\n",
      "         79,  80,  81,  83,  84,  85,  86,  88,  92,  93,  94,  96,  98,  99,\n",
      "        102, 103, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
      "        132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145, 147, 148,\n",
      "        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "        163, 164, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178,\n",
      "        180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255])  (len = 215)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 218: layer4.0.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 218\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([130, 146, 150, 153, 154, 159, 162, 165, 168, 177, 182, 185, 187, 190,\n",
      "        193, 201, 214, 220, 221, 224, 227, 228, 230, 232, 233, 244, 249, 254]) to machine 1\n",
      "\t\t sending C_out tensor([257, 293, 295, 303, 312, 314, 318, 319, 322, 324, 327, 328, 329, 331,\n",
      "        334, 338, 341, 347, 348, 349, 352, 359, 368, 373, 376, 378, 382]) to machine 2\n",
      "\t\t sending C_out tensor([388, 389, 391, 392, 395, 398, 400, 401, 403, 406, 414, 416, 420, 421,\n",
      "        423, 426, 428, 429, 430, 431, 432, 433, 435, 440, 443, 449, 450, 451,\n",
      "        453, 455, 459, 463, 465, 466, 469, 473, 474, 483, 486, 487, 493, 494,\n",
      "        495, 497, 498, 499, 500, 504, 510, 511]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 218\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  3,  23,  25,  34,  35,  40,  44,  53,  65,  68,  72,  77,  87, 104,\n",
      "        106, 112, 113, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 218\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  9,  12,  15,  20,  37,  38,  53,  68,  76, 101, 102, 105, 121, 122]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 218\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  7,  17,  21,  26,  31,  39,  45,  53,  55,  63,  64,  65,  68,  71,\n",
      "         72,  73,  74,  77,  86,  97, 101, 115, 119, 121]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 218\n",
      "Max diff:\n",
      " tensor([1.5632e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[7.1054e-15, 4.9960e-15, 2.6645e-14, 1.0658e-14, 1.0658e-14, 7.1054e-15,\n",
      "         5.5511e-15, 6.5850e-15, 1.0658e-14, 5.3291e-15, 5.8842e-15, 1.0658e-14,\n",
      "         9.7700e-15, 4.4409e-15, 7.5495e-15, 4.4409e-15, 6.2172e-15, 3.0198e-14,\n",
      "         7.1054e-15, 5.3291e-15, 5.9397e-15, 1.9540e-14, 6.2172e-15, 9.5479e-15,\n",
      "         6.2172e-15, 7.9936e-15, 4.4409e-15, 7.1054e-15, 5.3291e-15, 6.2172e-15,\n",
      "         7.5495e-15, 7.1054e-15, 7.1054e-15, 7.9936e-15, 6.6613e-15, 7.5495e-15,\n",
      "         6.2172e-15, 3.5527e-15, 1.4211e-14, 7.1054e-15, 5.3291e-15, 4.4409e-15,\n",
      "         5.3291e-15, 7.1054e-15, 8.5487e-15, 1.5987e-14, 4.4409e-15, 1.4211e-14,\n",
      "         1.0658e-14, 5.7732e-15, 3.5527e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15,\n",
      "         3.9968e-15, 5.3291e-15, 4.4409e-15, 8.8818e-15, 5.7732e-15, 8.8818e-15,\n",
      "         1.4211e-14, 7.1054e-15, 4.4409e-15, 5.7732e-15, 5.3291e-15, 7.5495e-15,\n",
      "         3.5527e-15, 4.8850e-15, 5.3291e-15, 1.4211e-14, 2.4869e-14, 1.0658e-14,\n",
      "         1.0658e-14, 6.2172e-15, 6.8834e-15, 2.8422e-14, 5.3291e-15, 4.6907e-15,\n",
      "         1.2434e-14, 8.8818e-15, 1.0658e-14, 2.6645e-15, 8.8818e-15, 8.8818e-15,\n",
      "         1.0658e-14, 5.3291e-15, 1.4211e-14, 1.0658e-14, 4.7740e-15, 5.9952e-15,\n",
      "         1.0658e-14, 8.4377e-15, 4.4409e-15, 6.6613e-15, 1.0658e-14, 8.8818e-15,\n",
      "         4.4409e-15, 7.5495e-15, 1.7764e-14, 1.4211e-14, 1.7764e-14, 1.2212e-14,\n",
      "         4.4409e-15, 2.6645e-15, 5.7454e-15, 6.2172e-15, 8.8818e-15, 5.3291e-15,\n",
      "         4.4409e-15, 5.9397e-15, 3.7748e-15, 5.3291e-15, 3.1086e-15, 1.6875e-14,\n",
      "         1.4211e-14, 6.8834e-15, 4.4409e-15, 8.4377e-15, 5.3291e-15, 6.2172e-15,\n",
      "         6.2172e-15, 1.4211e-14, 4.6629e-15, 6.2172e-15, 5.3291e-15, 9.7700e-15,\n",
      "         5.3291e-15, 7.1054e-15, 3.1974e-14, 3.3751e-14, 4.9738e-14, 2.8422e-14,\n",
      "         1.9762e-14, 3.5527e-14, 3.5527e-14, 4.9738e-14, 2.1316e-14, 4.2633e-14,\n",
      "         4.2633e-14, 3.5527e-14, 4.2633e-14, 3.9080e-14, 2.5757e-14, 3.1974e-14,\n",
      "         1.4655e-14, 2.8422e-14, 1.5543e-14, 3.5527e-14, 3.9080e-14, 4.2633e-14,\n",
      "         2.1316e-14, 2.8422e-14, 2.1316e-14, 4.2633e-14, 7.8160e-14, 4.2633e-14,\n",
      "         4.2633e-14, 3.5527e-14, 2.8422e-14, 7.1054e-14, 1.7764e-14, 2.8422e-14,\n",
      "         1.4211e-14, 4.2633e-14, 3.1974e-14, 4.2633e-14, 3.9080e-14, 2.8422e-14,\n",
      "         1.4655e-14, 2.6645e-14, 3.9080e-14, 1.5543e-14, 4.9738e-14, 3.1974e-14,\n",
      "         3.5527e-14, 2.7089e-14, 2.8422e-14, 7.1054e-14, 4.9738e-14, 3.1974e-14,\n",
      "         3.0198e-14, 4.9738e-14, 5.6843e-14, 1.4211e-14, 3.0198e-14, 2.0428e-14,\n",
      "         3.0198e-14, 3.5527e-14, 1.4211e-14, 3.6859e-14, 6.3949e-14, 8.5265e-14,\n",
      "         2.1316e-14, 3.5527e-14, 1.6431e-14, 3.5527e-14, 2.8422e-14, 2.8422e-14,\n",
      "         3.5527e-14, 1.7764e-14, 4.2633e-14, 7.1054e-14, 5.6843e-14, 5.6843e-14,\n",
      "         5.6843e-14, 3.0198e-14, 2.1316e-14, 2.3093e-14, 3.5527e-14, 2.6645e-14,\n",
      "         2.4869e-14, 3.5527e-14, 3.3751e-14, 7.1054e-14, 2.1316e-14, 3.5527e-14,\n",
      "         2.8422e-14, 2.3093e-14, 3.5527e-14, 2.4869e-14, 3.5527e-14, 3.5527e-14,\n",
      "         2.2649e-14, 4.2633e-14, 5.6843e-14, 2.4869e-14, 2.1316e-14, 2.5757e-14,\n",
      "         4.2633e-14, 1.2323e-14, 4.6185e-14, 2.7534e-14, 4.6185e-14, 3.5527e-14,\n",
      "         2.7089e-14, 4.2633e-14, 2.8422e-14, 9.9476e-14, 3.1974e-14, 2.6645e-14,\n",
      "         5.5511e-14, 3.5527e-14, 2.3981e-14, 3.5527e-14, 3.5527e-14, 7.1054e-14,\n",
      "         4.2633e-14, 1.4211e-14, 3.1974e-14, 3.5527e-14, 4.6185e-14, 4.9738e-14,\n",
      "         1.7764e-14, 3.0198e-14, 2.8422e-14, 2.8422e-14, 4.9738e-14, 7.1054e-14,\n",
      "         5.6843e-14, 4.2633e-14, 2.4869e-14, 3.9080e-14, 4.2633e-14, 2.1316e-14,\n",
      "         1.1369e-13, 1.4211e-14, 5.2902e-14, 2.4869e-14, 4.9738e-14, 4.2633e-14,\n",
      "         4.9738e-14, 2.8422e-14, 2.8422e-14, 2.1316e-14, 2.8422e-14, 3.9080e-14,\n",
      "         3.1974e-14, 6.3949e-14, 3.1974e-14, 1.4211e-14, 5.3291e-14, 5.6843e-14,\n",
      "         1.1369e-13, 4.9738e-14, 7.1054e-14, 4.2633e-14, 8.5265e-14, 4.9738e-14,\n",
      "         4.1300e-14, 4.2633e-14, 9.9476e-14, 6.3949e-14, 8.5265e-14, 6.3949e-14,\n",
      "         3.9080e-14, 1.1369e-13, 2.1316e-14, 4.2633e-14, 4.2633e-14, 4.9738e-14,\n",
      "         3.5527e-14, 3.1974e-14, 5.6843e-14, 3.5527e-14, 5.6843e-14, 1.7764e-14,\n",
      "         5.6843e-14, 4.2633e-14, 3.1974e-14, 4.9738e-14, 2.8422e-14, 2.4869e-14,\n",
      "         4.9738e-14, 4.9738e-14, 1.5632e-13, 2.6645e-14, 4.9738e-14, 3.5527e-14,\n",
      "         3.5527e-14, 3.2863e-14, 5.6843e-14, 4.4409e-14, 2.1316e-14, 5.6843e-14,\n",
      "         2.3093e-14, 5.6843e-14, 3.1086e-14, 4.9738e-14, 4.9738e-14, 5.6843e-14,\n",
      "         5.6843e-14, 4.2633e-14, 6.3949e-14, 5.6843e-14, 5.6843e-14, 7.1054e-14,\n",
      "         6.0396e-14, 2.4869e-14, 5.6843e-14, 4.9738e-14, 4.2633e-14, 1.0658e-14,\n",
      "         1.4211e-14, 7.1054e-14, 3.5527e-14, 3.5527e-14, 2.4869e-14, 3.5527e-14,\n",
      "         3.5527e-14, 3.5527e-14, 1.7764e-14, 9.9476e-14, 7.1054e-14, 2.8422e-14,\n",
      "         5.6843e-14, 3.9080e-14, 5.6843e-14, 5.6843e-14, 4.9738e-14, 3.5527e-14,\n",
      "         2.8422e-14, 3.5527e-14, 3.3751e-14, 4.2633e-14, 4.9738e-14, 4.2633e-14,\n",
      "         5.6843e-14, 6.3949e-14, 5.6843e-14, 3.9080e-14, 5.6843e-14, 2.4980e-14,\n",
      "         1.4211e-14, 4.2633e-14, 1.7764e-14, 6.3949e-14, 5.6843e-14, 4.2633e-14,\n",
      "         4.7962e-14, 7.1054e-14, 4.9738e-14, 3.5527e-14, 3.1974e-14, 7.1054e-14,\n",
      "         1.0658e-13, 5.3291e-14, 6.3949e-14, 5.8620e-14, 4.9738e-14, 3.5527e-14,\n",
      "         2.8422e-14, 4.9738e-14, 4.6185e-14, 3.5527e-14, 5.6843e-14, 4.9738e-14,\n",
      "         2.8422e-14, 3.8913e-14, 4.6185e-14, 2.8422e-14, 2.8422e-14, 5.6843e-14,\n",
      "         3.9968e-14, 3.3751e-14, 2.8422e-14, 5.6843e-14, 3.1974e-14, 7.1054e-14,\n",
      "         4.6185e-14, 3.5527e-14, 3.5527e-14, 6.3949e-14, 5.6843e-14, 2.6645e-14,\n",
      "         3.5527e-14, 3.1974e-14, 3.1974e-14, 1.7764e-14, 3.8636e-14, 3.1086e-14,\n",
      "         3.5527e-14, 4.4409e-14, 3.0198e-14, 3.1974e-14, 4.9738e-14, 4.2633e-14,\n",
      "         4.9738e-14, 3.8192e-14, 3.4639e-14, 4.2633e-14, 2.8422e-14, 4.2633e-14,\n",
      "         2.8422e-14, 4.2633e-14, 4.2633e-14, 3.5527e-14, 7.1054e-14, 4.2633e-14,\n",
      "         3.5527e-14, 6.3949e-14, 4.2633e-14, 4.9738e-14, 5.6843e-14, 3.7303e-14,\n",
      "         3.5527e-14, 5.6843e-14, 4.2633e-14, 5.6843e-14, 3.5527e-14, 3.5527e-14,\n",
      "         2.3537e-14, 2.8422e-14, 3.5527e-14, 3.1974e-14, 6.0396e-14, 3.3751e-14,\n",
      "         3.5527e-14, 5.5067e-14, 5.6843e-14, 4.2633e-14, 4.9738e-14, 3.5527e-14,\n",
      "         3.3751e-14, 3.9080e-14, 5.6843e-14, 3.5527e-14, 2.8422e-14, 7.1054e-14,\n",
      "         2.8422e-14, 5.6843e-14, 4.0856e-14, 6.3949e-14, 3.5527e-14, 4.2633e-14,\n",
      "         3.5527e-14, 4.2633e-14, 2.8422e-14, 4.9738e-14, 2.8422e-14, 4.2633e-14,\n",
      "         8.5265e-14, 2.8422e-14, 3.9080e-14, 6.0396e-14, 2.1316e-14, 6.3949e-14,\n",
      "         4.2633e-14, 4.9738e-14, 5.6843e-14, 2.8422e-14, 5.6843e-14, 4.9738e-14,\n",
      "         4.9738e-14, 5.6843e-14, 7.1054e-14, 5.3291e-14, 7.1054e-14, 5.6843e-14,\n",
      "         3.3973e-14, 2.8422e-14, 3.0198e-14, 7.8160e-14, 4.2633e-14, 3.7303e-14,\n",
      "         3.1974e-14, 5.6843e-14, 4.6185e-14, 4.9738e-14, 6.3949e-14, 7.1054e-14,\n",
      "         3.1974e-14, 4.4853e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 219: layer4.0.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 219\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 219\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 219\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 219\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 219\n",
      "Max diff:\n",
      " tensor([1.9540e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.6042e-16, 2.2031e-16, 2.6645e-15, 9.0206e-16, 6.6613e-16, 3.8858e-16,\n",
      "         4.1633e-16, 6.3664e-16, 8.8818e-16, 1.1102e-16, 3.8858e-16, 8.8818e-16,\n",
      "         5.5511e-16, 3.3307e-16, 5.5511e-16, 3.3307e-16, 7.7716e-16, 7.3275e-15,\n",
      "         3.3307e-16, 3.3307e-16, 2.4286e-16, 2.6645e-15, 5.5511e-16, 4.1633e-16,\n",
      "         1.6653e-16, 4.4409e-16, 3.7817e-16, 5.5511e-16, 2.7756e-16, 2.4980e-16,\n",
      "         4.4409e-16, 4.4409e-16, 3.3307e-16, 6.6613e-16, 9.9920e-16, 8.1879e-16,\n",
      "         3.8858e-16, 1.9429e-16, 7.7716e-16, 6.6613e-16, 5.5511e-16, 4.7184e-16,\n",
      "         5.5511e-16, 3.3307e-16, 7.2164e-16, 2.6368e-15, 1.6653e-16, 6.6613e-16,\n",
      "         8.8818e-16, 4.4409e-16, 1.3878e-16, 4.9960e-16, 3.5388e-16, 1.5543e-15,\n",
      "         1.3878e-16, 6.6613e-16, 2.2204e-16, 3.8858e-16, 4.9960e-16, 3.3307e-16,\n",
      "         1.1102e-15, 4.4409e-16, 1.6653e-16, 6.6613e-16, 2.2204e-16, 4.9266e-16,\n",
      "         3.6082e-16, 2.7062e-16, 4.4409e-16, 9.9920e-16, 5.5511e-16, 7.2164e-16,\n",
      "         8.8818e-16, 2.9143e-16, 5.1348e-16, 2.8866e-15, 1.6653e-16, 5.5511e-16,\n",
      "         5.5511e-16, 3.3307e-16, 4.4409e-16, 1.1102e-16, 3.3307e-16, 4.4409e-16,\n",
      "         5.5511e-16, 2.4980e-16, 1.7764e-15, 5.5511e-16, 1.8041e-16, 6.6613e-16,\n",
      "         8.8818e-16, 3.7123e-16, 1.9429e-16, 2.3592e-16, 8.8818e-16, 7.2164e-16,\n",
      "         6.6613e-16, 4.1633e-16, 1.4433e-15, 8.8818e-16, 1.1102e-15, 1.6098e-15,\n",
      "         6.6613e-16, 2.2204e-16, 2.6368e-16, 3.3307e-16, 7.2164e-16, 3.0531e-16,\n",
      "         2.4980e-16, 2.6368e-16, 1.5959e-16, 2.7756e-16, 1.9429e-16, 1.8874e-15,\n",
      "         7.7716e-16, 3.8858e-16, 2.4980e-16, 7.7716e-16, 1.8735e-16, 4.4409e-16,\n",
      "         2.7756e-16, 5.5511e-16, 1.0408e-16, 3.0531e-16, 3.8858e-16, 9.9920e-16,\n",
      "         3.3307e-16, 4.4409e-16, 3.3307e-15, 3.5527e-15, 5.3291e-15, 2.8866e-15,\n",
      "         2.5535e-15, 4.4409e-15, 3.7748e-15, 4.8850e-15, 2.2204e-15, 4.4409e-15,\n",
      "         5.3291e-15, 4.4409e-15, 5.3291e-15, 4.4409e-15, 2.7894e-15, 3.1086e-15,\n",
      "         1.4433e-15, 3.5527e-15, 2.0331e-15, 4.4409e-15, 3.9968e-15, 3.9968e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.1086e-15, 7.1054e-15, 1.0658e-14, 4.8850e-15,\n",
      "         4.4409e-15, 3.9968e-15, 3.5527e-15, 8.8818e-15, 1.7764e-15, 3.2474e-15,\n",
      "         1.3323e-15, 4.4409e-15, 5.3291e-15, 5.3291e-15, 4.4409e-15, 2.9976e-15,\n",
      "         1.7139e-15, 2.7200e-15, 3.9413e-15, 1.8319e-15, 7.1054e-15, 3.1086e-15,\n",
      "         4.4409e-15, 2.8866e-15, 1.9984e-15, 7.1054e-15, 7.1054e-15, 2.8866e-15,\n",
      "         2.8311e-15, 5.3291e-15, 5.7732e-15, 1.5543e-15, 3.1086e-15, 1.6653e-15,\n",
      "         4.6629e-15, 4.4409e-15, 1.7764e-15, 4.2188e-15, 8.8818e-15, 1.2434e-14,\n",
      "         2.1094e-15, 3.5527e-15, 1.8874e-15, 3.5527e-15, 3.1086e-15, 2.6645e-15,\n",
      "         4.4409e-15, 2.2204e-15, 6.2172e-15, 1.4211e-14, 6.2172e-15, 6.2172e-15,\n",
      "         5.7732e-15, 2.8866e-15, 2.6645e-15, 3.1086e-15, 3.1086e-15, 2.8866e-15,\n",
      "         3.3307e-15, 4.4409e-15, 4.5519e-15, 9.3259e-15, 3.5527e-15, 4.8850e-15,\n",
      "         3.1086e-15, 2.6645e-15, 3.9968e-15, 3.5527e-15, 3.5527e-15, 4.4409e-15,\n",
      "         3.0947e-15, 5.3291e-15, 5.3291e-15, 3.1086e-15, 2.3315e-15, 2.6645e-15,\n",
      "         2.2204e-15, 1.4433e-15, 5.3291e-15, 3.6637e-15, 6.2172e-15, 3.5527e-15,\n",
      "         2.3592e-15, 4.4409e-15, 2.6645e-15, 1.1546e-14, 2.8866e-15, 2.6645e-15,\n",
      "         5.9952e-15, 3.9968e-15, 2.4980e-15, 3.1086e-15, 3.9968e-15, 8.8818e-15,\n",
      "         3.5527e-15, 2.2204e-15, 3.5527e-15, 4.4409e-15, 5.8842e-15, 3.9968e-15,\n",
      "         1.5543e-15, 3.8858e-15, 2.9976e-15, 3.5527e-15, 6.2172e-15, 7.9936e-15,\n",
      "         7.9936e-15, 4.4409e-15, 3.1086e-15, 4.8850e-15, 5.3291e-15, 3.1086e-15,\n",
      "         1.4211e-14, 1.1102e-15, 6.1062e-15, 2.6645e-15, 6.2172e-15, 2.4425e-15,\n",
      "         5.3291e-15, 3.5527e-15, 4.8850e-15, 3.5527e-15, 2.6645e-15, 6.6613e-15,\n",
      "         4.4409e-15, 1.0658e-14, 3.9968e-15, 3.1086e-15, 5.1070e-15, 7.1054e-15,\n",
      "         1.1546e-14, 5.3291e-15, 9.7700e-15, 7.1054e-15, 1.5099e-14, 4.8850e-15,\n",
      "         4.3854e-15, 4.8850e-15, 1.7764e-14, 7.9936e-15, 1.0214e-14, 6.6613e-15,\n",
      "         4.8850e-15, 1.7764e-14, 2.6645e-15, 3.9968e-15, 7.1054e-15, 5.9952e-15,\n",
      "         4.4409e-15, 3.1086e-15, 8.8818e-15, 4.4409e-15, 8.8818e-15, 2.6645e-15,\n",
      "         7.9936e-15, 5.3291e-15, 3.9968e-15, 7.1054e-15, 3.1086e-15, 3.1086e-15,\n",
      "         7.1054e-15, 8.8818e-15, 1.9540e-14, 3.5527e-15, 6.2172e-15, 5.3291e-15,\n",
      "         3.1086e-15, 4.1078e-15, 1.2434e-14, 4.5519e-15, 4.4409e-15, 6.2172e-15,\n",
      "         2.4980e-15, 6.2172e-15, 3.2752e-15, 6.2172e-15, 7.9936e-15, 7.9936e-15,\n",
      "         7.1054e-15, 7.1054e-15, 1.0658e-14, 1.0658e-14, 6.2172e-15, 5.3291e-15,\n",
      "         9.3259e-15, 2.2204e-15, 8.8818e-15, 5.3291e-15, 6.2172e-15, 1.7764e-15,\n",
      "         1.5543e-15, 1.0658e-14, 4.1078e-15, 3.3307e-15, 4.8850e-15, 5.3291e-15,\n",
      "         4.4409e-15, 5.3291e-15, 2.2204e-15, 1.2434e-14, 1.0658e-14, 2.2204e-15,\n",
      "         8.8818e-15, 4.8850e-15, 4.8850e-15, 5.3291e-15, 7.1054e-15, 3.5527e-15,\n",
      "         3.1086e-15, 5.3291e-15, 3.4417e-15, 3.5527e-15, 6.2172e-15, 4.8850e-15,\n",
      "         7.1054e-15, 7.1054e-15, 2.6645e-15, 3.9968e-15, 8.8818e-15, 2.6645e-15,\n",
      "         2.2204e-15, 6.2172e-15, 1.5543e-15, 6.6613e-15, 5.3291e-15, 7.1054e-15,\n",
      "         5.1070e-15, 9.7700e-15, 7.1054e-15, 3.3307e-15, 3.1086e-15, 5.3291e-15,\n",
      "         9.3259e-15, 5.5511e-15, 6.2172e-15, 6.2172e-15, 4.4409e-15, 3.9968e-15,\n",
      "         2.6645e-15, 4.8850e-15, 4.8850e-15, 4.4409e-15, 5.3291e-15, 4.8850e-15,\n",
      "         2.2204e-15, 3.7678e-15, 3.7748e-15, 2.6645e-15, 2.4425e-15, 5.3291e-15,\n",
      "         3.4694e-15, 2.8866e-15, 2.6645e-15, 5.3291e-15, 3.1086e-15, 6.6613e-15,\n",
      "         4.8850e-15, 3.5527e-15, 3.1086e-15, 6.2172e-15, 5.7732e-15, 2.5535e-15,\n",
      "         4.4409e-15, 3.1086e-15, 3.7748e-15, 1.7764e-15, 3.7054e-15, 3.1086e-15,\n",
      "         3.5527e-15, 4.8850e-15, 2.7756e-15, 3.1086e-15, 4.4409e-15, 4.4409e-15,\n",
      "         4.4409e-15, 3.9968e-15, 4.2188e-15, 4.4409e-15, 2.6645e-15, 3.9968e-15,\n",
      "         2.6645e-15, 4.4409e-15, 4.8850e-15, 4.4409e-15, 6.2172e-15, 4.4409e-15,\n",
      "         3.5527e-15, 6.6613e-15, 4.4409e-15, 5.3291e-15, 5.7732e-15, 4.4409e-15,\n",
      "         4.4409e-15, 5.3291e-15, 4.4409e-15, 5.3291e-15, 3.5527e-15, 4.4409e-15,\n",
      "         2.3870e-15, 3.5527e-15, 3.1086e-15, 2.8866e-15, 5.3291e-15, 3.8858e-15,\n",
      "         3.5527e-15, 5.7732e-15, 4.4409e-15, 3.5527e-15, 4.8850e-15, 4.4409e-15,\n",
      "         3.1086e-15, 3.9968e-15, 5.3291e-15, 3.5527e-15, 3.1086e-15, 7.9936e-15,\n",
      "         4.4409e-15, 4.8850e-15, 3.9968e-15, 7.1054e-15, 3.5527e-15, 4.4409e-15,\n",
      "         3.5527e-15, 3.9968e-15, 3.1086e-15, 6.2172e-15, 3.1086e-15, 3.9968e-15,\n",
      "         9.3259e-15, 2.6645e-15, 3.6637e-15, 5.7732e-15, 2.2204e-15, 6.2172e-15,\n",
      "         4.4409e-15, 5.3291e-15, 6.2172e-15, 2.6645e-15, 4.8850e-15, 4.4409e-15,\n",
      "         4.8850e-15, 5.3291e-15, 6.2172e-15, 5.7732e-15, 7.1054e-15, 6.2172e-15,\n",
      "         3.7192e-15, 2.6645e-15, 2.9976e-15, 7.1054e-15, 5.3291e-15, 3.6637e-15,\n",
      "         3.1086e-15, 5.3291e-15, 4.4409e-15, 6.2172e-15, 6.6613e-15, 5.3291e-15,\n",
      "         3.1086e-15, 4.2744e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 220: layer4.0.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 220\n",
      "Max diff:\n",
      " tensor([9.7700e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.6042e-16, 2.2031e-16, 0.0000e+00, 2.7756e-16, 0.0000e+00, 0.0000e+00,\n",
      "         4.1633e-16, 2.7148e-16, 0.0000e+00, 0.0000e+00, 3.8858e-16, 0.0000e+00,\n",
      "         2.9143e-16, 0.0000e+00, 5.5511e-16, 3.3307e-16, 7.7716e-16, 8.6042e-16,\n",
      "         0.0000e+00, 0.0000e+00, 2.4286e-16, 6.1062e-16, 1.6653e-16, 4.1633e-16,\n",
      "         0.0000e+00, 4.4409e-16, 3.7817e-16, 0.0000e+00, 2.7756e-16, 0.0000e+00,\n",
      "         8.3267e-17, 0.0000e+00, 0.0000e+00, 3.8858e-16, 9.9920e-16, 8.1879e-16,\n",
      "         3.8858e-16, 0.0000e+00, 0.0000e+00, 1.8041e-16, 3.8858e-16, 0.0000e+00,\n",
      "         5.5511e-16, 2.1164e-16, 7.2164e-16, 2.6368e-15, 1.1102e-16, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 1.1102e-16, 1.3323e-15,\n",
      "         1.3878e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9960e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.6653e-16, 6.6613e-16, 0.0000e+00, 4.8572e-16,\n",
      "         3.3307e-16, 2.7062e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 1.8041e-16, 5.1348e-16, 0.0000e+00, 1.0929e-16, 5.5511e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.0817e-17, 0.0000e+00, 0.0000e+00, 1.8041e-16, 6.6613e-16,\n",
      "         0.0000e+00, 3.7123e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 1.7347e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6098e-15,\n",
      "         6.1062e-16, 0.0000e+00, 2.6368e-16, 0.0000e+00, 3.0531e-16, 0.0000e+00,\n",
      "         0.0000e+00, 2.6368e-16, 1.5959e-16, 2.5674e-16, 1.9429e-16, 0.0000e+00,\n",
      "         0.0000e+00, 3.8858e-16, 2.4980e-16, 0.0000e+00, 1.8735e-16, 2.7756e-16,\n",
      "         0.0000e+00, 0.0000e+00, 3.9248e-17, 2.3592e-16, 0.0000e+00, 9.9920e-16,\n",
      "         0.0000e+00, 4.1633e-17, 3.2127e-15, 3.5527e-15, 0.0000e+00, 0.0000e+00,\n",
      "         2.5535e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6645e-15, 1.1102e-16, 1.1657e-15,\n",
      "         1.3323e-15, 0.0000e+00, 1.7764e-15, 0.0000e+00, 2.2204e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8874e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 2.8866e-15,\n",
      "         0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.5543e-15, 0.0000e+00, 1.2490e-15, 1.8319e-15, 0.0000e+00, 3.1086e-15,\n",
      "         0.0000e+00, 6.6613e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-16, 0.0000e+00, 8.3267e-17, 2.4980e-16, 1.6653e-15, 7.2164e-16,\n",
      "         1.7764e-15, 0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.9151e-15, 8.6042e-16, 2.7756e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8943e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.7184e-16, 7.7716e-16, 0.0000e+00, 0.0000e+00, 2.5171e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0531e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0947e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 1.5543e-15, 2.6645e-15,\n",
      "         0.0000e+00, 1.4433e-15, 0.0000e+00, 3.6637e-15, 4.3854e-15, 0.0000e+00,\n",
      "         2.3592e-15, 0.0000e+00, 3.9205e-16, 1.6098e-15, 1.1657e-15, 2.6645e-15,\n",
      "         5.9952e-15, 0.0000e+00, 2.4980e-15, 0.0000e+00, 3.9968e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.6653e-15, 0.0000e+00, 2.6645e-15, 0.0000e+00,\n",
      "         6.6613e-16, 2.1649e-15, 1.9151e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3592e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.1062e-15, 1.7764e-15, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-16, 2.2204e-15, 0.0000e+00, 1.8041e-15, 0.0000e+00, 0.0000e+00,\n",
      "         4.2188e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.2204e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7625e-15,\n",
      "         4.3854e-15, 9.9920e-16, 0.0000e+00, 2.4425e-15, 0.0000e+00, 0.0000e+00,\n",
      "         3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6004e-15,\n",
      "         0.0000e+00, 4.8572e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.2212e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00,\n",
      "         0.0000e+00, 4.1078e-15, 0.0000e+00, 2.4425e-15, 0.0000e+00, 0.0000e+00,\n",
      "         2.4980e-15, 0.0000e+00, 3.2752e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.6653e-15, 1.2143e-15, 0.0000e+00, 3.5527e-15, 0.0000e+00, 0.0000e+00,\n",
      "         7.7716e-16, 0.0000e+00, 2.1649e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.4980e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5543e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.5226e-16, 0.0000e+00, 3.1225e-15, 0.0000e+00, 2.6645e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.1070e-15, 9.7700e-15, 0.0000e+00, 3.3307e-15, 1.3323e-15, 0.0000e+00,\n",
      "         0.0000e+00, 2.3592e-15, 0.0000e+00, 6.2172e-15, 1.6653e-15, 0.0000e+00,\n",
      "         1.5543e-15, 2.8866e-15, 6.6613e-16, 3.5527e-15, 5.3291e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.9984e-15, 0.0000e+00, 0.0000e+00, 1.4919e-15, 3.9968e-15,\n",
      "         3.4694e-15, 2.8866e-15, 0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8874e-15, 3.1086e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.7208e-15, 0.0000e+00, 0.0000e+00, 3.7054e-15, 3.1086e-15,\n",
      "         0.0000e+00, 4.8850e-15, 0.0000e+00, 1.5543e-15, 0.0000e+00, 3.5943e-15,\n",
      "         0.0000e+00, 3.9968e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 2.2204e-15,\n",
      "         0.0000e+00, 4.4409e-15, 3.9968e-15, 0.0000e+00, 0.0000e+00, 3.4209e-15,\n",
      "         0.0000e+00, 0.0000e+00, 6.8001e-16, 0.0000e+00, 2.3870e-15, 1.7764e-15,\n",
      "         9.1940e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         2.3870e-15, 0.0000e+00, 0.0000e+00, 1.8874e-15, 3.3307e-16, 1.9984e-15,\n",
      "         2.4425e-15, 5.7732e-15, 0.0000e+00, 0.0000e+00, 2.5535e-15, 2.1927e-15,\n",
      "         2.2204e-15, 2.2204e-15, 0.0000e+00, 1.7764e-15, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 3.1086e-15, 1.7764e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.5527e-15, 3.9968e-15, 0.0000e+00, 6.6613e-16, 0.0000e+00, 3.9968e-15,\n",
      "         0.0000e+00, 0.0000e+00, 3.6637e-15, 1.5543e-15, 1.9429e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0131e-15, 0.0000e+00, 2.6645e-15, 7.1054e-15, 6.2172e-15,\n",
      "         3.7192e-15, 1.4433e-15, 2.1094e-15, 0.0000e+00, 0.0000e+00, 1.2212e-15,\n",
      "         3.1086e-15, 0.0000e+00, 2.3315e-15, 6.2172e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.2744e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   3,   6,   7,  10,  12,  14,  15,  16,  17,  20,  21,  22,\n",
      "         23,  25,  26,  28,  30,  33,  34,  35,  36,  39,  40,  42,  43,  44,\n",
      "         45,  46,  49,  52,  53,  54,  58,  62,  63,  65,  66,  67,  71,  73,\n",
      "         74,  76,  77,  85,  88,  89,  91,  95,  97, 101, 102, 104, 106, 109,\n",
      "        110, 111, 112, 115, 116, 118, 119, 122, 123, 125, 127, 128, 129, 132,\n",
      "        136, 141, 142, 143, 144, 146, 148, 157, 160, 161, 163, 168, 170, 171,\n",
      "        173, 175, 180, 182, 183, 184, 185, 186, 189, 192, 193, 194, 199, 205,\n",
      "        206, 209, 214, 222, 225, 226, 227, 229, 231, 232, 234, 236, 237, 238,\n",
      "        239, 240, 242, 244, 248, 250, 252, 253, 254, 261, 266, 267, 270, 271,\n",
      "        273, 276, 282, 287, 288, 289, 291, 294, 299, 301, 306, 316, 319, 321,\n",
      "        324, 326, 336, 337, 339, 342, 344, 354, 362, 367, 369, 371, 378, 379,\n",
      "        381, 382, 385, 387, 388, 390, 391, 392, 393, 394, 397, 400, 401, 402,\n",
      "        403, 406, 411, 412, 415, 418, 419, 421, 423, 425, 427, 430, 431, 433,\n",
      "        434, 437, 440, 442, 443, 444, 448, 450, 453, 454, 455, 456, 457, 460,\n",
      "        461, 462, 463, 465, 466, 469, 470, 474, 475, 477, 479, 482, 483, 484,\n",
      "        489, 493, 495, 496, 497, 498, 499, 500, 503, 504, 506, 507, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   3,   6,   7,  10,  12,  14,  15,  16,  17,  20,  21,  22,\n",
      "         23,  25,  26,  28,  30,  33,  34,  35,  36,  39,  40,  42,  43,  44,\n",
      "         45,  46,  49,  52,  53,  54,  58,  62,  63,  65,  66,  67,  71,  73,\n",
      "         74,  76,  77,  85,  88,  89,  91,  95,  97, 101, 102, 104, 106, 109,\n",
      "        110, 111, 112, 115, 116, 118, 119, 122, 123, 125, 127, 128, 129, 132,\n",
      "        136, 141, 142, 143, 144, 146, 148, 157, 160, 161, 163, 168, 170, 171,\n",
      "        173, 175, 180, 182, 183, 184, 185, 186, 189, 192, 193, 194, 199, 205,\n",
      "        206, 209, 214, 222, 225, 226, 227, 229, 231, 232, 234, 236, 237, 238,\n",
      "        239, 240, 242, 244, 248, 250, 252, 253, 254, 261, 266, 267, 270, 271,\n",
      "        273, 276, 282, 287, 288, 289, 291, 294, 299, 301, 306, 316, 319, 321,\n",
      "        324, 326, 336, 337, 339, 342, 344, 354, 362, 367, 369, 371, 378, 379,\n",
      "        381, 382, 385, 387, 388, 390, 391, 392, 393, 394, 397, 400, 401, 402,\n",
      "        403, 406, 411, 412, 415, 418, 419, 421, 423, 425, 427, 430, 431, 433,\n",
      "        434, 437, 440, 442, 443, 444, 448, 450, 453, 454, 455, 456, 457, 460,\n",
      "        461, 462, 463, 465, 466, 469, 470, 474, 475, 477, 479, 482, 483, 484,\n",
      "        489, 493, 495, 496, 497, 498, 499, 500, 503, 504, 506, 507, 511])  (len = 223)\n",
      "passing Cout = tensor([275])  (len = 1)\n",
      "\n",
      "Executing module 221: layer4.0.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 221\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([141, 154, 176, 200, 204, 219, 228, 253, 254]) to machine 1\n",
      "\t\t sending C_out tensor([261, 263, 268, 269, 284, 289, 318, 358, 361, 375, 376]) to machine 2\n",
      "\t\t sending C_out tensor([386, 387, 388, 392, 418, 432, 436, 440, 444, 445, 450, 454, 468, 469,\n",
      "        474, 507]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 221\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   4,  12,  13,  20,  32,  34,  41,  45,  48,  54,  57,  69,\n",
      "         74,  90, 123]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
      "        369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
      "        383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 221\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,  20,  51,  64,  69,  74,  82,  90,  91,  94, 100, 117]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 221\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   3,   4,   9,  22,  24,  26,  33,  35,  40,  41,  46,  48,  55,\n",
      "         58,  59,  64,  67,  68,  75,  77,  81,  86,  91,  92,  93,  94,  98,\n",
      "        102, 103, 108, 116, 122, 123]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 221\n",
      "Max diff:\n",
      " tensor([4.9738e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.9968e-15, 3.5527e-15, 3.3307e-16, 1.3323e-15, 1.3323e-15, 4.1078e-15,\n",
      "         4.4409e-16, 8.8818e-16, 8.8818e-16, 2.2204e-16, 3.3307e-16, 6.6613e-16,\n",
      "         8.8818e-16, 1.1102e-15, 4.4409e-16, 1.9429e-15, 1.1102e-16, 1.2906e-15,\n",
      "         8.8818e-16, 2.2204e-15, 3.3307e-16, 7.1054e-15, 2.4425e-15, 6.2172e-15,\n",
      "         5.3291e-15, 1.3323e-15, 2.6645e-15, 3.8858e-16, 3.5527e-15, 8.8818e-16,\n",
      "         5.3291e-15, 1.9984e-15, 3.4417e-15, 1.3323e-15, 4.4409e-16, 7.9936e-15,\n",
      "         3.5527e-15, 2.2204e-16, 2.2204e-15, 3.5527e-15, 4.4409e-15, 3.5527e-15,\n",
      "         1.6653e-16, 1.3323e-15, 2.2204e-15, 1.3323e-15, 2.6645e-15, 5.3291e-15,\n",
      "         1.1102e-15, 1.3323e-15, 1.7764e-15, 5.3291e-15, 3.9968e-15, 6.2172e-15,\n",
      "         2.2204e-15, 7.1054e-15, 1.7764e-15, 4.4409e-16, 2.2204e-15, 6.6613e-16,\n",
      "         8.8818e-16, 4.4409e-15, 6.6613e-16, 1.1102e-15, 1.1102e-15, 2.2204e-16,\n",
      "         1.7764e-15, 1.7764e-15, 1.3878e-16, 3.3307e-16, 3.9968e-15, 7.7716e-16,\n",
      "         5.3291e-15, 2.2204e-16, 1.6653e-16, 3.7748e-15, 2.2204e-16, 3.1086e-15,\n",
      "         3.5527e-15, 6.6613e-16, 3.5527e-15, 6.6613e-16, 2.7756e-16, 2.6645e-15,\n",
      "         3.5527e-15, 4.4409e-16, 4.4409e-16, 3.3307e-16, 3.3307e-15, 8.8818e-16,\n",
      "         6.2172e-15, 8.8818e-16, 3.1086e-15, 1.7764e-15, 4.8850e-15, 6.6613e-16,\n",
      "         2.2204e-16, 4.4409e-16, 9.7700e-15, 1.3323e-15, 3.5527e-15, 6.6613e-16,\n",
      "         3.1086e-15, 4.4409e-16, 2.2204e-15, 2.6645e-15, 2.2204e-15, 6.6613e-16,\n",
      "         5.3291e-15, 3.3307e-16, 1.1102e-16, 3.3307e-16, 4.4409e-16, 2.2204e-16,\n",
      "         8.8818e-16, 8.8818e-16, 5.3291e-15, 2.7756e-16, 5.7732e-15, 2.2204e-16,\n",
      "         3.1641e-15, 3.3307e-16, 1.3323e-15, 3.1086e-15, 4.4409e-16, 2.6923e-15,\n",
      "         1.3323e-15, 3.8858e-16, 2.1316e-14, 2.4869e-14, 6.7724e-15, 1.4211e-14,\n",
      "         1.7764e-14, 1.5987e-14, 3.1974e-14, 1.0658e-14, 3.1974e-14, 1.3323e-14,\n",
      "         3.9080e-14, 1.6431e-14, 3.0198e-14, 1.7764e-14, 4.9738e-14, 1.5987e-14,\n",
      "         1.3323e-14, 1.2434e-14, 8.8818e-15, 2.3093e-14, 3.0198e-14, 1.0658e-14,\n",
      "         1.1546e-14, 1.1102e-14, 9.2149e-15, 1.4211e-14, 1.5543e-14, 3.9080e-14,\n",
      "         1.7764e-14, 3.9080e-14, 3.1086e-15, 2.4869e-14, 1.6875e-14, 1.2434e-14,\n",
      "         1.5987e-14, 2.4869e-14, 1.0658e-14, 2.4869e-14, 1.4211e-14, 1.2879e-14,\n",
      "         4.2633e-14, 1.5987e-14, 1.0658e-14, 8.8818e-15, 1.7764e-14, 2.4869e-14,\n",
      "         1.0658e-14, 9.3259e-15, 2.8422e-14, 1.0214e-14, 1.0658e-14, 1.2879e-14,\n",
      "         3.1974e-14, 1.7764e-14, 1.4211e-14, 1.4211e-14, 1.4211e-14, 1.2434e-14,\n",
      "         1.7764e-14, 1.9540e-14, 1.0658e-14, 1.0658e-14, 1.1824e-14, 1.2434e-14,\n",
      "         1.0658e-14, 1.2434e-14, 1.2434e-14, 7.1054e-15, 2.4869e-14, 1.0658e-14,\n",
      "         1.1546e-14, 1.4211e-14, 1.7764e-14, 1.0658e-14, 2.8422e-14, 1.0658e-14,\n",
      "         2.6645e-14, 2.1316e-14, 1.2434e-14, 1.0658e-14, 1.7764e-14, 1.0658e-14,\n",
      "         1.5987e-14, 1.4211e-14, 7.1054e-15, 9.7700e-15, 1.7764e-14, 1.5099e-14,\n",
      "         1.5987e-14, 5.3291e-15, 5.3291e-15, 1.2434e-14, 1.0658e-14, 8.8818e-15,\n",
      "         1.7764e-14, 2.1316e-14, 8.8818e-15, 1.9540e-14, 8.8818e-15, 2.4869e-14,\n",
      "         2.1316e-14, 1.6209e-14, 1.0658e-14, 2.1316e-14, 1.4211e-14, 1.5987e-14,\n",
      "         1.0658e-14, 7.1054e-15, 8.8818e-15, 1.2434e-14, 8.8818e-15, 2.1316e-14,\n",
      "         2.4869e-14, 2.4869e-14, 9.7700e-15, 1.2434e-14, 8.8818e-15, 1.5099e-14,\n",
      "         1.7764e-14, 1.9540e-14, 1.0658e-14, 2.4869e-14, 2.1316e-14, 1.5987e-14,\n",
      "         1.2434e-14, 1.1546e-14, 6.2172e-15, 1.7764e-14, 3.5527e-14, 2.1316e-14,\n",
      "         1.1990e-14, 1.1768e-14, 1.4211e-14, 1.6875e-14, 1.2434e-14, 4.8017e-15,\n",
      "         1.2434e-14, 1.0658e-14, 1.4211e-14, 2.1316e-14, 1.4211e-14, 1.0658e-14,\n",
      "         2.8422e-14, 1.0658e-14, 2.4869e-14, 1.1324e-14, 1.5099e-14, 1.1546e-14,\n",
      "         1.2434e-14, 1.0658e-14, 1.0658e-14, 1.4211e-14, 1.1990e-14, 1.0658e-14,\n",
      "         5.3291e-15, 1.0658e-14, 2.1316e-14, 3.5527e-15, 3.5527e-14, 2.1316e-14,\n",
      "         1.4211e-14, 2.1316e-14, 1.7764e-14, 2.1316e-14, 4.2633e-14, 2.1316e-14,\n",
      "         2.3093e-14, 2.1316e-14, 1.2434e-14, 1.4211e-14, 1.3767e-14, 1.4211e-14,\n",
      "         1.0658e-14, 1.4211e-14, 1.4211e-14, 1.5987e-14, 1.7542e-14, 2.1316e-14,\n",
      "         2.4869e-14, 1.9540e-14, 9.3259e-15, 1.7764e-15, 1.2434e-14, 1.0658e-14,\n",
      "         5.3291e-15, 1.4211e-14, 1.4211e-14, 1.4211e-14, 8.8818e-15, 7.9936e-15,\n",
      "         1.4211e-14, 1.7764e-14, 1.4211e-14, 8.8818e-15, 1.4211e-14, 7.1054e-15,\n",
      "         1.0658e-14, 2.1316e-14, 1.2434e-14, 1.4211e-14, 3.5527e-15, 1.8804e-14,\n",
      "         1.3323e-14, 8.8818e-15, 8.8818e-15, 1.9540e-14, 1.7764e-14, 1.4211e-14,\n",
      "         1.0436e-14, 1.2434e-14, 1.1546e-14, 1.7764e-14, 1.5987e-14, 1.7764e-14,\n",
      "         6.6613e-15, 7.1054e-15, 7.1054e-15, 1.9540e-14, 1.2434e-14, 9.7700e-15,\n",
      "         1.3323e-14, 1.9540e-14, 2.8422e-14, 2.1316e-14, 1.4211e-14, 1.7764e-14,\n",
      "         1.1102e-15, 1.4211e-14, 1.0658e-14, 1.5987e-14, 1.9540e-14, 1.0658e-14,\n",
      "         1.7764e-14, 1.2434e-14, 1.9540e-14, 7.1054e-15, 8.8818e-15, 1.7764e-14,\n",
      "         3.1974e-14, 2.1316e-14, 1.5987e-14, 4.4409e-15, 9.1038e-15, 1.4211e-14,\n",
      "         1.7764e-14, 1.4211e-14, 1.1990e-14, 2.4869e-14, 2.8422e-14, 1.2434e-14,\n",
      "         1.4211e-14, 1.0658e-14, 2.4869e-14, 2.1316e-14, 1.5987e-14, 4.4409e-15,\n",
      "         1.7764e-14, 1.2434e-14, 1.5987e-14, 1.5987e-14, 1.0658e-14, 1.4211e-14,\n",
      "         1.6875e-14, 1.0658e-14, 1.3323e-14, 1.3323e-14, 1.9540e-14, 1.2434e-14,\n",
      "         8.8818e-15, 3.0198e-14, 1.2434e-14, 1.1546e-14, 1.4211e-14, 2.4869e-14,\n",
      "         1.2434e-14, 1.5987e-14, 1.2434e-14, 2.4869e-14, 1.7764e-14, 1.2434e-14,\n",
      "         1.2434e-14, 1.0658e-14, 1.3323e-14, 1.0658e-14, 1.2434e-14, 1.0658e-14,\n",
      "         1.7764e-14, 1.8652e-14, 7.1054e-15, 1.5099e-14, 1.3323e-14, 1.0658e-14,\n",
      "         1.5987e-14, 1.0658e-14, 1.4655e-14, 7.1054e-15, 1.7764e-14, 1.2434e-14,\n",
      "         1.4211e-14, 1.2434e-14, 1.1713e-14, 1.0658e-14, 1.2434e-14, 1.2434e-14,\n",
      "         1.0658e-14, 2.1316e-14, 1.7764e-14, 1.7764e-14, 1.1546e-14, 2.1316e-14,\n",
      "         1.5987e-14, 1.5987e-14, 2.6645e-14, 2.3093e-14, 2.8422e-14, 1.3989e-14,\n",
      "         1.1102e-14, 1.7764e-14, 2.1316e-14, 1.5987e-14, 8.2157e-15, 1.0658e-14,\n",
      "         1.5987e-14, 7.1054e-15, 2.1316e-14, 1.0658e-14, 1.1102e-14, 1.2879e-14,\n",
      "         8.4377e-15, 1.3323e-14, 1.2212e-14, 2.1316e-14, 1.0658e-14, 1.0658e-14,\n",
      "         8.8818e-15, 1.4211e-14, 8.8818e-15, 9.7700e-15, 1.4211e-14, 1.2434e-14,\n",
      "         2.8422e-14, 1.4211e-14, 1.5321e-14, 1.0658e-14, 1.0658e-14, 2.8422e-14,\n",
      "         9.3259e-15, 8.8818e-15, 1.4211e-14, 2.3093e-14, 1.4211e-14, 1.5099e-14,\n",
      "         1.2434e-14, 2.1316e-14, 7.1054e-15, 1.1546e-14, 1.4211e-14, 1.5099e-14,\n",
      "         9.7700e-15, 1.6875e-14, 1.2879e-14, 1.1990e-14, 2.4869e-14, 1.1546e-14,\n",
      "         1.8652e-14, 1.0658e-14, 1.2434e-14, 1.4211e-14, 1.2434e-14, 1.0214e-14,\n",
      "         1.2212e-14, 2.3093e-14, 8.8818e-15, 8.8818e-15, 1.6875e-14, 1.4211e-14,\n",
      "         1.4211e-14, 1.4211e-14, 1.4211e-14, 1.1546e-14, 1.7764e-14, 1.9540e-14,\n",
      "         1.5987e-14, 8.8818e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 222: layer4.0.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 222\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 222\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 222\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 222\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 222\n",
      "Max diff:\n",
      " tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 6.6613e-16, 1.1102e-16, 3.3307e-16, 3.3307e-16, 9.4369e-16,\n",
      "         1.1102e-16, 4.4409e-16, 2.7756e-16, 6.9389e-17, 1.1102e-16, 2.2204e-16,\n",
      "         3.3307e-16, 4.4409e-16, 1.6653e-16, 3.2613e-16, 4.1633e-17, 3.4001e-16,\n",
      "         3.3307e-16, 4.4409e-16, 1.1102e-16, 2.2204e-15, 5.5511e-16, 3.5527e-15,\n",
      "         1.7764e-15, 3.3307e-16, 2.2204e-15, 1.3878e-16, 1.1102e-15, 3.3307e-16,\n",
      "         1.5543e-15, 7.7716e-16, 8.0491e-16, 4.4409e-16, 1.6653e-16, 3.5527e-15,\n",
      "         1.2212e-15, 6.9389e-17, 1.1102e-15, 8.8818e-16, 1.3323e-15, 1.7764e-15,\n",
      "         6.9389e-17, 6.6613e-16, 6.6613e-16, 2.7756e-16, 6.6613e-16, 3.5527e-15,\n",
      "         1.3878e-16, 4.4409e-16, 6.6613e-16, 2.2204e-15, 1.7764e-15, 2.8866e-15,\n",
      "         1.2212e-15, 4.4409e-15, 4.4409e-16, 1.3878e-16, 1.3323e-15, 2.7756e-16,\n",
      "         3.3307e-16, 2.2204e-15, 2.4980e-16, 3.3307e-16, 2.7756e-16, 5.5511e-17,\n",
      "         4.4409e-16, 8.8818e-16, 4.1633e-17, 1.1102e-16, 1.8874e-15, 2.2204e-16,\n",
      "         1.5543e-15, 8.3267e-17, 5.5511e-17, 1.6653e-15, 6.9389e-17, 1.1102e-15,\n",
      "         2.2204e-15, 3.3307e-16, 8.8818e-16, 2.2204e-16, 1.1102e-16, 3.8858e-16,\n",
      "         2.2204e-15, 1.6653e-16, 1.6653e-16, 8.3267e-17, 9.9920e-16, 2.7756e-16,\n",
      "         2.6645e-15, 3.3307e-16, 6.6613e-16, 6.6613e-16, 2.6645e-15, 3.3307e-16,\n",
      "         6.9389e-17, 1.6653e-16, 3.1086e-15, 6.6613e-16, 1.3323e-15, 2.2204e-16,\n",
      "         1.2212e-15, 1.6653e-16, 1.3323e-15, 8.8818e-16, 1.1102e-15, 2.2204e-16,\n",
      "         3.1086e-15, 1.1102e-16, 4.1633e-17, 1.1102e-16, 1.6653e-16, 8.3267e-17,\n",
      "         3.3307e-16, 3.3307e-16, 1.5543e-15, 1.1102e-16, 2.4425e-15, 8.3267e-17,\n",
      "         1.3045e-15, 1.1102e-16, 3.3307e-16, 8.8818e-16, 1.6653e-16, 6.8695e-16,\n",
      "         3.3307e-16, 1.3878e-16, 1.0658e-14, 1.3323e-14, 4.1633e-15, 7.1054e-15,\n",
      "         1.0658e-14, 1.0658e-14, 2.1316e-14, 6.2172e-15, 1.5987e-14, 7.5495e-15,\n",
      "         2.1316e-14, 9.5479e-15, 1.7319e-14, 7.5495e-15, 2.4869e-14, 8.8818e-15,\n",
      "         8.8818e-15, 7.9936e-15, 5.3291e-15, 1.2434e-14, 1.9540e-14, 4.8850e-15,\n",
      "         6.2172e-15, 6.4393e-15, 4.2188e-15, 7.9936e-15, 1.1102e-14, 1.9540e-14,\n",
      "         8.8818e-15, 1.9540e-14, 1.7764e-15, 1.0658e-14, 8.8818e-15, 6.2172e-15,\n",
      "         7.9936e-15, 1.4211e-14, 3.9968e-15, 2.1316e-14, 7.9936e-15, 5.8842e-15,\n",
      "         2.1316e-14, 7.9936e-15, 7.1054e-15, 4.4409e-15, 1.2434e-14, 1.4211e-14,\n",
      "         6.2172e-15, 6.2172e-15, 1.7764e-14, 6.2172e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.7764e-14, 1.0658e-14, 8.8818e-15, 8.8818e-15, 8.8818e-15, 5.3291e-15,\n",
      "         1.0658e-14, 1.0658e-14, 7.9936e-15, 6.2172e-15, 6.2172e-15, 4.4409e-15,\n",
      "         5.3291e-15, 8.8818e-15, 7.1054e-15, 3.5527e-15, 1.4211e-14, 5.3291e-15,\n",
      "         5.3291e-15, 8.8818e-15, 1.2434e-14, 5.3291e-15, 2.1316e-14, 5.3291e-15,\n",
      "         1.5987e-14, 1.1546e-14, 7.9936e-15, 5.3291e-15, 8.8818e-15, 5.3291e-15,\n",
      "         6.2172e-15, 1.0658e-14, 4.4409e-15, 5.8842e-15, 9.7700e-15, 7.8826e-15,\n",
      "         8.8818e-15, 4.4409e-15, 2.2204e-15, 7.1054e-15, 7.1054e-15, 5.3291e-15,\n",
      "         1.0658e-14, 1.0658e-14, 4.4409e-15, 9.7700e-15, 4.4409e-15, 1.4211e-14,\n",
      "         1.1546e-14, 9.5479e-15, 3.5527e-15, 1.0658e-14, 7.5495e-15, 8.4377e-15,\n",
      "         8.8818e-15, 3.5527e-15, 4.4409e-15, 6.2172e-15, 1.5543e-15, 1.2434e-14,\n",
      "         1.2434e-14, 1.5987e-14, 6.2172e-15, 8.8818e-15, 6.2172e-15, 8.4377e-15,\n",
      "         1.0658e-14, 1.1546e-14, 4.8850e-15, 1.4211e-14, 1.0658e-14, 9.7700e-15,\n",
      "         7.1054e-15, 7.1054e-15, 4.8850e-15, 9.7700e-15, 2.8422e-14, 1.4211e-14,\n",
      "         5.7732e-15, 7.6605e-15, 8.8818e-15, 8.8818e-15, 8.2157e-15, 2.5795e-15,\n",
      "         7.1054e-15, 5.3291e-15, 7.9936e-15, 1.0658e-14, 8.8818e-15, 3.5527e-15,\n",
      "         1.5987e-14, 7.1054e-15, 1.0658e-14, 4.6629e-15, 8.8818e-15, 5.3291e-15,\n",
      "         7.9936e-15, 4.4409e-15, 7.1054e-15, 8.8818e-15, 8.4377e-15, 5.3291e-15,\n",
      "         2.2204e-15, 7.1054e-15, 1.4211e-14, 1.3323e-15, 2.1316e-14, 1.0658e-14,\n",
      "         8.8818e-15, 1.0658e-14, 1.0658e-14, 1.0658e-14, 2.1316e-14, 1.4211e-14,\n",
      "         1.0658e-14, 1.0658e-14, 7.1054e-15, 7.1054e-15, 1.0436e-14, 9.7700e-15,\n",
      "         8.8818e-15, 1.4211e-14, 7.1054e-15, 1.0658e-14, 9.8810e-15, 1.2434e-14,\n",
      "         1.2434e-14, 1.0658e-14, 3.9968e-15, 8.8818e-16, 6.2172e-15, 7.1054e-15,\n",
      "         3.1086e-15, 6.2172e-15, 8.8818e-15, 1.0658e-14, 3.5527e-15, 6.2172e-15,\n",
      "         8.8818e-15, 1.2434e-14, 9.7700e-15, 4.8850e-15, 7.1054e-15, 3.5527e-15,\n",
      "         5.3291e-15, 1.3323e-14, 7.1054e-15, 8.8818e-15, 1.7764e-15, 1.2740e-14,\n",
      "         8.8818e-15, 3.5527e-15, 4.4409e-15, 7.5495e-15, 1.0658e-14, 8.8818e-15,\n",
      "         6.2172e-15, 7.1054e-15, 6.4393e-15, 1.0658e-14, 1.0658e-14, 1.0658e-14,\n",
      "         3.5527e-15, 4.4409e-15, 3.5527e-15, 1.0658e-14, 7.9936e-15, 3.7748e-15,\n",
      "         6.2172e-15, 1.2434e-14, 1.2434e-14, 1.4211e-14, 7.9936e-15, 1.0658e-14,\n",
      "         3.3307e-16, 6.6613e-15, 8.8818e-15, 6.2172e-15, 1.1546e-14, 7.1054e-15,\n",
      "         8.8818e-15, 6.2172e-15, 1.0658e-14, 3.5527e-15, 4.4409e-15, 1.7764e-14,\n",
      "         1.9540e-14, 1.4211e-14, 6.2172e-15, 2.8866e-15, 5.9952e-15, 7.1054e-15,\n",
      "         8.8818e-15, 5.7732e-15, 7.9936e-15, 1.0658e-14, 1.4211e-14, 6.2172e-15,\n",
      "         1.0658e-14, 7.5495e-15, 1.4211e-14, 1.4211e-14, 8.8818e-15, 1.9984e-15,\n",
      "         1.1990e-14, 6.2172e-15, 8.8818e-15, 9.7700e-15, 6.2172e-15, 8.8818e-15,\n",
      "         1.0658e-14, 7.1054e-15, 7.9936e-15, 6.6613e-15, 7.1054e-15, 6.2172e-15,\n",
      "         3.5527e-15, 1.3323e-14, 9.7700e-15, 7.1054e-15, 4.8850e-15, 1.0658e-14,\n",
      "         6.2172e-15, 7.1054e-15, 6.2172e-15, 1.4211e-14, 1.0658e-14, 7.1054e-15,\n",
      "         4.4409e-15, 6.2172e-15, 7.1054e-15, 5.3291e-15, 6.2172e-15, 4.4409e-15,\n",
      "         8.8818e-15, 1.0658e-14, 3.9968e-15, 6.8834e-15, 7.5495e-15, 5.3291e-15,\n",
      "         8.8818e-15, 7.1054e-15, 5.5511e-15, 3.9968e-15, 8.8818e-15, 7.1054e-15,\n",
      "         7.1054e-15, 6.2172e-15, 5.4540e-15, 6.2172e-15, 8.8818e-15, 5.3291e-15,\n",
      "         5.3291e-15, 1.1546e-14, 7.9936e-15, 7.9936e-15, 4.4409e-15, 1.1546e-14,\n",
      "         4.4409e-15, 7.9936e-15, 1.5987e-14, 1.1546e-14, 1.4211e-14, 7.7716e-15,\n",
      "         8.4377e-15, 9.7700e-15, 1.2434e-14, 9.7700e-15, 4.9405e-15, 5.3291e-15,\n",
      "         6.2172e-15, 4.4409e-15, 1.4211e-14, 6.6613e-15, 6.6613e-15, 7.1054e-15,\n",
      "         4.5727e-15, 6.6613e-15, 7.2164e-15, 1.0658e-14, 5.3291e-15, 5.3291e-15,\n",
      "         6.2172e-15, 9.3259e-15, 3.5527e-15, 6.2172e-15, 5.3291e-15, 8.8818e-15,\n",
      "         1.4211e-14, 8.8818e-15, 8.3267e-15, 6.6613e-15, 6.2172e-15, 1.5987e-14,\n",
      "         6.5503e-15, 5.3291e-15, 7.1054e-15, 1.5099e-14, 8.8818e-15, 7.5495e-15,\n",
      "         7.9936e-15, 1.0658e-14, 4.4409e-15, 6.2172e-15, 7.1054e-15, 6.6613e-15,\n",
      "         6.2172e-15, 1.0658e-14, 5.1070e-15, 5.3291e-15, 1.5987e-14, 5.3291e-15,\n",
      "         9.7700e-15, 4.4409e-15, 5.7732e-15, 8.8818e-15, 6.2172e-15, 4.6629e-15,\n",
      "         5.4401e-15, 1.0658e-14, 5.3291e-15, 4.4409e-15, 6.6613e-15, 7.1054e-15,\n",
      "         7.1054e-15, 9.7700e-15, 1.0658e-14, 4.8850e-15, 8.8818e-15, 1.2434e-14,\n",
      "         7.9936e-15, 6.2172e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 223: layer4.0.shortcut.0\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 223\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 142, 143, 145, 146,\n",
      "        147, 148, 149, 150, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162,\n",
      "        163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 175, 177, 178, 179,\n",
      "        181, 182, 183, 184, 185, 188, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 201, 202, 203, 204, 206, 209, 210, 211, 212, 213, 214, 215,\n",
      "        216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 232, 233,\n",
      "        234, 235, 236, 238, 239, 240, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 253, 254]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 269, 270, 271,\n",
      "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
      "        287, 288, 289, 290, 291, 293, 295, 296, 297, 298, 300, 301, 302, 303,\n",
      "        304, 305, 307, 310, 311, 312, 314, 316, 317, 318, 320, 322, 323, 324,\n",
      "        325, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
      "        342, 343, 345, 346, 348, 349, 353, 354, 355, 357, 358, 360, 361, 362,\n",
      "        363, 364, 365, 367, 369, 370, 371, 373, 374, 376, 377, 378, 379, 380,\n",
      "        381, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399,\n",
      "        401, 403, 404, 405, 406, 407, 408, 411, 412, 413, 414, 416, 417, 418,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 450,\n",
      "        453, 454, 455, 456, 457, 458, 459, 463, 464, 466, 467, 468, 469, 470,\n",
      "        471, 472, 473, 475, 476, 477, 478, 479, 480, 482, 483, 484, 486, 487,\n",
      "        488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 500, 501, 502, 504,\n",
      "        507, 509, 511]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 223\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
      "         73,  74,  75,  76,  77,  78,  79,  81,  82,  84,  85,  86,  87,  89,\n",
      "         90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 223\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
      "         59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  70,  71,  72,  73,\n",
      "         74,  75,  76,  77,  78,  79,  80,  81,  83,  84,  85,  86,  87,  88,\n",
      "         89,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "        120, 121, 122, 123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving current input. Swapping for input saved from start of block\n",
      "\t\t-Splitting conv layer 223\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  49,  50,  51,  52,  53,  54,  56,  58,  59,\n",
      "         60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  74,\n",
      "         75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "         89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "        103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117,\n",
      "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 223\n",
      "Max diff:\n",
      " tensor([2.3981e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.8850e-15, 2.6645e-15, 6.6613e-16, 1.9984e-15, 2.6645e-15, 5.3291e-15,\n",
      "         9.9920e-16, 8.8818e-16, 1.1102e-15, 2.9143e-16, 4.4409e-16, 9.7145e-16,\n",
      "         9.4369e-16, 1.6098e-15, 2.7756e-16, 7.1054e-15, 2.1164e-16, 1.8874e-15,\n",
      "         1.5543e-15, 3.7748e-15, 3.3307e-16, 2.6645e-15, 8.8818e-15, 5.1070e-15,\n",
      "         7.1054e-15, 5.6899e-16, 4.6629e-15, 5.5511e-16, 2.6645e-15, 1.7764e-15,\n",
      "         6.4393e-15, 5.7732e-15, 2.6090e-15, 1.5543e-15, 4.4409e-16, 4.4409e-15,\n",
      "         2.6645e-15, 3.1919e-16, 2.2204e-15, 4.8850e-15, 3.9968e-15, 4.1078e-15,\n",
      "         2.2898e-16, 2.2204e-15, 7.7716e-16, 1.9984e-15, 2.6645e-15, 4.6629e-15,\n",
      "         2.1649e-15, 2.6645e-15, 1.7764e-15, 8.8818e-15, 5.3291e-15, 7.1054e-15,\n",
      "         8.4377e-15, 1.5821e-15, 2.6645e-15, 2.3592e-16, 3.5527e-15, 6.6613e-16,\n",
      "         1.8874e-15, 2.6645e-15, 8.8818e-16, 2.6645e-15, 5.5511e-16, 3.8858e-16,\n",
      "         1.4849e-15, 6.2172e-15, 1.3878e-16, 9.9920e-16, 8.8818e-15, 9.9920e-16,\n",
      "         1.8874e-15, 6.6613e-16, 4.4409e-16, 4.8850e-15, 1.6653e-16, 1.4988e-15,\n",
      "         3.7748e-15, 1.2212e-15, 3.5527e-15, 1.3323e-15, 4.4409e-16, 1.7764e-15,\n",
      "         2.7756e-15, 1.1102e-15, 1.6653e-16, 7.7716e-16, 2.4286e-15, 1.3323e-15,\n",
      "         3.0531e-15, 1.7764e-15, 3.9968e-15, 1.7764e-15, 2.6645e-15, 9.9920e-16,\n",
      "         3.0531e-16, 6.6613e-16, 2.8866e-15, 3.5527e-15, 7.9936e-15, 6.6613e-16,\n",
      "         6.2172e-15, 9.9920e-16, 5.3291e-15, 2.1094e-15, 3.9968e-15, 4.4409e-16,\n",
      "         4.6629e-15, 5.5511e-16, 3.6082e-16, 7.7716e-16, 5.5511e-16, 3.8858e-16,\n",
      "         1.3323e-15, 9.9920e-16, 3.9968e-15, 7.7716e-16, 4.8850e-15, 3.3307e-16,\n",
      "         5.3291e-15, 6.1062e-16, 1.1102e-15, 1.7764e-15, 2.2204e-16, 3.4417e-15,\n",
      "         1.7764e-15, 2.6368e-16, 1.7764e-14, 8.8818e-15, 7.1054e-15, 6.2172e-15,\n",
      "         4.7740e-15, 5.7732e-15, 1.7764e-14, 7.5495e-15, 5.3291e-15, 8.8818e-15,\n",
      "         1.0658e-14, 3.5527e-15, 6.2172e-15, 5.3291e-15, 1.1546e-14, 4.4409e-15,\n",
      "         1.0658e-14, 1.0658e-14, 8.8818e-15, 6.4393e-15, 1.1546e-14, 8.8818e-15,\n",
      "         9.7700e-15, 6.2172e-15, 9.7700e-15, 9.7700e-15, 5.3291e-15, 9.7700e-15,\n",
      "         1.2434e-14, 1.1435e-14, 2.6645e-15, 7.1054e-15, 1.3323e-14, 1.0658e-14,\n",
      "         7.1054e-15, 7.1054e-15, 4.4409e-15, 9.7700e-15, 8.1046e-15, 1.0658e-14,\n",
      "         5.3291e-15, 3.9968e-15, 5.1070e-15, 8.2157e-15, 1.4211e-14, 4.5519e-15,\n",
      "         7.1054e-15, 9.8810e-15, 1.2434e-14, 7.1054e-15, 1.0658e-14, 7.9936e-15,\n",
      "         6.2172e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15, 6.2172e-15, 8.8818e-15,\n",
      "         8.8818e-15, 5.3291e-15, 5.3291e-15, 6.2172e-15, 1.1324e-14, 6.8556e-15,\n",
      "         6.2172e-15, 1.2434e-14, 7.1054e-15, 3.1086e-15, 8.8818e-15, 7.1054e-15,\n",
      "         1.1546e-14, 7.9936e-15, 1.0658e-14, 7.1054e-15, 8.8818e-15, 7.1054e-15,\n",
      "         7.1054e-15, 8.2712e-15, 3.9968e-15, 4.8850e-15, 6.2172e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.0686e-14, 7.1054e-15, 1.3545e-14, 7.9936e-15, 1.0658e-14,\n",
      "         5.7732e-15, 7.9936e-15, 5.4956e-15, 5.7732e-15, 4.4409e-15, 7.1054e-15,\n",
      "         1.0658e-14, 6.2172e-15, 5.3291e-15, 4.8850e-15, 8.8818e-15, 9.3259e-15,\n",
      "         7.1054e-15, 3.9968e-15, 7.1054e-15, 8.1046e-15, 7.7716e-15, 8.8818e-15,\n",
      "         6.4393e-15, 7.9936e-15, 5.3291e-15, 7.1054e-15, 8.8818e-15, 9.7700e-15,\n",
      "         7.9936e-15, 6.2172e-15, 6.3560e-15, 4.9960e-15, 1.1546e-14, 8.4377e-15,\n",
      "         8.8818e-15, 7.9936e-15, 7.1054e-15, 6.6613e-15, 1.1546e-14, 7.9936e-15,\n",
      "         9.5479e-15, 5.3291e-15, 5.7732e-15, 7.3275e-15, 6.2172e-15, 1.2434e-14,\n",
      "         7.1054e-15, 1.0658e-14, 1.7764e-14, 1.1990e-14, 1.0658e-14, 5.3291e-15,\n",
      "         7.1054e-15, 4.4409e-15, 6.2172e-15, 7.1054e-15, 9.7700e-15, 1.0658e-14,\n",
      "         2.0428e-14, 9.7700e-15, 1.6875e-14, 1.3323e-14, 8.8818e-15, 1.0658e-14,\n",
      "         9.7700e-15, 1.0658e-14, 6.2172e-15, 1.2434e-14, 9.1038e-15, 1.0658e-14,\n",
      "         2.6645e-15, 1.0214e-14, 1.1546e-14, 2.6645e-15, 8.8818e-15, 1.0658e-14,\n",
      "         1.0658e-14, 8.8818e-15, 1.4211e-14, 1.4211e-14, 1.0658e-14, 1.0658e-14,\n",
      "         6.2172e-15, 5.3291e-15, 1.2434e-14, 3.5527e-15, 7.1054e-15, 7.9936e-15,\n",
      "         1.0658e-14, 8.8818e-15, 1.4211e-14, 7.7716e-15, 9.7700e-15, 8.8818e-15,\n",
      "         8.8818e-15, 1.5099e-14, 7.9936e-15, 2.2204e-15, 6.2172e-15, 8.8818e-15,\n",
      "         2.6645e-15, 2.6645e-15, 1.0658e-14, 8.8818e-15, 7.9936e-15, 5.7732e-15,\n",
      "         7.1054e-15, 1.4211e-14, 8.8818e-15, 1.0658e-14, 7.0499e-15, 8.8818e-15,\n",
      "         8.8818e-15, 7.1054e-15, 8.8818e-15, 7.1054e-15, 1.7764e-15, 9.7700e-15,\n",
      "         7.1054e-15, 3.1086e-15, 5.3291e-15, 9.7700e-15, 1.0658e-14, 9.3259e-15,\n",
      "         1.4211e-14, 5.7732e-15, 1.0658e-14, 4.4409e-15, 7.1054e-15, 7.1054e-15,\n",
      "         8.4655e-15, 3.5527e-15, 3.9968e-15, 1.0658e-14, 1.0658e-14, 1.0658e-14,\n",
      "         1.0658e-14, 1.4433e-14, 7.1054e-15, 6.6613e-15, 7.1054e-15, 1.0658e-14,\n",
      "         1.7764e-15, 8.8818e-15, 8.8818e-15, 1.0658e-14, 8.8818e-15, 8.8818e-15,\n",
      "         8.8818e-15, 7.1054e-15, 4.4409e-15, 2.6645e-15, 8.8818e-15, 8.8818e-15,\n",
      "         7.9936e-15, 5.3291e-15, 1.5987e-14, 1.9984e-15, 8.8818e-15, 5.3291e-15,\n",
      "         1.2434e-14, 8.8818e-15, 7.1054e-15, 1.0658e-14, 8.8818e-15, 5.7732e-15,\n",
      "         7.1054e-15, 4.8850e-15, 8.8818e-15, 1.0880e-14, 7.9936e-15, 4.4409e-15,\n",
      "         5.3291e-15, 1.0658e-14, 1.3323e-14, 5.7732e-15, 1.0658e-14, 9.7700e-15,\n",
      "         1.0658e-14, 1.0658e-14, 1.2434e-14, 1.2434e-14, 6.8834e-15, 1.1546e-14,\n",
      "         9.7700e-15, 1.0658e-14, 9.7700e-15, 1.0325e-14, 9.5479e-15, 7.1054e-15,\n",
      "         1.0658e-14, 9.7700e-15, 8.8818e-15, 1.2434e-14, 6.2172e-15, 1.1990e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.4211e-14, 1.0658e-14, 1.2434e-14, 1.0214e-14,\n",
      "         1.0658e-14, 8.8818e-15, 8.4377e-15, 1.0658e-14, 8.8818e-15, 1.7764e-14,\n",
      "         1.2434e-14, 1.1990e-14, 1.0658e-14, 7.1054e-15, 1.1768e-14, 8.8818e-15,\n",
      "         1.2823e-14, 1.0658e-14, 9.7700e-15, 8.8818e-15, 7.1054e-15, 1.1102e-14,\n",
      "         1.0436e-14, 6.2172e-15, 2.2204e-14, 8.4377e-15, 1.1990e-14, 1.0658e-14,\n",
      "         1.7764e-14, 1.3323e-14, 1.0658e-14, 1.0658e-14, 7.1054e-15, 9.2149e-15,\n",
      "         1.0658e-14, 1.1990e-14, 8.8818e-15, 8.8818e-15, 1.0658e-14, 1.4211e-14,\n",
      "         1.4211e-14, 9.1038e-15, 8.8818e-15, 9.7700e-15, 9.7700e-15, 8.4377e-15,\n",
      "         1.0214e-14, 8.8818e-15, 1.4211e-14, 9.1038e-15, 7.1054e-15, 1.1990e-14,\n",
      "         1.2434e-14, 1.0658e-14, 8.9928e-15, 8.8818e-15, 6.2728e-15, 1.2434e-14,\n",
      "         1.0658e-14, 8.8818e-15, 1.0658e-14, 1.2212e-14, 1.4655e-14, 1.4211e-14,\n",
      "         1.2434e-14, 1.0658e-14, 1.1102e-14, 1.2434e-14, 1.1546e-14, 1.9540e-14,\n",
      "         1.0658e-14, 1.2434e-14, 8.6597e-15, 8.8818e-15, 6.2172e-15, 1.1768e-14,\n",
      "         7.1054e-15, 1.9540e-14, 1.5987e-14, 8.8818e-15, 9.7700e-15, 9.3259e-15,\n",
      "         9.7700e-15, 1.1990e-14, 1.0658e-14, 7.1054e-15, 1.3545e-14, 7.1054e-15,\n",
      "         1.0214e-14, 1.2434e-14, 8.8818e-15, 7.2164e-15, 1.7764e-14, 1.2434e-14,\n",
      "         1.0658e-14, 1.3323e-14, 8.8818e-15, 7.7716e-15, 1.2434e-14, 2.3981e-14,\n",
      "         8.8818e-15, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 224: layer4.0.shortcut.1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 224\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 224\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 224\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 224\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 224\n",
      "Max diff:\n",
      " tensor([6.6613e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.1633e-17, 4.4409e-16, 1.3878e-16, 3.3307e-16, 1.9429e-16, 1.7764e-15,\n",
      "         1.1102e-16, 6.9389e-17, 1.6653e-16, 2.7756e-17, 8.3267e-17, 1.1102e-16,\n",
      "         1.2490e-16, 2.6021e-16, 5.5511e-17, 2.2204e-15, 2.7756e-17, 4.1633e-16,\n",
      "         2.7756e-16, 5.5511e-16, 5.5511e-17, 8.3267e-16, 1.3323e-15, 4.9960e-16,\n",
      "         1.5543e-15, 6.2450e-17, 2.7756e-16, 8.3267e-17, 5.5511e-17, 2.7756e-16,\n",
      "         1.7764e-15, 1.3323e-15, 5.9328e-16, 2.2204e-16, 8.3267e-17, 8.8818e-16,\n",
      "         7.7716e-16, 5.5511e-17, 0.0000e+00, 1.3323e-15, 1.1796e-15, 1.5959e-16,\n",
      "         4.1633e-17, 4.4409e-16, 8.3267e-17, 4.9960e-16, 2.2204e-16, 2.6368e-16,\n",
      "         6.9389e-16, 3.8858e-16, 4.9960e-16, 5.5511e-16, 1.2212e-15, 8.8818e-16,\n",
      "         1.4433e-15, 1.9429e-16, 3.3307e-16, 2.7756e-17, 2.4980e-16, 1.1102e-16,\n",
      "         2.3245e-16, 6.3144e-16, 2.2204e-16, 4.4409e-16, 1.1102e-16, 3.1225e-17,\n",
      "         3.3307e-16, 8.6042e-16, 2.2551e-17, 1.3878e-16, 2.2204e-15, 1.3878e-16,\n",
      "         6.6613e-16, 6.9389e-17, 8.3267e-17, 9.7145e-16, 2.7756e-17, 1.9429e-16,\n",
      "         2.4980e-16, 1.2490e-16, 6.6613e-16, 2.4980e-16, 5.5511e-17, 4.4409e-16,\n",
      "         6.5919e-17, 1.6653e-16, 2.7756e-17, 1.6653e-16, 4.4409e-16, 2.2204e-16,\n",
      "         7.2858e-16, 2.7756e-16, 1.1657e-15, 2.2204e-16, 3.4694e-18, 9.7145e-17,\n",
      "         5.5511e-17, 1.1102e-16, 4.8572e-16, 5.5511e-16, 1.2212e-15, 8.3267e-17,\n",
      "         8.8818e-16, 1.6653e-16, 1.2212e-15, 2.7756e-16, 5.5511e-16, 8.3267e-17,\n",
      "         7.4940e-16, 8.3267e-17, 4.8572e-17, 1.3878e-16, 8.3267e-17, 8.3267e-17,\n",
      "         1.9429e-16, 1.8041e-16, 1.3878e-15, 1.2837e-16, 7.7022e-16, 4.8572e-17,\n",
      "         1.1102e-15, 1.0408e-16, 1.6653e-16, 1.1102e-16, 4.1633e-17, 9.7838e-16,\n",
      "         1.6653e-16, 2.7756e-17, 2.6645e-15, 1.9984e-15, 1.7764e-15, 1.3323e-15,\n",
      "         4.4409e-16, 5.0480e-16, 3.1086e-15, 3.1086e-15, 1.9429e-16, 2.6645e-15,\n",
      "         1.9984e-15, 1.7764e-15, 5.6205e-16, 5.5511e-16, 9.9920e-16, 1.1102e-16,\n",
      "         2.6645e-15, 1.6653e-15, 2.6645e-15, 6.1062e-16, 2.4425e-15, 2.2204e-15,\n",
      "         2.4425e-15, 1.2212e-15, 1.6653e-15, 2.2204e-15, 5.5511e-16, 1.8874e-15,\n",
      "         2.6645e-15, 2.8866e-15, 5.5511e-16, 1.1102e-15, 2.3315e-15, 1.9984e-15,\n",
      "         1.5543e-15, 1.1102e-15, 7.7716e-16, 1.9984e-15, 1.6653e-15, 2.2204e-15,\n",
      "         6.6613e-16, 9.9920e-16, 7.7716e-16, 1.3878e-15, 2.8866e-15, 1.2212e-15,\n",
      "         1.5543e-15, 2.3037e-15, 1.7764e-15, 1.7764e-15, 1.3323e-15, 1.9984e-15,\n",
      "         1.1102e-15, 5.0654e-16, 1.1102e-15, 1.1102e-15, 1.3323e-15, 2.2204e-15,\n",
      "         1.3323e-15, 7.7716e-16, 3.8858e-16, 1.2768e-15, 2.5535e-15, 9.7838e-16,\n",
      "         1.7764e-15, 3.5527e-15, 1.3323e-15, 3.3307e-16, 1.8874e-15, 1.3323e-15,\n",
      "         1.5543e-15, 1.0547e-15, 2.2204e-15, 2.2204e-15, 8.8818e-16, 1.3323e-15,\n",
      "         1.2212e-15, 1.5456e-15, 4.9960e-16, 4.4409e-16, 1.3323e-15, 1.3323e-15,\n",
      "         1.5543e-15, 2.1094e-15, 4.9960e-16, 2.0817e-15, 1.5543e-15, 1.9984e-15,\n",
      "         1.0547e-15, 1.4433e-15, 9.5236e-16, 9.9920e-16, 4.4409e-16, 1.9984e-15,\n",
      "         1.7764e-15, 1.3600e-15, 8.8818e-16, 8.8818e-16, 1.7764e-15, 1.7764e-15,\n",
      "         1.5543e-15, 8.8818e-16, 1.7764e-15, 1.2212e-15, 4.1078e-15, 2.2204e-15,\n",
      "         1.4433e-15, 1.6653e-15, 6.6613e-16, 1.7764e-15, 2.6645e-15, 2.2204e-15,\n",
      "         2.1094e-15, 9.4369e-16, 1.3323e-15, 1.1102e-15, 1.4433e-15, 1.3323e-15,\n",
      "         1.1657e-15, 1.0270e-15, 1.7764e-15, 9.9920e-16, 1.5543e-15, 8.8818e-16,\n",
      "         2.1788e-15, 1.1102e-15, 9.9920e-16, 7.7716e-16, 8.8818e-16, 2.6645e-15,\n",
      "         3.9968e-15, 6.6613e-16, 3.5527e-15, 2.1649e-15, 3.5527e-15, 8.8818e-16,\n",
      "         1.3323e-15, 6.6613e-16, 6.1062e-16, 1.1102e-15, 1.7764e-15, 4.4409e-15,\n",
      "         6.6613e-15, 9.9920e-16, 4.4409e-15, 3.7748e-15, 1.9984e-15, 3.1086e-15,\n",
      "         1.4572e-15, 1.7764e-15, 7.7716e-16, 3.1086e-15, 1.2143e-15, 1.1102e-15,\n",
      "         4.4409e-16, 1.9429e-15, 2.4425e-15, 3.3307e-16, 1.1102e-15, 1.1102e-15,\n",
      "         1.9984e-15, 3.5527e-15, 1.1102e-15, 3.5527e-15, 2.3315e-15, 8.8818e-16,\n",
      "         1.2212e-15, 1.1102e-15, 1.7764e-15, 4.4409e-16, 1.0200e-15, 1.1102e-15,\n",
      "         2.8866e-15, 2.4425e-15, 4.4409e-15, 1.6237e-15, 1.6098e-15, 1.9984e-15,\n",
      "         1.3323e-15, 4.6629e-15, 2.0539e-15, 3.0531e-16, 2.2204e-16, 1.9984e-15,\n",
      "         3.3307e-16, 1.3878e-16, 2.2204e-15, 3.1919e-16, 1.5543e-15, 6.6613e-16,\n",
      "         1.4988e-15, 2.3315e-15, 1.9984e-15, 1.7764e-15, 1.2212e-15, 1.9984e-15,\n",
      "         7.7716e-16, 1.1102e-15, 1.3323e-15, 1.1102e-15, 2.2204e-16, 1.9984e-15,\n",
      "         1.4988e-15, 5.5511e-16, 9.1593e-16, 5.7732e-15, 1.3323e-15, 8.4828e-16,\n",
      "         3.3307e-15, 8.8818e-16, 2.2204e-15, 4.4409e-16, 1.5543e-15, 5.5511e-16,\n",
      "         1.1657e-15, 5.5511e-16, 7.7716e-16, 2.2204e-15, 2.6645e-15, 1.7764e-15,\n",
      "         1.9984e-15, 2.9976e-15, 5.5511e-16, 8.3267e-16, 2.2204e-16, 1.3323e-15,\n",
      "         3.3307e-16, 1.7764e-15, 9.9920e-16, 3.8858e-15, 2.6645e-15, 2.2204e-15,\n",
      "         2.2204e-15, 8.8818e-16, 1.1102e-15, 4.4409e-16, 1.3323e-15, 2.2204e-15,\n",
      "         1.3461e-15, 8.8818e-16, 6.2172e-15, 3.0531e-16, 1.7764e-15, 1.1102e-15,\n",
      "         2.2204e-15, 1.5543e-15, 1.3323e-15, 1.7764e-15, 1.6653e-16, 9.9920e-16,\n",
      "         1.2768e-15, 9.9920e-16, 1.3323e-15, 4.1078e-15, 1.9984e-15, 1.1102e-15,\n",
      "         1.3323e-15, 2.2204e-15, 2.8866e-15, 1.3323e-15, 2.2204e-15, 3.1086e-15,\n",
      "         2.2204e-15, 1.6653e-15, 6.6613e-16, 3.1641e-15, 1.2768e-15, 3.9968e-15,\n",
      "         1.9984e-15, 1.9984e-15, 2.3349e-15, 2.5813e-15, 1.2212e-15, 1.7764e-15,\n",
      "         2.5535e-15, 2.1649e-15, 1.7764e-15, 3.1086e-15, 1.5543e-15, 2.6645e-15,\n",
      "         2.1094e-15, 1.7764e-15, 3.7748e-15, 2.6645e-15, 2.3592e-15, 1.9706e-15,\n",
      "         2.6645e-15, 1.7764e-15, 1.9151e-15, 1.5543e-15, 1.8874e-15, 4.4409e-15,\n",
      "         3.1086e-15, 2.8866e-15, 1.7764e-15, 1.3323e-15, 1.6931e-15, 1.7764e-15,\n",
      "         2.4425e-15, 2.2204e-15, 2.4425e-15, 1.7764e-15, 1.1102e-15, 1.8874e-15,\n",
      "         1.7347e-15, 1.1102e-15, 4.8850e-15, 1.5543e-15, 2.3870e-15, 2.2204e-15,\n",
      "         2.2204e-15, 3.5527e-15, 2.6645e-15, 2.2204e-15, 1.5543e-15, 1.9429e-15,\n",
      "         3.5527e-15, 2.6645e-15, 2.2204e-15, 1.9984e-15, 1.1102e-15, 3.9968e-15,\n",
      "         3.1086e-15, 1.8596e-15, 2.6645e-15, 3.1086e-15, 2.2204e-15, 2.4425e-15,\n",
      "         2.8866e-15, 1.8319e-15, 4.2188e-15, 1.6653e-15, 1.3323e-15, 2.6645e-15,\n",
      "         2.2204e-15, 2.6645e-15, 2.2204e-15, 1.9984e-15, 1.4433e-15, 2.8866e-15,\n",
      "         2.3315e-15, 1.7764e-15, 2.3037e-15, 3.6082e-15, 3.6637e-15, 3.9968e-15,\n",
      "         2.2204e-15, 3.1086e-15, 2.4425e-15, 2.6645e-15, 2.4425e-15, 3.9968e-15,\n",
      "         1.9984e-15, 2.6645e-15, 2.1094e-15, 2.2204e-15, 1.2212e-15, 2.1719e-15,\n",
      "         1.7764e-15, 4.8850e-15, 3.5527e-15, 2.1094e-15, 2.5535e-15, 1.8319e-15,\n",
      "         1.6653e-15, 2.3315e-15, 2.6645e-15, 1.3323e-15, 2.9698e-15, 1.1102e-15,\n",
      "         2.2204e-15, 2.2204e-15, 1.1657e-15, 1.2525e-15, 3.7748e-15, 1.9984e-15,\n",
      "         2.2204e-15, 3.5527e-15, 1.7764e-15, 1.6653e-15, 2.2204e-15, 5.9952e-15,\n",
      "         2.2204e-15, 1.7764e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
      "        393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
      "        421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
      "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
      "        463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "        477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
      "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
      "        393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
      "        421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "        435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
      "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
      "        463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "        477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
      "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "        505, 506, 507, 508, 509, 510, 511])  (len = 511)\n",
      "passing Cout = tensor([38])  (len = 1)\n",
      "\n",
      "Executing module 225: layer4.0.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "Finished execution of layer 225\n",
      "Max diff:\n",
      " tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.7764e-15, 5.5511e-16, 1.6653e-16, 4.4409e-16, 4.4409e-16, 1.5543e-15,\n",
      "         2.2204e-16, 5.5511e-16, 3.3307e-16, 1.1102e-16, 1.1102e-16, 2.2204e-16,\n",
      "         3.3307e-16, 5.5511e-16, 2.2204e-16, 2.0053e-15, 5.5511e-17, 6.1062e-16,\n",
      "         4.4409e-16, 6.6613e-16, 1.1102e-16, 1.9984e-15, 1.3323e-15, 3.5527e-15,\n",
      "         2.2204e-15, 3.3307e-16, 1.9984e-15, 1.3878e-16, 1.3323e-15, 5.5511e-16,\n",
      "         2.2204e-15, 1.4433e-15, 1.0825e-15, 4.4409e-16, 2.2204e-16, 3.5527e-15,\n",
      "         1.3323e-15, 1.1102e-16, 1.1102e-15, 1.5543e-15, 2.2204e-15, 1.9984e-15,\n",
      "         1.1102e-16, 6.6613e-16, 6.6613e-16, 6.6613e-16, 8.8818e-16, 3.5527e-15,\n",
      "         7.2164e-16, 4.4409e-16, 8.8818e-16, 1.7764e-15, 2.7756e-15, 3.2196e-15,\n",
      "         1.9984e-15, 4.4409e-15, 6.6613e-16, 1.1102e-16, 1.3323e-15, 2.2204e-16,\n",
      "         3.3307e-16, 2.2204e-15, 3.3307e-16, 4.4409e-16, 3.3307e-16, 6.9389e-17,\n",
      "         5.5511e-16, 1.3323e-15, 5.5511e-17, 1.9429e-16, 2.6645e-15, 3.3307e-16,\n",
      "         2.2204e-15, 1.3878e-16, 1.1102e-16, 2.2204e-15, 8.3267e-17, 1.3323e-15,\n",
      "         2.2204e-15, 2.7756e-16, 1.1102e-15, 3.8858e-16, 1.6653e-16, 5.5511e-16,\n",
      "         2.2204e-15, 2.2204e-16, 2.2204e-16, 1.6653e-16, 1.1102e-15, 4.4409e-16,\n",
      "         3.5527e-15, 3.3307e-16, 1.3878e-15, 6.6613e-16, 2.6645e-15, 3.3307e-16,\n",
      "         8.3267e-17, 2.2204e-16, 3.5527e-15, 8.8818e-16, 1.3323e-15, 2.2204e-16,\n",
      "         1.7764e-15, 2.2204e-16, 1.7764e-15, 8.8818e-16, 8.8818e-16, 1.6653e-16,\n",
      "         3.5527e-15, 1.1102e-16, 8.3267e-17, 1.6653e-16, 2.2204e-16, 1.1102e-16,\n",
      "         3.3307e-16, 4.4409e-16, 2.8866e-15, 1.1102e-16, 2.6645e-15, 5.5511e-17,\n",
      "         1.2768e-15, 1.6653e-16, 4.4409e-16, 8.8818e-16, 1.6653e-16, 1.3878e-15,\n",
      "         3.3307e-16, 1.6653e-16, 1.2434e-14, 1.4211e-14, 5.7732e-15, 7.9936e-15,\n",
      "         1.2434e-14, 1.0658e-14, 2.1316e-14, 8.8818e-15, 1.5987e-14, 7.3275e-15,\n",
      "         2.1316e-14, 8.6597e-15, 1.6875e-14, 7.9936e-15, 2.6645e-14, 8.8818e-15,\n",
      "         7.7161e-15, 7.9936e-15, 5.7732e-15, 1.2434e-14, 1.9540e-14, 5.3291e-15,\n",
      "         5.3291e-15, 6.2172e-15, 4.5519e-15, 7.9936e-15, 1.0658e-14, 1.9540e-14,\n",
      "         8.8818e-15, 1.9540e-14, 1.7764e-15, 1.0658e-14, 8.4377e-15, 7.9936e-15,\n",
      "         7.1054e-15, 1.0658e-14, 3.9968e-15, 2.1316e-14, 9.3259e-15, 6.6613e-15,\n",
      "         2.1316e-14, 7.9936e-15, 7.1054e-15, 4.8850e-15, 1.2434e-14, 1.5987e-14,\n",
      "         7.9936e-15, 7.9936e-15, 1.7764e-14, 7.1054e-15, 6.2172e-15, 7.5495e-15,\n",
      "         1.7764e-14, 1.0658e-14, 8.8818e-15, 8.8818e-15, 8.8818e-15, 5.3291e-15,\n",
      "         1.2434e-14, 1.0658e-14, 7.9936e-15, 6.2172e-15, 6.6613e-15, 4.4409e-15,\n",
      "         5.7732e-15, 7.1054e-15, 8.8818e-15, 3.5527e-15, 1.4211e-14, 7.1054e-15,\n",
      "         5.3291e-15, 9.5479e-15, 1.2434e-14, 5.3291e-15, 2.1316e-14, 6.2172e-15,\n",
      "         1.5987e-14, 1.2434e-14, 7.9936e-15, 5.3291e-15, 8.8818e-15, 5.3291e-15,\n",
      "         7.1054e-15, 1.1546e-14, 4.4409e-15, 6.2172e-15, 1.0658e-14, 7.5495e-15,\n",
      "         9.7700e-15, 4.4409e-15, 3.1086e-15, 7.9936e-15, 7.1054e-15, 5.3291e-15,\n",
      "         9.7700e-15, 8.8818e-15, 5.3291e-15, 1.0214e-14, 5.3291e-15, 1.4211e-14,\n",
      "         1.2434e-14, 9.7700e-15, 3.5527e-15, 1.0658e-14, 6.6613e-15, 9.3259e-15,\n",
      "         7.1054e-15, 4.4409e-15, 3.5527e-15, 7.1054e-15, 2.2204e-15, 1.2434e-14,\n",
      "         1.0658e-14, 1.7764e-14, 7.5495e-15, 8.8818e-15, 5.3291e-15, 9.3259e-15,\n",
      "         1.2434e-14, 1.2434e-14, 4.4409e-15, 1.4211e-14, 1.0658e-14, 9.7700e-15,\n",
      "         7.1054e-15, 7.9936e-15, 5.3291e-15, 9.7700e-15, 2.8422e-14, 1.4211e-14,\n",
      "         7.5495e-15, 7.6050e-15, 1.2434e-14, 9.7700e-15, 1.0325e-14, 3.1086e-15,\n",
      "         7.1054e-15, 7.1054e-15, 7.9936e-15, 1.0658e-14, 7.9936e-15, 8.8818e-15,\n",
      "         1.8652e-14, 8.8818e-15, 1.1546e-14, 6.6613e-15, 7.9936e-15, 6.2172e-15,\n",
      "         6.6613e-15, 3.5527e-15, 7.1054e-15, 1.0658e-14, 8.4377e-15, 5.3291e-15,\n",
      "         2.2204e-15, 7.1054e-15, 1.4211e-14, 1.3323e-15, 2.1316e-14, 1.0658e-14,\n",
      "         8.8818e-15, 8.8818e-15, 1.0658e-14, 8.8818e-15, 1.9540e-14, 1.4211e-14,\n",
      "         1.1546e-14, 1.0658e-14, 6.2172e-15, 6.2172e-15, 1.1102e-14, 1.0658e-14,\n",
      "         8.8818e-15, 1.4211e-14, 7.1054e-15, 1.0658e-14, 9.7700e-15, 1.2434e-14,\n",
      "         1.2434e-14, 1.5987e-14, 3.4417e-15, 8.8818e-16, 6.2172e-15, 7.1054e-15,\n",
      "         3.5527e-15, 6.2172e-15, 7.1054e-15, 1.0658e-14, 3.5527e-15, 6.2172e-15,\n",
      "         1.0658e-14, 1.2434e-14, 8.8818e-15, 5.3291e-15, 7.1054e-15, 4.4409e-15,\n",
      "         6.2172e-15, 1.4211e-14, 7.9936e-15, 7.1054e-15, 1.7764e-15, 1.3323e-14,\n",
      "         9.3259e-15, 3.1086e-15, 5.3291e-15, 7.1054e-15, 1.0658e-14, 8.8818e-15,\n",
      "         6.6613e-15, 5.3291e-15, 7.1054e-15, 1.0658e-14, 8.8818e-15, 1.1102e-14,\n",
      "         3.5527e-15, 4.4409e-15, 3.5527e-15, 1.0658e-14, 8.8818e-15, 5.3291e-15,\n",
      "         5.8842e-15, 1.2434e-14, 1.2434e-14, 1.4211e-14, 7.9936e-15, 1.0658e-14,\n",
      "         4.4409e-16, 7.1054e-15, 8.8818e-15, 7.9936e-15, 9.7700e-15, 7.1054e-15,\n",
      "         1.0658e-14, 6.2172e-15, 1.0658e-14, 4.4409e-15, 4.4409e-15, 1.7764e-14,\n",
      "         1.9540e-14, 1.7764e-14, 8.8818e-15, 2.6645e-15, 5.7732e-15, 8.8818e-15,\n",
      "         8.8818e-15, 6.2172e-15, 8.4377e-15, 1.0658e-14, 1.4211e-14, 5.3291e-15,\n",
      "         1.0658e-14, 7.9936e-15, 1.4211e-14, 1.4211e-14, 9.7700e-15, 2.6645e-15,\n",
      "         1.1546e-14, 6.2172e-15, 1.0658e-14, 9.7700e-15, 7.1054e-15, 1.0658e-14,\n",
      "         1.0214e-14, 8.8818e-15, 7.5495e-15, 6.6613e-15, 5.7732e-15, 1.0658e-14,\n",
      "         4.4409e-15, 1.1546e-14, 9.7700e-15, 7.5495e-15, 4.8850e-15, 1.1102e-14,\n",
      "         7.1054e-15, 7.9936e-15, 7.1054e-15, 1.5987e-14, 1.0658e-14, 4.4409e-15,\n",
      "         4.4409e-15, 7.1054e-15, 7.5495e-15, 6.2172e-15, 5.3291e-15, 3.5527e-15,\n",
      "         1.2434e-14, 1.1102e-14, 3.8858e-15, 7.2164e-15, 7.2164e-15, 8.8818e-15,\n",
      "         1.0658e-14, 7.1054e-15, 6.8834e-15, 5.3291e-15, 1.0658e-14, 7.1054e-15,\n",
      "         7.1054e-15, 7.1054e-15, 7.9936e-15, 7.1054e-15, 8.8818e-15, 6.2172e-15,\n",
      "         6.6613e-15, 1.1546e-14, 9.3259e-15, 9.7700e-15, 6.6613e-15, 1.0658e-14,\n",
      "         5.7732e-15, 9.7700e-15, 1.7764e-14, 1.2434e-14, 1.4211e-14, 9.2149e-15,\n",
      "         8.4377e-15, 1.0658e-14, 1.3323e-14, 1.0658e-14, 5.2180e-15, 8.4377e-15,\n",
      "         7.9936e-15, 5.7732e-15, 1.5987e-14, 8.4377e-15, 7.1054e-15, 5.3291e-15,\n",
      "         6.1062e-15, 7.1054e-15, 9.3259e-15, 1.0658e-14, 7.1054e-15, 7.1054e-15,\n",
      "         7.1054e-15, 8.8818e-15, 3.9968e-15, 7.1054e-15, 5.3291e-15, 1.2434e-14,\n",
      "         1.4211e-14, 8.8818e-15, 1.0214e-14, 1.0658e-14, 8.4377e-15, 1.5987e-14,\n",
      "         6.7724e-15, 7.1054e-15, 7.1054e-15, 1.4211e-14, 1.0658e-14, 7.1054e-15,\n",
      "         8.8818e-15, 1.0658e-14, 4.4409e-15, 7.9936e-15, 7.1054e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.1546e-14, 7.7716e-15, 6.6613e-15, 1.7764e-14, 6.2172e-15,\n",
      "         9.3259e-15, 4.4409e-15, 7.1054e-15, 9.7700e-15, 7.9936e-15, 4.6629e-15,\n",
      "         6.2172e-15, 1.2434e-14, 6.2172e-15, 5.3291e-15, 7.9936e-15, 5.3291e-15,\n",
      "         8.8818e-15, 8.8818e-15, 1.4211e-14, 5.3291e-15, 9.5479e-15, 1.3323e-14,\n",
      "         7.1054e-15, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 226: layer4.0.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 226\n",
      "Max diff:\n",
      " tensor([1.9540e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9984e-15, 0.0000e+00, 4.7184e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9984e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-15, 3.6082e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7716e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16, 3.2196e-15,\n",
      "         1.9984e-15, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1094e-15, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00, 0.0000e+00, 5.5511e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00, 8.3961e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7764e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.8866e-15, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         1.0547e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3878e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6645e-15, 7.9936e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-15, 0.0000e+00, 7.3275e-15,\n",
      "         0.0000e+00, 8.6597e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3315e-15,\n",
      "         4.9960e-15, 0.0000e+00, 4.8850e-15, 0.0000e+00, 0.0000e+00, 5.3291e-15,\n",
      "         0.0000e+00, 6.2172e-15, 3.9135e-15, 1.3323e-15, 6.6613e-15, 0.0000e+00,\n",
      "         6.8834e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 6.2172e-15,\n",
      "         5.2180e-15, 0.0000e+00, 2.1094e-15, 0.0000e+00, 7.5495e-15, 6.6613e-15,\n",
      "         0.0000e+00, 4.4409e-15, 0.0000e+00, 1.5543e-15, 0.0000e+00, 0.0000e+00,\n",
      "         6.2172e-15, 4.8850e-15, 0.0000e+00, 7.1054e-15, 3.5527e-15, 6.6613e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15,\n",
      "         0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00, 5.5511e-15, 2.9976e-15,\n",
      "         5.7732e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.5479e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00, 6.2172e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.2188e-15, 2.4425e-15, 5.1625e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 1.1102e-15, 7.9936e-15, 0.0000e+00, 3.5527e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4433e-15, 3.1086e-15, 0.0000e+00,\n",
      "         0.0000e+00, 9.7700e-15, 3.5527e-15, 0.0000e+00, 4.5519e-15, 9.3259e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.6629e-15, 5.3291e-15, 8.8818e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.2196e-15, 0.0000e+00, 0.0000e+00, 3.4417e-15,\n",
      "         0.0000e+00, 0.0000e+00, 2.8866e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.5495e-15, 7.6050e-15, 0.0000e+00, 9.7700e-15, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9936e-15, 1.4433e-15,\n",
      "         7.1054e-15, 0.0000e+00, 0.0000e+00, 6.6613e-15, 2.2204e-15, 0.0000e+00,\n",
      "         6.2172e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4377e-15, 3.5527e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.7732e-15, 0.0000e+00, 0.0000e+00, 1.7764e-15, 0.0000e+00, 0.0000e+00,\n",
      "         2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4980e-15, 0.0000e+00,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9952e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.5987e-14, 2.6645e-15, 0.0000e+00, 6.2172e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2172e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-15,\n",
      "         1.9984e-15, 3.9968e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-14,\n",
      "         7.0499e-15, 0.0000e+00, 3.9968e-15, 7.1054e-15, 0.0000e+00, 3.5527e-15,\n",
      "         5.7732e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-14,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         3.7748e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7700e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.9540e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7732e-15, 0.0000e+00,\n",
      "         0.0000e+00, 6.2172e-15, 7.7716e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.7724e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1546e-14, 0.0000e+00, 1.0658e-14, 4.7740e-15, 6.2172e-15, 0.0000e+00,\n",
      "         3.5527e-15, 0.0000e+00, 4.8850e-15, 6.6613e-15, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-15, 1.4433e-15, 5.4956e-15, 7.5495e-15, 3.1086e-15, 0.0000e+00,\n",
      "         2.6645e-15, 3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-15,\n",
      "         0.0000e+00, 7.1054e-15, 7.5495e-15, 3.9968e-15, 3.1086e-15, 0.0000e+00,\n",
      "         0.0000e+00, 7.9936e-15, 8.8818e-16, 5.6621e-15, 7.2164e-15, 8.8818e-15,\n",
      "         1.0658e-14, 0.0000e+00, 6.8834e-15, 5.3291e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.9936e-15, 0.0000e+00, 8.8818e-15, 2.8866e-15,\n",
      "         6.6613e-15, 4.5519e-15, 1.9984e-15, 5.3291e-15, 1.3323e-15, 4.1078e-15,\n",
      "         5.7732e-15, 9.7700e-15, 0.0000e+00, 7.1054e-15, 0.0000e+00, 9.2149e-15,\n",
      "         0.0000e+00, 3.7748e-15, 0.0000e+00, 4.8850e-15, 5.2180e-15, 5.3291e-15,\n",
      "         3.3307e-15, 3.9968e-15, 0.0000e+00, 5.8842e-15, 7.1054e-15, 0.0000e+00,\n",
      "         4.2188e-15, 7.1054e-15, 3.5527e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-15, 3.9968e-15, 6.2172e-15, 5.3291e-15, 1.2434e-14,\n",
      "         0.0000e+00, 4.8850e-15, 5.1070e-15, 4.8850e-15, 8.4377e-15, 0.0000e+00,\n",
      "         1.2212e-15, 6.4393e-15, 7.1054e-15, 0.0000e+00, 4.8850e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.0658e-14, 2.8866e-15, 6.2172e-15, 0.0000e+00, 3.5527e-15,\n",
      "         7.1054e-15, 7.1054e-15, 0.0000e+00, 1.5543e-15, 0.0000e+00, 0.0000e+00,\n",
      "         6.6613e-16, 0.0000e+00, 7.1054e-15, 9.7700e-15, 3.5527e-15, 3.9968e-15,\n",
      "         5.7732e-15, 0.0000e+00, 0.0000e+00, 2.3870e-15, 7.9936e-15, 0.0000e+00,\n",
      "         0.0000e+00, 3.5527e-15, 0.0000e+00, 5.3291e-15, 6.2172e-15, 1.1546e-14,\n",
      "         7.1054e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([  5,  15,  17,  26,  31,  32,  40,  52,  53,  54,  55,  66,  70,  72,\n",
      "         75,  80,  83,  88,  92,  94, 102, 116, 118, 120, 125, 130, 131, 135,\n",
      "        137, 139, 143, 144, 146, 149, 151, 152, 153, 154, 156, 160, 161, 162,\n",
      "        164, 166, 167, 169, 171, 174, 175, 177, 178, 179, 185, 188, 190, 191,\n",
      "        192, 199, 201, 203, 211, 212, 213, 217, 218, 219, 221, 225, 226, 229,\n",
      "        230, 232, 233, 241, 242, 243, 248, 251, 254, 258, 259, 261, 262, 268,\n",
      "        269, 270, 273, 274, 276, 280, 281, 288, 291, 294, 298, 300, 304, 307,\n",
      "        308, 310, 317, 323, 324, 325, 329, 330, 332, 333, 335, 336, 341, 346,\n",
      "        348, 358, 366, 370, 373, 374, 379, 384, 386, 387, 388, 390, 392, 393,\n",
      "        396, 397, 398, 399, 400, 402, 403, 407, 409, 410, 411, 412, 415, 416,\n",
      "        417, 418, 419, 420, 422, 423, 428, 430, 431, 432, 433, 434, 435, 436,\n",
      "        437, 438, 439, 441, 443, 445, 447, 448, 449, 450, 451, 453, 454, 456,\n",
      "        457, 458, 463, 464, 465, 466, 467, 469, 470, 471, 472, 474, 475, 476,\n",
      "        478, 481, 482, 483, 485, 486, 487, 489, 492, 494, 495, 496, 497, 498,\n",
      "        501, 502, 505, 507, 508, 509, 510])\n",
      "\n",
      "failing Cout = tensor([  5,  15,  17,  26,  31,  32,  40,  52,  53,  54,  55,  66,  70,  72,\n",
      "         75,  80,  83,  88,  92,  94, 102, 116, 118, 120, 125, 130, 131, 135,\n",
      "        137, 139, 143, 144, 146, 149, 151, 152, 153, 154, 156, 160, 161, 162,\n",
      "        164, 166, 167, 169, 171, 174, 175, 177, 178, 179, 185, 188, 190, 191,\n",
      "        192, 199, 201, 203, 211, 212, 213, 217, 218, 219, 221, 225, 226, 229,\n",
      "        230, 232, 233, 241, 242, 243, 248, 251, 254, 258, 259, 261, 262, 268,\n",
      "        269, 270, 273, 274, 276, 280, 281, 288, 291, 294, 298, 300, 304, 307,\n",
      "        308, 310, 317, 323, 324, 325, 329, 330, 332, 333, 335, 336, 341, 346,\n",
      "        348, 358, 366, 370, 373, 374, 379, 384, 386, 387, 388, 390, 392, 393,\n",
      "        396, 397, 398, 399, 400, 402, 403, 407, 409, 410, 411, 412, 415, 416,\n",
      "        417, 418, 419, 420, 422, 423, 428, 430, 431, 432, 433, 434, 435, 436,\n",
      "        437, 438, 439, 441, 443, 445, 447, 448, 449, 450, 451, 453, 454, 456,\n",
      "        457, 458, 463, 464, 465, 466, 467, 469, 470, 471, 472, 474, 475, 476,\n",
      "        478, 481, 482, 483, 485, 486, 487, 489, 492, 494, 495, 496, 497, 498,\n",
      "        501, 502, 505, 507, 508, 509, 510])  (len = 203)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 227: layer4.1.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 227\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 158,\n",
      "        159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173,\n",
      "        174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "        189, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 236,\n",
      "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "        251, 252, 253, 254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 260, 261, 263, 264, 266, 267, 268, 270, 271, 272, 274, 275,\n",
      "        276, 277, 278, 280, 281, 282, 283, 284, 285, 286, 287, 289, 291, 292,\n",
      "        293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        309, 310, 311, 312, 313, 315, 316, 317, 318, 319, 320, 323, 324, 325,\n",
      "        326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341,\n",
      "        342, 343, 345, 346, 347, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
      "        359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373,\n",
      "        374, 375, 376, 377, 379, 380, 381, 382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 413,\n",
      "        414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 428, 429,\n",
      "        430, 431, 432, 433, 434, 435, 436, 437, 438, 442, 443, 444, 445, 446,\n",
      "        447, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463,\n",
      "        465, 466, 467, 468, 469, 470, 471, 472, 473, 475, 476, 477, 478, 480,\n",
      "        482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496,\n",
      "        498, 499, 500, 501, 502, 504, 506, 508, 509, 510, 511]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 227\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   7,   9,  10,  11,  14,  15,  17,  18,\n",
      "         19,  20,  21,  22,  24,  26,  27,  28,  29,  30,  31,  32,  35,  36,\n",
      "         37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n",
      "         51,  52,  53,  54,  55,  57,  59,  60,  61,  63,  64,  65,  66,  67,\n",
      "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "         82,  84,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,  98,\n",
      "         99, 100, 101, 103, 104, 109, 110, 112, 115, 116, 118, 119, 121, 122,\n",
      "        123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 227\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   2,   4,   5,   7,   9,  10,  11,  12,  13,  14,  16,  17,  19,\n",
      "         20,  21,  22,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,\n",
      "         35,  37,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,\n",
      "         67,  68,  70,  71,  72,  74,  75,  76,  77,  78,  79,  80,  81,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,  98,  99,\n",
      "        100, 101, 102, 103, 104, 105, 107, 108, 109, 113, 114, 115, 116, 117,\n",
      "        118, 119, 120, 122, 123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 227\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 227\n",
      "Max diff:\n",
      " tensor([2.7001e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-15, 2.6645e-15, 5.3291e-15, 1.3323e-14, 7.1054e-15, 1.5099e-14,\n",
      "         1.4211e-14, 1.3323e-15, 5.3291e-15, 1.4211e-14, 7.1054e-15, 9.9920e-15,\n",
      "         4.4409e-15, 3.5527e-15, 1.2434e-14, 1.4211e-14, 6.6613e-15, 1.1546e-14,\n",
      "         8.8818e-15, 1.9540e-14, 8.8818e-15, 3.7748e-15, 1.5543e-15, 3.7748e-15,\n",
      "         6.2172e-15, 7.1054e-15, 7.1054e-15, 5.7732e-15, 8.8818e-15, 7.1054e-15,\n",
      "         4.8850e-15, 8.8818e-15, 2.4869e-14, 1.7764e-15, 1.0658e-14, 1.4211e-14,\n",
      "         4.4409e-15, 8.8818e-15, 3.1086e-15, 1.1546e-14, 6.2172e-15, 1.4211e-14,\n",
      "         8.8818e-15, 2.8422e-14, 1.0658e-14, 5.3291e-15, 1.1102e-15, 7.1054e-15,\n",
      "         7.1054e-15, 7.9936e-15, 1.4211e-14, 6.2172e-15, 7.5495e-15, 7.1054e-15,\n",
      "         7.1054e-15, 5.3291e-15, 7.9936e-15, 7.1054e-15, 1.4211e-14, 5.3291e-15,\n",
      "         1.6875e-14, 8.0491e-15, 1.1546e-14, 4.8850e-15, 1.5987e-14, 6.9944e-15,\n",
      "         1.9540e-14, 8.8818e-15, 7.1054e-15, 1.1546e-14, 2.4869e-14, 1.1824e-14,\n",
      "         1.0658e-14, 4.4409e-15, 7.1054e-15, 6.2172e-15, 1.0658e-14, 1.7764e-14,\n",
      "         1.4211e-14, 8.8818e-15, 1.3767e-14, 7.1054e-15, 6.8834e-15, 3.9968e-15,\n",
      "         1.2434e-14, 3.5527e-15, 7.7716e-15, 2.8422e-14, 1.4211e-14, 1.4211e-14,\n",
      "         1.4655e-14, 2.2204e-15, 1.0880e-14, 1.4211e-14, 4.8850e-15, 1.0658e-14,\n",
      "         6.2172e-15, 7.1054e-15, 4.8850e-15, 2.1316e-14, 1.1546e-14, 5.3291e-15,\n",
      "         1.7764e-15, 1.0658e-14, 8.8818e-15, 1.3323e-14, 1.1102e-15, 9.7700e-15,\n",
      "         1.4211e-14, 1.4211e-14, 5.3291e-15, 5.1070e-15, 1.1546e-14, 9.7700e-15,\n",
      "         1.0214e-14, 1.0658e-14, 8.8818e-15, 1.3323e-15, 7.9936e-15, 8.8818e-15,\n",
      "         5.3291e-15, 1.7764e-15, 1.0658e-14, 1.0658e-14, 1.4211e-14, 4.4409e-15,\n",
      "         8.8818e-15, 8.6597e-15, 3.5527e-14, 9.9476e-14, 1.4211e-13, 3.5527e-14,\n",
      "         3.5527e-14, 1.2790e-13, 8.5265e-14, 8.5265e-14, 2.4869e-14, 3.1974e-14,\n",
      "         3.1974e-14, 2.8422e-14, 7.1054e-14, 2.8422e-14, 2.1316e-14, 2.3093e-14,\n",
      "         8.5265e-14, 3.5527e-14, 5.6843e-14, 3.5527e-14, 1.0658e-14, 2.8422e-14,\n",
      "         1.2790e-13, 4.2633e-14, 2.8422e-14, 2.7534e-14, 2.1316e-14, 1.7764e-14,\n",
      "         1.1369e-13, 6.3949e-14, 2.4869e-14, 4.2633e-14, 5.6843e-14, 6.3949e-14,\n",
      "         2.8422e-14, 2.4869e-14, 4.2633e-14, 9.9476e-14, 7.1054e-14, 3.1308e-14,\n",
      "         1.4211e-14, 6.7502e-14, 3.8025e-14, 5.6843e-14, 8.5265e-14, 4.2633e-14,\n",
      "         3.1974e-14, 4.9738e-14, 8.5265e-14, 7.1054e-14, 2.4869e-14, 4.2633e-14,\n",
      "         4.6185e-14, 4.2633e-14, 7.1054e-14, 1.9540e-14, 8.5265e-14, 5.6843e-14,\n",
      "         3.3751e-14, 3.5527e-14, 3.1974e-14, 1.1369e-13, 5.6843e-14, 1.9096e-14,\n",
      "         2.8422e-14, 3.5527e-14, 4.9738e-14, 2.1316e-14, 4.2633e-14, 1.2790e-13,\n",
      "         2.8422e-14, 4.9738e-14, 8.5265e-14, 4.2633e-14, 1.2434e-14, 2.8422e-14,\n",
      "         7.1054e-14, 1.7764e-14, 7.1054e-14, 5.6843e-14, 1.7053e-13, 8.5265e-14,\n",
      "         5.6843e-14, 4.9738e-14, 1.9540e-14, 4.2633e-14, 5.6843e-14, 5.6843e-14,\n",
      "         5.6843e-14, 8.5265e-14, 8.5265e-14, 4.9738e-14, 6.3949e-14, 7.1054e-14,\n",
      "         2.1316e-14, 3.5527e-14, 8.8818e-15, 4.9738e-14, 7.1054e-14, 4.2633e-14,\n",
      "         7.1054e-14, 6.3949e-14, 8.8818e-15, 8.5265e-14, 4.2633e-14, 8.5265e-14,\n",
      "         3.9080e-14, 6.3949e-14, 6.3949e-14, 3.5527e-14, 6.3949e-14, 7.8160e-14,\n",
      "         6.3949e-14, 1.7053e-13, 6.3949e-14, 3.9080e-14, 7.1054e-14, 2.1316e-14,\n",
      "         7.1054e-14, 7.1054e-14, 2.8422e-14, 2.3093e-14, 5.6843e-14, 3.5527e-14,\n",
      "         9.9476e-14, 7.1054e-14, 4.2633e-14, 2.1316e-14, 4.2633e-14, 1.4211e-13,\n",
      "         6.3949e-14, 4.9738e-14, 3.5527e-14, 8.5265e-14, 8.5265e-14, 5.6843e-14,\n",
      "         8.5265e-14, 8.5265e-14, 2.6645e-14, 1.5632e-13, 8.5265e-14, 5.6843e-14,\n",
      "         3.3751e-14, 4.2633e-14, 6.3949e-14, 3.5527e-14, 2.8422e-14, 4.2633e-14,\n",
      "         7.1054e-14, 9.9476e-14, 2.1316e-14, 5.6843e-14, 7.1054e-14, 3.9080e-14,\n",
      "         6.3949e-14, 5.6843e-14, 5.6843e-14, 8.5265e-14, 4.9738e-14, 1.2790e-13,\n",
      "         5.6843e-14, 7.1054e-14, 2.8422e-14, 1.7764e-14, 4.9738e-14, 9.9476e-14,\n",
      "         3.5527e-14, 4.9738e-14, 2.8422e-14, 4.9738e-14, 5.6843e-14, 3.2863e-14,\n",
      "         1.1369e-13, 1.5987e-14, 5.6843e-14, 7.1054e-14, 4.2633e-14, 9.9476e-14,\n",
      "         1.2790e-13, 7.1054e-14, 6.3949e-14, 8.5265e-14, 9.9476e-14, 7.1054e-14,\n",
      "         5.6843e-14, 5.6843e-14, 5.6843e-14, 2.2649e-14, 1.2790e-13, 4.2633e-14,\n",
      "         3.5527e-14, 3.1974e-14, 8.5265e-14, 1.5632e-13, 4.9738e-14, 2.8422e-14,\n",
      "         3.1974e-14, 9.9476e-14, 7.1054e-14, 4.2633e-14, 2.4869e-14, 3.1974e-14,\n",
      "         8.5265e-14, 8.5265e-14, 4.2633e-14, 4.2633e-14, 1.1369e-13, 7.1054e-14,\n",
      "         8.5265e-14, 7.1054e-14, 3.5527e-14, 4.2633e-14, 7.1054e-14, 4.2633e-14,\n",
      "         4.2633e-14, 7.1054e-14, 2.8422e-14, 5.6843e-14, 8.5265e-14, 8.5265e-14,\n",
      "         3.2863e-14, 4.9738e-14, 6.3949e-14, 3.5527e-14, 5.6843e-14, 3.5527e-14,\n",
      "         8.8818e-15, 4.9738e-14, 2.4869e-14, 1.1369e-13, 7.8160e-14, 3.5527e-14,\n",
      "         6.3949e-14, 1.2790e-13, 1.0658e-13, 2.1316e-14, 2.4869e-14, 1.0658e-14,\n",
      "         4.2633e-14, 1.0658e-13, 3.1974e-14, 5.6843e-14, 5.6843e-14, 4.9738e-14,\n",
      "         7.8160e-14, 6.3949e-14, 1.4211e-13, 2.7001e-13, 4.2633e-14, 1.4211e-14,\n",
      "         2.8422e-14, 4.2633e-14, 5.6843e-14, 4.9738e-14, 3.5527e-14, 7.1054e-14,\n",
      "         4.2633e-14, 2.8422e-14, 3.5527e-14, 3.5527e-14, 7.1054e-14, 6.0840e-14,\n",
      "         7.1054e-14, 6.3949e-14, 8.5265e-14, 4.6185e-14, 7.1054e-14, 7.1054e-14,\n",
      "         7.1054e-14, 6.1284e-14, 5.6843e-14, 7.8160e-14, 4.6185e-14, 1.5632e-13,\n",
      "         7.1054e-14, 5.6843e-14, 4.9738e-14, 5.6843e-14, 9.9476e-14, 5.6843e-14,\n",
      "         2.1316e-14, 6.3949e-14, 4.9738e-14, 8.5265e-14, 9.9476e-14, 3.5527e-14,\n",
      "         8.5265e-14, 3.5527e-14, 1.7053e-13, 4.6185e-14, 5.6843e-14, 5.8620e-14,\n",
      "         5.6843e-14, 4.2633e-14, 6.3949e-14, 8.7041e-14, 2.8422e-14, 6.3949e-14,\n",
      "         4.2633e-14, 4.9738e-14, 2.8422e-14, 7.1054e-14, 4.9738e-14, 2.8422e-14,\n",
      "         8.5265e-14, 4.9738e-14, 4.6185e-14, 2.5757e-14, 2.7534e-14, 7.1054e-14,\n",
      "         1.7053e-13, 7.1054e-14, 4.2633e-14, 3.9080e-14, 4.2633e-14, 3.9968e-14,\n",
      "         3.5527e-14, 1.7053e-13, 6.3949e-14, 5.6843e-14, 4.2633e-14, 3.1974e-14,\n",
      "         8.5265e-14, 3.5527e-14, 8.5265e-14, 9.2371e-14, 9.2371e-14, 4.2633e-14,\n",
      "         3.5527e-14, 7.1054e-14, 4.0856e-14, 3.1974e-14, 7.1054e-14, 4.2633e-14,\n",
      "         4.2633e-14, 5.6843e-14, 4.9738e-14, 3.1974e-14, 5.6843e-14, 1.0658e-13,\n",
      "         9.9476e-14, 3.0198e-14, 3.5527e-14, 4.2633e-14, 4.9738e-14, 1.5632e-13,\n",
      "         3.5527e-14, 3.5527e-14, 3.5527e-14, 5.6843e-14, 2.4869e-14, 4.6185e-14,\n",
      "         4.9738e-14, 4.2633e-14, 3.5527e-14, 8.5265e-14, 7.1054e-14, 3.2974e-14,\n",
      "         1.1369e-13, 7.1054e-14, 5.6843e-14, 5.6843e-14, 4.6185e-14, 5.6843e-14,\n",
      "         2.5757e-14, 7.1054e-14, 5.6843e-14, 2.7534e-14, 5.6843e-14, 4.2633e-14,\n",
      "         9.9476e-14, 9.9476e-14, 1.2790e-13, 1.1369e-13, 5.6843e-14, 2.1316e-14,\n",
      "         3.1974e-14, 5.6843e-14, 3.5527e-14, 4.2633e-14, 4.2633e-14, 2.8422e-14,\n",
      "         9.9476e-14, 3.5527e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 228: layer4.1.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 228\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 228\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 228\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 228\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 228\n",
      "Max diff:\n",
      " tensor([1.2079e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3323e-15, 6.6613e-16, 1.3323e-15, 4.5519e-15, 1.7764e-15, 4.5519e-15,\n",
      "         4.6629e-15, 4.4409e-16, 1.7764e-15, 5.3291e-15, 1.7764e-15, 2.9976e-15,\n",
      "         1.3323e-15, 1.1102e-15, 3.1086e-15, 4.4409e-15, 2.5535e-15, 3.9968e-15,\n",
      "         2.6645e-15, 4.8850e-15, 3.1086e-15, 1.3323e-15, 4.9960e-16, 8.8818e-16,\n",
      "         1.8874e-15, 2.6645e-15, 2.6645e-15, 2.3315e-15, 4.4409e-15, 1.7764e-15,\n",
      "         2.1094e-15, 2.6645e-15, 1.0658e-14, 4.4409e-16, 5.3291e-15, 3.1086e-15,\n",
      "         1.3323e-15, 3.9968e-15, 1.3323e-15, 4.8850e-15, 2.6645e-15, 4.4409e-15,\n",
      "         3.5527e-15, 1.0658e-14, 3.5527e-15, 8.8818e-16, 3.3307e-16, 1.7764e-15,\n",
      "         2.3870e-15, 3.5527e-15, 3.9968e-15, 1.1102e-15, 3.1086e-15, 1.7764e-15,\n",
      "         3.5527e-15, 2.6645e-15, 3.1086e-15, 2.6645e-15, 5.3291e-15, 1.7764e-15,\n",
      "         7.1054e-15, 2.0539e-15, 2.6645e-15, 1.7764e-15, 4.4409e-15, 2.5813e-15,\n",
      "         7.9936e-15, 2.2204e-15, 2.6645e-15, 4.5519e-15, 7.9936e-15, 4.4964e-15,\n",
      "         1.7764e-15, 1.9984e-15, 2.6645e-15, 2.6645e-15, 3.5527e-15, 6.2172e-15,\n",
      "         3.5527e-15, 3.9968e-15, 4.2188e-15, 2.6645e-15, 2.3592e-15, 6.6613e-16,\n",
      "         4.4409e-15, 1.1102e-15, 2.7756e-15, 7.1054e-15, 5.3291e-15, 4.4409e-15,\n",
      "         4.7740e-15, 7.7716e-16, 3.8858e-15, 7.1054e-15, 1.6653e-15, 2.6645e-15,\n",
      "         2.6645e-15, 2.6645e-15, 1.9984e-15, 1.0658e-14, 5.3291e-15, 1.7764e-15,\n",
      "         4.4409e-16, 4.4409e-15, 2.6645e-15, 5.3291e-15, 3.3307e-16, 3.5527e-15,\n",
      "         4.4409e-15, 4.4409e-15, 1.7764e-15, 2.1649e-15, 3.1086e-15, 3.3307e-15,\n",
      "         3.5527e-15, 3.5527e-15, 4.4409e-15, 5.5511e-16, 2.8866e-15, 3.5527e-15,\n",
      "         2.2204e-15, 5.5511e-16, 4.4409e-15, 3.1086e-15, 4.4409e-15, 1.5543e-15,\n",
      "         3.9968e-15, 2.4980e-15, 1.7764e-14, 3.9080e-14, 7.8160e-14, 1.2434e-14,\n",
      "         1.4211e-14, 4.2633e-14, 2.4869e-14, 3.5527e-14, 8.8818e-15, 1.0658e-14,\n",
      "         1.2434e-14, 1.0658e-14, 2.8422e-14, 7.1054e-15, 1.2434e-14, 1.0658e-14,\n",
      "         2.8422e-14, 1.0658e-14, 2.1316e-14, 1.4211e-14, 6.2172e-15, 1.0658e-14,\n",
      "         6.3949e-14, 1.5987e-14, 1.0658e-14, 1.2879e-14, 8.8818e-15, 7.1054e-15,\n",
      "         4.2633e-14, 3.1974e-14, 7.1054e-15, 1.2434e-14, 2.1316e-14, 2.4869e-14,\n",
      "         7.9936e-15, 7.1054e-15, 1.7764e-14, 4.2633e-14, 2.8422e-14, 2.0872e-14,\n",
      "         7.1054e-15, 3.1530e-14, 1.4683e-14, 2.1316e-14, 4.9738e-14, 1.7764e-14,\n",
      "         1.5987e-14, 1.5987e-14, 2.8422e-14, 2.4869e-14, 7.1054e-15, 1.7764e-14,\n",
      "         1.5099e-14, 1.0658e-14, 2.8422e-14, 6.2172e-15, 4.2633e-14, 2.1316e-14,\n",
      "         1.3323e-14, 8.8818e-15, 1.4211e-14, 5.6843e-14, 2.8422e-14, 7.6605e-15,\n",
      "         9.7700e-15, 1.7764e-14, 2.1316e-14, 7.1054e-15, 1.4211e-14, 5.6843e-14,\n",
      "         8.8818e-15, 1.5099e-14, 2.8422e-14, 1.4211e-14, 6.2172e-15, 1.0658e-14,\n",
      "         4.2633e-14, 8.8818e-15, 3.1974e-14, 2.8422e-14, 6.3949e-14, 2.8422e-14,\n",
      "         3.1974e-14, 1.5987e-14, 5.7732e-15, 1.5987e-14, 1.5987e-14, 2.1316e-14,\n",
      "         3.5527e-14, 3.5527e-14, 3.5527e-14, 1.9540e-14, 2.4869e-14, 3.1974e-14,\n",
      "         1.2434e-14, 1.4211e-14, 3.1086e-15, 2.4869e-14, 2.1316e-14, 1.4211e-14,\n",
      "         2.4869e-14, 3.1974e-14, 5.3291e-15, 2.4869e-14, 1.4211e-14, 4.2633e-14,\n",
      "         1.5099e-14, 3.1974e-14, 2.4869e-14, 1.4211e-14, 3.1974e-14, 3.5527e-14,\n",
      "         2.8422e-14, 7.1054e-14, 1.5987e-14, 1.5987e-14, 2.4869e-14, 7.9936e-15,\n",
      "         2.4869e-14, 3.1974e-14, 1.2434e-14, 1.0658e-14, 2.1316e-14, 1.4211e-14,\n",
      "         3.1974e-14, 3.1974e-14, 1.4211e-14, 1.0658e-14, 1.7764e-14, 5.6843e-14,\n",
      "         3.5527e-14, 1.7764e-14, 8.8818e-15, 3.5527e-14, 4.2633e-14, 2.8422e-14,\n",
      "         3.1974e-14, 3.1974e-14, 8.8818e-15, 6.3949e-14, 4.2633e-14, 2.1316e-14,\n",
      "         1.4211e-14, 1.7764e-14, 2.4869e-14, 1.7764e-14, 7.1054e-15, 2.8422e-14,\n",
      "         3.5527e-14, 4.2633e-14, 1.2434e-14, 2.1316e-14, 4.2633e-14, 2.1316e-14,\n",
      "         3.1974e-14, 4.2633e-14, 2.8422e-14, 2.8422e-14, 2.8422e-14, 5.6843e-14,\n",
      "         2.8422e-14, 2.8422e-14, 7.1054e-15, 5.3291e-15, 2.8422e-14, 6.3949e-14,\n",
      "         1.4211e-14, 1.7764e-14, 1.4211e-14, 2.8422e-14, 1.7764e-14, 1.0214e-14,\n",
      "         6.3949e-14, 7.9936e-15, 2.4869e-14, 2.8422e-14, 1.4211e-14, 4.9738e-14,\n",
      "         5.6843e-14, 2.8422e-14, 2.8422e-14, 3.5527e-14, 6.3949e-14, 3.1974e-14,\n",
      "         2.1316e-14, 2.4869e-14, 2.1316e-14, 7.5495e-15, 6.3949e-14, 1.7319e-14,\n",
      "         1.7764e-14, 1.4211e-14, 3.5527e-14, 7.8160e-14, 2.4869e-14, 1.1546e-14,\n",
      "         1.2434e-14, 4.6185e-14, 2.8422e-14, 1.7764e-14, 1.0658e-14, 1.0658e-14,\n",
      "         3.1974e-14, 4.2633e-14, 1.4211e-14, 1.7764e-14, 5.6843e-14, 2.8422e-14,\n",
      "         4.2633e-14, 2.8422e-14, 1.4211e-14, 1.7764e-14, 4.9738e-14, 2.8422e-14,\n",
      "         2.4869e-14, 2.8422e-14, 1.2434e-14, 2.8422e-14, 3.5527e-14, 4.2633e-14,\n",
      "         1.4655e-14, 2.1316e-14, 2.4869e-14, 1.4211e-14, 2.8422e-14, 1.0658e-14,\n",
      "         4.4409e-15, 1.7764e-14, 1.2434e-14, 4.2633e-14, 3.5527e-14, 1.4211e-14,\n",
      "         1.5987e-14, 5.3291e-14, 4.9738e-14, 5.3291e-15, 1.5987e-14, 6.2172e-15,\n",
      "         1.7764e-14, 4.9738e-14, 2.1316e-14, 2.4869e-14, 2.8422e-14, 2.1316e-14,\n",
      "         3.5527e-14, 2.4869e-14, 6.3949e-14, 1.2079e-13, 1.7764e-14, 7.1054e-15,\n",
      "         1.7764e-14, 1.0658e-14, 2.4869e-14, 1.9540e-14, 1.2434e-14, 2.1316e-14,\n",
      "         1.5099e-14, 8.8818e-15, 1.2434e-14, 1.0658e-14, 2.4869e-14, 1.8430e-14,\n",
      "         2.1316e-14, 2.3093e-14, 2.8422e-14, 1.5099e-14, 2.4869e-14, 3.1974e-14,\n",
      "         2.4869e-14, 1.8208e-14, 1.7764e-14, 2.1316e-14, 1.5099e-14, 4.9738e-14,\n",
      "         2.4869e-14, 1.7764e-14, 1.5987e-14, 1.4211e-14, 3.1974e-14, 1.7764e-14,\n",
      "         6.2172e-15, 2.1316e-14, 1.5987e-14, 3.0198e-14, 3.9080e-14, 1.2434e-14,\n",
      "         2.8422e-14, 1.0658e-14, 6.0396e-14, 1.2434e-14, 1.4211e-14, 1.7319e-14,\n",
      "         1.9540e-14, 1.2434e-14, 2.1316e-14, 2.6201e-14, 7.5495e-15, 2.1316e-14,\n",
      "         1.4211e-14, 1.4211e-14, 9.7700e-15, 2.8422e-14, 1.7764e-14, 8.8818e-15,\n",
      "         2.3093e-14, 2.1316e-14, 1.5987e-14, 7.3275e-15, 8.2157e-15, 1.7764e-14,\n",
      "         6.7502e-14, 2.4869e-14, 2.1316e-14, 1.2434e-14, 1.2434e-14, 9.2149e-15,\n",
      "         8.8818e-15, 5.3291e-14, 1.9540e-14, 1.7764e-14, 1.2434e-14, 1.2434e-14,\n",
      "         2.8422e-14, 1.0658e-14, 2.8422e-14, 2.8422e-14, 2.8422e-14, 1.4211e-14,\n",
      "         1.2434e-14, 2.4869e-14, 1.3323e-14, 1.1990e-14, 2.3093e-14, 8.8818e-15,\n",
      "         1.4211e-14, 1.7764e-14, 1.0658e-14, 9.7700e-15, 1.5987e-14, 3.1974e-14,\n",
      "         2.8422e-14, 9.7700e-15, 8.8818e-15, 1.0658e-14, 1.7764e-14, 6.3949e-14,\n",
      "         1.0658e-14, 1.0658e-14, 8.8818e-15, 2.1316e-14, 9.5479e-15, 1.9540e-14,\n",
      "         1.2879e-14, 1.4211e-14, 1.1546e-14, 2.8422e-14, 2.1316e-14, 1.1741e-14,\n",
      "         3.1974e-14, 2.4869e-14, 1.7764e-14, 2.1316e-14, 1.2434e-14, 2.4869e-14,\n",
      "         7.5495e-15, 2.1316e-14, 1.7764e-14, 7.1054e-15, 1.7764e-14, 1.9540e-14,\n",
      "         3.5527e-14, 3.1974e-14, 3.9080e-14, 3.5527e-14, 1.5987e-14, 7.9936e-15,\n",
      "         7.9936e-15, 1.7764e-14, 1.1990e-14, 1.0658e-14, 1.4211e-14, 1.4211e-14,\n",
      "         3.5527e-14, 1.0658e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 229: layer4.1.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 229\n",
      "Max diff:\n",
      " tensor([3.1530e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5519e-15, 0.0000e+00, 4.5519e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9421e-15, 2.5500e-16, 1.9429e-15,\n",
      "         8.7430e-16, 0.0000e+00, 3.1086e-15, 0.0000e+00, 2.5535e-15, 3.9968e-15,\n",
      "         0.0000e+00, 1.9984e-15, 5.6899e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4433e-15, 0.0000e+00, 7.7716e-16, 0.0000e+00, 1.5543e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.2212e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1008e-15,\n",
      "         1.3323e-15, 0.0000e+00, 9.9920e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3870e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 0.0000e+00, 2.1944e-16, 5.5511e-17, 0.0000e+00, 6.6613e-16,\n",
      "         2.6645e-15, 1.4710e-15, 5.2736e-16, 8.8818e-16, 0.0000e+00, 2.2204e-15,\n",
      "         0.0000e+00, 2.1094e-15, 1.5543e-15, 0.0000e+00, 6.6613e-15, 4.4964e-15,\n",
      "         0.0000e+00, 3.3307e-16, 0.0000e+00, 7.7716e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7756e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.7740e-15, 0.0000e+00, 9.9920e-16, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         7.2164e-16, 2.6645e-15, 0.0000e+00, 1.4433e-15, 0.0000e+00, 5.5511e-16,\n",
      "         0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00, 0.0000e+00, 3.5527e-15,\n",
      "         0.0000e+00, 2.4425e-15, 0.0000e+00, 8.8818e-16, 2.3870e-15, 0.0000e+00,\n",
      "         3.5527e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-15, 1.2212e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9920e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2172e-15,\n",
      "         1.2434e-14, 1.0492e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         0.0000e+00, 2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2879e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.4956e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.4393e-15, 6.2172e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3767e-14,\n",
      "         0.0000e+00, 3.1530e-14, 2.2204e-16, 3.1641e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 0.0000e+00, 0.0000e+00,\n",
      "         2.6645e-15, 0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00, 4.6629e-15,\n",
      "         5.3291e-15, 0.0000e+00, 3.5527e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-15, 5.3291e-15, 0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3307e-15, 2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3323e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.4369e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.3291e-15, 1.5987e-14, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0658e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7764e-15, 1.1102e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.3259e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0658e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9968e-15, 0.0000e+00, 0.0000e+00,\n",
      "         4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2172e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.1054e-15, 0.0000e+00, 4.3437e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.1990e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.1070e-15, 0.0000e+00, 0.0000e+00, 5.9674e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.8866e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4655e-14, 3.9968e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.2180e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3307e-15, 0.0000e+00, 1.3600e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9968e-15, 0.0000e+00,\n",
      "         0.0000e+00, 4.9960e-15, 0.0000e+00, 2.1316e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.7748e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.8850e-15, 6.8834e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2196e-15,\n",
      "         0.0000e+00, 7.1054e-15, 0.0000e+00, 4.4409e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-15, 0.0000e+00, 3.1086e-15, 2.2204e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.6613e-15, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.5987e-14, 7.2720e-15, 8.2157e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4956e-15, 0.0000e+00, 9.2149e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-15, 4.4409e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.7764e-14, 0.0000e+00, 0.0000e+00, 6.7222e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-14, 1.1990e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.5479e-15, 5.1070e-15, 5.1070e-15, 0.0000e+00,\n",
      "         0.0000e+00, 9.7700e-15, 6.1062e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.5479e-15, 0.0000e+00,\n",
      "         5.4401e-15, 0.0000e+00, 1.1546e-14, 0.0000e+00, 0.0000e+00, 6.6613e-16,\n",
      "         1.9984e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2434e-14, 0.0000e+00,\n",
      "         7.5495e-15, 0.0000e+00, 0.0000e+00, 4.4409e-15, 0.0000e+00, 6.8834e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.8826e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([  3,   5,   9,  10,  11,  12,  14,  16,  17,  19,  20,  24,  26,  28,\n",
      "         31,  35,  36,  38,  48,  53,  56,  57,  59,  60,  61,  62,  63,  65,\n",
      "         67,  68,  70,  71,  73,  75,  80,  82,  86,  90,  92,  93,  96,  97,\n",
      "         99, 101, 104, 107, 109, 111, 112, 114, 118, 119, 123, 131, 137, 138,\n",
      "        139, 143, 145, 153, 158, 162, 163, 167, 169, 170, 171, 175, 183, 186,\n",
      "        188, 191, 192, 194, 198, 199, 201, 211, 212, 223, 225, 234, 242, 243,\n",
      "        245, 249, 254, 255, 270, 282, 291, 294, 299, 313, 315, 318, 326, 329,\n",
      "        344, 348, 349, 356, 363, 385, 387, 394, 397, 399, 403, 408, 409, 413,\n",
      "        415, 417, 421, 423, 424, 428, 431, 434, 435, 436, 441, 443, 448, 449,\n",
      "        452, 455, 458, 459, 464, 465, 466, 469, 470, 478, 480, 482, 485, 486,\n",
      "        490, 492, 495, 497, 506])\n",
      "\n",
      "failing Cout = tensor([  3,   5,   9,  10,  11,  12,  14,  16,  17,  19,  20,  24,  26,  28,\n",
      "         31,  35,  36,  38,  48,  53,  56,  57,  59,  60,  61,  62,  63,  65,\n",
      "         67,  68,  70,  71,  73,  75,  80,  82,  86,  90,  92,  93,  96,  97,\n",
      "         99, 101, 104, 107, 109, 111, 112, 114, 118, 119, 123, 131, 137, 138,\n",
      "        139, 143, 145, 153, 158, 162, 163, 167, 169, 170, 171, 175, 183, 186,\n",
      "        188, 191, 192, 194, 198, 199, 201, 211, 212, 223, 225, 234, 242, 243,\n",
      "        245, 249, 254, 255, 270, 282, 291, 294, 299, 313, 315, 318, 326, 329,\n",
      "        344, 348, 349, 356, 363, 385, 387, 394, 397, 399, 403, 408, 409, 413,\n",
      "        415, 417, 421, 423, 424, 428, 431, 434, 435, 436, 441, 443, 448, 449,\n",
      "        452, 455, 458, 459, 464, 465, 466, 469, 470, 478, 480, 482, 485, 486,\n",
      "        490, 492, 495, 497, 506])  (len = 145)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 230: layer4.1.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 230\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([131, 134, 136, 137, 141, 143, 145, 147, 150, 153, 155, 156, 159, 162,\n",
      "        163, 167, 168, 170, 171, 174, 177, 179, 181, 184, 185, 187, 190, 191,\n",
      "        195, 200, 203, 204, 207, 209, 211, 214, 215, 216, 222, 223, 225, 235,\n",
      "        236, 238, 240, 241, 242, 250, 252]) to machine 1\n",
      "\t\t sending C_out tensor([263, 268, 269, 275, 276, 279, 282, 284, 285, 286, 287, 289, 290, 292,\n",
      "        293, 296, 298, 300, 303, 304, 310, 316, 317, 319, 325, 326, 327, 329,\n",
      "        332, 333, 334, 335, 336, 338, 341, 343, 344, 345, 346, 348, 353, 354,\n",
      "        359, 360, 362, 364, 365, 369, 370, 374, 376, 377, 378, 380, 381, 382,\n",
      "        383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 389, 393, 394, 396, 400, 401, 405, 407, 408, 409, 412,\n",
      "        413, 414, 417, 418, 422, 424, 425, 426, 427, 429, 434, 436, 438, 439,\n",
      "        441, 442, 443, 444, 445, 448, 450, 453, 454, 457, 458, 459, 460, 461,\n",
      "        463, 464, 465, 467, 468, 469, 470, 471, 473, 476, 477, 478, 479, 484,\n",
      "        487, 489, 490, 491, 493, 494, 495, 498, 499, 502, 506, 507, 508, 510,\n",
      "        511]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 230\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   4,   5,   6,   7,   8,   9,  10,  12,  13,  14,  15,  16,\n",
      "         17,  18,  21,  23,  25,  26,  27,  28,  29,  31,  32,  34,  35,  36,\n",
      "         37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  51,\n",
      "         52,  54,  55,  56,  57,  58,  60,  61,  62,  63,  64,  66,  67,  68,\n",
      "         69,  70,  71,  74,  75,  77,  78,  80,  82,  84,  85,  86,  87,  89,\n",
      "         90,  91,  93,  94,  95,  96,  97,  98,  99, 101, 102, 103, 104, 105,\n",
      "        107, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122,\n",
      "        123, 124, 125, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 230\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   3,   4,   6,   7,   8,   9,  10,  14,  15,  16,  17,  19,\n",
      "         20,  21,  25,  27,  28,  29,  30,  34,  37,  38,  40,  42,  43,  45,\n",
      "         49,  52,  54,  55,  57,  58,  59,  60,  61,  64,  67,  68,  69,  71,\n",
      "         72,  73,  75,  76,  80,  84,  85,  89,  90,  92,  93,  94,  95,  97,\n",
      "        100, 102, 103, 104, 105, 109, 112, 114, 116, 118, 119, 120, 121, 122,\n",
      "        123, 124]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 157,\n",
      "        158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
      "        172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
      "        187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "        202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
      "        217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
      "        233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 230\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  35,  36,  37,  38,  40,  41,  42,  43,  44,\n",
      "         45,  46,  47,  49,  50,  51,  52,  53,  54,  55,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "         75,  76,  77,  78,  80,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 101, 102, 103, 104, 105,\n",
      "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 230\n",
      "Max diff:\n",
      " tensor([6.3949e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.6645e-14, 1.0658e-14, 6.6613e-16, 8.8818e-15, 1.1102e-14, 6.2172e-15,\n",
      "         1.9540e-14, 3.5527e-14, 1.5987e-14, 1.5987e-14, 1.0658e-14, 1.4211e-14,\n",
      "         1.4211e-14, 6.2172e-15, 1.4211e-14, 1.2434e-14, 1.7764e-14, 1.0880e-14,\n",
      "         1.4211e-14, 7.1054e-15, 2.4869e-14, 1.0658e-14, 1.4211e-14, 8.3406e-15,\n",
      "         1.5987e-14, 1.7764e-14, 8.8818e-15, 1.0658e-14, 1.1768e-14, 5.3291e-15,\n",
      "         8.8818e-15, 1.0658e-14, 1.4211e-14, 1.4211e-14, 5.3291e-15, 1.3323e-14,\n",
      "         9.7700e-15, 1.3323e-14, 9.7700e-15, 1.4211e-14, 8.8818e-15, 2.3093e-14,\n",
      "         3.5527e-14, 1.4211e-14, 1.2434e-14, 7.1054e-15, 3.0198e-14, 1.7764e-14,\n",
      "         5.3291e-15, 2.8422e-14, 1.5987e-14, 1.4211e-14, 2.8422e-14, 8.8818e-15,\n",
      "         1.7764e-14, 2.5757e-14, 1.0658e-14, 2.4869e-14, 7.9936e-15, 1.3323e-14,\n",
      "         1.1546e-14, 1.0658e-14, 1.7764e-14, 2.1316e-14, 2.8422e-14, 1.7764e-14,\n",
      "         7.1054e-15, 1.5099e-14, 8.8818e-15, 3.9080e-14, 1.9540e-14, 2.8422e-14,\n",
      "         1.2434e-14, 1.0658e-14, 1.0658e-14, 2.0428e-14, 1.5987e-14, 1.4211e-14,\n",
      "         1.7764e-14, 1.3323e-15, 1.4211e-14, 1.4211e-14, 1.1546e-14, 8.8818e-15,\n",
      "         1.5099e-14, 2.1316e-14, 1.1546e-14, 1.0658e-14, 1.0658e-14, 1.4211e-14,\n",
      "         2.1316e-14, 1.4211e-14, 5.3291e-15, 1.0658e-14, 1.4211e-14, 4.5297e-14,\n",
      "         8.4377e-15, 1.5099e-14, 1.4211e-14, 8.8818e-15, 7.1054e-15, 1.3323e-15,\n",
      "         3.1974e-14, 1.7764e-14, 1.2434e-14, 3.5971e-14, 1.2434e-14, 1.0658e-14,\n",
      "         5.3291e-15, 1.4211e-14, 1.0658e-14, 6.2172e-15, 1.4211e-14, 1.9540e-14,\n",
      "         3.5527e-15, 7.9936e-15, 1.1546e-14, 1.1102e-15, 2.8422e-14, 1.0658e-14,\n",
      "         8.4099e-15, 2.4869e-14, 1.6431e-14, 1.0658e-14, 2.6645e-15, 3.5527e-14,\n",
      "         2.3093e-14, 1.7764e-14, 3.9080e-14, 2.6645e-14, 1.7764e-14, 1.7764e-14,\n",
      "         3.1974e-14, 4.2633e-14, 3.9080e-14, 2.6645e-14, 3.1974e-14, 2.6645e-14,\n",
      "         3.9080e-14, 6.3949e-14, 2.8422e-14, 3.1974e-14, 5.6843e-14, 2.9754e-14,\n",
      "         2.8422e-14, 4.5297e-14, 4.2633e-14, 2.8422e-14, 3.1974e-14, 1.9540e-14,\n",
      "         2.0428e-14, 1.4211e-14, 2.4869e-14, 3.9080e-14, 2.1316e-14, 4.6185e-14,\n",
      "         2.2204e-14, 3.1086e-14, 2.7631e-14, 3.5527e-14, 1.5987e-14, 2.8422e-14,\n",
      "         5.6843e-14, 2.4869e-14, 2.0428e-14, 4.2633e-14, 1.2434e-14, 2.1316e-14,\n",
      "         3.0198e-14, 4.2633e-14, 4.2633e-14, 5.6843e-14, 2.6645e-14, 2.1316e-14,\n",
      "         2.1316e-14, 2.4869e-14, 1.5099e-14, 2.1316e-14, 3.5527e-14, 2.8422e-14,\n",
      "         2.7534e-14, 4.2633e-14, 4.2633e-14, 1.7764e-14, 4.6185e-14, 1.3323e-14,\n",
      "         2.8422e-14, 1.7764e-14, 2.8422e-14, 3.5527e-14, 3.9080e-14, 3.9080e-14,\n",
      "         3.3751e-14, 3.5527e-14, 1.9984e-14, 3.0198e-14, 3.9080e-14, 3.5527e-14,\n",
      "         7.5495e-15, 2.7534e-14, 2.3981e-14, 1.9540e-14, 2.6645e-14, 4.9738e-14,\n",
      "         2.8422e-14, 1.5987e-14, 1.7764e-14, 3.5527e-14, 3.5527e-14, 4.9738e-14,\n",
      "         2.7756e-14, 2.4869e-14, 4.9738e-14, 1.4211e-14, 1.7764e-14, 2.4869e-14,\n",
      "         2.1316e-14, 2.3093e-14, 2.5757e-14, 3.9080e-14, 3.5527e-14, 3.0198e-14,\n",
      "         2.3093e-14, 1.9540e-14, 2.8422e-14, 3.9080e-14, 4.9738e-14, 3.1974e-14,\n",
      "         3.3751e-14, 3.0198e-14, 1.6431e-14, 4.2633e-14, 1.4211e-14, 1.2434e-14,\n",
      "         2.0206e-14, 3.9080e-14, 3.9080e-14, 2.8422e-14, 6.3949e-14, 2.4869e-14,\n",
      "         1.5987e-14, 3.5527e-14, 3.9080e-14, 1.8430e-14, 3.9080e-14, 1.7764e-14,\n",
      "         3.5527e-14, 3.5527e-14, 1.1102e-14, 2.8422e-14, 6.3949e-14, 2.8422e-14,\n",
      "         1.8652e-14, 1.5987e-14, 3.9080e-14, 2.8422e-14, 3.5527e-14, 3.9080e-14,\n",
      "         2.8422e-14, 2.8422e-14, 1.1546e-14, 3.1974e-14, 1.7764e-14, 2.8422e-14,\n",
      "         3.9080e-14, 3.1974e-14, 4.2633e-14, 2.4869e-14, 3.5527e-14, 2.1316e-14,\n",
      "         2.1316e-14, 2.1316e-14, 2.4869e-14, 1.7764e-14, 3.1974e-14, 1.7764e-14,\n",
      "         4.9738e-14, 1.9540e-14, 2.8422e-14, 1.9540e-14, 1.8652e-14, 1.7764e-14,\n",
      "         2.4869e-14, 2.4869e-14, 3.9080e-14, 3.9080e-14, 2.8422e-14, 2.1316e-14,\n",
      "         1.6875e-14, 4.2633e-14, 1.4211e-14, 3.5527e-14, 2.1316e-14, 2.0428e-14,\n",
      "         3.5527e-14, 2.1316e-14, 1.5987e-14, 1.0658e-14, 3.0198e-14, 2.1316e-14,\n",
      "         3.1974e-14, 1.9984e-14, 2.3093e-14, 2.3315e-14, 1.5987e-14, 4.9738e-14,\n",
      "         4.2633e-14, 4.6185e-14, 1.7764e-14, 2.8422e-14, 1.4211e-14, 3.3751e-14,\n",
      "         2.1316e-14, 5.6843e-14, 5.6843e-14, 1.9540e-14, 1.5987e-14, 2.1316e-14,\n",
      "         1.2434e-14, 1.7764e-14, 2.1316e-14, 4.6185e-14, 2.4869e-14, 1.7764e-14,\n",
      "         1.2434e-14, 2.4869e-14, 1.6875e-14, 3.5527e-14, 2.1316e-14, 2.8422e-14,\n",
      "         1.5987e-14, 2.0872e-14, 1.7764e-14, 2.4869e-14, 4.2633e-14, 2.1316e-14,\n",
      "         2.1316e-14, 3.5527e-14, 4.2633e-14, 1.6875e-14, 2.1316e-14, 2.8422e-14,\n",
      "         1.7764e-14, 2.0428e-14, 3.1974e-14, 1.7764e-14, 2.3981e-14, 2.4869e-14,\n",
      "         2.3981e-14, 1.2434e-14, 3.5527e-14, 1.7764e-14, 2.3093e-14, 4.2633e-14,\n",
      "         1.3323e-14, 2.0872e-14, 2.4869e-14, 2.4869e-14, 3.1974e-14, 5.6843e-14,\n",
      "         1.7764e-14, 4.2633e-14, 2.1316e-14, 2.8422e-14, 3.5527e-14, 2.8422e-14,\n",
      "         1.7764e-14, 2.4869e-14, 3.5527e-14, 2.8422e-14, 2.4869e-14, 1.0658e-14,\n",
      "         6.3949e-14, 2.6645e-14, 2.4869e-14, 2.1316e-14, 2.5313e-14, 2.4869e-14,\n",
      "         2.8422e-14, 3.1974e-14, 2.1316e-14, 3.9080e-14, 4.2633e-14, 3.5527e-14,\n",
      "         2.3981e-14, 1.7764e-14, 2.3093e-14, 3.0198e-14, 1.7764e-14, 2.4869e-14,\n",
      "         1.9540e-14, 2.8422e-14, 2.4869e-14, 2.1316e-14, 1.9540e-14, 1.7764e-14,\n",
      "         2.8422e-14, 4.9738e-14, 4.9072e-14, 2.1316e-14, 4.2633e-14, 2.4869e-14,\n",
      "         2.8422e-14, 1.7764e-14, 1.9540e-14, 2.1316e-14, 2.6645e-14, 2.3093e-14,\n",
      "         2.8422e-14, 1.4211e-14, 3.1974e-14, 3.5527e-14, 3.1974e-14, 3.5527e-14,\n",
      "         4.2633e-14, 3.9968e-14, 3.1974e-14, 2.1316e-14, 3.1974e-14, 1.0658e-14,\n",
      "         3.5527e-14, 2.4425e-14, 2.6645e-14, 2.5757e-14, 4.2633e-14, 2.3537e-14,\n",
      "         5.8620e-14, 1.9540e-14, 1.7764e-14, 3.5527e-14, 5.5067e-14, 2.4869e-14,\n",
      "         4.6185e-14, 3.0198e-14, 2.4869e-14, 2.8422e-14, 4.9738e-14, 1.4211e-14,\n",
      "         2.4869e-14, 3.5527e-14, 3.9080e-14, 2.1316e-14, 2.8422e-14, 2.8422e-14,\n",
      "         2.8422e-14, 1.2434e-14, 3.0198e-14, 3.5527e-14, 1.9540e-14, 1.5987e-14,\n",
      "         3.1974e-14, 3.5527e-14, 1.4211e-14, 3.1974e-14, 5.6843e-14, 1.5987e-14,\n",
      "         2.5313e-14, 1.8208e-14, 3.5527e-14, 2.4869e-14, 4.2633e-14, 1.7764e-14,\n",
      "         2.7534e-14, 2.1316e-14, 2.1316e-14, 3.0198e-14, 2.8422e-14, 2.3093e-14,\n",
      "         3.1974e-14, 3.0198e-14, 3.1974e-14, 2.8422e-14, 4.9738e-14, 2.8422e-14,\n",
      "         2.8422e-14, 3.1974e-14, 4.2633e-14, 2.8422e-14, 3.5527e-14, 3.9080e-14,\n",
      "         3.5527e-14, 3.1974e-14, 2.8422e-14, 4.9738e-14, 1.5099e-14, 1.7764e-14,\n",
      "         2.1316e-14, 2.8422e-14, 2.8422e-14, 4.2633e-14, 1.7764e-14, 2.8422e-14,\n",
      "         4.6185e-14, 2.4869e-14, 1.8652e-14, 5.3291e-14, 3.1974e-14, 2.3093e-14,\n",
      "         3.5527e-14, 2.6645e-14, 4.2633e-14, 3.3085e-14, 3.9080e-14, 2.8422e-14,\n",
      "         3.1974e-14, 2.2204e-14, 4.2633e-14, 2.8422e-14, 4.9738e-14, 2.1316e-14,\n",
      "         4.2633e-14, 5.6843e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 231: layer4.1.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 231\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 231\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 231\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 231\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 231\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.2434e-14, 3.5527e-15, 2.7756e-16, 3.5527e-15, 2.9976e-15, 9.9920e-16,\n",
      "         6.2172e-15, 1.2434e-14, 5.9952e-15, 4.4409e-15, 5.3291e-15, 5.3291e-15,\n",
      "         3.5527e-15, 2.2204e-15, 4.4409e-15, 2.6645e-15, 6.2172e-15, 4.6629e-15,\n",
      "         4.4409e-15, 3.5527e-15, 7.9936e-15, 2.2204e-15, 4.4409e-15, 2.4702e-15,\n",
      "         7.1054e-15, 5.3291e-15, 5.3291e-15, 4.4409e-15, 4.8295e-15, 2.2204e-15,\n",
      "         2.6645e-15, 3.5527e-15, 7.1054e-15, 5.3291e-15, 1.7764e-15, 5.3291e-15,\n",
      "         3.4972e-15, 4.6629e-15, 2.4425e-15, 3.1086e-15, 1.3323e-15, 7.9936e-15,\n",
      "         1.2434e-14, 4.4409e-15, 6.2172e-15, 1.7764e-15, 7.5495e-15, 5.3291e-15,\n",
      "         1.3323e-15, 7.9936e-15, 3.1086e-15, 5.3291e-15, 3.5527e-15, 3.7748e-15,\n",
      "         3.1086e-15, 1.8874e-15, 4.4409e-15, 4.4409e-15, 2.2204e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.5527e-15, 3.5527e-15, 6.2172e-15, 1.2434e-14, 5.3291e-15,\n",
      "         6.6613e-16, 7.1054e-15, 4.4409e-15, 1.2434e-14, 6.2172e-15, 8.8818e-15,\n",
      "         2.6645e-15, 4.4409e-15, 3.1086e-15, 1.5543e-15, 5.3291e-15, 4.4409e-15,\n",
      "         3.8858e-16, 3.3307e-16, 3.5527e-15, 5.7732e-15, 3.5527e-15, 2.6645e-15,\n",
      "         4.8850e-15, 4.4409e-15, 3.9968e-15, 4.4409e-15, 4.8919e-16, 4.4409e-15,\n",
      "         7.1054e-15, 3.7748e-15, 2.2204e-15, 3.5527e-15, 4.4409e-15, 2.2204e-14,\n",
      "         2.9976e-15, 4.2188e-15, 4.4409e-15, 3.3307e-15, 2.6645e-15, 4.4409e-16,\n",
      "         2.6645e-15, 7.5495e-15, 5.3291e-15, 1.1158e-14, 4.8850e-15, 3.5527e-15,\n",
      "         1.1102e-15, 5.3291e-15, 4.4409e-15, 1.9984e-15, 7.1054e-15, 7.9936e-15,\n",
      "         6.6613e-16, 3.1086e-15, 7.7716e-16, 3.3307e-16, 5.3291e-15, 3.4417e-15,\n",
      "         1.7208e-15, 1.0658e-14, 6.2172e-15, 3.5527e-15, 4.4409e-16, 7.5495e-15,\n",
      "         1.2434e-14, 7.1054e-15, 8.8818e-15, 5.7732e-15, 3.9968e-15, 6.2172e-15,\n",
      "         1.5987e-14, 1.7764e-14, 1.2434e-14, 7.1054e-15, 1.4211e-14, 6.2172e-15,\n",
      "         7.9936e-15, 2.6645e-14, 8.8818e-15, 5.5511e-15, 1.7764e-14, 7.7161e-15,\n",
      "         1.4211e-14, 1.5099e-14, 1.5987e-14, 6.2172e-15, 1.1546e-14, 3.9968e-15,\n",
      "         6.2172e-15, 3.5527e-15, 7.9936e-15, 7.9936e-15, 9.7700e-15, 1.2434e-14,\n",
      "         5.3291e-15, 8.2157e-15, 1.1047e-14, 2.1316e-14, 2.8866e-15, 4.4409e-15,\n",
      "         1.2434e-14, 1.4211e-14, 2.7756e-15, 1.7764e-14, 5.3291e-15, 3.5527e-15,\n",
      "         7.1054e-15, 1.0658e-14, 1.4211e-14, 1.5987e-14, 1.3323e-14, 3.7748e-15,\n",
      "         4.4409e-15, 8.8818e-15, 2.7756e-15, 5.3291e-15, 1.0658e-14, 5.3291e-15,\n",
      "         7.3275e-15, 1.0658e-14, 2.4869e-14, 6.2172e-15, 1.4211e-14, 3.3307e-15,\n",
      "         7.9936e-15, 4.4409e-15, 9.7700e-15, 7.1054e-15, 7.1054e-15, 1.9540e-14,\n",
      "         7.9936e-15, 1.4211e-14, 7.9936e-15, 1.7764e-14, 8.8818e-15, 8.8818e-15,\n",
      "         8.8818e-16, 6.2172e-15, 6.4393e-15, 2.7756e-15, 1.2879e-14, 8.8818e-15,\n",
      "         8.8818e-15, 3.5527e-15, 4.4409e-15, 1.4211e-14, 9.7700e-15, 2.6645e-14,\n",
      "         4.4409e-15, 7.1054e-15, 1.2434e-14, 5.3291e-15, 6.2172e-15, 4.4409e-15,\n",
      "         5.3291e-15, 7.9936e-15, 4.6629e-15, 1.1546e-14, 9.7700e-15, 8.3267e-15,\n",
      "         6.6613e-15, 3.5527e-15, 1.2434e-14, 6.2172e-15, 1.0658e-14, 9.3259e-15,\n",
      "         9.7700e-15, 8.8818e-15, 2.1927e-15, 8.8818e-15, 4.4409e-15, 2.6645e-15,\n",
      "         4.3299e-15, 9.7700e-15, 1.4211e-14, 6.2172e-15, 2.4869e-14, 7.1054e-15,\n",
      "         3.9968e-15, 8.8818e-15, 1.3323e-14, 6.2172e-15, 1.2434e-14, 3.5527e-15,\n",
      "         7.1054e-15, 1.2434e-14, 1.4433e-15, 1.2434e-14, 1.9540e-14, 1.4211e-14,\n",
      "         4.6629e-15, 3.5527e-15, 1.7764e-14, 8.8818e-15, 1.5987e-14, 2.1316e-14,\n",
      "         8.8818e-15, 1.2434e-14, 6.2172e-15, 7.1054e-15, 6.2172e-15, 1.4211e-14,\n",
      "         2.3093e-14, 1.9540e-14, 2.8422e-14, 1.2434e-14, 9.7700e-15, 3.9968e-15,\n",
      "         7.1054e-15, 8.8818e-15, 5.3291e-15, 3.7748e-15, 1.0436e-14, 3.9968e-15,\n",
      "         1.9540e-14, 9.7700e-15, 1.5987e-14, 7.1054e-15, 6.6613e-15, 7.1054e-15,\n",
      "         8.8818e-15, 1.2434e-14, 1.4211e-14, 1.5987e-14, 1.7764e-14, 1.4211e-14,\n",
      "         6.7307e-15, 1.2434e-14, 9.7700e-15, 1.4211e-14, 3.9968e-15, 7.1054e-15,\n",
      "         1.4211e-14, 1.0658e-14, 7.9936e-15, 7.1054e-15, 1.1546e-14, 9.7700e-15,\n",
      "         1.5987e-14, 1.1990e-14, 1.2434e-14, 8.1046e-15, 5.3291e-15, 1.5987e-14,\n",
      "         1.0658e-14, 1.4211e-14, 2.6645e-15, 1.4211e-14, 7.1054e-15, 1.6875e-14,\n",
      "         1.0658e-14, 2.8422e-14, 1.5987e-14, 9.3259e-15, 1.0658e-14, 1.4211e-14,\n",
      "         3.5527e-15, 7.1054e-15, 6.2172e-15, 2.4869e-14, 5.7732e-15, 4.8850e-15,\n",
      "         1.5543e-15, 8.8818e-15, 9.7700e-15, 2.1316e-14, 9.7700e-15, 1.4655e-14,\n",
      "         3.9968e-15, 1.1990e-14, 4.4409e-15, 6.2172e-15, 2.1316e-14, 7.1054e-15,\n",
      "         1.0658e-14, 1.9540e-14, 9.7700e-15, 7.1054e-15, 1.0658e-14, 1.9540e-14,\n",
      "         5.3291e-15, 1.0658e-14, 1.9540e-14, 8.8818e-15, 1.2101e-14, 1.2434e-14,\n",
      "         6.6613e-15, 5.3291e-15, 1.9540e-14, 8.8818e-15, 1.4211e-14, 1.2434e-14,\n",
      "         8.8818e-15, 5.5511e-15, 1.4211e-14, 4.8850e-15, 6.2172e-15, 3.1974e-14,\n",
      "         9.7700e-15, 2.4869e-14, 1.4211e-14, 1.5987e-14, 2.1316e-14, 1.4211e-14,\n",
      "         6.2172e-15, 8.8818e-15, 7.1054e-15, 1.4877e-14, 8.8818e-15, 3.1086e-15,\n",
      "         1.5987e-14, 1.4211e-14, 8.8818e-15, 1.0658e-14, 1.5987e-14, 1.4211e-14,\n",
      "         1.5987e-14, 1.2434e-14, 1.0658e-14, 1.5987e-14, 1.3767e-14, 1.7764e-14,\n",
      "         5.7732e-15, 3.5527e-15, 6.4393e-15, 8.4377e-15, 7.1054e-15, 7.5495e-15,\n",
      "         5.7732e-15, 9.7700e-15, 8.4377e-15, 4.4409e-15, 3.5527e-15, 5.3291e-15,\n",
      "         8.8818e-15, 1.7764e-14, 1.7625e-14, 6.2172e-15, 3.7748e-15, 5.3291e-15,\n",
      "         8.8818e-15, 3.7748e-15, 6.2172e-15, 6.2172e-15, 7.9936e-15, 5.7732e-15,\n",
      "         5.7732e-15, 3.5527e-15, 8.8818e-15, 9.7700e-15, 8.8818e-15, 8.8818e-15,\n",
      "         1.0658e-14, 1.0658e-14, 8.8818e-15, 5.3291e-15, 8.8818e-15, 2.8866e-15,\n",
      "         8.8818e-15, 7.3275e-15, 4.8850e-15, 8.4377e-15, 1.2434e-14, 6.8279e-15,\n",
      "         1.2657e-14, 5.3291e-15, 5.3291e-15, 9.7700e-15, 1.6875e-14, 5.3291e-15,\n",
      "         1.4211e-14, 8.4377e-15, 7.9936e-15, 7.1054e-15, 1.1546e-14, 4.4409e-15,\n",
      "         7.4940e-16, 8.4377e-15, 1.2434e-14, 5.3291e-15, 7.9936e-15, 7.1054e-15,\n",
      "         1.0658e-14, 3.5527e-15, 8.8818e-15, 1.0658e-14, 7.1054e-15, 3.5527e-15,\n",
      "         7.1054e-15, 1.1546e-14, 5.3291e-15, 1.0658e-14, 2.0428e-14, 3.9968e-15,\n",
      "         5.4956e-15, 5.3291e-15, 1.4211e-14, 5.3291e-15, 8.8818e-15, 6.2172e-15,\n",
      "         1.1324e-14, 7.9936e-15, 3.5527e-15, 1.1546e-14, 7.1054e-15, 8.8818e-15,\n",
      "         8.8818e-15, 9.7700e-15, 9.7700e-15, 8.8818e-15, 1.7764e-14, 9.7700e-15,\n",
      "         8.8818e-15, 1.2434e-14, 1.3323e-14, 7.9936e-15, 9.7700e-15, 1.0658e-14,\n",
      "         9.3259e-15, 8.8818e-15, 8.4377e-15, 1.4211e-14, 4.4409e-15, 4.4409e-15,\n",
      "         7.1054e-15, 8.8818e-15, 5.3291e-15, 1.2434e-14, 5.3291e-15, 4.4409e-15,\n",
      "         1.4877e-14, 7.1054e-15, 4.8850e-15, 2.1316e-14, 8.8818e-15, 7.1054e-15,\n",
      "         6.2172e-15, 6.4393e-15, 1.2434e-14, 7.9936e-15, 9.7700e-15, 8.8818e-15,\n",
      "         7.9936e-15, 7.9936e-15, 1.2434e-14, 5.3291e-15, 7.9936e-15, 6.2172e-15,\n",
      "         1.0658e-14, 2.1316e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 232: layer4.1.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 232\n",
      "Max diff:\n",
      " tensor([3.1974e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.2434e-14, 3.5527e-15, 2.7756e-16, 3.5527e-15, 2.9976e-15, 2.5535e-15,\n",
      "         6.2172e-15, 1.2434e-14, 5.9952e-15, 4.4409e-15, 5.3291e-15, 5.3291e-15,\n",
      "         3.5527e-15, 2.2204e-15, 4.4409e-15, 2.6645e-15, 6.2172e-15, 4.6629e-15,\n",
      "         4.4409e-15, 3.5527e-15, 7.9936e-15, 2.2204e-15, 4.4409e-15, 2.4702e-15,\n",
      "         7.1054e-15, 5.3291e-15, 5.3291e-15, 4.4409e-15, 4.8295e-15, 2.2204e-15,\n",
      "         2.6645e-15, 3.5527e-15, 7.1054e-15, 5.3291e-15, 1.7764e-15, 5.3291e-15,\n",
      "         3.4972e-15, 4.6629e-15, 2.4425e-15, 3.1086e-15, 1.3323e-15, 7.9936e-15,\n",
      "         1.2434e-14, 4.4409e-15, 6.2172e-15, 1.7764e-15, 7.5495e-15, 5.3291e-15,\n",
      "         1.3323e-15, 7.9936e-15, 3.1086e-15, 5.3291e-15, 3.5527e-15, 3.3307e-15,\n",
      "         3.1086e-15, 2.3315e-15, 4.4409e-15, 4.4409e-15, 2.2204e-15, 5.3291e-15,\n",
      "         4.4409e-15, 3.5527e-15, 3.5527e-15, 6.2172e-15, 1.2434e-14, 5.3291e-15,\n",
      "         6.6613e-16, 7.1054e-15, 4.4409e-15, 1.2434e-14, 7.9936e-15, 8.8818e-15,\n",
      "         2.6645e-15, 4.4409e-15, 3.1086e-15, 1.9151e-15, 5.3291e-15, 4.4409e-15,\n",
      "         3.8858e-16, 3.3307e-16, 3.5527e-15, 5.7732e-15, 3.5527e-15, 3.1086e-15,\n",
      "         4.8850e-15, 4.4409e-15, 3.9968e-15, 4.4409e-15, 9.9920e-16, 4.4409e-15,\n",
      "         7.1054e-15, 3.7748e-15, 2.2204e-15, 3.5527e-15, 4.4409e-15, 2.2204e-14,\n",
      "         2.9976e-15, 4.2188e-15, 4.4409e-15, 3.3307e-15, 2.6645e-15, 4.4409e-16,\n",
      "         2.6645e-15, 7.5495e-15, 5.3291e-15, 1.1158e-14, 4.8850e-15, 3.5527e-15,\n",
      "         1.1102e-15, 5.3291e-15, 4.4409e-15, 1.9984e-15, 7.1054e-15, 7.9936e-15,\n",
      "         6.6613e-16, 3.1086e-15, 3.5527e-15, 3.3307e-16, 5.3291e-15, 3.4417e-15,\n",
      "         1.8319e-15, 1.0658e-14, 6.2172e-15, 3.5527e-15, 4.4409e-16, 7.9936e-15,\n",
      "         1.2434e-14, 7.1054e-15, 8.8818e-15, 5.7732e-15, 3.9968e-15, 1.4211e-14,\n",
      "         1.5987e-14, 1.7764e-14, 1.2434e-14, 1.2434e-14, 1.4211e-14, 8.4377e-15,\n",
      "         7.9936e-15, 2.6645e-14, 8.8818e-15, 5.5511e-15, 1.7764e-14, 7.7161e-15,\n",
      "         1.4211e-14, 1.5099e-14, 1.5987e-14, 6.2172e-15, 1.1546e-14, 9.3259e-15,\n",
      "         6.2172e-15, 8.8818e-15, 7.9936e-15, 7.9936e-15, 9.7700e-15, 1.2434e-14,\n",
      "         6.2172e-15, 8.2157e-15, 1.1047e-14, 2.1316e-14, 3.9968e-15, 7.5495e-15,\n",
      "         1.2434e-14, 1.4211e-14, 2.7756e-15, 1.7764e-14, 1.1546e-14, 5.7732e-15,\n",
      "         7.1054e-15, 1.0658e-14, 1.4211e-14, 1.5987e-14, 1.3323e-14, 3.7748e-15,\n",
      "         1.0658e-14, 7.5495e-15, 2.7756e-15, 1.0658e-14, 1.0658e-14, 7.1054e-15,\n",
      "         7.3275e-15, 1.0658e-14, 2.4869e-14, 6.2172e-15, 1.4211e-14, 5.3291e-15,\n",
      "         7.9936e-15, 4.4409e-15, 9.7700e-15, 7.1054e-15, 7.1054e-15, 1.9540e-14,\n",
      "         1.1102e-14, 1.4211e-14, 7.9936e-15, 1.7764e-14, 8.8818e-15, 8.8818e-15,\n",
      "         8.8818e-16, 1.2879e-14, 6.4393e-15, 5.3291e-15, 1.2879e-14, 8.8818e-15,\n",
      "         8.8818e-15, 3.5527e-15, 4.4409e-15, 1.4211e-14, 9.7700e-15, 2.6645e-14,\n",
      "         4.4409e-15, 7.1054e-15, 1.2434e-14, 7.1054e-15, 6.2172e-15, 4.4409e-15,\n",
      "         5.3291e-15, 7.9936e-15, 4.6629e-15, 1.1546e-14, 9.7700e-15, 8.3267e-15,\n",
      "         6.6613e-15, 3.5527e-15, 1.2434e-14, 6.2172e-15, 1.0658e-14, 9.3259e-15,\n",
      "         9.7700e-15, 8.8818e-15, 3.5527e-15, 8.8818e-15, 8.8818e-15, 9.7700e-15,\n",
      "         4.3299e-15, 9.7700e-15, 1.4211e-14, 6.2172e-15, 2.4869e-14, 7.1054e-15,\n",
      "         3.9968e-15, 8.8818e-15, 1.5099e-14, 1.5987e-14, 1.2434e-14, 3.5527e-15,\n",
      "         7.1054e-15, 1.2434e-14, 3.1086e-15, 1.2434e-14, 1.9540e-14, 1.4211e-14,\n",
      "         4.6629e-15, 3.5527e-15, 1.7764e-14, 8.8818e-15, 1.5987e-14, 2.1316e-14,\n",
      "         7.3275e-15, 1.2434e-14, 6.2172e-15, 9.7700e-15, 8.8818e-15, 1.4211e-14,\n",
      "         2.3093e-14, 1.9540e-14, 2.8422e-14, 1.2434e-14, 1.6875e-14, 3.9968e-15,\n",
      "         9.3259e-15, 8.8818e-15, 5.3291e-15, 6.6613e-15, 1.0436e-14, 3.9968e-15,\n",
      "         1.9540e-14, 9.7700e-15, 1.5987e-14, 7.1054e-15, 1.0658e-14, 8.8818e-15,\n",
      "         8.8818e-15, 1.2434e-14, 1.4211e-14, 1.5987e-14, 1.7764e-14, 1.4211e-14,\n",
      "         8.8818e-15, 1.2434e-14, 9.7700e-15, 1.4211e-14, 3.9968e-15, 7.1054e-15,\n",
      "         1.0658e-14, 1.0658e-14, 7.9936e-15, 7.1054e-15, 1.1546e-14, 9.7700e-15,\n",
      "         1.4211e-14, 1.1990e-14, 1.2434e-14, 8.1046e-15, 7.7716e-15, 1.5987e-14,\n",
      "         1.0658e-14, 2.2204e-14, 2.6645e-15, 1.4211e-14, 9.3259e-15, 1.6875e-14,\n",
      "         1.0658e-14, 2.8422e-14, 1.5987e-14, 9.3259e-15, 1.0658e-14, 1.4211e-14,\n",
      "         3.5527e-15, 7.1054e-15, 6.2172e-15, 2.4869e-14, 5.7732e-15, 5.3291e-15,\n",
      "         2.6645e-15, 8.8818e-15, 9.7700e-15, 2.1316e-14, 9.7700e-15, 2.1316e-14,\n",
      "         8.8818e-15, 1.1990e-14, 3.5527e-15, 1.0658e-14, 2.1316e-14, 7.1054e-15,\n",
      "         1.0658e-14, 1.9540e-14, 9.7700e-15, 7.1054e-15, 1.0658e-14, 1.9540e-14,\n",
      "         5.3291e-15, 1.0658e-14, 1.9540e-14, 8.8818e-15, 1.2434e-14, 1.2434e-14,\n",
      "         6.4393e-15, 5.3291e-15, 1.9540e-14, 8.8818e-15, 1.4211e-14, 1.2434e-14,\n",
      "         8.8818e-15, 5.5511e-15, 1.4211e-14, 4.8850e-15, 1.2434e-14, 3.1974e-14,\n",
      "         9.7700e-15, 2.4869e-14, 1.4211e-14, 1.5987e-14, 2.1316e-14, 1.4211e-14,\n",
      "         2.4869e-14, 8.8818e-15, 7.1054e-15, 1.4877e-14, 9.7700e-15, 3.1086e-15,\n",
      "         1.5987e-14, 1.3323e-14, 8.8818e-15, 1.0658e-14, 1.5987e-14, 1.4211e-14,\n",
      "         1.5987e-14, 1.2434e-14, 1.0658e-14, 1.5987e-14, 1.3767e-14, 1.7764e-14,\n",
      "         1.0214e-14, 3.5527e-15, 7.7716e-15, 8.4377e-15, 7.1054e-15, 7.5495e-15,\n",
      "         8.8818e-15, 9.7700e-15, 1.3323e-14, 8.4377e-15, 3.5527e-15, 5.3291e-15,\n",
      "         9.7700e-15, 1.7764e-14, 1.7625e-14, 9.3259e-15, 3.7748e-15, 5.3291e-15,\n",
      "         1.1546e-14, 3.7748e-15, 6.2172e-15, 6.2172e-15, 7.9936e-15, 7.1054e-15,\n",
      "         5.7732e-15, 7.9936e-15, 1.1102e-14, 9.7700e-15, 8.8818e-15, 8.8818e-15,\n",
      "         1.0658e-14, 1.0658e-14, 8.8818e-15, 7.9936e-15, 1.2434e-14, 6.2172e-15,\n",
      "         1.5987e-14, 7.3275e-15, 7.5495e-15, 9.7700e-15, 1.2434e-14, 6.8279e-15,\n",
      "         1.2657e-14, 5.3291e-15, 5.3291e-15, 9.7700e-15, 1.6875e-14, 5.3291e-15,\n",
      "         7.9936e-15, 1.0658e-14, 1.0214e-14, 1.0658e-14, 1.1546e-14, 4.4409e-15,\n",
      "         6.2172e-15, 1.7764e-14, 1.2434e-14, 1.0658e-14, 7.9936e-15, 8.9928e-15,\n",
      "         1.0658e-14, 3.5527e-15, 8.8818e-15, 1.0658e-14, 7.1054e-15, 8.8818e-15,\n",
      "         7.1054e-15, 1.1546e-14, 5.3291e-15, 1.0658e-14, 2.0428e-14, 3.9968e-15,\n",
      "         7.5495e-15, 7.5495e-15, 1.4211e-14, 5.3291e-15, 8.8818e-15, 6.2172e-15,\n",
      "         1.1324e-14, 1.4211e-14, 6.2172e-15, 1.4655e-14, 1.1546e-14, 1.2434e-14,\n",
      "         8.8818e-15, 1.2434e-14, 9.7700e-15, 8.8818e-15, 8.8818e-15, 9.7700e-15,\n",
      "         8.8818e-15, 1.2434e-14, 1.0658e-14, 7.9936e-15, 9.7700e-15, 1.0658e-14,\n",
      "         9.3259e-15, 1.0658e-14, 7.3275e-15, 1.4211e-14, 4.4409e-15, 7.1054e-15,\n",
      "         8.8818e-15, 8.8818e-15, 5.3291e-15, 1.2434e-14, 5.3291e-15, 4.4409e-15,\n",
      "         1.4877e-14, 7.1054e-15, 1.1546e-14, 2.0428e-14, 1.0658e-14, 7.1054e-15,\n",
      "         1.0214e-14, 6.4393e-15, 1.2434e-14, 7.9936e-15, 1.3323e-14, 8.8818e-15,\n",
      "         7.9936e-15, 7.9936e-15, 1.2434e-14, 5.7732e-15, 8.8818e-15, 1.2879e-14,\n",
      "         1.5987e-14, 2.1316e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 233: layer4.1.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 233\n",
      "Max diff:\n",
      " tensor([2.4869e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9976e-15, 1.5543e-15,\n",
      "         0.0000e+00, 2.8588e-15, 5.9952e-15, 4.4409e-15, 1.7764e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4417e-15, 1.7764e-15, 3.6637e-15, 6.6613e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9429e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 4.8295e-15, 1.9151e-15,\n",
      "         0.0000e+00, 0.0000e+00, 6.9389e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4972e-15, 3.2752e-15, 2.2204e-15, 0.0000e+00, 7.7716e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.1062e-16, 0.0000e+00, 1.0547e-15, 0.0000e+00, 2.3870e-15, 3.3307e-15,\n",
      "         1.7764e-15, 2.3315e-15, 3.5527e-15, 0.0000e+00, 9.0206e-17, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         5.5511e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4425e-15, 1.1102e-15, 1.9151e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3315e-15, 3.1086e-15,\n",
      "         4.8850e-15, 0.0000e+00, 2.0955e-15, 0.0000e+00, 9.9920e-16, 0.0000e+00,\n",
      "         0.0000e+00, 2.2204e-15, 0.0000e+00, 4.4409e-16, 0.0000e+00, 2.2204e-14,\n",
      "         2.8311e-15, 0.0000e+00, 0.0000e+00, 2.7894e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.5527e-15, 1.2377e-15, 1.1158e-14, 1.2837e-15, 7.7716e-16,\n",
      "         1.1102e-15, 6.6613e-16, 0.0000e+00, 8.3267e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.8866e-15, 3.5527e-15, 0.0000e+00, 0.0000e+00, 2.9837e-15,\n",
      "         1.6098e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7184e-16, 2.1094e-15, 1.4211e-14,\n",
      "         4.4409e-16, 0.0000e+00, 2.7756e-16, 1.2434e-14, 8.8818e-15, 2.6645e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 4.4409e-15, 4.4409e-15,\n",
      "         0.0000e+00, 2.8866e-15, 4.1078e-15, 0.0000e+00, 0.0000e+00, 9.3259e-15,\n",
      "         2.8866e-15, 8.8818e-15, 7.9936e-15, 0.0000e+00, 6.6613e-15, 0.0000e+00,\n",
      "         4.6629e-15, 1.7764e-15, 4.8850e-15, 0.0000e+00, 2.8866e-15, 7.5495e-15,\n",
      "         3.5527e-15, 8.9373e-15, 1.7764e-15, 0.0000e+00, 0.0000e+00, 5.7732e-15,\n",
      "         0.0000e+00, 8.8818e-16, 0.0000e+00, 0.0000e+00, 3.5527e-15, 2.4980e-15,\n",
      "         1.0658e-14, 5.3291e-15, 9.0553e-16, 0.0000e+00, 3.1086e-15, 7.1054e-15,\n",
      "         7.3275e-15, 2.0192e-15, 0.0000e+00, 0.0000e+00, 5.7732e-15, 3.7748e-15,\n",
      "         0.0000e+00, 3.4417e-15, 0.0000e+00, 1.5543e-15, 2.6645e-15, 0.0000e+00,\n",
      "         1.1102e-14, 0.0000e+00, 7.9936e-15, 6.2172e-15, 0.0000e+00, 0.0000e+00,\n",
      "         7.7716e-16, 1.2879e-14, 2.7756e-15, 5.3291e-15, 5.8842e-15, 8.8818e-15,\n",
      "         0.0000e+00, 3.5527e-15, 0.0000e+00, 4.9960e-15, 2.4980e-15, 0.0000e+00,\n",
      "         1.0547e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15,\n",
      "         0.0000e+00, 1.9984e-15, 3.7748e-15, 8.4377e-15, 0.0000e+00, 8.3267e-15,\n",
      "         0.0000e+00, 2.2204e-15, 0.0000e+00, 4.4409e-16, 0.0000e+00, 1.6931e-15,\n",
      "         3.5527e-15, 7.1054e-15, 3.5527e-15, 0.0000e+00, 0.0000e+00, 9.7700e-15,\n",
      "         4.0523e-15, 0.0000e+00, 1.0658e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3323e-15, 4.4409e-15, 8.4377e-15, 1.5987e-14, 1.2434e-14, 3.5527e-15,\n",
      "         0.0000e+00, 0.0000e+00, 3.1086e-15, 0.0000e+00, 0.0000e+00, 5.1625e-15,\n",
      "         4.6629e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.6613e-15, 8.9928e-15, 4.4409e-15, 9.7700e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6629e-15, 7.1054e-15, 0.0000e+00,\n",
      "         9.3259e-15, 0.0000e+00, 0.0000e+00, 6.6613e-15, 7.3275e-15, 1.5543e-15,\n",
      "         7.1054e-15, 9.7700e-15, 0.0000e+00, 0.0000e+00, 1.0658e-14, 2.1649e-15,\n",
      "         2.9976e-15, 7.9103e-16, 0.0000e+00, 6.6613e-16, 1.9984e-15, 0.0000e+00,\n",
      "         8.8818e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9968e-15, 5.3291e-15,\n",
      "         0.0000e+00, 0.0000e+00, 7.3830e-15, 2.2204e-15, 1.1546e-14, 0.0000e+00,\n",
      "         9.7700e-15, 1.0658e-14, 0.0000e+00, 8.1046e-15, 1.4988e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.5099e-14, 3.3307e-16, 3.1086e-15, 9.3259e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16,\n",
      "         6.1062e-16, 0.0000e+00, 0.0000e+00, 6.2172e-15, 1.6653e-15, 5.3291e-15,\n",
      "         2.6645e-15, 8.8818e-15, 9.7700e-15, 0.0000e+00, 0.0000e+00, 2.1316e-14,\n",
      "         5.1070e-15, 1.1990e-14, 2.2204e-15, 0.0000e+00, 0.0000e+00, 3.5527e-15,\n",
      "         2.2204e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00, 8.6597e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.0658e-14, 0.0000e+00, 6.2381e-15, 2.6645e-15, 0.0000e+00,\n",
      "         5.3291e-15, 8.8818e-16, 7.1054e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.1054e-15, 3.3307e-15, 2.9629e-15, 0.0000e+00, 8.4377e-15, 0.0000e+00,\n",
      "         0.0000e+00, 5.3846e-15, 0.0000e+00, 1.5099e-14, 4.8850e-15, 0.0000e+00,\n",
      "         2.4869e-14, 2.9837e-16, 0.0000e+00, 1.4877e-14, 0.0000e+00, 1.5543e-15,\n",
      "         0.0000e+00, 6.2172e-15, 2.2204e-15, 7.4385e-15, 0.0000e+00, 1.4211e-14,\n",
      "         0.0000e+00, 8.8818e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.5543e-15, 3.1086e-15, 7.7716e-15, 1.9984e-15, 4.4409e-15, 0.0000e+00,\n",
      "         8.8818e-15, 2.5258e-15, 1.3323e-14, 6.2172e-15, 0.0000e+00, 0.0000e+00,\n",
      "         9.7700e-15, 0.0000e+00, 1.6875e-14, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         0.0000e+00, 7.9936e-15, 2.6645e-15, 1.4433e-15, 6.6613e-15, 3.9968e-15,\n",
      "         3.6082e-15, 1.0658e-14, 0.0000e+00, 1.7764e-15, 9.7700e-15, 6.2172e-15,\n",
      "         0.0000e+00, 3.9274e-15, 7.5495e-15, 6.6613e-15, 0.0000e+00, 6.8279e-15,\n",
      "         5.7732e-15, 0.0000e+00, 1.3323e-15, 0.0000e+00, 1.3323e-14, 0.0000e+00,\n",
      "         6.6613e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-15, 1.8874e-15,\n",
      "         6.2172e-15, 1.7764e-14, 3.1086e-15, 8.8818e-15, 0.0000e+00, 2.5535e-15,\n",
      "         0.0000e+00, 2.6645e-15, 0.0000e+00, 6.6613e-15, 2.4425e-15, 8.8818e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7732e-15, 0.0000e+00,\n",
      "         7.5495e-15, 7.5495e-15, 0.0000e+00, 0.0000e+00, 1.4069e-15, 0.0000e+00,\n",
      "         5.3291e-15, 7.1054e-15, 6.2172e-15, 0.0000e+00, 7.1054e-15, 1.2434e-14,\n",
      "         1.9013e-15, 0.0000e+00, 3.3307e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0658e-14, 0.0000e+00, 7.1054e-15, 0.0000e+00,\n",
      "         3.9968e-15, 1.0658e-14, 5.3291e-15, 0.0000e+00, 3.9968e-15, 3.7748e-15,\n",
      "         4.2188e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00, 2.8866e-15, 0.0000e+00,\n",
      "         1.4877e-14, 0.0000e+00, 1.1546e-14, 6.2172e-15, 0.0000e+00, 5.3291e-15,\n",
      "         1.3323e-15, 0.0000e+00, 0.0000e+00, 2.8866e-15, 0.0000e+00, 0.0000e+00,\n",
      "         3.2752e-15, 2.6645e-15, 0.0000e+00, 5.7732e-15, 8.8818e-15, 1.2879e-14,\n",
      "         4.4409e-15, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([  0,   4,   5,   7,   8,   9,  10,  14,  15,  16,  17,  23,  27,  28,\n",
      "         29,  32,  36,  37,  38,  40,  48,  50,  52,  53,  54,  55,  56,  58,\n",
      "         64,  66,  73,  74,  75,  82,  83,  84,  86,  88,  91,  93,  95,  96,\n",
      "         99, 103, 104, 105, 106, 107, 108, 109, 111, 115, 116, 119, 120, 129,\n",
      "        130, 131, 132, 134, 135, 136, 137, 141, 142, 143, 145, 146, 149, 150,\n",
      "        151, 152, 154, 156, 157, 158, 160, 161, 162, 163, 164, 167, 169, 172,\n",
      "        173, 174, 175, 176, 178, 179, 180, 181, 184, 185, 187, 189, 190, 192,\n",
      "        194, 195, 198, 199, 200, 201, 202, 203, 205, 207, 208, 210, 215, 217,\n",
      "        218, 219, 221, 223, 225, 227, 228, 229, 230, 233, 234, 236, 240, 241,\n",
      "        242, 243, 244, 245, 248, 251, 252, 258, 259, 260, 261, 267, 268, 270,\n",
      "        273, 274, 275, 276, 277, 280, 281, 282, 283, 285, 286, 288, 292, 293,\n",
      "        296, 297, 298, 300, 301, 303, 304, 307, 308, 309, 310, 317, 318, 321,\n",
      "        322, 323, 324, 325, 326, 329, 330, 331, 332, 335, 336, 337, 340, 343,\n",
      "        345, 346, 348, 349, 350, 354, 355, 356, 358, 361, 363, 364, 366, 367,\n",
      "        369, 371, 373, 374, 375, 377, 379, 384, 385, 386, 387, 388, 390, 391,\n",
      "        392, 393, 396, 398, 400, 407, 409, 410, 411, 412, 413, 414, 415, 417,\n",
      "        418, 419, 421, 422, 423, 425, 426, 428, 430, 432, 436, 437, 438, 439,\n",
      "        440, 441, 443, 445, 447, 448, 449, 454, 456, 457, 460, 462, 463, 464,\n",
      "        466, 467, 468, 470, 472, 476, 478, 480, 481, 482, 484, 485, 486, 488,\n",
      "        490, 492, 494, 495, 497, 498, 501, 504, 505, 507, 508, 509, 510])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   7,   8,   9,  10,  14,  15,  16,  17,  23,  27,  28,\n",
      "         29,  32,  36,  37,  38,  40,  48,  50,  52,  53,  54,  55,  56,  58,\n",
      "         64,  66,  73,  74,  75,  82,  83,  84,  86,  88,  91,  93,  95,  96,\n",
      "         99, 103, 104, 105, 106, 107, 108, 109, 111, 115, 116, 119, 120, 129,\n",
      "        130, 131, 132, 134, 135, 136, 137, 141, 142, 143, 145, 146, 149, 150,\n",
      "        151, 152, 154, 156, 157, 158, 160, 161, 162, 163, 164, 167, 169, 172,\n",
      "        173, 174, 175, 176, 178, 179, 180, 181, 184, 185, 187, 189, 190, 192,\n",
      "        194, 195, 198, 199, 200, 201, 202, 203, 205, 207, 208, 210, 215, 217,\n",
      "        218, 219, 221, 223, 225, 227, 228, 229, 230, 233, 234, 236, 240, 241,\n",
      "        242, 243, 244, 245, 248, 251, 252, 258, 259, 260, 261, 267, 268, 270,\n",
      "        273, 274, 275, 276, 277, 280, 281, 282, 283, 285, 286, 288, 292, 293,\n",
      "        296, 297, 298, 300, 301, 303, 304, 307, 308, 309, 310, 317, 318, 321,\n",
      "        322, 323, 324, 325, 326, 329, 330, 331, 332, 335, 336, 337, 340, 343,\n",
      "        345, 346, 348, 349, 350, 354, 355, 356, 358, 361, 363, 364, 366, 367,\n",
      "        369, 371, 373, 374, 375, 377, 379, 384, 385, 386, 387, 388, 390, 391,\n",
      "        392, 393, 396, 398, 400, 407, 409, 410, 411, 412, 413, 414, 415, 417,\n",
      "        418, 419, 421, 422, 423, 425, 426, 428, 430, 432, 436, 437, 438, 439,\n",
      "        440, 441, 443, 445, 447, 448, 449, 454, 456, 457, 460, 462, 463, 464,\n",
      "        466, 467, 468, 470, 472, 476, 478, 480, 481, 482, 484, 485, 486, 488,\n",
      "        490, 492, 494, 495, 497, 498, 501, 504, 505, 507, 508, 509, 510])  (len = 279)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 234: layer4.2.conv1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 234\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 130, 131, 132, 137, 139, 143, 144, 145, 149, 153, 157, 158, 159,\n",
      "        163, 164, 165, 166, 167, 168, 169, 170, 172, 174, 175, 176, 178, 181,\n",
      "        184, 185, 187, 188, 190, 191, 192, 193, 195, 198, 199, 202, 203, 208,\n",
      "        209, 211, 213, 214, 217, 218, 221, 224, 225, 227, 229, 232, 233, 234,\n",
      "        236, 239, 241, 243, 244, 246, 247, 249, 250, 252, 254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 264, 266, 267, 268, 270, 272, 273, 275, 276, 280,\n",
      "        281, 286, 290, 292, 294, 295, 296, 298, 300, 302, 305, 307, 308, 309,\n",
      "        310, 314, 315, 322, 324, 325, 327, 328, 329, 330, 331, 332, 333, 335,\n",
      "        341, 342, 344, 348, 351, 354, 356, 362, 364, 365, 366, 369, 370, 375,\n",
      "        376, 378, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 388, 389, 391, 398, 401, 403, 404, 406, 413, 416, 417, 418,\n",
      "        420, 421, 422, 425, 427, 429, 430, 433, 436, 437, 441, 443, 446, 447,\n",
      "        450, 453, 456, 460, 462, 465, 471, 473, 474, 477, 478, 479, 480, 482,\n",
      "        483, 487, 489, 490, 493, 494, 496, 500, 503]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 234\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  1,   2,   3,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,  17,  18,  19,  20,  21,  22,  23,  24,  26,  28,  29,  30,  31,\n",
      "         32,  33,  34,  35,  36,  37,  39,  40,  41,  42,  43,  44,  45,  46,\n",
      "         47,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
      "         63,  64,  65,  66,  67,  69,  70,  71,  72,  74,  75,  76,  78,  79,\n",
      "         80,  81,  82,  83,  84,  85,  86,  90,  91,  93,  95,  97,  98,  99,\n",
      "        101, 102, 103, 105, 106, 107, 108, 110, 112, 113, 114, 115, 117, 118,\n",
      "        119, 120, 121, 122, 125, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 234\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  21,  22,  24,  25,  26,  27,  29,  30,  31,\n",
      "         32,  34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
      "         49,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "         79,  80,  81,  82,  83,  84,  87,  88,  89,  90,  91,  92,  95,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 125, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Saving input for later...\n",
      "\t\t-Splitting conv layer 234\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  37,  38,  39,  40,  41,  42,  43,\n",
      "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "         58,  59,  60,  61,  62,  63,  64,  65,  66,  68,  69,  70,  71,  72,\n",
      "         73,  74,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "         89,  90,  91,  92,  93,  95,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "        119, 120, 121, 122, 123, 124, 125, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 234\n",
      "Max diff:\n",
      " tensor([1.4211e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[8.8818e-15, 1.2434e-14, 1.0658e-14, 7.1054e-15, 1.7764e-14, 1.1546e-14,\n",
      "         2.3093e-14, 1.0658e-14, 2.1094e-14, 1.4211e-14, 1.8652e-14, 1.4211e-14,\n",
      "         1.4211e-14, 1.2434e-14, 1.0214e-14, 8.8818e-15, 7.1054e-15, 1.1546e-14,\n",
      "         1.9096e-14, 2.1316e-14, 1.5987e-14, 8.8818e-15, 9.8810e-15, 1.4211e-14,\n",
      "         1.1546e-14, 8.8818e-15, 7.9936e-15, 1.5987e-14, 1.2434e-14, 7.1054e-15,\n",
      "         1.1102e-14, 1.4211e-14, 1.2851e-14, 4.4409e-16, 1.3323e-14, 9.7700e-15,\n",
      "         8.8818e-15, 1.5987e-14, 8.8818e-15, 1.8652e-14, 1.5987e-14, 1.7764e-14,\n",
      "         1.3767e-14, 1.2434e-14, 1.5099e-14, 1.5987e-14, 2.1316e-14, 1.4211e-14,\n",
      "         5.3291e-15, 1.0658e-14, 1.4211e-14, 2.1316e-14, 1.5987e-14, 2.3093e-14,\n",
      "         1.2879e-14, 1.7764e-14, 1.6126e-14, 1.1380e-14, 1.5987e-14, 2.8422e-14,\n",
      "         1.2434e-14, 2.8422e-14, 1.0658e-14, 1.4211e-14, 1.2434e-14, 1.4211e-14,\n",
      "         1.5987e-14, 8.8818e-15, 8.8818e-15, 1.2434e-14, 1.5099e-14, 1.0658e-14,\n",
      "         8.6042e-15, 1.4211e-14, 2.8422e-14, 1.4211e-14, 2.1316e-14, 1.1990e-14,\n",
      "         1.4211e-14, 2.1316e-14, 1.4211e-14, 1.2434e-14, 1.4211e-14, 1.4211e-14,\n",
      "         8.4377e-15, 7.5495e-15, 7.1054e-15, 1.5987e-14, 1.1990e-14, 2.2204e-14,\n",
      "         1.4211e-14, 1.2434e-14, 7.1054e-15, 1.3323e-15, 1.7764e-14, 1.8652e-14,\n",
      "         1.2837e-14, 1.7764e-14, 1.0658e-14, 1.2434e-14, 1.5987e-14, 1.0658e-14,\n",
      "         1.4211e-14, 1.2434e-14, 1.2434e-14, 1.5987e-14, 1.5987e-14, 8.8818e-15,\n",
      "         1.3767e-14, 1.1102e-14, 2.1316e-14, 7.1054e-15, 8.6597e-15, 7.1054e-15,\n",
      "         1.2434e-14, 1.7764e-14, 1.3323e-14, 1.7764e-14, 1.1102e-14, 1.5987e-14,\n",
      "         6.3283e-15, 7.9936e-15, 1.5987e-14, 1.9540e-14, 1.4211e-14, 1.4211e-14,\n",
      "         1.2434e-14, 1.2712e-14, 3.5527e-14, 2.4869e-14, 3.5527e-14, 3.5527e-14,\n",
      "         7.8160e-14, 4.2633e-14, 4.9738e-14, 7.1054e-14, 4.2633e-14, 3.5527e-14,\n",
      "         2.4869e-14, 3.5527e-14, 6.3949e-14, 6.7502e-14, 7.1054e-14, 2.0206e-14,\n",
      "         2.6645e-14, 3.5527e-14, 4.9738e-14, 4.9738e-14, 3.5527e-14, 4.9738e-14,\n",
      "         9.2371e-14, 3.1974e-14, 2.8422e-14, 7.8160e-14, 3.0198e-14, 5.6843e-14,\n",
      "         4.7962e-14, 2.6645e-14, 4.6185e-14, 2.2649e-14, 4.9738e-14, 3.1974e-14,\n",
      "         9.9476e-14, 2.1316e-14, 3.1974e-14, 3.5527e-14, 3.1974e-14, 4.9738e-14,\n",
      "         2.8422e-14, 2.0428e-14, 7.1054e-14, 3.9080e-14, 5.6843e-14, 2.8422e-14,\n",
      "         4.2633e-14, 3.1974e-14, 2.3093e-14, 5.6843e-14, 2.1316e-14, 2.8422e-14,\n",
      "         3.1974e-14, 2.8422e-14, 2.8422e-14, 1.1369e-13, 2.8422e-14, 3.5527e-14,\n",
      "         3.1974e-14, 3.5527e-14, 3.1974e-14, 6.0396e-14, 3.5527e-14, 2.1316e-14,\n",
      "         3.5527e-14, 2.4869e-14, 7.1054e-14, 3.1974e-14, 4.9738e-14, 3.9080e-14,\n",
      "         3.5527e-14, 4.2633e-14, 3.5527e-14, 6.0396e-14, 4.9738e-14, 7.1054e-14,\n",
      "         3.5527e-14, 1.7764e-14, 4.2633e-14, 3.0198e-14, 7.1054e-14, 2.5757e-14,\n",
      "         2.8422e-14, 3.5527e-14, 5.6843e-14, 5.2403e-14, 4.9738e-14, 3.5527e-14,\n",
      "         3.1974e-14, 3.7303e-14, 2.8422e-14, 2.8422e-14, 2.8422e-14, 4.8850e-14,\n",
      "         3.5527e-14, 4.9738e-14, 3.3751e-14, 6.3949e-14, 3.1974e-14, 2.8422e-14,\n",
      "         2.7867e-14, 1.1324e-14, 5.6843e-14, 3.1974e-14, 3.3085e-14, 1.7764e-14,\n",
      "         4.2633e-14, 2.8422e-14, 2.8422e-14, 4.9738e-14, 2.8422e-14, 3.4639e-14,\n",
      "         4.9738e-14, 5.6843e-14, 4.6185e-14, 4.6185e-14, 3.9080e-14, 6.3949e-14,\n",
      "         6.3949e-14, 3.5527e-14, 1.7764e-14, 7.1054e-14, 3.9080e-14, 1.7764e-14,\n",
      "         2.1316e-14, 1.4211e-14, 3.5527e-14, 3.2196e-14, 3.9080e-14, 7.1054e-14,\n",
      "         2.1316e-14, 7.1054e-14, 3.5527e-14, 3.1974e-14, 4.2633e-14, 7.1054e-14,\n",
      "         6.3949e-14, 4.9738e-14, 1.7764e-14, 4.9738e-14, 5.6843e-14, 4.9738e-14,\n",
      "         6.3949e-14, 5.6843e-14, 7.1054e-14, 3.5527e-14, 1.5987e-14, 5.6843e-14,\n",
      "         4.2633e-14, 4.2633e-14, 4.9738e-14, 5.6843e-14, 3.5527e-14, 1.1369e-13,\n",
      "         2.1316e-14, 3.5527e-14, 4.9738e-14, 4.6185e-14, 5.6843e-14, 9.2371e-14,\n",
      "         4.9738e-14, 3.0198e-14, 5.6843e-14, 2.8422e-14, 5.3291e-14, 6.3949e-14,\n",
      "         7.1054e-14, 3.5527e-14, 4.2633e-14, 7.8160e-14, 4.2633e-14, 5.6843e-14,\n",
      "         3.0198e-14, 4.2633e-14, 1.0658e-14, 4.9738e-14, 1.7542e-14, 2.1316e-14,\n",
      "         4.2633e-14, 1.9540e-14, 2.1316e-14, 9.9476e-14, 4.2633e-14, 2.1316e-14,\n",
      "         4.2633e-14, 4.2633e-14, 8.5265e-14, 2.1316e-14, 3.5527e-14, 4.2633e-14,\n",
      "         2.4869e-14, 3.5527e-14, 2.8422e-14, 6.3949e-14, 3.9080e-14, 8.5265e-14,\n",
      "         2.1316e-14, 3.1974e-14, 3.5527e-14, 5.0848e-14, 6.3949e-14, 6.3949e-14,\n",
      "         5.6843e-14, 2.8422e-14, 5.2403e-14, 9.2371e-14, 2.1316e-14, 4.9738e-14,\n",
      "         5.6843e-14, 3.5527e-14, 5.6843e-14, 7.8160e-14, 1.4211e-14, 3.5527e-14,\n",
      "         3.9080e-14, 2.5757e-14, 3.5527e-14, 7.8160e-14, 3.5527e-14, 2.9310e-14,\n",
      "         1.7764e-14, 4.2633e-14, 4.2633e-14, 3.5527e-14, 3.5527e-14, 3.9080e-14,\n",
      "         4.9738e-14, 3.5527e-14, 4.9738e-14, 2.6645e-14, 3.1974e-14, 7.8160e-14,\n",
      "         3.5527e-14, 3.1974e-14, 6.3949e-14, 5.6843e-14, 4.9738e-14, 6.3949e-14,\n",
      "         6.3949e-14, 4.2633e-14, 6.3949e-14, 2.4869e-14, 2.8422e-14, 5.3291e-14,\n",
      "         3.1974e-14, 6.3949e-14, 4.2633e-14, 4.2633e-14, 2.4869e-14, 4.2633e-14,\n",
      "         2.8422e-14, 3.5527e-14, 4.2633e-14, 3.9080e-14, 1.3323e-14, 3.5527e-14,\n",
      "         4.2633e-14, 2.3981e-14, 4.6185e-14, 2.8422e-14, 4.2633e-14, 4.2633e-14,\n",
      "         2.4869e-14, 7.1054e-14, 6.3949e-14, 1.7764e-14, 2.4869e-14, 5.6843e-14,\n",
      "         3.5527e-14, 2.1316e-14, 7.1054e-14, 4.9738e-14, 5.6843e-14, 7.1054e-14,\n",
      "         4.9738e-14, 3.5527e-14, 3.5527e-14, 9.2371e-14, 4.2633e-14, 4.9738e-14,\n",
      "         4.2633e-14, 2.8422e-14, 6.3949e-14, 4.2633e-14, 4.2633e-14, 4.9738e-14,\n",
      "         4.9738e-14, 7.1054e-14, 3.9080e-14, 7.1054e-14, 2.8422e-14, 4.0856e-14,\n",
      "         3.5527e-14, 7.1054e-14, 6.3949e-14, 4.2633e-14, 2.8422e-14, 2.4869e-14,\n",
      "         4.0856e-14, 4.2633e-14, 3.9080e-14, 4.9738e-14, 4.2633e-14, 7.1054e-14,\n",
      "         9.9476e-14, 4.6185e-14, 2.1316e-14, 3.5527e-14, 2.1316e-14, 4.9738e-14,\n",
      "         5.6843e-14, 7.1054e-14, 4.9738e-14, 3.5083e-14, 5.6843e-14, 3.3751e-14,\n",
      "         7.1054e-14, 5.6843e-14, 4.9738e-14, 2.8422e-14, 4.9738e-14, 2.8422e-14,\n",
      "         3.9080e-14, 3.1974e-14, 3.8636e-14, 4.9738e-14, 7.1054e-14, 4.0856e-14,\n",
      "         3.1974e-14, 3.9080e-14, 3.3751e-14, 5.6843e-14, 3.1974e-14, 4.2633e-14,\n",
      "         3.0198e-14, 2.8422e-14, 4.2633e-14, 2.8422e-14, 4.2633e-14, 5.6843e-14,\n",
      "         3.5527e-14, 1.4211e-13, 4.9294e-14, 3.1974e-14, 7.1054e-14, 4.6185e-14,\n",
      "         4.2633e-14, 4.9738e-14, 4.9738e-14, 2.8422e-14, 4.2633e-14, 3.5527e-14,\n",
      "         4.2633e-14, 2.8422e-14, 3.5527e-14, 8.5265e-14, 4.2633e-14, 2.4869e-14,\n",
      "         4.6185e-14, 4.7073e-14, 5.6843e-14, 3.1974e-14, 3.1974e-14, 4.2633e-14,\n",
      "         3.5527e-14, 6.7502e-14, 3.1974e-14, 2.8422e-14, 4.2633e-14, 5.3291e-14,\n",
      "         2.8422e-14, 4.2633e-14, 5.6843e-14, 5.3291e-14, 3.5527e-14, 4.9738e-14,\n",
      "         3.9080e-14, 4.2633e-14, 3.1974e-14, 4.2633e-14, 4.2633e-14, 6.3949e-14,\n",
      "         4.2633e-14, 3.5527e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 235: layer4.2.bn1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 235\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 235\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 235\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 235\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 235\n",
      "Max diff:\n",
      " tensor([7.1054e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[2.6645e-15, 3.5527e-15, 4.4409e-15, 2.6645e-15, 6.2172e-15, 3.2196e-15,\n",
      "         8.8818e-15, 6.6613e-16, 6.7168e-15, 6.2172e-15, 5.9952e-15, 4.4409e-15,\n",
      "         3.5527e-15, 3.7748e-15, 2.7756e-15, 3.5527e-15, 3.1086e-15, 6.2172e-15,\n",
      "         5.5511e-15, 5.7732e-15, 5.3291e-15, 2.6645e-15, 4.3021e-15, 4.8850e-15,\n",
      "         3.8858e-15, 3.1086e-15, 2.8866e-15, 6.2172e-15, 3.6637e-15, 2.1094e-15,\n",
      "         3.1086e-15, 6.2172e-15, 4.7462e-15, 1.6653e-16, 3.9968e-15, 3.1086e-15,\n",
      "         2.6645e-15, 6.2172e-15, 3.5527e-15, 5.7732e-15, 5.3291e-15, 5.3291e-15,\n",
      "         4.6629e-15, 3.9968e-15, 5.7732e-15, 4.8850e-15, 8.8818e-15, 5.3291e-15,\n",
      "         1.8874e-15, 3.5527e-15, 7.1054e-15, 4.8850e-15, 5.3291e-15, 7.1054e-15,\n",
      "         2.7200e-15, 8.8818e-15, 5.3846e-15, 3.2196e-15, 5.5511e-15, 1.4211e-14,\n",
      "         4.6629e-15, 8.8818e-15, 3.5527e-15, 5.7732e-15, 3.7748e-15, 5.3291e-15,\n",
      "         7.1054e-15, 4.2188e-15, 1.5543e-15, 3.5527e-15, 4.4409e-15, 3.3307e-15,\n",
      "         1.9429e-15, 4.8850e-15, 1.4211e-14, 4.8850e-15, 8.8818e-15, 5.6621e-15,\n",
      "         5.3291e-15, 5.3291e-15, 6.2172e-15, 4.4409e-15, 5.3291e-15, 4.4409e-15,\n",
      "         2.3315e-15, 2.3315e-15, 2.6645e-15, 4.4409e-15, 3.1641e-15, 7.5495e-15,\n",
      "         4.4409e-15, 3.5527e-15, 2.6645e-15, 3.3307e-16, 4.4409e-15, 6.5503e-15,\n",
      "         3.4573e-15, 6.2172e-15, 4.4409e-15, 5.3291e-15, 6.2172e-15, 3.5527e-15,\n",
      "         5.3291e-15, 5.3291e-15, 2.6645e-15, 5.3291e-15, 3.5527e-15, 3.1086e-15,\n",
      "         4.6629e-15, 2.9976e-15, 7.1054e-15, 2.6645e-15, 2.6090e-15, 2.6645e-15,\n",
      "         3.5527e-15, 6.6613e-15, 4.2188e-15, 6.6613e-15, 4.6629e-15, 7.1054e-15,\n",
      "         2.2204e-15, 1.5543e-15, 4.4409e-15, 7.1054e-15, 4.4409e-15, 5.7732e-15,\n",
      "         5.3291e-15, 3.4972e-15, 1.5987e-14, 7.9936e-15, 1.0658e-14, 1.4211e-14,\n",
      "         3.1974e-14, 1.7764e-14, 2.4869e-14, 3.9080e-14, 1.4211e-14, 1.2434e-14,\n",
      "         8.2157e-15, 1.5987e-14, 2.3093e-14, 2.3093e-14, 4.2633e-14, 7.6328e-15,\n",
      "         1.0658e-14, 1.7764e-14, 2.1316e-14, 2.3093e-14, 1.7764e-14, 1.7764e-14,\n",
      "         4.6185e-14, 1.2879e-14, 1.0658e-14, 3.5527e-14, 9.9920e-15, 2.4869e-14,\n",
      "         2.7534e-14, 1.0658e-14, 1.7764e-14, 7.7716e-15, 1.5987e-14, 8.8818e-15,\n",
      "         4.6185e-14, 1.2434e-14, 1.1546e-14, 1.2434e-14, 1.2434e-14, 2.1316e-14,\n",
      "         1.7764e-14, 8.8818e-15, 3.1974e-14, 1.3323e-14, 2.4869e-14, 8.8818e-15,\n",
      "         2.4869e-14, 1.2434e-14, 8.8818e-15, 2.1316e-14, 7.9936e-15, 1.4211e-14,\n",
      "         1.1546e-14, 1.0658e-14, 1.2434e-14, 5.6843e-14, 9.7700e-15, 1.4211e-14,\n",
      "         1.0658e-14, 1.7764e-14, 1.0658e-14, 2.3981e-14, 1.0658e-14, 7.1054e-15,\n",
      "         1.0658e-14, 7.1054e-15, 4.2633e-14, 9.7700e-15, 1.7764e-14, 1.1546e-14,\n",
      "         2.1316e-14, 1.4211e-14, 1.7764e-14, 2.6645e-14, 2.1316e-14, 3.3751e-14,\n",
      "         1.4211e-14, 7.1054e-15, 1.7764e-14, 1.5099e-14, 3.1974e-14, 1.0214e-14,\n",
      "         1.1546e-14, 2.1316e-14, 2.4869e-14, 2.1760e-14, 1.5987e-14, 1.7764e-14,\n",
      "         1.0658e-14, 1.6875e-14, 1.0658e-14, 1.4211e-14, 1.2434e-14, 1.4433e-14,\n",
      "         1.5987e-14, 2.1316e-14, 1.0214e-14, 2.4869e-14, 8.8818e-15, 1.4211e-14,\n",
      "         1.0103e-14, 3.3862e-15, 2.4869e-14, 1.5987e-14, 1.3101e-14, 6.2172e-15,\n",
      "         2.1316e-14, 8.8818e-15, 1.1546e-14, 1.7764e-14, 1.0658e-14, 1.2434e-14,\n",
      "         2.4869e-14, 2.4869e-14, 1.5987e-14, 1.9540e-14, 1.9540e-14, 2.4869e-14,\n",
      "         3.5527e-14, 1.4211e-14, 6.2172e-15, 3.5527e-14, 1.7764e-14, 7.9936e-15,\n",
      "         1.0658e-14, 5.3291e-15, 1.0658e-14, 9.7145e-15, 1.7764e-14, 2.8422e-14,\n",
      "         1.1546e-14, 3.5527e-14, 1.4211e-14, 1.4211e-14, 1.7764e-14, 2.2204e-14,\n",
      "         2.8422e-14, 1.5987e-14, 6.2172e-15, 2.4869e-14, 2.4869e-14, 3.1974e-14,\n",
      "         4.6185e-14, 2.8422e-14, 2.3093e-14, 1.4211e-14, 5.3291e-15, 2.1316e-14,\n",
      "         1.4211e-14, 1.7764e-14, 2.4869e-14, 2.8422e-14, 1.4211e-14, 7.1054e-14,\n",
      "         1.2434e-14, 2.1316e-14, 2.1316e-14, 1.9540e-14, 2.8422e-14, 3.5527e-14,\n",
      "         2.4869e-14, 1.3323e-14, 2.8422e-14, 1.2434e-14, 2.1316e-14, 2.8422e-14,\n",
      "         2.6645e-14, 1.2434e-14, 2.6645e-14, 3.9080e-14, 2.1316e-14, 2.4869e-14,\n",
      "         1.8652e-14, 1.4211e-14, 3.5527e-15, 1.9540e-14, 8.7708e-15, 7.1054e-15,\n",
      "         2.1316e-14, 4.8850e-15, 1.0658e-14, 4.9738e-14, 2.8422e-14, 7.1054e-15,\n",
      "         2.1316e-14, 2.1316e-14, 3.5527e-14, 4.4409e-15, 1.0658e-14, 1.7764e-14,\n",
      "         1.7764e-14, 1.7764e-14, 1.0214e-14, 3.1974e-14, 1.5987e-14, 4.9738e-14,\n",
      "         8.8818e-15, 1.1546e-14, 1.7764e-14, 1.5987e-14, 2.4869e-14, 3.9080e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.0650e-14, 3.9080e-14, 1.3323e-14, 2.4869e-14,\n",
      "         2.4869e-14, 2.1316e-14, 2.8422e-14, 3.9080e-14, 6.2172e-15, 1.2434e-14,\n",
      "         1.9540e-14, 1.1546e-14, 1.7764e-14, 2.8422e-14, 1.7764e-14, 1.0214e-14,\n",
      "         5.3291e-15, 2.6645e-14, 2.4869e-14, 2.1316e-14, 1.4211e-14, 1.9540e-14,\n",
      "         2.1316e-14, 1.4211e-14, 2.4869e-14, 9.3259e-15, 1.0658e-14, 3.5527e-14,\n",
      "         1.4211e-14, 1.3323e-14, 3.5527e-14, 3.5527e-14, 2.1316e-14, 2.4869e-14,\n",
      "         2.4869e-14, 2.8422e-14, 2.8422e-14, 8.8818e-15, 1.4211e-14, 2.3093e-14,\n",
      "         1.2434e-14, 3.5527e-14, 2.4869e-14, 1.7764e-14, 8.8818e-15, 1.4211e-14,\n",
      "         1.2434e-14, 1.7764e-14, 1.7764e-14, 1.5987e-14, 3.2196e-15, 1.7764e-14,\n",
      "         1.2434e-14, 7.9936e-15, 1.3323e-14, 8.8818e-15, 1.2434e-14, 1.7764e-14,\n",
      "         1.0658e-14, 2.3093e-14, 2.3093e-14, 5.3291e-15, 8.8818e-15, 2.1316e-14,\n",
      "         1.7764e-14, 7.1054e-15, 2.6645e-14, 2.1316e-14, 2.1316e-14, 2.8422e-14,\n",
      "         1.5987e-14, 1.2434e-14, 9.7700e-15, 2.8422e-14, 1.5987e-14, 1.5987e-14,\n",
      "         1.5987e-14, 9.7700e-15, 2.4869e-14, 1.5987e-14, 1.0658e-14, 1.9540e-14,\n",
      "         2.1316e-14, 2.4869e-14, 1.2434e-14, 3.1974e-14, 1.0658e-14, 1.3767e-14,\n",
      "         1.2434e-14, 2.6645e-14, 2.6645e-14, 1.9540e-14, 8.8818e-15, 1.0658e-14,\n",
      "         1.4211e-14, 1.7764e-14, 1.3323e-14, 2.1316e-14, 1.5987e-14, 2.1316e-14,\n",
      "         2.6645e-14, 1.9540e-14, 6.2172e-15, 1.0658e-14, 7.1054e-15, 1.7764e-14,\n",
      "         2.4869e-14, 2.4869e-14, 1.7764e-14, 1.1768e-14, 2.4869e-14, 9.7700e-15,\n",
      "         2.4869e-14, 2.3093e-14, 1.7764e-14, 8.8818e-15, 1.7764e-14, 8.8818e-15,\n",
      "         1.7764e-14, 1.2434e-14, 1.0436e-14, 1.6875e-14, 2.1316e-14, 1.3323e-14,\n",
      "         1.0658e-14, 1.4211e-14, 1.2879e-14, 2.1316e-14, 1.2434e-14, 1.7764e-14,\n",
      "         9.7700e-15, 1.0658e-14, 1.2434e-14, 1.0658e-14, 1.7764e-14, 2.1316e-14,\n",
      "         1.4211e-14, 4.9738e-14, 1.4988e-14, 1.1546e-14, 3.1974e-14, 1.5987e-14,\n",
      "         1.5099e-14, 1.5987e-14, 1.5987e-14, 1.0658e-14, 1.4211e-14, 1.3323e-14,\n",
      "         1.0658e-14, 1.0658e-14, 1.2434e-14, 3.1974e-14, 1.4211e-14, 9.7700e-15,\n",
      "         1.4655e-14, 1.5349e-14, 2.1316e-14, 1.1546e-14, 1.0658e-14, 1.7764e-14,\n",
      "         1.4211e-14, 2.3093e-14, 1.2434e-14, 1.0658e-14, 1.7764e-14, 1.9540e-14,\n",
      "         7.9936e-15, 1.7764e-14, 2.1316e-14, 1.8652e-14, 1.2434e-14, 1.7764e-14,\n",
      "         1.5099e-14, 1.7764e-14, 1.2434e-14, 1.4211e-14, 1.4211e-14, 1.9540e-14,\n",
      "         1.5099e-14, 1.2434e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 236: layer4.2.relu\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 236\n",
      "Max diff:\n",
      " tensor([2.3093e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[6.3838e-16, 2.1094e-15, 0.0000e+00, 4.9960e-16, 0.0000e+00, 1.7764e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15, 4.4409e-15,\n",
      "         8.6042e-16, 0.0000e+00, 1.7764e-15, 0.0000e+00, 0.0000e+00, 3.7886e-15,\n",
      "         1.9429e-15, 5.7732e-15, 0.0000e+00, 0.0000e+00, 3.1086e-15, 1.9429e-15,\n",
      "         3.5527e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4988e-15,\n",
      "         2.6645e-15, 1.1657e-15, 4.7462e-15, 0.0000e+00, 0.0000e+00, 3.1086e-15,\n",
      "         1.8874e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6142e-15, 0.0000e+00,\n",
      "         3.7748e-15, 0.0000e+00, 8.8818e-16, 4.8850e-15, 0.0000e+00, 0.0000e+00,\n",
      "         9.4369e-16, 0.0000e+00, 0.0000e+00, 4.8850e-15, 0.0000e+00, 7.1054e-15,\n",
      "         2.7200e-15, 0.0000e+00, 5.3846e-15, 3.2196e-15, 1.5543e-15, 2.9907e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9976e-15, 3.7748e-15, 0.0000e+00,\n",
      "         0.0000e+00, 2.4425e-15, 0.0000e+00, 0.0000e+00, 4.4409e-15, 3.3307e-15,\n",
      "         1.9429e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6621e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4702e-15, 3.6776e-15, 0.0000e+00,\n",
      "         2.2204e-15, 2.3315e-15, 0.0000e+00, 0.0000e+00, 3.1641e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7732e-15,\n",
      "         3.4573e-15, 0.0000e+00, 2.2204e-15, 5.3291e-15, 3.8650e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.6645e-15, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         2.6645e-15, 2.9976e-15, 0.0000e+00, 0.0000e+00, 9.7145e-16, 0.0000e+00,\n",
      "         1.9984e-15, 0.0000e+00, 1.4433e-15, 0.0000e+00, 4.6629e-15, 0.0000e+00,\n",
      "         2.2204e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.9968e-15, 1.6428e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.9936e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6328e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-15, 6.3283e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-15, 0.0000e+00, 4.4409e-15,\n",
      "         0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.9984e-15, 8.8818e-15, 0.0000e+00, 7.7716e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.9405e-15, 1.6376e-15, 5.9952e-15, 0.0000e+00,\n",
      "         1.1546e-14, 7.1054e-15, 0.0000e+00, 0.0000e+00, 3.7470e-15, 0.0000e+00,\n",
      "         4.8850e-15, 0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 5.8842e-15,\n",
      "         0.0000e+00, 7.1054e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8834e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.8834e-15, 2.1760e-14, 1.4433e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.9968e-15, 0.0000e+00, 0.0000e+00, 1.4433e-14,\n",
      "         0.0000e+00, 0.0000e+00, 3.4417e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.8818e-15, 1.5543e-15, 0.0000e+00, 4.1763e-16, 1.1907e-14, 5.3291e-15,\n",
      "         0.0000e+00, 5.3291e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3275e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.9920e-16, 5.3291e-15, 0.0000e+00, 9.7145e-15, 0.0000e+00, 0.0000e+00,\n",
      "         3.1086e-15, 0.0000e+00, 1.4211e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 3.9968e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5527e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1241e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1078e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3323e-14, 0.0000e+00, 2.7756e-15, 0.0000e+00, 4.2188e-15,\n",
      "         0.0000e+00, 3.5527e-15, 0.0000e+00, 0.0000e+00, 1.1990e-14, 0.0000e+00,\n",
      "         1.5543e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7708e-15, 5.5511e-16,\n",
      "         0.0000e+00, 4.4409e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9397e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         7.3127e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.1062e-15, 5.7732e-15, 0.0000e+00, 1.1657e-14, 0.0000e+00, 9.7700e-15,\n",
      "         0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4417e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.9936e-15, 0.0000e+00, 8.6597e-15, 2.2204e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2188e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2196e-15, 0.0000e+00,\n",
      "         0.0000e+00, 7.9936e-15, 0.0000e+00, 7.9381e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.3259e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.7716e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4425e-15, 3.3307e-16, 0.0000e+00, 0.0000e+00, 5.5511e-15,\n",
      "         4.1217e-15, 9.9920e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6107e-15,\n",
      "         0.0000e+00, 0.0000e+00, 7.3275e-15, 0.0000e+00, 2.9421e-15, 9.7700e-15,\n",
      "         2.1094e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.5527e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-16,\n",
      "         0.0000e+00, 0.0000e+00, 6.2172e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3323e-15, 2.7756e-16, 0.0000e+00, 6.6613e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4417e-15, 3.3862e-15, 0.0000e+00, 4.4409e-15,\n",
      "         0.0000e+00, 3.2196e-15, 1.0436e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3315e-15, 0.0000e+00, 1.0214e-14, 0.0000e+00, 7.1054e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.0658e-14, 6.2172e-15, 5.8521e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.5495e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.3323e-14, 1.5349e-14, 0.0000e+00, 1.7764e-15, 6.8834e-15, 0.0000e+00,\n",
      "         0.0000e+00, 2.3093e-14, 0.0000e+00, 0.0000e+00, 5.7732e-15, 0.0000e+00,\n",
      "         4.8850e-15, 1.5987e-14, 0.0000e+00, 1.1102e-14, 0.0000e+00, 0.0000e+00,\n",
      "         1.5099e-14, 0.0000e+00, 3.8858e-15, 6.2450e-15, 0.0000e+00, 4.4409e-15,\n",
      "         0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
      " tensor([  0,   1,   3,   5,  10,  11,  12,  14,  17,  18,  19,  22,  23,  24,\n",
      "         29,  30,  31,  32,  35,  36,  40,  42,  44,  45,  48,  51,  53,  54,\n",
      "         56,  57,  58,  59,  63,  64,  67,  70,  71,  72,  77,  81,  82,  84,\n",
      "         85,  88,  95,  96,  98,  99, 100, 104, 106, 108, 109, 112, 114, 116,\n",
      "        118, 120, 126, 127, 138, 143, 151, 152, 154, 159, 161, 164, 168, 169,\n",
      "        171, 176, 177, 178, 180, 181, 184, 186, 189, 191, 193, 201, 207, 212,\n",
      "        213, 214, 218, 221, 224, 228, 229, 231, 232, 233, 235, 239, 242, 252,\n",
      "        253, 255, 258, 260, 266, 269, 274, 280, 285, 289, 291, 293, 295, 298,\n",
      "        300, 304, 305, 307, 311, 316, 318, 324, 325, 327, 329, 332, 336, 340,\n",
      "        348, 355, 357, 358, 369, 382, 385, 387, 392, 396, 403, 404, 407, 408,\n",
      "        409, 413, 416, 418, 419, 420, 426, 431, 434, 438, 439, 441, 446, 447,\n",
      "        449, 451, 452, 456, 458, 460, 463, 464, 465, 470, 483, 486, 487, 489,\n",
      "        490, 493, 496, 498, 499, 501, 504, 506, 507, 509])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   3,   5,  10,  11,  12,  14,  17,  18,  19,  22,  23,  24,\n",
      "         29,  30,  31,  32,  35,  36,  40,  42,  44,  45,  48,  51,  53,  54,\n",
      "         56,  57,  58,  59,  63,  64,  67,  70,  71,  72,  77,  81,  82,  84,\n",
      "         85,  88,  95,  96,  98,  99, 100, 104, 106, 108, 109, 112, 114, 116,\n",
      "        118, 120, 126, 127, 138, 143, 151, 152, 154, 159, 161, 164, 168, 169,\n",
      "        171, 176, 177, 178, 180, 181, 184, 186, 189, 191, 193, 201, 207, 212,\n",
      "        213, 214, 218, 221, 224, 228, 229, 231, 232, 233, 235, 239, 242, 252,\n",
      "        253, 255, 258, 260, 266, 269, 274, 280, 285, 289, 291, 293, 295, 298,\n",
      "        300, 304, 305, 307, 311, 316, 318, 324, 325, 327, 329, 332, 336, 340,\n",
      "        348, 355, 357, 358, 369, 382, 385, 387, 392, 396, 403, 404, 407, 408,\n",
      "        409, 413, 416, 418, 419, 420, 426, 431, 434, 438, 439, 441, 446, 447,\n",
      "        449, 451, 452, 456, 458, 460, 463, 464, 465, 470, 483, 486, 487, 489,\n",
      "        490, 493, 496, 498, 499, 501, 504, 506, 507, 509])  (len = 178)\n",
      "passing Cout = tensor([209])  (len = 1)\n",
      "\n",
      "Executing module 237: layer4.2.conv2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting conv layer 237\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([129, 131, 138, 141, 142, 143, 144, 145, 157, 161, 162, 166, 170, 172,\n",
      "        176, 177, 183, 189, 194, 195, 204, 207, 208, 219, 221, 222, 225, 226,\n",
      "        230, 235, 236, 242, 243, 247, 250, 252, 254]) to machine 1\n",
      "\t\t sending C_out tensor([262, 263, 264, 270, 273, 276, 277, 282, 287, 288, 290, 292, 293, 294,\n",
      "        297, 298, 300, 302, 304, 305, 308, 309, 310, 311, 312, 332, 333, 335,\n",
      "        337, 338, 347, 348, 350, 353, 356, 359, 360, 363, 364, 365, 367, 372,\n",
      "        373, 377, 383]) to machine 2\n",
      "\t\t sending C_out tensor([387, 388, 390, 391, 392, 395, 397, 398, 399, 400, 401, 402, 404, 405,\n",
      "        407, 408, 412, 414, 415, 416, 417, 421, 422, 423, 425, 427, 428, 430,\n",
      "        431, 432, 438, 439, 440, 447, 450, 451, 454, 455, 456, 457, 458, 462,\n",
      "        464, 465, 466, 467, 469, 473, 476, 477, 479, 481, 484, 487, 488, 489,\n",
      "        494, 498, 499, 501, 503, 504, 511]) to machine 3\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting conv layer 237\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,  30,\n",
      "         31,  32,  33,  34,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "         46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
      "         61,  62,  65,  66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,\n",
      "         79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,  92,  94,  95,\n",
      "         96,  97,  98,  99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting conv layer 237\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  1,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,  14,  16,  19,\n",
      "         20,  21,  23,  24,  25,  26,  27,  29,  30,  31,  32,  33,  36,  37,\n",
      "         38,  42,  43,  45,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  63,  64,  66,  67,  68,  69,  70,  71,  73,\n",
      "         74,  75,  78,  79,  80,  81,  82,  84,  85,  86,  87,  89,  90,  92,\n",
      "         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 105, 109, 110,\n",
      "        112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
      "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "        227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "        241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "        255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting conv layer 237\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127]) to machine 0\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 237\n",
      "Max diff:\n",
      " tensor([1.2079e-13], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.2434e-14, 2.4869e-14, 1.7764e-14, 2.1316e-14, 2.4869e-14, 1.2879e-14,\n",
      "         1.9540e-14, 2.8422e-14, 2.1316e-14, 2.8422e-14, 1.4211e-14, 3.9080e-14,\n",
      "         2.8422e-14, 4.9738e-14, 1.7764e-14, 2.8422e-14, 2.8422e-14, 1.2434e-14,\n",
      "         2.1316e-14, 1.7764e-14, 1.7764e-14, 4.2633e-14, 1.4211e-14, 1.4211e-14,\n",
      "         2.8422e-14, 2.1316e-14, 1.4211e-14, 2.8422e-14, 1.7764e-14, 2.8422e-14,\n",
      "         2.8422e-14, 1.7764e-14, 1.5987e-14, 2.8422e-14, 1.5987e-14, 2.4869e-14,\n",
      "         1.4211e-14, 1.7764e-14, 2.4869e-14, 1.4211e-14, 1.7764e-14, 1.7764e-14,\n",
      "         1.4211e-14, 1.7764e-14, 1.7764e-14, 1.7764e-14, 3.5527e-14, 7.1054e-15,\n",
      "         2.4869e-14, 2.8422e-14, 1.2434e-14, 1.8319e-14, 1.4211e-14, 2.3093e-14,\n",
      "         8.4377e-15, 2.4869e-14, 1.4211e-14, 2.8422e-14, 1.7764e-14, 2.1316e-14,\n",
      "         1.7764e-14, 3.5527e-14, 3.5527e-14, 1.3767e-14, 2.1316e-14, 2.1316e-14,\n",
      "         1.1546e-14, 3.1974e-14, 2.1316e-14, 1.4211e-14, 2.4869e-14, 1.4211e-14,\n",
      "         1.4211e-14, 1.0658e-14, 2.4869e-14, 1.4211e-14, 2.1316e-14, 1.4211e-14,\n",
      "         2.1316e-14, 2.1316e-14, 1.5987e-14, 3.1974e-14, 2.4869e-14, 1.1990e-14,\n",
      "         1.7764e-14, 3.5527e-14, 8.8818e-15, 2.1316e-14, 1.4211e-14, 1.6875e-14,\n",
      "         3.5527e-14, 2.1316e-14, 2.8422e-14, 1.7764e-14, 4.2633e-14, 9.7700e-15,\n",
      "         2.1316e-14, 4.2633e-14, 1.4211e-14, 2.3093e-14, 1.7764e-14, 1.7764e-14,\n",
      "         2.4869e-14, 1.7764e-14, 1.5987e-14, 2.3093e-14, 1.7764e-14, 2.1316e-14,\n",
      "         1.0658e-14, 1.7764e-14, 2.1316e-14, 2.1316e-14, 2.8422e-14, 1.9540e-14,\n",
      "         1.4211e-14, 2.8422e-14, 2.3093e-14, 2.4869e-14, 4.2633e-14, 1.0658e-14,\n",
      "         7.1054e-15, 3.1974e-14, 1.7764e-14, 2.1316e-14, 3.5527e-15, 2.8422e-14,\n",
      "         1.7764e-14, 2.8422e-14, 3.0198e-14, 5.3291e-14, 2.8422e-14, 3.1974e-14,\n",
      "         2.8422e-14, 3.9080e-14, 4.2633e-14, 3.3751e-14, 4.9738e-14, 1.7542e-14,\n",
      "         2.1316e-14, 1.7764e-14, 3.5527e-14, 2.8422e-14, 3.1974e-14, 2.1094e-14,\n",
      "         2.4869e-14, 4.2633e-14, 3.0198e-14, 3.7303e-14, 5.6843e-14, 2.4869e-14,\n",
      "         2.4869e-14, 1.7764e-14, 1.3545e-14, 2.4869e-14, 2.4869e-14, 2.8422e-14,\n",
      "         3.1974e-14, 1.4211e-14, 4.9738e-14, 1.2079e-13, 2.8422e-14, 2.1316e-14,\n",
      "         3.1974e-14, 3.1974e-14, 3.5527e-14, 2.8422e-14, 4.2633e-14, 5.6843e-14,\n",
      "         1.7764e-14, 2.6645e-14, 4.2633e-14, 3.1974e-14, 2.1316e-14, 3.1974e-14,\n",
      "         4.9738e-14, 4.2633e-14, 2.3093e-14, 4.9738e-14, 4.2633e-14, 5.6843e-14,\n",
      "         3.1974e-14, 2.4869e-14, 3.1974e-14, 2.4869e-14, 4.2633e-14, 2.4869e-14,\n",
      "         3.0198e-14, 2.0428e-14, 2.0428e-14, 1.1990e-14, 3.5527e-14, 2.4869e-14,\n",
      "         4.2633e-14, 2.4869e-14, 2.6645e-14, 9.2371e-14, 2.4869e-14, 2.1316e-14,\n",
      "         2.8422e-14, 1.5987e-14, 3.0198e-14, 2.1427e-14, 1.9540e-14, 3.5527e-14,\n",
      "         1.7764e-14, 6.3949e-14, 4.6185e-14, 4.9738e-14, 3.9080e-14, 5.6843e-14,\n",
      "         2.1316e-14, 3.3751e-14, 1.6875e-14, 3.1974e-14, 4.2633e-14, 1.4211e-14,\n",
      "         2.8422e-14, 1.7764e-14, 4.2633e-14, 1.9540e-14, 2.9310e-14, 2.1316e-14,\n",
      "         2.1316e-14, 1.2434e-14, 4.2633e-14, 1.5987e-14, 1.4211e-14, 2.8422e-14,\n",
      "         2.4869e-14, 1.7764e-14, 2.1316e-14, 4.9738e-14, 3.3751e-14, 1.9540e-14,\n",
      "         3.1974e-14, 3.3751e-14, 3.5527e-14, 3.9080e-14, 4.2633e-14, 2.8422e-14,\n",
      "         4.6185e-14, 3.5527e-14, 1.9540e-14, 4.2633e-14, 5.6843e-14, 1.4211e-14,\n",
      "         2.3093e-14, 2.0983e-14, 1.7764e-14, 4.2633e-14, 2.4869e-14, 4.0856e-14,\n",
      "         1.7764e-14, 2.4869e-14, 2.1316e-14, 2.4869e-14, 3.1974e-14, 2.1316e-14,\n",
      "         1.1546e-14, 1.8874e-14, 1.4211e-14, 3.1974e-14, 2.4869e-14, 4.9738e-14,\n",
      "         3.4639e-14, 1.7764e-14, 3.5527e-14, 1.7764e-14, 1.4211e-14, 3.5527e-14,\n",
      "         4.9738e-14, 2.6645e-14, 3.9080e-14, 1.7764e-14, 2.4869e-14, 3.5527e-14,\n",
      "         2.8422e-14, 2.8422e-14, 3.0198e-14, 1.7319e-14, 4.7962e-14, 1.4877e-14,\n",
      "         3.0198e-14, 3.5527e-14, 1.9540e-14, 2.4869e-14, 2.1316e-14, 3.9080e-14,\n",
      "         2.8422e-14, 2.1316e-14, 3.1974e-14, 4.9738e-14, 2.8422e-14, 1.7764e-14,\n",
      "         6.3949e-14, 2.4869e-14, 2.1316e-14, 1.7764e-14, 2.4869e-14, 1.7764e-14,\n",
      "         3.9080e-14, 2.8422e-14, 1.7764e-14, 2.1316e-14, 1.2434e-14, 2.8422e-14,\n",
      "         2.1316e-14, 1.4211e-14, 2.8422e-14, 3.5527e-14, 4.2633e-14, 2.6645e-14,\n",
      "         1.7764e-14, 3.9080e-14, 1.4211e-14, 2.3093e-14, 2.1316e-14, 2.4869e-14,\n",
      "         1.5987e-14, 2.4869e-14, 1.4211e-14, 4.2633e-14, 1.2434e-14, 1.4211e-14,\n",
      "         1.5987e-14, 1.9540e-14, 1.9540e-14, 2.1316e-14, 2.8422e-14, 2.3537e-14,\n",
      "         3.1974e-14, 2.6645e-14, 2.6645e-14, 1.7764e-14, 5.6843e-14, 2.1316e-14,\n",
      "         2.1316e-14, 2.1316e-14, 1.0658e-14, 2.2204e-14, 2.1316e-14, 2.4869e-14,\n",
      "         8.8818e-15, 3.1974e-14, 2.8422e-14, 3.5527e-14, 1.5987e-14, 2.4869e-14,\n",
      "         2.6645e-14, 2.4869e-14, 2.4869e-14, 3.5527e-14, 3.5527e-14, 1.4211e-14,\n",
      "         2.5757e-14, 1.4211e-14, 3.0198e-14, 1.9540e-14, 2.1316e-14, 2.8422e-14,\n",
      "         4.9738e-14, 4.2633e-14, 2.1316e-14, 2.1316e-14, 1.5987e-14, 4.9738e-14,\n",
      "         4.9738e-14, 4.2633e-14, 1.0658e-14, 1.6875e-14, 2.4869e-14, 2.8422e-14,\n",
      "         2.4869e-14, 1.7764e-14, 3.1974e-14, 6.3949e-14, 2.1316e-14, 3.1974e-14,\n",
      "         1.4211e-14, 1.3323e-14, 3.5527e-14, 2.1316e-14, 2.1316e-14, 3.1974e-14,\n",
      "         2.8422e-14, 2.4869e-14, 2.8422e-14, 3.1974e-14, 4.6185e-14, 2.8422e-14,\n",
      "         2.3093e-14, 2.1316e-14, 1.4211e-14, 1.7764e-14, 2.1316e-14, 4.9738e-14,\n",
      "         2.8422e-14, 2.4869e-14, 7.1054e-14, 1.5987e-14, 2.1316e-14, 4.6185e-14,\n",
      "         2.4869e-14, 4.2633e-14, 3.1086e-14, 2.8422e-14, 4.0856e-14, 1.7764e-14,\n",
      "         4.2633e-14, 2.1316e-14, 3.1974e-14, 2.7534e-14, 3.1974e-14, 4.0856e-14,\n",
      "         4.2633e-14, 1.5987e-14, 3.5527e-14, 3.9080e-14, 3.1974e-14, 2.4869e-14,\n",
      "         4.9738e-14, 2.4869e-14, 1.9762e-14, 2.6645e-14, 2.1316e-14, 3.5527e-14,\n",
      "         4.2633e-14, 2.3981e-14, 2.8422e-14, 2.8422e-14, 3.9080e-14, 4.6185e-14,\n",
      "         2.8422e-14, 2.8422e-14, 6.3949e-14, 1.7319e-14, 2.4869e-14, 4.2633e-14,\n",
      "         3.5527e-14, 2.1316e-14, 3.5527e-14, 4.2633e-14, 2.4869e-14, 2.8422e-14,\n",
      "         2.8422e-14, 1.5987e-14, 3.1974e-14, 3.5527e-14, 2.8422e-14, 3.3751e-14,\n",
      "         2.8422e-14, 3.9080e-14, 3.3751e-14, 1.5987e-14, 2.8422e-14, 2.8422e-14,\n",
      "         1.4211e-14, 8.5265e-14, 2.1316e-14, 3.5527e-14, 1.9540e-14, 2.3093e-14,\n",
      "         3.5527e-14, 3.1974e-14, 3.2349e-14, 1.5987e-14, 5.3291e-14, 4.6185e-14,\n",
      "         3.1974e-14, 2.4869e-14, 1.0658e-14, 2.4869e-14, 3.5527e-14, 3.1974e-14,\n",
      "         3.1974e-14, 2.4869e-14, 2.9643e-14, 3.9080e-14, 3.9080e-14, 3.0198e-14,\n",
      "         3.0198e-14, 1.7764e-14, 2.0428e-14, 2.6645e-14, 3.1974e-14, 3.1974e-14,\n",
      "         4.8850e-14, 3.1974e-14, 1.2657e-14, 5.6843e-14, 2.4869e-14, 2.1316e-14,\n",
      "         1.4211e-14, 3.5527e-14, 3.9080e-14, 2.8422e-14, 4.2633e-14, 3.1974e-14,\n",
      "         2.4869e-14, 2.8422e-14, 4.6185e-14, 3.7303e-14, 1.8985e-14, 1.9540e-14,\n",
      "         2.2871e-14, 4.2633e-14, 2.1316e-14, 1.2434e-14, 2.8422e-14, 2.4869e-14,\n",
      "         2.8422e-14, 5.1514e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 238: layer4.2.bn2\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting batch norm layer 238\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting batch norm layer 238\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255]) to machine 1\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting batch norm layer 238\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383]) to machine 2\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting batch norm layer 238\n",
      "\t\t Output tensor shape : torch.Size([1, 512, 4, 4])\n",
      "\t\t sending C_out tensor([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "        398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "        426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "        440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
      "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "        510, 511]) to machine 3\n",
      "Finished execution of layer 238\n",
      "Max diff:\n",
      " tensor([6.0396e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.1086e-15, 7.1054e-15, 5.3291e-15, 6.2172e-15, 4.4409e-15, 1.8388e-15,\n",
      "         7.1054e-15, 7.9936e-15, 5.3291e-15, 1.0658e-14, 4.4409e-15, 6.2172e-15,\n",
      "         8.8818e-15, 9.7700e-15, 7.1054e-15, 7.9936e-15, 8.8818e-15, 2.4425e-15,\n",
      "         7.9936e-15, 3.9968e-15, 2.2204e-15, 8.8818e-15, 5.3291e-15, 6.2172e-15,\n",
      "         1.4211e-14, 8.8818e-15, 3.5527e-15, 1.1546e-14, 6.2172e-15, 4.4409e-15,\n",
      "         6.2172e-15, 7.1054e-15, 3.9968e-15, 1.1546e-14, 6.6613e-15, 1.0658e-14,\n",
      "         2.6645e-15, 5.3291e-15, 7.1054e-15, 4.4409e-15, 1.4433e-15, 3.5527e-15,\n",
      "         3.5527e-15, 6.2172e-15, 5.3291e-15, 7.9936e-15, 1.9540e-14, 1.7764e-15,\n",
      "         8.8818e-15, 5.3291e-15, 1.2212e-15, 5.9952e-15, 1.5543e-15, 1.2434e-14,\n",
      "         1.1657e-15, 2.6645e-15, 4.4409e-15, 1.0658e-14, 7.1054e-15, 5.3291e-15,\n",
      "         5.3291e-15, 4.4409e-15, 1.7764e-14, 3.4417e-15, 4.4409e-15, 4.4409e-15,\n",
      "         9.9920e-16, 9.7700e-15, 5.3291e-15, 3.9968e-15, 1.0658e-14, 3.5527e-15,\n",
      "         2.6645e-15, 3.5527e-15, 8.8818e-15, 7.4940e-16, 7.1054e-15, 4.4409e-15,\n",
      "         6.2172e-15, 7.1054e-15, 2.1094e-15, 1.4211e-14, 6.2172e-15, 1.4433e-15,\n",
      "         3.5527e-15, 1.7764e-14, 2.6645e-15, 7.1054e-15, 3.5527e-15, 6.2172e-15,\n",
      "         1.4211e-14, 7.1054e-15, 1.0658e-14, 6.2172e-15, 6.6613e-15, 2.4425e-15,\n",
      "         5.3291e-15, 1.0658e-14, 4.4409e-15, 4.4409e-15, 3.5527e-15, 4.4409e-15,\n",
      "         2.2204e-15, 3.5527e-15, 4.8850e-15, 9.7700e-15, 3.5527e-15, 5.3291e-15,\n",
      "         1.1102e-15, 6.2172e-15, 4.4409e-15, 8.8818e-15, 7.1054e-15, 5.3291e-15,\n",
      "         4.4409e-15, 7.1054e-15, 2.6645e-15, 7.9936e-15, 4.4409e-15, 1.7764e-15,\n",
      "         8.8818e-16, 1.1546e-14, 3.5527e-15, 8.8818e-15, 8.8818e-16, 8.8818e-15,\n",
      "         4.4409e-15, 8.8818e-15, 5.3291e-15, 2.1316e-14, 7.9936e-15, 8.8818e-15,\n",
      "         1.0658e-14, 1.5987e-14, 1.4211e-14, 1.0658e-14, 1.5987e-14, 4.1633e-15,\n",
      "         5.3291e-15, 8.8818e-15, 8.8818e-15, 6.6613e-15, 7.1054e-15, 4.1911e-15,\n",
      "         7.9936e-15, 1.5987e-14, 9.7700e-15, 1.0214e-14, 1.7764e-14, 6.2172e-15,\n",
      "         7.9936e-15, 6.2172e-15, 3.5111e-15, 6.2172e-15, 8.8818e-15, 7.1054e-15,\n",
      "         7.1054e-15, 3.5527e-15, 2.2204e-14, 6.0396e-14, 7.1054e-15, 6.2172e-15,\n",
      "         1.0658e-14, 1.4211e-14, 9.7700e-15, 1.0658e-14, 1.3323e-14, 1.0658e-14,\n",
      "         5.3291e-15, 4.4409e-15, 2.1316e-14, 9.7700e-15, 7.1054e-15, 1.4211e-14,\n",
      "         1.7764e-14, 1.2434e-14, 7.1054e-15, 1.1546e-14, 1.4211e-14, 1.7764e-14,\n",
      "         1.1546e-14, 5.3291e-15, 1.7764e-14, 1.0214e-14, 1.2434e-14, 5.7732e-15,\n",
      "         1.3323e-14, 5.7732e-15, 7.1054e-15, 1.9984e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.2434e-14, 8.8818e-15, 6.6613e-15, 4.2633e-14, 6.2172e-15, 6.2172e-15,\n",
      "         5.7732e-15, 4.4409e-15, 8.8818e-15, 5.0515e-15, 8.4377e-15, 8.8818e-15,\n",
      "         6.2172e-15, 1.4211e-14, 1.7764e-14, 2.4869e-14, 9.7700e-15, 1.9540e-14,\n",
      "         5.1070e-15, 1.4211e-14, 5.3291e-15, 9.7700e-15, 1.2434e-14, 3.5527e-15,\n",
      "         6.2172e-15, 7.1054e-15, 1.2434e-14, 4.4409e-15, 9.3259e-15, 7.9936e-15,\n",
      "         5.3291e-15, 3.3307e-15, 1.9540e-14, 4.8850e-15, 3.1086e-15, 8.8818e-15,\n",
      "         7.3275e-15, 6.2172e-15, 3.5527e-15, 1.0658e-14, 1.3323e-14, 4.8850e-15,\n",
      "         9.7700e-15, 8.8818e-15, 7.9936e-15, 9.7700e-15, 1.7764e-14, 8.8818e-15,\n",
      "         1.4211e-14, 1.2434e-14, 6.2172e-15, 1.3323e-14, 2.0428e-14, 4.4409e-15,\n",
      "         6.2172e-15, 7.6050e-15, 3.5527e-15, 1.7764e-14, 6.2172e-15, 1.2434e-14,\n",
      "         6.2172e-15, 1.0658e-14, 7.5495e-15, 5.3291e-15, 1.5987e-14, 1.0658e-14,\n",
      "         5.3291e-15, 4.7740e-15, 6.2172e-15, 7.5495e-15, 7.9936e-15, 1.9540e-14,\n",
      "         2.0428e-14, 8.8818e-15, 1.7764e-14, 7.9936e-15, 4.4409e-15, 1.2434e-14,\n",
      "         2.3093e-14, 1.1990e-14, 1.3323e-14, 5.3291e-15, 8.8818e-15, 5.3291e-15,\n",
      "         1.2434e-14, 1.0658e-14, 1.3323e-14, 4.8850e-15, 1.8652e-14, 3.7470e-15,\n",
      "         7.1054e-15, 1.7764e-14, 6.2172e-15, 5.3291e-15, 1.0658e-14, 2.8422e-14,\n",
      "         1.1990e-14, 8.4377e-15, 1.4211e-14, 1.5987e-14, 1.7764e-14, 7.1054e-15,\n",
      "         1.5099e-14, 8.8818e-15, 1.2434e-14, 6.8834e-15, 7.1054e-15, 7.1054e-15,\n",
      "         1.6875e-14, 1.5987e-14, 7.9936e-15, 7.9936e-15, 2.6645e-15, 7.1054e-15,\n",
      "         7.1054e-15, 3.9968e-15, 3.5527e-15, 1.3323e-14, 2.1316e-14, 1.4211e-14,\n",
      "         7.1054e-15, 1.4211e-14, 3.5527e-15, 1.1546e-14, 1.0658e-14, 1.0658e-14,\n",
      "         4.4409e-15, 8.8818e-15, 4.4409e-15, 1.9540e-14, 4.4409e-15, 5.3291e-15,\n",
      "         5.3291e-15, 7.5495e-15, 8.8818e-15, 1.0658e-14, 1.4211e-14, 9.5479e-15,\n",
      "         1.3323e-14, 1.2434e-14, 7.9936e-15, 7.9936e-15, 1.7764e-14, 4.4409e-15,\n",
      "         1.0658e-14, 8.8818e-15, 3.5527e-15, 8.8818e-15, 1.0658e-14, 1.2434e-14,\n",
      "         2.2204e-15, 1.5987e-14, 1.2434e-14, 1.0658e-14, 4.4409e-15, 1.2434e-14,\n",
      "         7.9936e-15, 7.9936e-15, 7.9936e-15, 1.4211e-14, 1.9540e-14, 5.3291e-15,\n",
      "         1.2434e-14, 3.1086e-15, 1.5987e-14, 6.6613e-15, 1.0658e-14, 1.2434e-14,\n",
      "         1.7764e-14, 1.9540e-14, 1.0658e-14, 8.8818e-15, 7.1054e-15, 3.1974e-14,\n",
      "         1.5987e-14, 1.2434e-14, 3.5527e-15, 6.2172e-15, 8.8818e-15, 1.0658e-14,\n",
      "         7.9936e-15, 7.1054e-15, 1.1546e-14, 3.1974e-14, 1.0658e-14, 1.5987e-14,\n",
      "         5.7732e-15, 4.4409e-15, 1.9540e-14, 7.9936e-15, 5.3291e-15, 1.5987e-14,\n",
      "         9.7700e-15, 8.8818e-15, 8.8818e-15, 7.9936e-15, 1.3323e-14, 7.9936e-15,\n",
      "         6.6613e-15, 7.9936e-15, 4.4409e-15, 4.4409e-15, 1.0658e-14, 1.5987e-14,\n",
      "         9.7700e-15, 9.3259e-15, 2.3093e-14, 4.4409e-15, 7.1054e-15, 1.3323e-14,\n",
      "         8.8818e-15, 1.0658e-14, 1.1102e-14, 1.0658e-14, 1.3323e-14, 5.3291e-15,\n",
      "         1.7764e-14, 7.9936e-15, 7.9936e-15, 8.4377e-15, 9.7700e-15, 1.4211e-14,\n",
      "         1.2434e-14, 5.3291e-15, 1.3323e-14, 1.1102e-14, 7.1054e-15, 7.1054e-15,\n",
      "         1.7764e-14, 6.6613e-15, 5.5511e-15, 7.5495e-15, 6.2172e-15, 1.2434e-14,\n",
      "         1.7764e-14, 8.4377e-15, 1.0658e-14, 1.2434e-14, 1.1546e-14, 1.5099e-14,\n",
      "         8.8818e-15, 1.0658e-14, 2.3093e-14, 5.8842e-15, 5.3291e-15, 1.4211e-14,\n",
      "         1.9540e-14, 5.3291e-15, 1.2434e-14, 1.0658e-14, 1.0658e-14, 1.0214e-14,\n",
      "         1.0658e-14, 7.9936e-15, 9.7700e-15, 1.0658e-14, 9.7700e-15, 9.7700e-15,\n",
      "         8.8818e-15, 1.1546e-14, 1.4211e-14, 6.2172e-15, 1.0658e-14, 1.0658e-14,\n",
      "         4.4409e-15, 3.5527e-14, 8.8818e-15, 1.0658e-14, 7.1054e-15, 7.9936e-15,\n",
      "         1.1546e-14, 1.2434e-14, 8.6320e-15, 5.5511e-15, 1.5987e-14, 1.7764e-14,\n",
      "         1.0658e-14, 6.6613e-15, 3.5527e-15, 7.9936e-15, 1.5987e-14, 1.0658e-14,\n",
      "         8.8818e-15, 8.4377e-15, 8.3284e-15, 1.2434e-14, 1.2434e-14, 9.7700e-15,\n",
      "         7.9936e-15, 5.3291e-15, 6.8834e-15, 7.9936e-15, 7.4385e-15, 1.0658e-14,\n",
      "         1.3434e-14, 9.7700e-15, 3.1641e-15, 1.9540e-14, 6.2172e-15, 5.3291e-15,\n",
      "         4.4409e-15, 9.7700e-15, 1.1546e-14, 9.7700e-15, 1.7764e-14, 8.8818e-15,\n",
      "         8.8818e-15, 5.3291e-15, 1.2434e-14, 1.3323e-14, 6.1062e-15, 7.1054e-15,\n",
      "         7.2164e-15, 1.4211e-14, 8.8818e-15, 2.4425e-15, 8.8818e-15, 1.0658e-14,\n",
      "         9.7700e-15, 1.6875e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 239: layer4.2.add\n",
      "\tExecuting on machine 0\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 1\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 2\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "\tExecuting on machine 3\n",
      "\t\t-adding residual\n",
      "\t\t-assuming shortcut had no layers\n",
      "Finished execution of layer 239\n",
      "Max diff:\n",
      " tensor([6.0396e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.6629e-15, 7.1054e-15, 5.3291e-15, 6.2172e-15, 4.4409e-15, 1.8388e-15,\n",
      "         7.1054e-15, 7.9936e-15, 9.7700e-15, 7.4385e-15, 4.4409e-15, 6.2172e-15,\n",
      "         8.8818e-15, 9.7700e-15, 8.8818e-15, 7.9936e-15, 8.8818e-15, 2.4425e-15,\n",
      "         7.9936e-15, 3.9968e-15, 2.2204e-15, 8.8818e-15, 5.3291e-15, 6.2172e-15,\n",
      "         1.4211e-14, 8.8818e-15, 3.5527e-15, 1.2434e-14, 6.2172e-15, 4.4409e-15,\n",
      "         6.2172e-15, 7.1054e-15, 3.9968e-15, 1.1546e-14, 6.6613e-15, 1.0658e-14,\n",
      "         3.5527e-15, 5.3291e-15, 8.4377e-15, 4.4409e-15, 1.4433e-15, 3.5527e-15,\n",
      "         3.5527e-15, 6.2172e-15, 5.3291e-15, 7.9936e-15, 1.9540e-14, 1.7764e-15,\n",
      "         8.8818e-15, 5.3291e-15, 1.2212e-15, 5.9952e-15, 2.7756e-15, 1.2434e-14,\n",
      "         1.3323e-15, 2.6645e-15, 7.1054e-15, 1.0658e-14, 7.1054e-15, 5.3291e-15,\n",
      "         5.3291e-15, 4.4409e-15, 1.7764e-14, 3.4417e-15, 4.4409e-15, 4.4409e-15,\n",
      "         9.9920e-16, 9.7700e-15, 5.3291e-15, 3.9968e-15, 1.0658e-14, 3.5527e-15,\n",
      "         2.6645e-15, 3.5527e-15, 8.8818e-15, 1.5543e-15, 7.1054e-15, 4.4409e-15,\n",
      "         6.2172e-15, 7.1054e-15, 2.1094e-15, 1.4211e-14, 7.1054e-15, 2.4425e-15,\n",
      "         6.6613e-15, 1.7764e-14, 2.6645e-15, 7.1054e-15, 3.5527e-15, 6.2172e-15,\n",
      "         1.4211e-14, 7.1054e-15, 1.0658e-14, 6.2172e-15, 6.6613e-15, 2.1316e-14,\n",
      "         7.9936e-15, 1.0658e-14, 4.4409e-15, 4.4409e-15, 3.5527e-15, 4.4409e-15,\n",
      "         2.2204e-15, 5.7732e-15, 4.8850e-15, 9.7700e-15, 3.5527e-15, 5.3291e-15,\n",
      "         2.2204e-15, 6.2172e-15, 4.4409e-15, 8.8818e-15, 7.1054e-15, 5.3291e-15,\n",
      "         4.4409e-15, 7.1054e-15, 4.6629e-15, 7.9936e-15, 4.4409e-15, 2.4425e-15,\n",
      "         1.8874e-15, 1.1546e-14, 3.5527e-15, 8.8818e-15, 8.8818e-16, 8.8818e-15,\n",
      "         4.4409e-15, 8.8818e-15, 5.3291e-15, 2.1316e-14, 7.9936e-15, 1.5987e-14,\n",
      "         1.0658e-14, 1.5987e-14, 1.4211e-14, 1.7764e-14, 1.7764e-14, 4.1633e-15,\n",
      "         5.3291e-15, 8.8818e-15, 8.8818e-15, 6.2172e-15, 7.1054e-15, 5.2180e-15,\n",
      "         7.9936e-15, 1.5987e-14, 1.3767e-14, 1.0214e-14, 1.7764e-14, 1.2434e-14,\n",
      "         7.9936e-15, 1.2434e-14, 8.8818e-15, 6.2172e-15, 8.8818e-15, 7.1054e-15,\n",
      "         1.1102e-14, 3.9968e-15, 1.7764e-14, 6.0396e-14, 7.1054e-15, 1.0658e-14,\n",
      "         1.0658e-14, 1.4211e-14, 9.7700e-15, 1.0658e-14, 1.3323e-14, 1.0658e-14,\n",
      "         5.3291e-15, 4.4409e-15, 2.1316e-14, 9.7700e-15, 7.1054e-15, 1.4211e-14,\n",
      "         1.7764e-14, 1.2434e-14, 7.1054e-15, 1.1546e-14, 1.4211e-14, 1.7764e-14,\n",
      "         9.7700e-15, 5.3291e-15, 1.7764e-14, 1.0214e-14, 1.2434e-14, 6.6613e-15,\n",
      "         1.3323e-14, 5.7732e-15, 7.1054e-15, 1.9984e-15, 1.0658e-14, 8.8818e-15,\n",
      "         1.2434e-14, 8.8818e-15, 1.0214e-14, 4.2633e-14, 6.2172e-15, 6.2172e-15,\n",
      "         6.2172e-15, 1.1990e-14, 8.8818e-15, 9.7700e-15, 8.4377e-15, 7.9936e-15,\n",
      "         6.2172e-15, 1.4211e-14, 1.7764e-14, 2.4869e-14, 9.7700e-15, 1.9540e-14,\n",
      "         5.3291e-15, 1.4211e-14, 5.3291e-15, 9.7700e-15, 1.2434e-14, 3.5527e-15,\n",
      "         6.2172e-15, 8.8818e-15, 1.2434e-14, 8.4377e-15, 9.3259e-15, 6.6613e-15,\n",
      "         5.3291e-15, 3.3307e-15, 1.9540e-14, 4.8850e-15, 3.1086e-15, 8.8818e-15,\n",
      "         7.3275e-15, 7.1054e-15, 5.3291e-15, 1.0658e-14, 1.3323e-14, 1.3767e-14,\n",
      "         9.7700e-15, 8.8818e-15, 1.4211e-14, 9.7700e-15, 1.7764e-14, 8.8818e-15,\n",
      "         1.4211e-14, 1.2434e-14, 1.1990e-14, 1.3323e-14, 3.1974e-14, 3.3307e-15,\n",
      "         6.2172e-15, 7.6050e-15, 4.4409e-15, 1.7764e-14, 6.2172e-15, 1.2434e-14,\n",
      "         8.8818e-15, 1.0658e-14, 7.5495e-15, 5.3291e-15, 1.5987e-14, 1.0658e-14,\n",
      "         1.0658e-14, 1.0658e-14, 7.9936e-15, 7.5495e-15, 7.9936e-15, 1.9540e-14,\n",
      "         2.0428e-14, 8.8818e-15, 1.7764e-14, 7.9936e-15, 6.2172e-15, 1.2434e-14,\n",
      "         2.3093e-14, 1.1990e-14, 1.3323e-14, 1.0214e-14, 8.8818e-15, 5.3291e-15,\n",
      "         1.2434e-14, 1.0658e-14, 1.3323e-14, 4.8850e-15, 2.1316e-14, 3.8858e-15,\n",
      "         7.1054e-15, 1.7764e-14, 6.2172e-15, 5.3291e-15, 1.0658e-14, 2.8422e-14,\n",
      "         1.1990e-14, 8.4377e-15, 1.4211e-14, 1.5987e-14, 2.1316e-14, 7.1054e-15,\n",
      "         1.5099e-14, 8.8818e-15, 1.2434e-14, 6.8834e-15, 8.8818e-15, 7.1054e-15,\n",
      "         2.3981e-14, 1.5099e-14, 7.9936e-15, 8.8818e-15, 2.6645e-15, 7.1054e-15,\n",
      "         7.1054e-15, 1.1102e-14, 3.5527e-15, 1.3323e-14, 1.9540e-14, 1.4211e-14,\n",
      "         7.1054e-15, 1.4211e-14, 3.5527e-15, 1.1546e-14, 1.0658e-14, 1.0658e-14,\n",
      "         4.4409e-15, 8.8818e-15, 4.4409e-15, 1.9540e-14, 4.4409e-15, 1.0658e-14,\n",
      "         5.3291e-15, 1.4211e-14, 8.8818e-15, 1.0658e-14, 1.4211e-14, 2.8422e-14,\n",
      "         1.3323e-14, 2.3093e-14, 7.5495e-15, 7.9936e-15, 1.7764e-14, 4.6629e-15,\n",
      "         1.0658e-14, 8.8818e-15, 3.5527e-15, 8.8818e-15, 1.5987e-14, 1.2434e-14,\n",
      "         2.2204e-15, 2.1316e-14, 1.2434e-14, 1.0658e-14, 4.4409e-15, 1.2434e-14,\n",
      "         7.1054e-15, 7.9936e-15, 7.9936e-15, 1.4211e-14, 1.9540e-14, 5.3291e-15,\n",
      "         1.1990e-14, 3.1086e-15, 1.5987e-14, 6.6613e-15, 1.7764e-14, 1.2434e-14,\n",
      "         1.7764e-14, 1.9540e-14, 1.0658e-14, 8.8818e-15, 7.1054e-15, 3.1974e-14,\n",
      "         2.8422e-14, 1.2434e-14, 3.5527e-15, 1.5099e-14, 8.8818e-15, 1.0658e-14,\n",
      "         7.9936e-15, 1.1546e-14, 1.3323e-14, 3.1974e-14, 1.0658e-14, 1.5987e-14,\n",
      "         5.7732e-15, 1.1546e-14, 1.9540e-14, 7.9936e-15, 5.3291e-15, 1.5987e-14,\n",
      "         9.7700e-15, 8.8818e-15, 1.2434e-14, 7.9936e-15, 1.3323e-14, 7.9936e-15,\n",
      "         9.7700e-15, 7.9936e-15, 1.7764e-14, 4.4409e-15, 1.0658e-14, 1.5987e-14,\n",
      "         1.1546e-14, 9.3259e-15, 2.3093e-14, 4.4409e-15, 6.2172e-15, 1.3323e-14,\n",
      "         8.8818e-15, 1.0658e-14, 1.1102e-14, 1.0658e-14, 1.3323e-14, 8.8818e-15,\n",
      "         1.7764e-14, 1.1102e-14, 7.9936e-15, 8.4377e-15, 9.7700e-15, 1.4211e-14,\n",
      "         1.2434e-14, 1.3323e-14, 1.3323e-14, 1.1102e-14, 1.0658e-14, 8.8818e-15,\n",
      "         1.7764e-14, 6.6613e-15, 1.0658e-14, 1.1990e-14, 6.2172e-15, 1.2434e-14,\n",
      "         1.7764e-14, 8.4377e-15, 1.0658e-14, 1.2434e-14, 1.1546e-14, 1.5099e-14,\n",
      "         8.8818e-15, 1.0658e-14, 2.3093e-14, 5.8842e-15, 5.3291e-15, 1.4211e-14,\n",
      "         2.4869e-14, 2.3093e-14, 1.2434e-14, 1.0658e-14, 1.0658e-14, 1.0214e-14,\n",
      "         1.0658e-14, 7.9936e-15, 9.7700e-15, 1.0658e-14, 9.7700e-15, 9.7700e-15,\n",
      "         8.8818e-15, 1.1546e-14, 1.4211e-14, 6.2172e-15, 1.0658e-14, 1.0658e-14,\n",
      "         1.1990e-14, 3.5527e-14, 8.8818e-15, 1.0658e-14, 7.1054e-15, 7.9936e-15,\n",
      "         1.1546e-14, 1.9540e-14, 1.0658e-14, 5.5511e-15, 1.5987e-14, 1.2434e-14,\n",
      "         1.0658e-14, 6.6613e-15, 4.6629e-15, 7.9936e-15, 1.7764e-14, 1.0658e-14,\n",
      "         8.8818e-15, 8.4377e-15, 1.0658e-14, 1.2434e-14, 1.2434e-14, 9.7700e-15,\n",
      "         7.9936e-15, 9.7700e-15, 6.8834e-15, 7.9936e-15, 7.4385e-15, 1.5099e-14,\n",
      "         1.3434e-14, 9.7700e-15, 8.4377e-15, 1.9540e-14, 6.2172e-15, 5.3291e-15,\n",
      "         1.8652e-14, 9.7700e-15, 1.3323e-14, 1.1546e-14, 1.7764e-14, 8.8818e-15,\n",
      "         8.8818e-15, 5.3291e-15, 1.2434e-14, 1.3323e-14, 6.1062e-15, 7.1054e-15,\n",
      "         7.2164e-15, 1.4211e-14, 8.8818e-15, 5.7732e-15, 1.5987e-14, 1.6875e-14,\n",
      "         9.7700e-15, 1.6875e-14]], dtype=torch.float64)\n",
      " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])  (len = 512)\n",
      "passing Cout = tensor([], dtype=torch.int64)  (len = 0)\n",
      "\n",
      "Executing module 240: layer4.2.relu_1\n",
      "\tExecuting on machine 0\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 1\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 2\n",
      "\t\t-Applying ReLU\n",
      "\tExecuting on machine 3\n",
      "\t\t-Applying ReLU\n",
      "Finished execution of layer 240\n",
      "Max diff:\n",
      " tensor([2.8422e-14], dtype=torch.float64)\n",
      "\n",
      " tensor([[4.6629e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8858e-15, 1.8388e-15,\n",
      "         0.0000e+00, 0.0000e+00, 3.7748e-15, 7.4385e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6613e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-15, 0.0000e+00,\n",
      "         1.7764e-15, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 1.4294e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9952e-15, 2.7756e-15, 0.0000e+00,\n",
      "         1.3323e-15, 1.6653e-15, 0.0000e+00, 8.4377e-15, 4.4409e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.9920e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5543e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4425e-15,\n",
      "         2.6645e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4377e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2981e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.5527e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.8858e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.6629e-15, 0.0000e+00, 0.0000e+00, 9.7145e-16,\n",
      "         0.0000e+00, 1.7902e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7347e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7764e-14, 0.0000e+00, 4.1633e-15,\n",
      "         0.0000e+00, 0.0000e+00, 6.6613e-16, 4.2188e-15, 1.7208e-15, 5.2180e-15,\n",
      "         0.0000e+00, 0.0000e+00, 7.6189e-15, 0.0000e+00, 0.0000e+00, 1.2434e-14,\n",
      "         3.3307e-15, 0.0000e+00, 8.8818e-15, 5.5511e-16, 7.1054e-15, 0.0000e+00,\n",
      "         0.0000e+00, 3.9968e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4433e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.6637e-15, 7.5495e-15, 0.0000e+00, 0.0000e+00, 3.7748e-15,\n",
      "         0.0000e+00, 0.0000e+00, 1.4433e-15, 0.0000e+00, 1.7764e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5380e-15, 0.0000e+00, 4.4409e-15,\n",
      "         0.0000e+00, 2.3315e-15, 0.0000e+00, 1.9984e-15, 6.6613e-15, 0.0000e+00,\n",
      "         2.4425e-15, 0.0000e+00, 5.3291e-15, 7.7716e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-15, 2.6645e-15, 9.7700e-15, 7.4107e-15, 5.3291e-15,\n",
      "         0.0000e+00, 1.1102e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.7208e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.6613e-15, 3.5527e-15, 8.3267e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5309e-15, 0.0000e+00, 0.0000e+00, 2.0539e-15, 0.0000e+00,\n",
      "         2.5535e-15, 0.0000e+00, 5.3291e-15, 0.0000e+00, 0.0000e+00, 1.3878e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4417e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.9920e-16, 6.2172e-15, 1.0214e-14, 6.6613e-16,\n",
      "         0.0000e+00, 7.6050e-15, 4.4409e-16, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         0.0000e+00, 2.9421e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.3259e-15, 4.7740e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.9936e-15, 0.0000e+00, 0.0000e+00, 3.5527e-15, 6.2172e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.6752e-15, 8.8818e-15, 0.0000e+00, 1.5543e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1102e-15, 2.1316e-14, 7.2164e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8834e-15,\n",
      "         0.0000e+00, 0.0000e+00, 6.7377e-15, 0.0000e+00, 8.8818e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3323e-15, 0.0000e+00,\n",
      "         0.0000e+00, 1.1102e-14, 5.5511e-16, 0.0000e+00, 0.0000e+00, 7.7716e-15,\n",
      "         1.3323e-15, 0.0000e+00, 2.2204e-15, 2.2204e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.5543e-15, 3.7748e-15, 2.5258e-15, 0.0000e+00, 1.1657e-15, 5.7732e-15,\n",
      "         8.8818e-16, 1.0658e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8422e-14,\n",
      "         4.4409e-16, 1.9540e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 8.8818e-15, 1.2143e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2196e-15, 3.7748e-15, 0.0000e+00,\n",
      "         4.1078e-15, 8.8818e-16, 2.6645e-15, 9.9920e-15, 0.0000e+00, 0.0000e+00,\n",
      "         9.9920e-15, 2.2760e-15, 0.0000e+00, 0.0000e+00, 8.8818e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3291e-15, 0.0000e+00,\n",
      "         2.5757e-14, 0.0000e+00, 0.0000e+00, 1.5099e-14, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.2172e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.8866e-15, 1.1546e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.7732e-15, 0.0000e+00, 9.7700e-15, 0.0000e+00, 0.0000e+00, 3.6637e-15,\n",
      "         0.0000e+00, 0.0000e+00, 5.3291e-15, 4.4409e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.1546e-14, 0.0000e+00, 1.1990e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1054e-15,\n",
      "         0.0000e+00, 8.8818e-15, 0.0000e+00, 4.2188e-15, 7.5495e-15, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8818e-15,\n",
      "         0.0000e+00, 5.5511e-15, 1.0658e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.8818e-16, 2.6645e-15, 1.1546e-14, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8842e-15, 2.6645e-15, 0.0000e+00,\n",
      "         7.1054e-15, 1.5987e-14, 2.6645e-15, 7.9936e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.4393e-15, 0.0000e+00, 0.0000e+00, 2.2204e-15, 3.5527e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7748e-15, 0.0000e+00,\n",
      "         1.1990e-14, 1.6431e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9540e-14, 1.0658e-14, 5.5511e-15, 3.5527e-15, 2.2204e-15,\n",
      "         0.0000e+00, 1.7208e-15, 4.6629e-15, 0.0000e+00, 1.2434e-14, 0.0000e+00,\n",
      "         0.0000e+00, 8.4377e-15, 1.0658e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 4.4409e-15, 0.0000e+00, 7.4385e-15, 0.0000e+00,\n",
      "         1.2101e-14, 0.0000e+00, 8.4377e-15, 7.6501e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.8652e-14, 0.0000e+00, 3.2196e-15, 3.9968e-15, 0.0000e+00, 7.1054e-15,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1062e-15, 0.0000e+00,\n",
      "         5.6621e-15, 0.0000e+00, 0.0000e+00, 5.7732e-15, 8.8818e-16, 7.1054e-15,\n",
      "         0.0000e+00, 7.1054e-15]], dtype=torch.float64)\n",
      " tensor([  0,   4,   5,   8,   9,  17,  26,  40,  42,  44,  47,  51,  52,  54,\n",
      "         55,  57,  58,  66,  75,  83,  84,  95,  99, 103, 108, 116, 119, 121,\n",
      "        126, 135, 137, 140, 141, 142, 143, 146, 149, 150, 152, 153, 154, 157,\n",
      "        161, 169, 170, 173, 176, 178, 183, 185, 187, 189, 190, 192, 194, 195,\n",
      "        199, 200, 201, 202, 203, 205, 210, 217, 218, 219, 223, 226, 228, 230,\n",
      "        233, 237, 242, 243, 244, 245, 247, 248, 251, 253, 258, 259, 264, 267,\n",
      "        268, 272, 273, 275, 279, 280, 281, 293, 296, 298, 304, 307, 308, 311,\n",
      "        312, 314, 315, 318, 319, 320, 322, 323, 324, 325, 329, 330, 331, 335,\n",
      "        337, 338, 345, 346, 348, 349, 350, 351, 354, 355, 358, 364, 366, 369,\n",
      "        373, 378, 379, 384, 386, 389, 392, 393, 396, 398, 407, 409, 411, 412,\n",
      "        419, 421, 422, 428, 429, 430, 435, 436, 438, 439, 440, 441, 445, 448,\n",
      "        449, 454, 456, 457, 463, 464, 465, 466, 467, 469, 470, 472, 475, 476,\n",
      "        481, 482, 484, 486, 488, 489, 492, 494, 495, 497, 502, 504, 507, 508,\n",
      "        509, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   8,   9,  17,  26,  40,  42,  44,  47,  51,  52,  54,\n",
      "         55,  57,  58,  66,  75,  83,  84,  95,  99, 103, 108, 116, 119, 121,\n",
      "        126, 135, 137, 140, 141, 142, 143, 146, 149, 150, 152, 153, 154, 157,\n",
      "        161, 169, 170, 173, 176, 178, 183, 185, 187, 189, 190, 192, 194, 195,\n",
      "        199, 200, 201, 202, 203, 205, 210, 217, 218, 219, 223, 226, 228, 230,\n",
      "        233, 237, 242, 243, 244, 245, 247, 248, 251, 253, 258, 259, 264, 267,\n",
      "        268, 272, 273, 275, 279, 280, 281, 293, 296, 298, 304, 307, 308, 311,\n",
      "        312, 314, 315, 318, 319, 320, 322, 323, 324, 325, 329, 330, 331, 335,\n",
      "        337, 338, 345, 346, 348, 349, 350, 351, 354, 355, 358, 364, 366, 369,\n",
      "        373, 378, 379, 384, 386, 389, 392, 393, 396, 398, 407, 409, 411, 412,\n",
      "        419, 421, 422, 428, 429, 430, 435, 436, 438, 439, 440, 441, 445, 448,\n",
      "        449, 454, 456, 457, 463, 464, 465, 466, 467, 469, 470, 472, 475, 476,\n",
      "        481, 482, 484, 486, 488, 489, 492, 494, 495, 497, 502, 504, 507, 508,\n",
      "        509, 511])  (len = 184)\n",
      "passing Cout = tensor([82])  (len = 1)\n",
      "\n",
      "Executing module 241: avg_pool\n",
      "\tExecuting on machine 0\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 1\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 2\n",
      "\t\t-average pooling\n",
      "\tExecuting on machine 3\n",
      "\t\t-average pooling\n",
      "Finished execution of layer 241\n",
      "Max diff:\n",
      " tensor([3.1086e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6082e-16, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 6.1062e-16, 1.1102e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1633e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.3267e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-17, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 1.9429e-16, 0.0000e+00, 0.0000e+00, 2.3939e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2164e-16, 2.0817e-16, 0.0000e+00,\n",
      "         2.2204e-16, 2.3592e-16, 0.0000e+00, 1.2212e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8858e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9960e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8113e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.8858e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9429e-16, 0.0000e+00, 0.0000e+00, 6.5919e-17,\n",
      "         0.0000e+00, 1.1189e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0842e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15, 0.0000e+00, 5.2736e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.1633e-17, 2.6368e-16, 1.0755e-16, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.7618e-16, 0.0000e+00, 0.0000e+00, 1.1657e-15,\n",
      "         1.2490e-16, 0.0000e+00, 1.3323e-15, 2.7756e-17, 6.6613e-16, 0.0000e+00,\n",
      "         0.0000e+00, 2.9490e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0206e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 4.7184e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 9.0206e-17, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8363e-16, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 1.9429e-16, 0.0000e+00, 1.6653e-16, 4.1633e-16, 0.0000e+00,\n",
      "         8.3267e-17, 0.0000e+00, 2.2204e-16, 4.8572e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-16, 5.5511e-17, 2.6645e-15, 1.1102e-15, 6.1062e-16,\n",
      "         0.0000e+00, 1.2212e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.1633e-16, 1.3878e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.5681e-17, 0.0000e+00, 0.0000e+00, 1.3184e-16, 0.0000e+00,\n",
      "         1.5959e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 1.5266e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.2450e-17, 4.4409e-16, 1.7208e-15, 4.1633e-17,\n",
      "         0.0000e+00, 8.0491e-16, 2.7756e-17, 0.0000e+00, 0.0000e+00, 9.7145e-17,\n",
      "         0.0000e+00, 1.8388e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.8287e-16, 8.1879e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.9960e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0491e-16, 9.9920e-16, 0.0000e+00, 9.7145e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-17, 8.8818e-16, 4.5103e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7716e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.2110e-16, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3267e-17, 0.0000e+00,\n",
      "         0.0000e+00, 7.4940e-16, 3.4694e-17, 0.0000e+00, 0.0000e+00, 8.3267e-16,\n",
      "         8.3267e-17, 0.0000e+00, 3.0531e-16, 1.3878e-16, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-17, 2.3592e-16, 1.9429e-16, 0.0000e+00, 8.3267e-17, 2.2204e-16,\n",
      "         5.5511e-17, 1.0547e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         2.7756e-17, 2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 1.1102e-15, 1.0408e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0123e-16, 5.5511e-17, 0.0000e+00,\n",
      "         4.4409e-16, 5.5511e-17, 1.6653e-16, 1.1380e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-15, 1.4225e-16, 0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2164e-16, 0.0000e+00,\n",
      "         2.3315e-15, 0.0000e+00, 0.0000e+00, 9.9920e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.8041e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.8287e-16, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 2.2898e-16,\n",
      "         0.0000e+00, 0.0000e+00, 3.6082e-16, 4.9960e-16, 0.0000e+00, 0.0000e+00,\n",
      "         7.7716e-16, 0.0000e+00, 1.8874e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 1.1102e-15, 0.0000e+00, 2.2204e-16, 4.7184e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2212e-15,\n",
      "         0.0000e+00, 1.3878e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 1.6653e-16, 7.2164e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 1.6653e-16, 0.0000e+00,\n",
      "         2.2204e-16, 1.3323e-15, 1.6653e-16, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.0246e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-16, 0.0000e+00,\n",
      "         2.6645e-15, 1.0270e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8874e-15, 3.3307e-16, 8.8818e-16, 2.2204e-16, 1.3878e-16,\n",
      "         0.0000e+00, 1.3184e-16, 2.2204e-16, 0.0000e+00, 1.1102e-15, 0.0000e+00,\n",
      "         0.0000e+00, 8.0491e-16, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 8.8818e-16, 0.0000e+00, 9.9920e-16, 0.0000e+00,\n",
      "         7.7716e-16, 0.0000e+00, 1.3323e-15, 3.3307e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.1657e-15, 0.0000e+00, 2.4980e-16, 4.3021e-16, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8532e-16, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16, 5.5511e-17, 4.4409e-16,\n",
      "         0.0000e+00, 7.7716e-16]], dtype=torch.float64)\n",
      " tensor([  0,   4,   5,   8,   9,  17,  26,  40,  42,  44,  47,  51,  52,  54,\n",
      "         55,  57,  66,  75,  83,  84,  95,  99, 103, 108, 116, 119, 121, 126,\n",
      "        135, 137, 140, 141, 142, 143, 146, 149, 150, 152, 153, 154, 157, 161,\n",
      "        169, 170, 173, 176, 178, 183, 185, 187, 189, 190, 192, 194, 195, 199,\n",
      "        200, 201, 202, 203, 205, 210, 217, 218, 219, 223, 226, 228, 230, 233,\n",
      "        237, 242, 243, 244, 245, 247, 248, 251, 253, 258, 259, 264, 267, 268,\n",
      "        272, 273, 275, 279, 280, 281, 293, 296, 298, 304, 307, 308, 311, 312,\n",
      "        314, 315, 318, 319, 320, 322, 323, 324, 325, 329, 330, 331, 335, 337,\n",
      "        338, 345, 346, 348, 349, 350, 351, 354, 355, 358, 364, 366, 369, 373,\n",
      "        378, 379, 384, 386, 389, 392, 393, 396, 398, 407, 409, 411, 412, 419,\n",
      "        421, 422, 428, 429, 430, 435, 436, 438, 439, 440, 441, 445, 449, 454,\n",
      "        456, 457, 463, 464, 465, 466, 467, 469, 470, 472, 475, 476, 481, 482,\n",
      "        484, 486, 488, 489, 492, 494, 495, 497, 502, 504, 507, 508, 509, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   8,   9,  17,  26,  40,  42,  44,  47,  51,  52,  54,\n",
      "         55,  57,  66,  75,  83,  84,  95,  99, 103, 108, 116, 119, 121, 126,\n",
      "        135, 137, 140, 141, 142, 143, 146, 149, 150, 152, 153, 154, 157, 161,\n",
      "        169, 170, 173, 176, 178, 183, 185, 187, 189, 190, 192, 194, 195, 199,\n",
      "        200, 201, 202, 203, 205, 210, 217, 218, 219, 223, 226, 228, 230, 233,\n",
      "        237, 242, 243, 244, 245, 247, 248, 251, 253, 258, 259, 264, 267, 268,\n",
      "        272, 273, 275, 279, 280, 281, 293, 296, 298, 304, 307, 308, 311, 312,\n",
      "        314, 315, 318, 319, 320, 322, 323, 324, 325, 329, 330, 331, 335, 337,\n",
      "        338, 345, 346, 348, 349, 350, 351, 354, 355, 358, 364, 366, 369, 373,\n",
      "        378, 379, 384, 386, 389, 392, 393, 396, 398, 407, 409, 411, 412, 419,\n",
      "        421, 422, 428, 429, 430, 435, 436, 438, 439, 440, 441, 445, 449, 454,\n",
      "        456, 457, 463, 464, 465, 466, 467, 469, 470, 472, 475, 476, 481, 482,\n",
      "        484, 486, 488, 489, 492, 494, 495, 497, 502, 504, 507, 508, 509, 511])  (len = 182)\n",
      "passing Cout = tensor([ 58,  82, 448])  (len = 3)\n",
      "\n",
      "Executing module 242: size\n",
      "\tExecuting on machine 0\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 1\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 2\n",
      "\t\t-skipping\n",
      "\tExecuting on machine 3\n",
      "\t\t-skipping\n",
      "Finished execution of layer 242\n",
      "Horizontal output is <class 'int'>. Skipping comparison\n",
      "\n",
      "Executing module 243: view\n",
      "\tExecuting on machine 0\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 1\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 2\n",
      "\t\t-reshaping (view)\n",
      "\tExecuting on machine 3\n",
      "\t\t-reshaping (view)\n",
      "Finished execution of layer 243\n",
      "Max diff:\n",
      " tensor([3.1086e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[3.3307e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6082e-16, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 6.1062e-16, 1.1102e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1633e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.3267e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-17, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 1.9429e-16, 0.0000e+00, 0.0000e+00, 2.3939e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2164e-16, 2.0817e-16, 0.0000e+00,\n",
      "         2.2204e-16, 2.3592e-16, 0.0000e+00, 1.2212e-15, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5511e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8858e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9960e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8113e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.8858e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4694e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.9429e-16, 0.0000e+00, 0.0000e+00, 6.5919e-17,\n",
      "         0.0000e+00, 1.1189e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0842e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1086e-15, 0.0000e+00, 5.2736e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.1633e-17, 2.6368e-16, 1.0755e-16, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.7618e-16, 0.0000e+00, 0.0000e+00, 1.1657e-15,\n",
      "         1.2490e-16, 0.0000e+00, 1.3323e-15, 2.7756e-17, 6.6613e-16, 0.0000e+00,\n",
      "         0.0000e+00, 2.9490e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0206e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 4.7184e-16, 0.0000e+00, 0.0000e+00, 4.4409e-16,\n",
      "         0.0000e+00, 0.0000e+00, 9.0206e-17, 0.0000e+00, 1.1102e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8363e-16, 0.0000e+00, 1.1102e-16,\n",
      "         0.0000e+00, 1.9429e-16, 0.0000e+00, 1.6653e-16, 4.1633e-16, 0.0000e+00,\n",
      "         8.3267e-17, 0.0000e+00, 2.2204e-16, 4.8572e-17, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.8818e-16, 5.5511e-17, 2.6645e-15, 1.1102e-15, 6.1062e-16,\n",
      "         0.0000e+00, 1.2212e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.1633e-16, 1.3878e-16, 1.1102e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.5681e-17, 0.0000e+00, 0.0000e+00, 1.3184e-16, 0.0000e+00,\n",
      "         1.5959e-16, 0.0000e+00, 2.2204e-16, 0.0000e+00, 0.0000e+00, 1.5266e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.2450e-17, 4.4409e-16, 1.7208e-15, 4.1633e-17,\n",
      "         0.0000e+00, 8.0491e-16, 2.7756e-17, 0.0000e+00, 0.0000e+00, 9.7145e-17,\n",
      "         0.0000e+00, 1.8388e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.8287e-16, 8.1879e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.9960e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.0491e-16, 9.9920e-16, 0.0000e+00, 9.7145e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9389e-17, 8.8818e-16, 4.5103e-17,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7716e-16,\n",
      "         0.0000e+00, 0.0000e+00, 4.2110e-16, 0.0000e+00, 8.8818e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3267e-17, 0.0000e+00,\n",
      "         0.0000e+00, 7.4940e-16, 3.4694e-17, 0.0000e+00, 0.0000e+00, 8.3267e-16,\n",
      "         8.3267e-17, 0.0000e+00, 3.0531e-16, 1.3878e-16, 0.0000e+00, 0.0000e+00,\n",
      "         2.7756e-17, 2.3592e-16, 1.9429e-16, 0.0000e+00, 8.3267e-17, 2.2204e-16,\n",
      "         5.5511e-17, 1.0547e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5543e-15,\n",
      "         2.7756e-17, 2.4425e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-17,\n",
      "         0.0000e+00, 1.1102e-15, 1.0408e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0123e-16, 5.5511e-17, 0.0000e+00,\n",
      "         4.4409e-16, 5.5511e-17, 1.6653e-16, 1.1380e-15, 0.0000e+00, 0.0000e+00,\n",
      "         1.3878e-15, 1.4225e-16, 0.0000e+00, 0.0000e+00, 5.5511e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2164e-16, 0.0000e+00,\n",
      "         2.3315e-15, 0.0000e+00, 0.0000e+00, 9.9920e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.8041e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.8287e-16, 0.0000e+00, 1.3323e-15, 0.0000e+00, 0.0000e+00, 2.2898e-16,\n",
      "         0.0000e+00, 0.0000e+00, 3.6082e-16, 4.9960e-16, 0.0000e+00, 0.0000e+00,\n",
      "         7.7716e-16, 0.0000e+00, 1.8874e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3307e-16,\n",
      "         0.0000e+00, 1.1102e-15, 0.0000e+00, 2.2204e-16, 4.7184e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2212e-15,\n",
      "         0.0000e+00, 1.3878e-16, 8.8818e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.5511e-17, 1.6653e-16, 7.2164e-16, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16, 1.6653e-16, 0.0000e+00,\n",
      "         2.2204e-16, 1.3323e-15, 1.6653e-16, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.0246e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7756e-16, 0.0000e+00,\n",
      "         2.6645e-15, 1.0270e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8874e-15, 3.3307e-16, 8.8818e-16, 2.2204e-16, 1.3878e-16,\n",
      "         0.0000e+00, 1.3184e-16, 2.2204e-16, 0.0000e+00, 1.1102e-15, 0.0000e+00,\n",
      "         0.0000e+00, 8.0491e-16, 1.3323e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7756e-17, 8.8818e-16, 0.0000e+00, 9.9920e-16, 0.0000e+00,\n",
      "         7.7716e-16, 0.0000e+00, 1.3323e-15, 3.3307e-16, 0.0000e+00, 0.0000e+00,\n",
      "         1.1657e-15, 0.0000e+00, 2.4980e-16, 4.3021e-16, 0.0000e+00, 2.2204e-16,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8532e-16, 0.0000e+00,\n",
      "         1.1102e-16, 0.0000e+00, 0.0000e+00, 2.2204e-16, 5.5511e-17, 4.4409e-16,\n",
      "         0.0000e+00, 7.7716e-16]], dtype=torch.float64)\n",
      " tensor([  0,   4,   5,   8,   9,  17,  26,  40,  42,  44,  47,  51,  52,  54,\n",
      "         55,  57,  66,  75,  83,  84,  95,  99, 103, 108, 116, 119, 121, 126,\n",
      "        135, 137, 140, 141, 142, 143, 146, 149, 150, 152, 153, 154, 157, 161,\n",
      "        169, 170, 173, 176, 178, 183, 185, 187, 189, 190, 192, 194, 195, 199,\n",
      "        200, 201, 202, 203, 205, 210, 217, 218, 219, 223, 226, 228, 230, 233,\n",
      "        237, 242, 243, 244, 245, 247, 248, 251, 253, 258, 259, 264, 267, 268,\n",
      "        272, 273, 275, 279, 280, 281, 293, 296, 298, 304, 307, 308, 311, 312,\n",
      "        314, 315, 318, 319, 320, 322, 323, 324, 325, 329, 330, 331, 335, 337,\n",
      "        338, 345, 346, 348, 349, 350, 351, 354, 355, 358, 364, 366, 369, 373,\n",
      "        378, 379, 384, 386, 389, 392, 393, 396, 398, 407, 409, 411, 412, 419,\n",
      "        421, 422, 428, 429, 430, 435, 436, 438, 439, 440, 441, 445, 449, 454,\n",
      "        456, 457, 463, 464, 465, 466, 467, 469, 470, 472, 475, 476, 481, 482,\n",
      "        484, 486, 488, 489, 492, 494, 495, 497, 502, 504, 507, 508, 509, 511])\n",
      "\n",
      "failing Cout = tensor([  0,   4,   5,   8,   9,  17,  26,  40,  42,  44,  47,  51,  52,  54,\n",
      "         55,  57,  66,  75,  83,  84,  95,  99, 103, 108, 116, 119, 121, 126,\n",
      "        135, 137, 140, 141, 142, 143, 146, 149, 150, 152, 153, 154, 157, 161,\n",
      "        169, 170, 173, 176, 178, 183, 185, 187, 189, 190, 192, 194, 195, 199,\n",
      "        200, 201, 202, 203, 205, 210, 217, 218, 219, 223, 226, 228, 230, 233,\n",
      "        237, 242, 243, 244, 245, 247, 248, 251, 253, 258, 259, 264, 267, 268,\n",
      "        272, 273, 275, 279, 280, 281, 293, 296, 298, 304, 307, 308, 311, 312,\n",
      "        314, 315, 318, 319, 320, 322, 323, 324, 325, 329, 330, 331, 335, 337,\n",
      "        338, 345, 346, 348, 349, 350, 351, 354, 355, 358, 364, 366, 369, 373,\n",
      "        378, 379, 384, 386, 389, 392, 393, 396, 398, 407, 409, 411, 412, 419,\n",
      "        421, 422, 428, 429, 430, 435, 436, 438, 439, 440, 441, 445, 449, 454,\n",
      "        456, 457, 463, 464, 465, 466, 467, 469, 470, 472, 475, 476, 481, 482,\n",
      "        484, 486, 488, 489, 492, 494, 495, 497, 502, 504, 507, 508, 509, 511])  (len = 182)\n",
      "passing Cout = tensor([ 58,  82, 448])  (len = 3)\n",
      "\n",
      "Executing module 244: out\n",
      "\tExecuting on machine 0\n",
      "\t\t-Splitting linear layer 244\n",
      "\t\t Output tensor shape : torch.Size([1, 100])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]) to machine 0\n",
      "\tExecuting on machine 1\n",
      "\t\t-Splitting linear layer 244\n",
      "\t\t Output tensor shape : torch.Size([1, 100])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]) to machine 0\n",
      "\tExecuting on machine 2\n",
      "\t\t-Splitting linear layer 244\n",
      "\t\t Output tensor shape : torch.Size([1, 100])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]) to machine 0\n",
      "\tExecuting on machine 3\n",
      "\t\t-Splitting linear layer 244\n",
      "\t\t Output tensor shape : torch.Size([1, 100])\n",
      "\t\t sending C_out tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]) to machine 0\n",
      "Finished execution of layer 244\n",
      "\n",
      "\n",
      "############################# FINAL EXECUTION TIME 44.11044359207153 [seconds] #############################\n",
      "\n",
      "\n",
      "Max diff:\n",
      " tensor([4.8850e-15], dtype=torch.float64)\n",
      "\n",
      " tensor([[1.3323e-15, 4.4409e-16, 2.6645e-15, 4.4409e-15, 3.1086e-15, 2.6645e-15,\n",
      "         1.3323e-15, 2.4425e-15, 8.8818e-16, 5.5511e-16, 8.8818e-16, 2.2204e-15,\n",
      "         4.4409e-16, 1.9984e-15, 1.7764e-15, 8.8818e-16, 2.1094e-15, 0.0000e+00,\n",
      "         1.7764e-15, 1.7764e-15, 1.6653e-15, 1.3323e-15, 4.4409e-16, 1.2768e-15,\n",
      "         2.2204e-15, 2.2204e-15, 1.3323e-15, 1.3323e-15, 8.8818e-16, 1.7764e-15,\n",
      "         8.8818e-16, 2.6645e-15, 3.1086e-15, 4.4409e-15, 0.0000e+00, 1.3323e-15,\n",
      "         1.5543e-15, 1.9984e-15, 4.4409e-16, 4.4409e-16, 0.0000e+00, 2.2204e-16,\n",
      "         4.4409e-16, 0.0000e+00, 8.8818e-16, 1.3323e-15, 8.8818e-16, 2.6645e-15,\n",
      "         0.0000e+00, 8.8818e-16, 1.3323e-15, 1.3323e-15, 3.5527e-15, 2.2204e-16,\n",
      "         3.5527e-15, 0.0000e+00, 8.8818e-16, 2.2204e-15, 1.3323e-15, 4.4409e-16,\n",
      "         2.2204e-15, 2.7756e-15, 2.4425e-15, 4.4409e-16, 1.3323e-15, 4.4409e-16,\n",
      "         4.4409e-16, 4.8850e-15, 8.8818e-16, 2.2204e-16, 3.5527e-15, 4.4409e-16,\n",
      "         4.4409e-16, 8.8818e-16, 1.3323e-15, 4.4409e-16, 1.3323e-15, 1.2212e-15,\n",
      "         1.1102e-15, 3.1086e-15, 2.7756e-15, 8.8818e-16, 1.7764e-15, 1.2212e-15,\n",
      "         1.1102e-15, 1.3323e-15, 8.8818e-16, 0.0000e+00, 6.6613e-16, 8.8818e-16,\n",
      "         0.0000e+00, 3.5527e-15, 8.8818e-16, 4.4409e-16, 0.0000e+00, 0.0000e+00,\n",
      "         4.8850e-15, 1.3323e-15, 4.4409e-16, 1.9984e-15]], dtype=torch.float64)\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37,\n",
      "        38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59,\n",
      "        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
      "        78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 91, 92, 93, 96, 97, 98, 99])\n",
      "\n",
      "failing Cout = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37,\n",
      "        38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59,\n",
      "        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
      "        78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 91, 92, 93, 96, 97, 98, 99])  (len = 90)\n",
      "passing Cout = tensor([17, 34, 40, 43, 48, 55, 87, 90, 94, 95])  (len = 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Prep Inout for Mock Run version 2 (fx)'''\n",
    "\n",
    "# TODO: reduce size of communicated tensors to only what is necessary \n",
    "# TODO: also check bias for nonzero\n",
    "# TODO: come up with more general scheme to handle residual layers\n",
    "\n",
    "# channel_id == INPUTS\n",
    "# filter_id  == OUTPUTS\n",
    "\n",
    "# try greater precision\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# model input \n",
    "N_batch = 1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# if configs['model'] == 'resnet18' or configs['model'] == 'wrn28_10':\n",
    "if dataset == 'cifar10' or dataset == 'cifar100':\n",
    "    input_tensor = torch.rand(N_batch, 3, 32, 32, dtype=torch.float64, device=torch.device(configs['device'])) # 1k images, 3 channels, 32x32 image (cifar10)\n",
    "    input_tensor = tuple([input_tensor])\n",
    "    input_tensor = torch.cat(input_tensor, dim=1)\n",
    "# elif configs['model'] == 'EscFusion':\n",
    "elif dataset == 'esc':\n",
    "    input_tensor = torch.rand(N_batch, 3, 266, 320, dtype=torch.float64, device=torch.device(configs['device']))\n",
    "    input_tensor = tuple([input_tensor])\n",
    "    input_tensor = torch.cat(input_tensor, dim=1)\n",
    "    \n",
    "    # input_tensor = tuple([input_tensor])\n",
    "    # input_tensor = torch.cat(input_tensor, dim=1)\n",
    "# elif configs['model'] == 'InfoFusionThree':\n",
    "elif dataset == 'flash':\n",
    "    input_tensor = torch.rand(N_batch, 2, 10, 10, dtype=torch.float64, device=torch.device(configs['device']))\n",
    "\n",
    "\n",
    "# if configs['data_code'] == 'flash':\n",
    "#     input_shape = [(2, 1),\n",
    "#                 #    (90, 160, 3),\n",
    "#                     (360, 640, 3),\n",
    "#                     (20, 20, 20),]\n",
    "# elif configs['data_code'] == 'esc':\n",
    "#     input_shape = [(3, 266, 320) for _ in range(5)]\n",
    "# else:\n",
    "#     input_shape = [(3, 32, 32)]\n",
    "\n",
    "# input_np = (np.random.uniform(0, 1, (1,)+x) for x in input_shape)\n",
    "# input_tensor = tuple(Variable(torch.FloatTensor(x), requires_grad=False).to(configs[\"device\"]) for x in input_np)\n",
    "# # input_tensor = torch.cat(input_tensor, dim=1)\n",
    "\n",
    "# print(input_tensor.shape)\n",
    "# print(input_tensor[0].shape)\n",
    "# print(len(input_tensor))\n",
    "\n",
    "# print(f'input_tensor: {input_tensor}')\n",
    "\n",
    "model = model.type(torch.float64)\n",
    "\n",
    "# make SplitManagers for split model execution \n",
    "configs['dtype'] = 'float64'\n",
    "split_managers = [SplitManager]*num_machines\n",
    "for i in range(num_machines):\n",
    "    split_managers[i] = SplitManager(configs, i, num_machines, input_tensor)\n",
    "\n",
    "# broadcast input_tensor to different machines\n",
    "# TODO: find a better datastructure for this\n",
    "#input = np.empty((num_machines, num_machines), dtype=torch.Tensor)\n",
    "input = [None]*num_machines\n",
    "input = [input[:] for i in range(num_machines)]\n",
    "for imach in range(num_machines):\n",
    "    input[imach][imach] = input_tensor\n",
    "\n",
    "# print(f'input: {input}')\n",
    "\n",
    "residual_block_start, residual_connection_start, residual_block_end = get_residual_block_indexes(model)\n",
    "\n",
    "# print(f'residual_block_start: {residual_block_start}')\n",
    "# print(f'residual_connection_start: {residual_connection_start}')\n",
    "# print(f'residual_block_end: {residual_block_end}')\n",
    "\n",
    "# put models into eval mode and on device\n",
    "model.eval()\n",
    "model.to(configs['device'])\n",
    "\n",
    "# set index to execute vertical splitting up to \n",
    "exec_to_layer = total_layers_fx-1\n",
    "\n",
    "# get true output at each layer\n",
    "# WARNING: bn layers are initialized differently between model in this notebook and model in split manager. The moving mean and variance fields do not match HOWEVER the weights and biases are the same\n",
    "#horz_output, size_LUT = get_output_at_each_layer(model, input_tensor) \n",
    "horz_output, size_LUT = get_output_at_each_layer(split_managers[0].model, input_tensor)\n",
    "\n",
    "BREAK_LOOP = 0 # break loop when output differs\n",
    "\n",
    "'''\n",
    "    mock run through inference using split models \n",
    "'''\n",
    "\n",
    "# timing\n",
    "split_execution_start_time = time.time()\n",
    "layer_completion_time_stamp = {}\n",
    "layer_execution_duration = {}\n",
    "\n",
    "# make inference \n",
    "with torch.no_grad():\n",
    "    residual_input = {} # use this to keep track of inputs stored in machine memory for residule layers\n",
    "\n",
    "    # iterate through layers 1 module at a time \n",
    "    for imodule in range(exec_to_layer+1):#range(num_total_modules): # 16 <=> layer_1 block \n",
    "\n",
    "        # initialize output for ilayer\n",
    "        #output = np.empty((num_machines, num_machines), dtype=torch.Tensor) # square list indexed as: output[destination/RX machine][origin/TX machine]\n",
    "        # TODO: find a better datastructure for this \n",
    "\n",
    "        output = [None]*num_machines\n",
    "        output = [output[:] for i in range(num_machines)]\n",
    "\n",
    "        # print(f'output: {output}')\n",
    "\n",
    "        # DEBUG\n",
    "        full_input = combine_all_inputs(input, num_machines)\n",
    "\n",
    "        print(f'Executing module {imodule}: {layer_names_fx[imodule]}')\n",
    "\n",
    "        # iterate through each machine (done in parallel later)\n",
    "        for imach in range(num_machines):\n",
    "            print(f'\\tExecuting on machine {imach}')\n",
    "            # print(f'curr_input: {curr_input}')\n",
    "            # print(f'input: {input}')\n",
    "            # collect communication inputs if necessary \n",
    "            if not imodule == 0 and ('conv' in layer_names_fx[imodule-1] or 'linear' in layer_names_fx[imodule-1] or 'shortcut.1' in layer_names_fx[imodule]): # TODO: this is very hacky, needs to be generalized. The issue is ID'ing conv layers in shortcut blocks\n",
    "                curr_input = combine_inputs(input, num_machines, imach)\n",
    "                # print(f'ilk if e girdi, curr_input: {curr_input}')\n",
    "            else:\n",
    "                curr_input = input[imach][imach]\n",
    "                # print(f'ikinci elif e girdi, curr_input: {curr_input}')\n",
    "\n",
    "            # print(f'len curr_input: {len(curr_input)}')\n",
    "            \n",
    "            out_tensor, do_comms = split_managers[imach].execute_split_layer(curr_input, imodule)\n",
    "            # print(f'out_tensor: {out_tensor}')\n",
    "            if not do_comms:\n",
    "                # update output to current machine and continue\n",
    "                if torch.is_tensor(out_tensor):\n",
    "                    # sometimes out_tensor is None\n",
    "                    # input is sent to all machines for 1st layer execution even though not all machines need to compute \n",
    "                    # Output from machine is None in this case TODO: fix where inputs are sent \n",
    "                    output[imach][imach] = out_tensor\n",
    "                    # print(f'output: {output}')\n",
    "                continue\n",
    "            # print(f'out_tensor: {out_tensor}')\n",
    "            # END SplitManager execute split_layer\n",
    "\n",
    "            print(f'\\t\\t Output tensor shape : {out_tensor.shape}')\n",
    "\n",
    "            # debug\n",
    "            nonzero_out_tensor = torch.unique(torch.nonzero(out_tensor, as_tuple=True)[1])\n",
    "\n",
    "            # look at which C_out need to be computed and sent\n",
    "            #nonzero_Cout = torch.unique(torch.nonzero(split_layer.weight, as_tuple=True)[0]) # find nonzero dimensions in output channels\n",
    "            nonzero_Cout = get_nonzero_channels(out_tensor)\n",
    "            # print(f'\\t\\t\\t nonzero_Cout: {nonzero_Cout}')\n",
    "\n",
    "            # prep communications by populating output\n",
    "            out_channel_array = torch.arange(out_tensor.shape[1])\n",
    "            for rx_mach in range(num_machines):\n",
    "                # only add to output if communication is necessary \n",
    "\n",
    "                # Get output channels for current rx machine? TODO: consider removing, this just maps C_out's to machine\n",
    "                #output_channels = torch.tensor(configs['partition'][][rx_mach],\n",
    "                #        device=torch.device(configs['device']))\n",
    "                output_channels = torch.tensor(split_managers[imach].output_channel_map[rx_mach],\n",
    "                        device=torch.device(configs['device']))\n",
    "                \n",
    "                # print(f'\\t\\t\\t output_channels: {output_channels}')\n",
    "\n",
    "                # TODO: is there a faster way to do this? Consider putting larger array 1st... just not sure which one that'd be\n",
    "                nonzero_out_channels = nonzero_Cout[torch.isin(nonzero_Cout, output_channels)]\n",
    "                if nonzero_out_channels.nelement() > 0:\n",
    "                        communication_mask = torch.isin(out_channel_array, nonzero_out_channels)\n",
    "\n",
    "                        # TODO: this is inefficient, redo. Probbably need to send a tensor and some info what output channels are being sent\n",
    "                        tmp_out = torch.zeros(out_tensor.shape, dtype= split_managers[imach].dtype) \n",
    "                        if imodule == total_layers_fx-1 or 'linear' in layer_names_fx[imodule]:\n",
    "                                tmp_out[:,communication_mask] = out_tensor[:,communication_mask]\n",
    "                        else:\n",
    "                                tmp_out[:,communication_mask,:,:] = out_tensor[:,communication_mask,:,:]\n",
    "                        output[rx_mach][imach] = tmp_out\n",
    "\n",
    "                        # debug\n",
    "                        print(f'\\t\\t sending C_out {nonzero_out_channels} to machine {rx_mach}')\n",
    "\n",
    "        # send to next layer  \n",
    "        input = output\n",
    "        print(f'Finished execution of layer {imodule}')\n",
    "\n",
    "        # update timing\n",
    "        layer_completion_time_stamp[layer_names_fx[imodule]] = time.time()\n",
    "        if imodule > 0:\n",
    "            layer_execution_duration[layer_names_fx[imodule]] = layer_completion_time_stamp[layer_names_fx[imodule]] - layer_completion_time_stamp[layer_names_fx[imodule-1]] \n",
    "        else:\n",
    "            layer_execution_duration[layer_names_fx[imodule]] = layer_completion_time_stamp[layer_names_fx[imodule]] - split_execution_start_time\n",
    "\n",
    "        # check output at end of each layer to see if fit matches \n",
    "        tmp_output = input \n",
    "        # print(f'tmp_output = {tmp_output}')\n",
    "        need_to_init  = True\n",
    "        for rx_mach in range(num_machines):\n",
    "                for tx_mach in range(num_machines):\n",
    "                        if not tmp_output[rx_mach][tx_mach] == None:\n",
    "                                if need_to_init:\n",
    "                                        vert_output = tmp_output[rx_mach][tx_mach]\n",
    "                                        need_to_init = False\n",
    "                                else:\n",
    "                                        # TODO: += causes assignment issues, switched to x = x+y which might be more more inefficent memory wise ... \n",
    "                                        vert_output = vert_output + tmp_output[rx_mach][tx_mach] \n",
    "                                        #nz_channels = get_nonzero_channels(vert_output)\n",
    "                                        #print(f'({rx_mach},{tx_mach}) {nz_channels}')\n",
    "        \n",
    "        if imodule == total_layers_fx-1:\n",
    "            # apply bias\n",
    "            # TODO: assumes Linear layer is final layer and bias can be handled as final step \n",
    "            vert_output = vert_output + get_current_module(model, imodule).bias\n",
    "            \n",
    "            # final execution time\n",
    "            tot_split_execution_time = time.time() - split_execution_start_time\n",
    "            print(f'\\n\\n############################# FINAL EXECUTION TIME {tot_split_execution_time} [seconds] #############################\\n\\n')\n",
    "\n",
    "        truth_output = horz_output[layer_names_fx[imodule]]\n",
    "        # if 'x' == layer_names_fx[imodule] or '_x' == layer_names_fx[imodule] or 'getitem' == layer_names_fx[imodule] or 'getitem_1' == layer_names_fx[imodule] or 'getitem_2' == layer_names_fx[imodule] or 'getitem_3' == layer_names_fx[imodule] or 'getitem_4' == layer_names_fx[imodule] or 'cat' == layer_names_fx[imodule]:\n",
    "        if 'x' == layer_names_fx[imodule]:    \n",
    "            print(f'Input layer. Skipping comparison')\n",
    "        elif torch.is_tensor(truth_output):\n",
    "            max_diff, max_by_Cout = compare_outputs(vert_output, truth_output)\n",
    "            if max_diff > 0.1:\n",
    "                # pass\n",
    "                BREAK_LOOP = 1 \n",
    "        else:\n",
    "            print(f'Horizontal output is {type(truth_output)}. Skipping comparison')\n",
    "        print()\n",
    "\n",
    "        if BREAK_LOOP:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Conv1 layer test -- should we expect some difference, or exactly 0 in the output when we split the model?\n",
    "# '''\n",
    "\n",
    "# # DIFFERENCE SHOULD BE 0 NOT 1E-7\n",
    "\n",
    "# N_in = 1\n",
    "# split_1 = nn.Conv2d(N_in,\n",
    "#             model.conv1.weight.shape[0], # TODO does this need to be an int? (currently tensor)\n",
    "#             kernel_size= model.conv1.kernel_size,\n",
    "#             stride=model.conv1.stride,\n",
    "#             padding=model.conv1.padding, \n",
    "#             bias=False) # TODO: add bias during input collecting step on next layer \n",
    "# split_1.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([0])))  \n",
    "# out_split1 = split_1(input_tensor.index_select(1, torch.tensor([0])))\n",
    "\n",
    "# split_2 = split_1\n",
    "# split_2.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([1])))  \n",
    "# out_split2 = split_2(input_tensor.index_select(1, torch.tensor([1])))\n",
    "\n",
    "# split_3 = split_1\n",
    "# split_3.weight = torch.nn.Parameter(model.conv1.weight.index_select(1, torch.tensor([2])))  \n",
    "# out_split3 = split_3(input_tensor.index_select(1, torch.tensor([2])))\n",
    "\n",
    "# split_out = torch.add(torch.add(out_split1, out_split2), out_split3)\n",
    "# full_out = model.conv1(input_tensor)\n",
    "\n",
    "# diff_output = torch.abs(full_out - split_out)\n",
    "# max_diff = torch.max(diff_output)\n",
    "# max_diff.sci_mode = True\n",
    "# print(max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''  \n",
    "#     Inspect I/O of single layer\n",
    "# '''\n",
    "\n",
    "# t = torch.ones((1,2,2,2), dtype=torch.float32) # (batch, in channel, H, W)\n",
    "# w = torch.ones((1,2,2,2), dtype=torch.float32) # (out channels, in channels, H, W)\n",
    "# w[0,0,0,0] = 1e-10\n",
    "# w[0,0,0,1] = 1e-10\n",
    "# w[0,1,0,0] = 1e-10\n",
    "\n",
    "# full_conv = torch.nn.Conv2d(2,1,kernel_size=(2,2), bias=False, stride=(1),dtype=torch.float32)\n",
    "# full_conv.weight = torch.nn.Parameter(w)\n",
    "# conv1 = torch.nn.Conv2d(1,1,kernel_size=(2,2), bias=False, stride=1, dtype=torch.float32)\n",
    "# conv1.weight =torch.nn.Parameter( w[:,0:1,:,:])\n",
    "# conv2 = torch.nn.Conv2d(1,1,kernel_size=(2,2), bias=False, stride=1,dtype=torch.float32)\n",
    "# conv2.weight = torch.nn.Parameter(w[:,1:2,:,:])\n",
    "\n",
    "# full_conv.eval()\n",
    "# conv1.eval()\n",
    "# conv2.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     full_out = full_conv(t)\n",
    "#     split_out =  conv2(t[0,1:2,:,:]) + conv1(t[:,0:1,:,:])\n",
    "\n",
    "# diff = torch.abs(full_out - split_out)\n",
    "\n",
    "# torch.nonzero(diff)\n",
    "# #print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test bn1\n",
    "#estimate = -bn1.running_mean[1]/torch.sqrt(bn1.running_var[1] + bn1.eps)*bn1.weight[1] + bn1.bias[1]\n",
    "#estimate_split = -split_layer.running_mean[1]/torch.sqrt(split_layer.running_var[1] + split_layer.eps)*split_layer.weight[1] + split_layer.bias[1]\n",
    "\n",
    "# running estimates are different \n",
    "#bn1.running_mean[1] - split_layer.running_mean[1]\n",
    "#bn1.running_var[1] - split_layer.running_var[1] \n",
    "#bn1.weight[1] - split_layer.weight[1]\n",
    "#bn1.eps - split_layer.eps\n",
    "#bn1.bias[1] - split_layer.bias[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
